{
  "best_metric": 0.9375,
  "best_model_checkpoint": "src/../outputs/T5_LM_3B/T0Mixture/weighted_batch_exp3/42/copa/cosine/1.0/16/0.0001/10/10/checkpoint-700",
  "epoch": 0.00021793614470960008,
  "global_step": 1700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 33.632965087890625,
        "ag_news": 39.66808319091797,
        "amazon_polarity": 35.1775016784668,
        "cnn_dailymail/3.0.0": -55.81035614013672,
        "common_gen": 27.9975528717041,
        "cos_e/v1.11": 29.496400833129883,
        "glue/mrpc": 29.46228790283203,
        "kilt_tasks/hotpotqa": 33.43335723876953
      },
      "epoch": 0.0,
      "learning_rate": 1e-05,
      "loss": 4.9254,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13745130598545074,
        "ag_news": 0.14858488738536835,
        "amazon_polarity": 0.14021018147468567,
        "cnn_dailymail/3.0.0": 0.04811723530292511,
        "common_gen": 0.12788468599319458,
        "cos_e/v1.11": 0.1303546279668808,
        "glue/mrpc": 0.13029782474040985,
        "kilt_tasks/hotpotqa": 0.13709917664527893
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 184,
        "ag_news": 144,
        "amazon_polarity": 152,
        "cnn_dailymail/3.0.0": 88,
        "common_gen": 224,
        "cos_e/v1.11": 152,
        "glue/mrpc": 184,
        "kilt_tasks/hotpotqa": 152
      },
      "step": 10
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 63.737548828125,
        "ag_news": 71.5411605834961,
        "amazon_polarity": 69.285888671875,
        "cnn_dailymail/3.0.0": -293.2812805175781,
        "common_gen": 54.31155014038086,
        "cos_e/v1.11": 63.17757034301758,
        "glue/mrpc": 66.0340805053711,
        "kilt_tasks/hotpotqa": 71.50471496582031
      },
      "epoch": 0.0,
      "learning_rate": 2e-05,
      "loss": 4.4276,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13835662603378296,
        "ag_news": 0.14829033613204956,
        "amazon_polarity": 0.14534342288970947,
        "cnn_dailymail/3.0.0": 0.013592423871159554,
        "common_gen": 0.1272992640733719,
        "cos_e/v1.11": 0.13767170906066895,
        "glue/mrpc": 0.14120395481586456,
        "kilt_tasks/hotpotqa": 0.14824222028255463
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 344,
        "ag_news": 264,
        "amazon_polarity": 280,
        "cnn_dailymail/3.0.0": 248,
        "common_gen": 416,
        "cos_e/v1.11": 328,
        "glue/mrpc": 392,
        "kilt_tasks/hotpotqa": 288
      },
      "step": 20
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 88.62931060791016,
        "ag_news": 94.49099731445312,
        "amazon_polarity": 93.99617004394531,
        "cnn_dailymail/3.0.0": -462.5594177246094,
        "common_gen": 57.021942138671875,
        "cos_e/v1.11": 78.64698028564453,
        "glue/mrpc": 80.285888671875,
        "kilt_tasks/hotpotqa": 96.41429138183594
      },
      "epoch": 0.0,
      "learning_rate": 3e-05,
      "loss": 3.2447,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.14543861150741577,
        "ag_news": 0.1517370045185089,
        "amazon_polarity": 0.15119439363479614,
        "cnn_dailymail/3.0.0": 0.009556684643030167,
        "common_gen": 0.11592377722263336,
        "cos_e/v1.11": 0.13533900678157806,
        "glue/mrpc": 0.13694491982460022,
        "kilt_tasks/hotpotqa": 0.15386565029621124
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 504,
        "ag_news": 480,
        "amazon_polarity": 488,
        "cnn_dailymail/3.0.0": 336,
        "common_gen": 576,
        "cos_e/v1.11": 456,
        "glue/mrpc": 560,
        "kilt_tasks/hotpotqa": 440
      },
      "step": 30
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 68.01358795166016,
        "ag_news": 85.61261749267578,
        "amazon_polarity": 88.01836395263672,
        "cnn_dailymail/3.0.0": -310.5455017089844,
        "common_gen": 33.97068405151367,
        "cos_e/v1.11": 66.89927673339844,
        "glue/mrpc": 67.87200164794922,
        "kilt_tasks/hotpotqa": 81.54556274414062
      },
      "epoch": 0.0,
      "learning_rate": 4e-05,
      "loss": 2.129,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1376141756772995,
        "ag_news": 0.15360820293426514,
        "amazon_polarity": 0.15594105422496796,
        "cnn_dailymail/3.0.0": 0.017492497339844704,
        "common_gen": 0.1114422157406807,
        "cos_e/v1.11": 0.13666211068630219,
        "glue/mrpc": 0.137492835521698,
        "kilt_tasks/hotpotqa": 0.14974689483642578
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 656,
        "ag_news": 680,
        "amazon_polarity": 632,
        "cnn_dailymail/3.0.0": 480,
        "common_gen": 712,
        "cos_e/v1.11": 608,
        "glue/mrpc": 744,
        "kilt_tasks/hotpotqa": 608
      },
      "step": 40
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 60.88144302368164,
        "ag_news": 83.19283294677734,
        "amazon_polarity": 85.33065032958984,
        "cnn_dailymail/3.0.0": -211.18048095703125,
        "common_gen": 23.347736358642578,
        "cos_e/v1.11": 68.19924926757812,
        "glue/mrpc": 65.32134246826172,
        "kilt_tasks/hotpotqa": 71.2109603881836
      },
      "epoch": 0.0,
      "learning_rate": 5e-05,
      "loss": 1.663,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13410818576812744,
        "ag_news": 0.1518964171409607,
        "amazon_polarity": 0.15372517704963684,
        "cnn_dailymail/3.0.0": 0.03212444484233856,
        "common_gen": 0.10893209278583527,
        "cos_e/v1.11": 0.13969001173973083,
        "glue/mrpc": 0.1374664306640625,
        "kilt_tasks/hotpotqa": 0.1420571655035019
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 776,
        "ag_news": 864,
        "amazon_polarity": 896,
        "cnn_dailymail/3.0.0": 568,
        "common_gen": 800,
        "cos_e/v1.11": 792,
        "glue/mrpc": 904,
        "kilt_tasks/hotpotqa": 800
      },
      "step": 50
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 51.58101272583008,
        "ag_news": 82.47109985351562,
        "amazon_polarity": 84.58390045166016,
        "cnn_dailymail/3.0.0": -153.78909301757812,
        "common_gen": 13.477842330932617,
        "cos_e/v1.11": 64.09000396728516,
        "glue/mrpc": 61.572750091552734,
        "kilt_tasks/hotpotqa": 65.75248718261719
      },
      "epoch": 0.0,
      "learning_rate": 6e-05,
      "loss": 1.6201,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12928368151187897,
        "ag_news": 0.151311993598938,
        "amazon_polarity": 0.1529543548822403,
        "cnn_dailymail/3.0.0": 0.04708196595311165,
        "common_gen": 0.1066325381398201,
        "cos_e/v1.11": 0.13777269423007965,
        "glue/mrpc": 0.13601894676685333,
        "kilt_tasks/hotpotqa": 0.13894380629062653
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 952,
        "ag_news": 1024,
        "amazon_polarity": 1096,
        "cnn_dailymail/3.0.0": 752,
        "common_gen": 912,
        "cos_e/v1.11": 920,
        "glue/mrpc": 1032,
        "kilt_tasks/hotpotqa": 992
      },
      "step": 60
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 39.22245407104492,
        "ag_news": 81.97338104248047,
        "amazon_polarity": 84.50843048095703,
        "cnn_dailymail/3.0.0": -122.41720581054688,
        "common_gen": 7.108727931976318,
        "cos_e/v1.11": 62.786678314208984,
        "glue/mrpc": 61.87561798095703,
        "kilt_tasks/hotpotqa": 58.36736297607422
      },
      "epoch": 0.0,
      "learning_rate": 7e-05,
      "loss": 1.5366,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12313792109489441,
        "ag_news": 0.15062540769577026,
        "amazon_polarity": 0.1524427980184555,
        "cnn_dailymail/3.0.0": 0.05853402614593506,
        "common_gen": 0.10595566034317017,
        "cos_e/v1.11": 0.13757666945457458,
        "glue/mrpc": 0.13698697090148926,
        "kilt_tasks/hotpotqa": 0.13474057614803314
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1136,
        "ag_news": 1256,
        "amazon_polarity": 1248,
        "cnn_dailymail/3.0.0": 872,
        "common_gen": 1064,
        "cos_e/v1.11": 1056,
        "glue/mrpc": 1136,
        "kilt_tasks/hotpotqa": 1192
      },
      "step": 70
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 26.086606979370117,
        "ag_news": 81.23814392089844,
        "amazon_polarity": 83.96240234375,
        "cnn_dailymail/3.0.0": -91.60405731201172,
        "common_gen": 2.4802751541137695,
        "cos_e/v1.11": 65.8116226196289,
        "glue/mrpc": 63.46887969970703,
        "kilt_tasks/hotpotqa": 54.005252838134766
      },
      "epoch": 0.0,
      "learning_rate": 8e-05,
      "loss": 1.487,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1167069748044014,
        "ag_news": 0.148810014128685,
        "amazon_polarity": 0.1506148874759674,
        "cnn_dailymail/3.0.0": 0.07009346038103104,
        "common_gen": 0.10525091737508774,
        "cos_e/v1.11": 0.13900232315063477,
        "glue/mrpc": 0.13757236301898956,
        "kilt_tasks/hotpotqa": 0.1319490522146225
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1304,
        "ag_news": 1440,
        "amazon_polarity": 1392,
        "cnn_dailymail/3.0.0": 1000,
        "common_gen": 1200,
        "cos_e/v1.11": 1272,
        "glue/mrpc": 1272,
        "kilt_tasks/hotpotqa": 1360
      },
      "step": 80
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 22.492950439453125,
        "ag_news": 81.01802062988281,
        "amazon_polarity": 83.4511947631836,
        "cnn_dailymail/3.0.0": -78.7264175415039,
        "common_gen": 5.167067527770996,
        "cos_e/v1.11": 66.2235107421875,
        "glue/mrpc": 62.34408187866211,
        "kilt_tasks/hotpotqa": 50.849063873291016
      },
      "epoch": 0.0,
      "learning_rate": 9e-05,
      "loss": 1.434,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11549200862646103,
        "ag_news": 0.14728862047195435,
        "amazon_polarity": 0.14879156649112701,
        "cnn_dailymail/3.0.0": 0.07626910507678986,
        "common_gen": 0.10751345008611679,
        "cos_e/v1.11": 0.13848081231117249,
        "glue/mrpc": 0.13626237213611603,
        "kilt_tasks/hotpotqa": 0.12990200519561768
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1488,
        "ag_news": 1616,
        "amazon_polarity": 1504,
        "cnn_dailymail/3.0.0": 1144,
        "common_gen": 1376,
        "cos_e/v1.11": 1424,
        "glue/mrpc": 1464,
        "kilt_tasks/hotpotqa": 1504
      },
      "step": 90
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 14.221304893493652,
        "ag_news": 80.72443389892578,
        "amazon_polarity": 83.0629653930664,
        "cnn_dailymail/3.0.0": -61.591400146484375,
        "common_gen": 5.038914203643799,
        "cos_e/v1.11": 65.22512817382812,
        "glue/mrpc": 61.86709213256836,
        "kilt_tasks/hotpotqa": 50.699398040771484
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2767,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11231699585914612,
        "ag_news": 0.14598341286182404,
        "amazon_polarity": 0.14734120666980743,
        "cnn_dailymail/3.0.0": 0.08356459438800812,
        "common_gen": 0.1083441823720932,
        "cos_e/v1.11": 0.13730370998382568,
        "glue/mrpc": 0.13549429178237915,
        "kilt_tasks/hotpotqa": 0.12965165078639984
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1648,
        "ag_news": 1760,
        "amazon_polarity": 1760,
        "cnn_dailymail/3.0.0": 1336,
        "common_gen": 1480,
        "cos_e/v1.11": 1576,
        "glue/mrpc": 1632,
        "kilt_tasks/hotpotqa": 1608
      },
      "step": 100
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.2797,
      "eval_samples_per_second": 57.201,
      "eval_steps_per_second": 3.575,
      "step": 100
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 4.353754043579102,
        "ag_news": 80.13208770751953,
        "amazon_polarity": 82.86847686767578,
        "cnn_dailymail/3.0.0": -32.12915802001953,
        "common_gen": 3.3090262413024902,
        "cos_e/v1.11": 63.46406555175781,
        "glue/mrpc": 61.1400146484375,
        "kilt_tasks/hotpotqa": 48.46274948120117
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4059,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10860475897789001,
        "ag_news": 0.14438961446285248,
        "amazon_polarity": 0.14588893949985504,
        "cnn_dailymail/3.0.0": 0.09478498995304108,
        "common_gen": 0.10818123817443848,
        "cos_e/v1.11": 0.13559266924858093,
        "glue/mrpc": 0.13441064953804016,
        "kilt_tasks/hotpotqa": 0.1281471699476242
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1768,
        "ag_news": 1904,
        "amazon_polarity": 1944,
        "cnn_dailymail/3.0.0": 1592,
        "common_gen": 1584,
        "cos_e/v1.11": 1728,
        "glue/mrpc": 1816,
        "kilt_tasks/hotpotqa": 1744
      },
      "step": 110
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -3.4221925735473633,
        "ag_news": 80.01529693603516,
        "amazon_polarity": 82.55366516113281,
        "cnn_dailymail/3.0.0": -30.291080474853516,
        "common_gen": 2.1339144706726074,
        "cos_e/v1.11": 64.17227172851562,
        "glue/mrpc": 58.27168655395508,
        "kilt_tasks/hotpotqa": 44.12070083618164
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3147,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10693604499101639,
        "ag_news": 0.14439785480499268,
        "amazon_polarity": 0.14572928845882416,
        "cnn_dailymail/3.0.0": 0.09714000672101974,
        "common_gen": 0.10908648371696472,
        "cos_e/v1.11": 0.13636526465415955,
        "glue/mrpc": 0.13349223136901855,
        "kilt_tasks/hotpotqa": 0.12685300409793854
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1944,
        "ag_news": 2000,
        "amazon_polarity": 2208,
        "cnn_dailymail/3.0.0": 1752,
        "common_gen": 1736,
        "cos_e/v1.11": 1832,
        "glue/mrpc": 1960,
        "kilt_tasks/hotpotqa": 1928
      },
      "step": 120
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -12.623109817504883,
        "ag_news": 79.2962875366211,
        "amazon_polarity": 82.40319061279297,
        "cnn_dailymail/3.0.0": -11.561060905456543,
        "common_gen": 2.6655495166778564,
        "cos_e/v1.11": 65.23845672607422,
        "glue/mrpc": 55.20278549194336,
        "kilt_tasks/hotpotqa": 42.7874870300293
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3733,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1041158139705658,
        "ag_news": 0.1430796980857849,
        "amazon_polarity": 0.14463265240192413,
        "cnn_dailymail/3.0.0": 0.1044970378279686,
        "common_gen": 0.10974518954753876,
        "cos_e/v1.11": 0.13626395165920258,
        "glue/mrpc": 0.1316029578447342,
        "kilt_tasks/hotpotqa": 0.12606263160705566
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2072,
        "ag_news": 2224,
        "amazon_polarity": 2336,
        "cnn_dailymail/3.0.0": 1888,
        "common_gen": 1944,
        "cos_e/v1.11": 1992,
        "glue/mrpc": 2096,
        "kilt_tasks/hotpotqa": 2088
      },
      "step": 130
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -14.381668090820312,
        "ag_news": 79.0434341430664,
        "amazon_polarity": 82.32029724121094,
        "cnn_dailymail/3.0.0": -5.309714317321777,
        "common_gen": 4.520876407623291,
        "cos_e/v1.11": 61.41767883300781,
        "glue/mrpc": 55.43391799926758,
        "kilt_tasks/hotpotqa": 38.05088806152344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3966,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10437143594026566,
        "ag_news": 0.14251866936683655,
        "amazon_polarity": 0.1440913826227188,
        "cnn_dailymail/3.0.0": 0.1075630784034729,
        "common_gen": 0.11113564670085907,
        "cos_e/v1.11": 0.1343560814857483,
        "glue/mrpc": 0.13169531524181366,
        "kilt_tasks/hotpotqa": 0.12426843494176865
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2264,
        "ag_news": 2320,
        "amazon_polarity": 2488,
        "cnn_dailymail/3.0.0": 2040,
        "common_gen": 2136,
        "cos_e/v1.11": 2160,
        "glue/mrpc": 2280,
        "kilt_tasks/hotpotqa": 2232
      },
      "step": 140
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -18.12337303161621,
        "ag_news": 79.02037048339844,
        "amazon_polarity": 82.08282470703125,
        "cnn_dailymail/3.0.0": 4.670101165771484,
        "common_gen": 6.6259765625,
        "cos_e/v1.11": 61.66244888305664,
        "glue/mrpc": 51.46086502075195,
        "kilt_tasks/hotpotqa": 34.398746490478516
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4146,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10378335416316986,
        "ag_news": 0.14193286001682281,
        "amazon_polarity": 0.14334657788276672,
        "cnn_dailymail/3.0.0": 0.11166515946388245,
        "common_gen": 0.11236963421106339,
        "cos_e/v1.11": 0.13418541848659515,
        "glue/mrpc": 0.12983568012714386,
        "kilt_tasks/hotpotqa": 0.12288142740726471
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2408,
        "ag_news": 2504,
        "amazon_polarity": 2640,
        "cnn_dailymail/3.0.0": 2208,
        "common_gen": 2304,
        "cos_e/v1.11": 2320,
        "glue/mrpc": 2408,
        "kilt_tasks/hotpotqa": 2408
      },
      "step": 150
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -22.700389862060547,
        "ag_news": 78.55834197998047,
        "amazon_polarity": 81.9554672241211,
        "cnn_dailymail/3.0.0": 16.050785064697266,
        "common_gen": 9.908082962036133,
        "cos_e/v1.11": 58.43836212158203,
        "glue/mrpc": 49.79811096191406,
        "kilt_tasks/hotpotqa": 35.60700988769531
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.397,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10273643583059311,
        "ag_news": 0.14091962575912476,
        "amazon_polarity": 0.14242802560329437,
        "cnn_dailymail/3.0.0": 0.11590611934661865,
        "common_gen": 0.11370783299207687,
        "cos_e/v1.11": 0.132314994931221,
        "glue/mrpc": 0.1287868767976761,
        "kilt_tasks/hotpotqa": 0.12320010364055634
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2584,
        "ag_news": 2648,
        "amazon_polarity": 2824,
        "cnn_dailymail/3.0.0": 2368,
        "common_gen": 2472,
        "cos_e/v1.11": 2472,
        "glue/mrpc": 2528,
        "kilt_tasks/hotpotqa": 2584
      },
      "step": 160
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -30.58123779296875,
        "ag_news": 78.50477600097656,
        "amazon_polarity": 81.63961791992188,
        "cnn_dailymail/3.0.0": 29.08713150024414,
        "common_gen": 7.736635684967041,
        "cos_e/v1.11": 58.58161926269531,
        "glue/mrpc": 46.03070068359375,
        "kilt_tasks/hotpotqa": 30.9982967376709
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3583,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10109608620405197,
        "ag_news": 0.14067111909389496,
        "amazon_polarity": 0.14201875030994415,
        "cnn_dailymail/3.0.0": 0.12107492238283157,
        "common_gen": 0.11349673569202423,
        "cos_e/v1.11": 0.1324068307876587,
        "glue/mrpc": 0.127457395195961,
        "kilt_tasks/hotpotqa": 0.12177813053131104
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2744,
        "ag_news": 2872,
        "amazon_polarity": 2920,
        "cnn_dailymail/3.0.0": 2512,
        "common_gen": 2640,
        "cos_e/v1.11": 2592,
        "glue/mrpc": 2688,
        "kilt_tasks/hotpotqa": 2792
      },
      "step": 170
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -31.930908203125,
        "ag_news": 78.4141845703125,
        "amazon_polarity": 81.52717590332031,
        "cnn_dailymail/3.0.0": 34.82080078125,
        "common_gen": 5.231627464294434,
        "cos_e/v1.11": 56.875980377197266,
        "glue/mrpc": 45.75034713745117,
        "kilt_tasks/hotpotqa": 27.497438430786133
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3142,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10143335908651352,
        "ag_news": 0.14037248492240906,
        "amazon_polarity": 0.141670361161232,
        "cnn_dailymail/3.0.0": 0.12342333048582077,
        "common_gen": 0.11312699317932129,
        "cos_e/v1.11": 0.1317194700241089,
        "glue/mrpc": 0.12746544182300568,
        "kilt_tasks/hotpotqa": 0.12078864872455597
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2872,
        "ag_news": 3032,
        "amazon_polarity": 3104,
        "cnn_dailymail/3.0.0": 2624,
        "common_gen": 2856,
        "cos_e/v1.11": 2752,
        "glue/mrpc": 2824,
        "kilt_tasks/hotpotqa": 2976
      },
      "step": 180
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -36.75227737426758,
        "ag_news": 78.66564178466797,
        "amazon_polarity": 80.64375305175781,
        "cnn_dailymail/3.0.0": 48.10986328125,
        "common_gen": 6.04250431060791,
        "cos_e/v1.11": 56.03715133666992,
        "glue/mrpc": 46.22726058959961,
        "kilt_tasks/hotpotqa": 19.86432456970215
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4007,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10054393857717514,
        "ag_news": 0.1399727463722229,
        "amazon_polarity": 0.14077194035053253,
        "cnn_dailymail/3.0.0": 0.12820027768611908,
        "common_gen": 0.11362912505865097,
        "cos_e/v1.11": 0.1311536431312561,
        "glue/mrpc": 0.1275089532136917,
        "kilt_tasks/hotpotqa": 0.11821939796209335
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2968,
        "ag_news": 3232,
        "amazon_polarity": 3248,
        "cnn_dailymail/3.0.0": 2784,
        "common_gen": 3040,
        "cos_e/v1.11": 2920,
        "glue/mrpc": 2960,
        "kilt_tasks/hotpotqa": 3168
      },
      "step": 190
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -41.43239212036133,
        "ag_news": 78.53728485107422,
        "amazon_polarity": 80.76885223388672,
        "cnn_dailymail/3.0.0": 59.12762451171875,
        "common_gen": 7.273725509643555,
        "cos_e/v1.11": 57.6692008972168,
        "glue/mrpc": 46.447269439697266,
        "kilt_tasks/hotpotqa": 13.260706901550293
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.5467,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09963474422693253,
        "ag_news": 0.13932006061077118,
        "amazon_polarity": 0.14019513130187988,
        "cnn_dailymail/3.0.0": 0.13194024562835693,
        "common_gen": 0.11412359774112701,
        "cos_e/v1.11": 0.1314021348953247,
        "glue/mrpc": 0.12733592092990875,
        "kilt_tasks/hotpotqa": 0.11604815721511841
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3104,
        "ag_news": 3352,
        "amazon_polarity": 3360,
        "cnn_dailymail/3.0.0": 3000,
        "common_gen": 3216,
        "cos_e/v1.11": 3120,
        "glue/mrpc": 3088,
        "kilt_tasks/hotpotqa": 3360
      },
      "step": 200
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.2853,
      "eval_samples_per_second": 56.075,
      "eval_steps_per_second": 3.505,
      "step": 200
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.18281555175781,
        "ag_news": 78.373291015625,
        "amazon_polarity": 80.31854248046875,
        "cnn_dailymail/3.0.0": 64.12262725830078,
        "common_gen": 5.072734355926514,
        "cos_e/v1.11": 53.2293586730957,
        "glue/mrpc": 46.4198112487793,
        "kilt_tasks/hotpotqa": 14.01833438873291
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4234,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09955756366252899,
        "ag_news": 0.13908497989177704,
        "amazon_polarity": 0.1398279368877411,
        "cnn_dailymail/3.0.0": 0.13376349210739136,
        "common_gen": 0.11383853852748871,
        "cos_e/v1.11": 0.1298362910747528,
        "glue/mrpc": 0.12744136154651642,
        "kilt_tasks/hotpotqa": 0.1166497990489006
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3248,
        "ag_news": 3488,
        "amazon_polarity": 3536,
        "cnn_dailymail/3.0.0": 3144,
        "common_gen": 3416,
        "cos_e/v1.11": 3264,
        "glue/mrpc": 3192,
        "kilt_tasks/hotpotqa": 3592
      },
      "step": 210
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -47.48445510864258,
        "ag_news": 78.38629150390625,
        "amazon_polarity": 80.27300262451172,
        "cnn_dailymail/3.0.0": 69.477294921875,
        "common_gen": 2.1938586235046387,
        "cos_e/v1.11": 53.45970916748047,
        "glue/mrpc": 46.27290725708008,
        "kilt_tasks/hotpotqa": 14.880465507507324
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3788,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09916330128908157,
        "ag_news": 0.13870558142662048,
        "amazon_polarity": 0.13940772414207458,
        "cnn_dailymail/3.0.0": 0.13543838262557983,
        "common_gen": 0.11317005008459091,
        "cos_e/v1.11": 0.12976045906543732,
        "glue/mrpc": 0.1272924542427063,
        "kilt_tasks/hotpotqa": 0.117062047123909
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3392,
        "ag_news": 3632,
        "amazon_polarity": 3656,
        "cnn_dailymail/3.0.0": 3352,
        "common_gen": 3528,
        "cos_e/v1.11": 3464,
        "glue/mrpc": 3392,
        "kilt_tasks/hotpotqa": 3744
      },
      "step": 220
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.096778869628906,
        "ag_news": 78.39693450927734,
        "amazon_polarity": 80.1682357788086,
        "cnn_dailymail/3.0.0": 72.09626007080078,
        "common_gen": 3.254804849624634,
        "cos_e/v1.11": 54.750694274902344,
        "glue/mrpc": 46.550254821777344,
        "kilt_tasks/hotpotqa": 12.936355590820312
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2974,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1003512293100357,
        "ag_news": 0.13813301920890808,
        "amazon_polarity": 0.1387750655412674,
        "cnn_dailymail/3.0.0": 0.1358737051486969,
        "common_gen": 0.11351271718740463,
        "cos_e/v1.11": 0.12984664738178253,
        "glue/mrpc": 0.12709294259548187,
        "kilt_tasks/hotpotqa": 0.11641471087932587
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3560,
        "ag_news": 3712,
        "amazon_polarity": 3816,
        "cnn_dailymail/3.0.0": 3528,
        "common_gen": 3664,
        "cos_e/v1.11": 3624,
        "glue/mrpc": 3664,
        "kilt_tasks/hotpotqa": 3872
      },
      "step": 230
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -40.45112991333008,
        "ag_news": 78.40203094482422,
        "amazon_polarity": 80.11674499511719,
        "cnn_dailymail/3.0.0": 80.006591796875,
        "common_gen": 1.7763893604278564,
        "cos_e/v1.11": 54.100921630859375,
        "glue/mrpc": 45.56475067138672,
        "kilt_tasks/hotpotqa": 12.745841026306152
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4425,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10148867964744568,
        "ag_news": 0.13749438524246216,
        "amazon_polarity": 0.13809999823570251,
        "cnn_dailymail/3.0.0": 0.1380610167980194,
        "common_gen": 0.11302218586206436,
        "cos_e/v1.11": 0.1291966736316681,
        "glue/mrpc": 0.1264047622680664,
        "kilt_tasks/hotpotqa": 0.11623232811689377
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3696,
        "ag_news": 3864,
        "amazon_polarity": 3944,
        "cnn_dailymail/3.0.0": 3736,
        "common_gen": 3840,
        "cos_e/v1.11": 3744,
        "glue/mrpc": 3756,
        "kilt_tasks/hotpotqa": 4136
      },
      "step": 240
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -39.24388885498047,
        "ag_news": 78.15015411376953,
        "amazon_polarity": 79.89286804199219,
        "cnn_dailymail/3.0.0": 84.0689468383789,
        "common_gen": 1.5794923305511475,
        "cos_e/v1.11": 58.5871467590332,
        "glue/mrpc": 47.74970245361328,
        "kilt_tasks/hotpotqa": 17.419235229492188
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3409,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10171875357627869,
        "ag_news": 0.13647359609603882,
        "amazon_polarity": 0.13707225024700165,
        "cnn_dailymail/3.0.0": 0.13851772248744965,
        "common_gen": 0.1126403957605362,
        "cos_e/v1.11": 0.1299334317445755,
        "glue/mrpc": 0.1264488250017166,
        "kilt_tasks/hotpotqa": 0.1171950101852417
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3840,
        "ag_news": 4024,
        "amazon_polarity": 4096,
        "cnn_dailymail/3.0.0": 3896,
        "common_gen": 4008,
        "cos_e/v1.11": 3888,
        "glue/mrpc": 3916,
        "kilt_tasks/hotpotqa": 4328
      },
      "step": 250
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -40.02444076538086,
        "ag_news": 78.10336303710938,
        "amazon_polarity": 79.9438705444336,
        "cnn_dailymail/3.0.0": 86.95122528076172,
        "common_gen": 5.948957443237305,
        "cos_e/v1.11": 55.89684295654297,
        "glue/mrpc": 46.96299362182617,
        "kilt_tasks/hotpotqa": 14.655218124389648
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3257,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10192324221134186,
        "ag_news": 0.13622601330280304,
        "amazon_polarity": 0.13684502243995667,
        "cnn_dailymail/3.0.0": 0.13922810554504395,
        "common_gen": 0.114080049097538,
        "cos_e/v1.11": 0.12897847592830658,
        "glue/mrpc": 0.12617476284503937,
        "kilt_tasks/hotpotqa": 0.11654442548751831
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3936,
        "ag_news": 4208,
        "amazon_polarity": 4232,
        "cnn_dailymail/3.0.0": 4040,
        "common_gen": 4176,
        "cos_e/v1.11": 4088,
        "glue/mrpc": 4068,
        "kilt_tasks/hotpotqa": 4528
      },
      "step": 260
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -40.22698974609375,
        "ag_news": 78.25081634521484,
        "amazon_polarity": 79.7748031616211,
        "cnn_dailymail/3.0.0": 85.60730743408203,
        "common_gen": 5.64619779586792,
        "cos_e/v1.11": 55.39150619506836,
        "glue/mrpc": 48.17326354980469,
        "kilt_tasks/hotpotqa": 16.295007705688477
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3048,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10225744545459747,
        "ag_news": 0.13605952262878418,
        "amazon_polarity": 0.13656175136566162,
        "cnn_dailymail/3.0.0": 0.13850137591362,
        "common_gen": 0.11419020593166351,
        "cos_e/v1.11": 0.12874798476696014,
        "glue/mrpc": 0.1265234351158142,
        "kilt_tasks/hotpotqa": 0.11715833842754364
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4096,
        "ag_news": 4312,
        "amazon_polarity": 4408,
        "cnn_dailymail/3.0.0": 4216,
        "common_gen": 4328,
        "cos_e/v1.11": 4264,
        "glue/mrpc": 4228,
        "kilt_tasks/hotpotqa": 4704
      },
      "step": 270
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -43.43553161621094,
        "ag_news": 76.62224578857422,
        "amazon_polarity": 79.36504364013672,
        "cnn_dailymail/3.0.0": 84.68933868408203,
        "common_gen": 6.916919708251953,
        "cos_e/v1.11": 51.290592193603516,
        "glue/mrpc": 45.7224006652832,
        "kilt_tasks/hotpotqa": 9.935967445373535
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.334,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10237813740968704,
        "ag_news": 0.1360388994216919,
        "amazon_polarity": 0.13692782819271088,
        "cnn_dailymail/3.0.0": 0.13867032527923584,
        "common_gen": 0.11531740427017212,
        "cos_e/v1.11": 0.12810172140598297,
        "glue/mrpc": 0.126421257853508,
        "kilt_tasks/hotpotqa": 0.11614440381526947
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4232,
        "ag_news": 4512,
        "amazon_polarity": 4552,
        "cnn_dailymail/3.0.0": 4352,
        "common_gen": 4464,
        "cos_e/v1.11": 4464,
        "glue/mrpc": 4380,
        "kilt_tasks/hotpotqa": 4880
      },
      "step": 280
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -50.042381286621094,
        "ag_news": 76.70919799804688,
        "amazon_polarity": 79.48054504394531,
        "cnn_dailymail/3.0.0": 87.98328399658203,
        "common_gen": 10.687124252319336,
        "cos_e/v1.11": 47.77492904663086,
        "glue/mrpc": 45.33006286621094,
        "kilt_tasks/hotpotqa": 11.772894859313965
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.245,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10118162631988525,
        "ag_news": 0.1358899027109146,
        "amazon_polarity": 0.13677163422107697,
        "cnn_dailymail/3.0.0": 0.13951332867145538,
        "common_gen": 0.11651252955198288,
        "cos_e/v1.11": 0.12702271342277527,
        "glue/mrpc": 0.12630100548267365,
        "kilt_tasks/hotpotqa": 0.1168072521686554
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4432,
        "ag_news": 4688,
        "amazon_polarity": 4728,
        "cnn_dailymail/3.0.0": 4488,
        "common_gen": 4584,
        "cos_e/v1.11": 4648,
        "glue/mrpc": 4516,
        "kilt_tasks/hotpotqa": 5032
      },
      "step": 290
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -51.586181640625,
        "ag_news": 76.73670959472656,
        "amazon_polarity": 79.4830322265625,
        "cnn_dailymail/3.0.0": 95.04142761230469,
        "common_gen": 11.546243667602539,
        "cos_e/v1.11": 44.47370147705078,
        "glue/mrpc": 43.33840560913086,
        "kilt_tasks/hotpotqa": 8.931533813476562
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2837,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10120043903589249,
        "ag_news": 0.13573910295963287,
        "amazon_polarity": 0.13659729063510895,
        "cnn_dailymail/3.0.0": 0.14156435430049896,
        "common_gen": 0.11690305173397064,
        "cos_e/v1.11": 0.12605883181095123,
        "glue/mrpc": 0.12573128938674927,
        "kilt_tasks/hotpotqa": 0.11620574444532394
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4568,
        "ag_news": 4816,
        "amazon_polarity": 4928,
        "cnn_dailymail/3.0.0": 4728,
        "common_gen": 4728,
        "cos_e/v1.11": 4840,
        "glue/mrpc": 4668,
        "kilt_tasks/hotpotqa": 5120
      },
      "step": 300
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.291,
      "eval_samples_per_second": 54.987,
      "eval_steps_per_second": 3.437,
      "step": 300
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -49.97933578491211,
        "ag_news": 75.99008178710938,
        "amazon_polarity": 79.35685729980469,
        "cnn_dailymail/3.0.0": 97.7757797241211,
        "common_gen": 15.243769645690918,
        "cos_e/v1.11": 46.67007827758789,
        "glue/mrpc": 41.84915542602539,
        "kilt_tasks/hotpotqa": 6.621190071105957
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3902,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.101760633289814,
        "ag_news": 0.13513176143169403,
        "amazon_polarity": 0.1361628621816635,
        "cnn_dailymail/3.0.0": 0.1419472098350525,
        "common_gen": 0.1178339347243309,
        "cos_e/v1.11": 0.1264813244342804,
        "glue/mrpc": 0.12511390447616577,
        "kilt_tasks/hotpotqa": 0.11556840687990189
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4736,
        "ag_news": 4976,
        "amazon_polarity": 5040,
        "cnn_dailymail/3.0.0": 4944,
        "common_gen": 4904,
        "cos_e/v1.11": 4992,
        "glue/mrpc": 4788,
        "kilt_tasks/hotpotqa": 5296
      },
      "step": 310
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -52.62668991088867,
        "ag_news": 76.3205795288086,
        "amazon_polarity": 79.15818786621094,
        "cnn_dailymail/3.0.0": 102.74463653564453,
        "common_gen": 13.779967308044434,
        "cos_e/v1.11": 51.52277374267578,
        "glue/mrpc": 41.93356704711914,
        "kilt_tasks/hotpotqa": 9.044000625610352
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2854,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10123036801815033,
        "ag_news": 0.1347196400165558,
        "amazon_polarity": 0.1355719268321991,
        "cnn_dailymail/3.0.0": 0.1428718864917755,
        "common_gen": 0.1172584593296051,
        "cos_e/v1.11": 0.127499520778656,
        "glue/mrpc": 0.12481424957513809,
        "kilt_tasks/hotpotqa": 0.11603400856256485
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4912,
        "ag_news": 5120,
        "amazon_polarity": 5200,
        "cnn_dailymail/3.0.0": 5136,
        "common_gen": 5096,
        "cos_e/v1.11": 5136,
        "glue/mrpc": 4948,
        "kilt_tasks/hotpotqa": 5408
      },
      "step": 320
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -50.8112907409668,
        "ag_news": 76.95103454589844,
        "amazon_polarity": 78.8399429321289,
        "cnn_dailymail/3.0.0": 105.36358642578125,
        "common_gen": 13.742525100708008,
        "cos_e/v1.11": 51.345733642578125,
        "glue/mrpc": 42.54983901977539,
        "kilt_tasks/hotpotqa": 8.539911270141602
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3207,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10183015465736389,
        "ag_news": 0.1345890313386917,
        "amazon_polarity": 0.13514664769172668,
        "cnn_dailymail/3.0.0": 0.1432291716337204,
        "common_gen": 0.11721926182508469,
        "cos_e/v1.11": 0.1272570639848709,
        "glue/mrpc": 0.12483325600624084,
        "kilt_tasks/hotpotqa": 0.11589545756578445
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5064,
        "ag_news": 5296,
        "amazon_polarity": 5352,
        "cnn_dailymail/3.0.0": 5256,
        "common_gen": 5280,
        "cos_e/v1.11": 5296,
        "glue/mrpc": 5116,
        "kilt_tasks/hotpotqa": 5576
      },
      "step": 330
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -51.97543716430664,
        "ag_news": 76.99976348876953,
        "amazon_polarity": 78.41207885742188,
        "cnn_dailymail/3.0.0": 106.49636840820312,
        "common_gen": 12.778363227844238,
        "cos_e/v1.11": 46.755218505859375,
        "glue/mrpc": 45.098453521728516,
        "kilt_tasks/hotpotqa": 12.05396842956543
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2732,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10188187658786774,
        "ag_news": 0.13445967435836792,
        "amazon_polarity": 0.13486984372138977,
        "cnn_dailymail/3.0.0": 0.14329573512077332,
        "common_gen": 0.11708826571702957,
        "cos_e/v1.11": 0.12597376108169556,
        "glue/mrpc": 0.12552496790885925,
        "kilt_tasks/hotpotqa": 0.11690595000982285
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5184,
        "ag_news": 5496,
        "amazon_polarity": 5520,
        "cnn_dailymail/3.0.0": 5472,
        "common_gen": 5432,
        "cos_e/v1.11": 5392,
        "glue/mrpc": 5284,
        "kilt_tasks/hotpotqa": 5736
      },
      "step": 340
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -47.2667236328125,
        "ag_news": 76.98302459716797,
        "amazon_polarity": 78.49890899658203,
        "cnn_dailymail/3.0.0": 108.34153747558594,
        "common_gen": 12.771221160888672,
        "cos_e/v1.11": 46.88646697998047,
        "glue/mrpc": 43.38227462768555,
        "kilt_tasks/hotpotqa": 4.537761688232422
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2882,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10327604413032532,
        "ag_news": 0.13441461324691772,
        "amazon_polarity": 0.13484850525856018,
        "cnn_dailymail/3.0.0": 0.14368602633476257,
        "common_gen": 0.1172817125916481,
        "cos_e/v1.11": 0.12608802318572998,
        "glue/mrpc": 0.12515327334403992,
        "kilt_tasks/hotpotqa": 0.11525185406208038
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5320,
        "ag_news": 5672,
        "amazon_polarity": 5688,
        "cnn_dailymail/3.0.0": 5664,
        "common_gen": 5576,
        "cos_e/v1.11": 5552,
        "glue/mrpc": 5404,
        "kilt_tasks/hotpotqa": 5920
      },
      "step": 350
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.15040588378906,
        "ag_news": 76.91490936279297,
        "amazon_polarity": 78.60458374023438,
        "cnn_dailymail/3.0.0": 109.02629089355469,
        "common_gen": 13.444369316101074,
        "cos_e/v1.11": 47.265281677246094,
        "glue/mrpc": 41.559967041015625,
        "kilt_tasks/hotpotqa": 4.0304365158081055
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2311,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10417230427265167,
        "ag_news": 0.1341942548751831,
        "amazon_polarity": 0.1346704661846161,
        "cnn_dailymail/3.0.0": 0.14354431629180908,
        "common_gen": 0.11749254912137985,
        "cos_e/v1.11": 0.12611085176467896,
        "glue/mrpc": 0.12461313605308533,
        "kilt_tasks/hotpotqa": 0.11520209163427353
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5472,
        "ag_news": 5872,
        "amazon_polarity": 5840,
        "cnn_dailymail/3.0.0": 5816,
        "common_gen": 5680,
        "cos_e/v1.11": 5712,
        "glue/mrpc": 5580,
        "kilt_tasks/hotpotqa": 6104
      },
      "step": 360
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -33.5209846496582,
        "ag_news": 76.86360168457031,
        "amazon_polarity": 78.17549896240234,
        "cnn_dailymail/3.0.0": 109.4908447265625,
        "common_gen": 13.543234825134277,
        "cos_e/v1.11": 43.121559143066406,
        "glue/mrpc": 44.04875564575195,
        "kilt_tasks/hotpotqa": 1.7116007804870605
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.234,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10660047829151154,
        "ag_news": 0.13387830555438995,
        "amazon_polarity": 0.13424204289913177,
        "cnn_dailymail/3.0.0": 0.1432289481163025,
        "common_gen": 0.1174624040722847,
        "cos_e/v1.11": 0.12485930323600769,
        "glue/mrpc": 0.12509867548942566,
        "kilt_tasks/hotpotqa": 0.11462990194559097
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5584,
        "ag_news": 6016,
        "amazon_polarity": 6048,
        "cnn_dailymail/3.0.0": 5944,
        "common_gen": 5832,
        "cos_e/v1.11": 5920,
        "glue/mrpc": 5756,
        "kilt_tasks/hotpotqa": 6256
      },
      "step": 370
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -34.092262268066406,
        "ag_news": 76.44571685791016,
        "amazon_polarity": 78.28145599365234,
        "cnn_dailymail/3.0.0": 110.98726654052734,
        "common_gen": 10.924118041992188,
        "cos_e/v1.11": 39.9163703918457,
        "glue/mrpc": 47.527984619140625,
        "kilt_tasks/hotpotqa": 6.906209945678711
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2411,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10660821199417114,
        "ag_news": 0.1335306316614151,
        "amazon_polarity": 0.13403187692165375,
        "cnn_dailymail/3.0.0": 0.1432894617319107,
        "common_gen": 0.11683373898267746,
        "cos_e/v1.11": 0.12394293397665024,
        "glue/mrpc": 0.12588128447532654,
        "kilt_tasks/hotpotqa": 0.1158817782998085
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5760,
        "ag_news": 6216,
        "amazon_polarity": 6200,
        "cnn_dailymail/3.0.0": 6064,
        "common_gen": 6016,
        "cos_e/v1.11": 6064,
        "glue/mrpc": 5924,
        "kilt_tasks/hotpotqa": 6392
      },
      "step": 380
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -36.12565612792969,
        "ag_news": 76.3401107788086,
        "amazon_polarity": 77.9715576171875,
        "cnn_dailymail/3.0.0": 112.22786712646484,
        "common_gen": 10.318328857421875,
        "cos_e/v1.11": 38.88787841796875,
        "glue/mrpc": 44.268375396728516,
        "kilt_tasks/hotpotqa": 9.149569511413574
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2976,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10648869723081589,
        "ag_news": 0.13351503014564514,
        "amazon_polarity": 0.13395465910434723,
        "cnn_dailymail/3.0.0": 0.14353278279304504,
        "common_gen": 0.11690147966146469,
        "cos_e/v1.11": 0.1238161250948906,
        "glue/mrpc": 0.1251641809940338,
        "kilt_tasks/hotpotqa": 0.11662711948156357
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5928,
        "ag_news": 6392,
        "amazon_polarity": 6368,
        "cnn_dailymail/3.0.0": 6256,
        "common_gen": 6184,
        "cos_e/v1.11": 6224,
        "glue/mrpc": 6028,
        "kilt_tasks/hotpotqa": 6536
      },
      "step": 390
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -34.0734977722168,
        "ag_news": 76.2216796875,
        "amazon_polarity": 77.02240753173828,
        "cnn_dailymail/3.0.0": 116.07823944091797,
        "common_gen": 6.666100978851318,
        "cos_e/v1.11": 35.4904670715332,
        "glue/mrpc": 42.79835891723633,
        "kilt_tasks/hotpotqa": 9.8494291305542
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.392,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10720782727003098,
        "ag_news": 0.133464515209198,
        "amazon_polarity": 0.13367734849452972,
        "cnn_dailymail/3.0.0": 0.1444869339466095,
        "common_gen": 0.11623205989599228,
        "cos_e/v1.11": 0.1230807974934578,
        "glue/mrpc": 0.12488146871328354,
        "kilt_tasks/hotpotqa": 0.11696898192167282
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6048,
        "ag_news": 6504,
        "amazon_polarity": 6544,
        "cnn_dailymail/3.0.0": 6432,
        "common_gen": 6408,
        "cos_e/v1.11": 6400,
        "glue/mrpc": 6124,
        "kilt_tasks/hotpotqa": 6736
      },
      "step": 400
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1898,
      "eval_samples_per_second": 84.285,
      "eval_steps_per_second": 5.268,
      "step": 400
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -31.588104248046875,
        "ag_news": 76.26264190673828,
        "amazon_polarity": 76.87368774414062,
        "cnn_dailymail/3.0.0": 118.13552856445312,
        "common_gen": 5.546681880950928,
        "cos_e/v1.11": 39.09944534301758,
        "glue/mrpc": 42.323020935058594,
        "kilt_tasks/hotpotqa": 12.70496940612793
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2147,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10769566893577576,
        "ag_news": 0.1330769658088684,
        "amazon_polarity": 0.13323688507080078,
        "cnn_dailymail/3.0.0": 0.14450015127658844,
        "common_gen": 0.11582568287849426,
        "cos_e/v1.11": 0.12370793521404266,
        "glue/mrpc": 0.12449339032173157,
        "kilt_tasks/hotpotqa": 0.11746332794427872
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6248,
        "ag_news": 6736,
        "amazon_polarity": 6632,
        "cnn_dailymail/3.0.0": 6576,
        "common_gen": 6568,
        "cos_e/v1.11": 6584,
        "glue/mrpc": 6268,
        "kilt_tasks/hotpotqa": 6864
      },
      "step": 410
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -30.444154739379883,
        "ag_news": 76.14342498779297,
        "amazon_polarity": 76.73540496826172,
        "cnn_dailymail/3.0.0": 122.7444076538086,
        "common_gen": 5.916980743408203,
        "cos_e/v1.11": 31.66875457763672,
        "glue/mrpc": 39.75631332397461,
        "kilt_tasks/hotpotqa": 8.70486068725586
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2471,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10831774771213531,
        "ag_news": 0.13318586349487305,
        "amazon_polarity": 0.13333909213542938,
        "cnn_dailymail/3.0.0": 0.1458117961883545,
        "common_gen": 0.11622098088264465,
        "cos_e/v1.11": 0.12217100709676743,
        "glue/mrpc": 0.12410285323858261,
        "kilt_tasks/hotpotqa": 0.11685064435005188
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6400,
        "ag_news": 6960,
        "amazon_polarity": 6800,
        "cnn_dailymail/3.0.0": 6736,
        "common_gen": 6696,
        "cos_e/v1.11": 6744,
        "glue/mrpc": 6364,
        "kilt_tasks/hotpotqa": 7056
      },
      "step": 420
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -28.549894332885742,
        "ag_news": 75.89234161376953,
        "amazon_polarity": 76.69992065429688,
        "cnn_dailymail/3.0.0": 124.81070709228516,
        "common_gen": 6.04933500289917,
        "cos_e/v1.11": 30.41592788696289,
        "glue/mrpc": 39.21567916870117,
        "kilt_tasks/hotpotqa": 10.02993392944336
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3292,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10880853980779648,
        "ag_news": 0.13292308151721954,
        "amazon_polarity": 0.1331293135881424,
        "cnn_dailymail/3.0.0": 0.1460200399160385,
        "common_gen": 0.11626023054122925,
        "cos_e/v1.11": 0.12181784957647324,
        "glue/mrpc": 0.12389063835144043,
        "kilt_tasks/hotpotqa": 0.1171502098441124
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6568,
        "ag_news": 7104,
        "amazon_polarity": 6920,
        "cnn_dailymail/3.0.0": 6880,
        "common_gen": 6888,
        "cos_e/v1.11": 6944,
        "glue/mrpc": 6516,
        "kilt_tasks/hotpotqa": 7216
      },
      "step": 430
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -31.282135009765625,
        "ag_news": 75.7364730834961,
        "amazon_polarity": 76.44112396240234,
        "cnn_dailymail/3.0.0": 126.71046447753906,
        "common_gen": 4.164169788360596,
        "cos_e/v1.11": 29.999990463256836,
        "glue/mrpc": 38.66965866088867,
        "kilt_tasks/hotpotqa": 4.672665119171143
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3337,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10863451659679413,
        "ag_news": 0.13305868208408356,
        "amazon_polarity": 0.13323676586151123,
        "cnn_dailymail/3.0.0": 0.14658522605895996,
        "common_gen": 0.11617355048656464,
        "cos_e/v1.11": 0.12200204282999039,
        "glue/mrpc": 0.12402378022670746,
        "kilt_tasks/hotpotqa": 0.11628550291061401
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6728,
        "ag_news": 7264,
        "amazon_polarity": 7072,
        "cnn_dailymail/3.0.0": 7136,
        "common_gen": 7072,
        "cos_e/v1.11": 7104,
        "glue/mrpc": 6620,
        "kilt_tasks/hotpotqa": 7320
      },
      "step": 440
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -27.840007781982422,
        "ag_news": 75.4634017944336,
        "amazon_polarity": 76.32523345947266,
        "cnn_dailymail/3.0.0": 127.41044616699219,
        "common_gen": 5.41980504989624,
        "cos_e/v1.11": 31.026491165161133,
        "glue/mrpc": 38.67466354370117,
        "kilt_tasks/hotpotqa": 2.5739545822143555
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1613,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10941772162914276,
        "ag_news": 0.13279148936271667,
        "amazon_polarity": 0.1330064833164215,
        "cnn_dailymail/3.0.0": 0.14640119671821594,
        "common_gen": 0.11644752323627472,
        "cos_e/v1.11": 0.12217137962579727,
        "glue/mrpc": 0.12393581867218018,
        "kilt_tasks/hotpotqa": 0.11582846194505692
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6864,
        "ag_news": 7456,
        "amazon_polarity": 7232,
        "cnn_dailymail/3.0.0": 7256,
        "common_gen": 7208,
        "cos_e/v1.11": 7240,
        "glue/mrpc": 6828,
        "kilt_tasks/hotpotqa": 7512
      },
      "step": 450
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -24.77577018737793,
        "ag_news": 75.13847351074219,
        "amazon_polarity": 75.79679107666016,
        "cnn_dailymail/3.0.0": 128.10662841796875,
        "common_gen": 5.094949722290039,
        "cos_e/v1.11": 34.4350471496582,
        "glue/mrpc": 39.09510040283203,
        "kilt_tasks/hotpotqa": 3.8394510746002197
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3006,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1100190207362175,
        "ag_news": 0.1324082612991333,
        "amazon_polarity": 0.13257019221782684,
        "cnn_dailymail/3.0.0": 0.14610101282596588,
        "common_gen": 0.11627694219350815,
        "cos_e/v1.11": 0.12277611345052719,
        "glue/mrpc": 0.12384181469678879,
        "kilt_tasks/hotpotqa": 0.1160067543387413
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7016,
        "ag_news": 7608,
        "amazon_polarity": 7344,
        "cnn_dailymail/3.0.0": 7368,
        "common_gen": 7344,
        "cos_e/v1.11": 7448,
        "glue/mrpc": 7012,
        "kilt_tasks/hotpotqa": 7736
      },
      "step": 460
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -26.521469116210938,
        "ag_news": 74.90570831298828,
        "amazon_polarity": 75.0116958618164,
        "cnn_dailymail/3.0.0": 130.92771911621094,
        "common_gen": 11.573850631713867,
        "cos_e/v1.11": 35.2240104675293,
        "glue/mrpc": 35.972442626953125,
        "kilt_tasks/hotpotqa": 3.186347723007202
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2003,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10972359776496887,
        "ag_news": 0.13215972483158112,
        "amazon_polarity": 0.1321854591369629,
        "cnn_dailymail/3.0.0": 0.14649491012096405,
        "common_gen": 0.11765752732753754,
        "cos_e/v1.11": 0.12287397682666779,
        "glue/mrpc": 0.12304283678531647,
        "kilt_tasks/hotpotqa": 0.11586204916238785
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7176,
        "ag_news": 7752,
        "amazon_polarity": 7552,
        "cnn_dailymail/3.0.0": 7472,
        "common_gen": 7536,
        "cos_e/v1.11": 7616,
        "glue/mrpc": 7180,
        "kilt_tasks/hotpotqa": 7872
      },
      "step": 470
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -27.483491897583008,
        "ag_news": 74.77937316894531,
        "amazon_polarity": 74.8130874633789,
        "cnn_dailymail/3.0.0": 130.9901885986328,
        "common_gen": 12.385152816772461,
        "cos_e/v1.11": 36.7708625793457,
        "glue/mrpc": 36.018558502197266,
        "kilt_tasks/hotpotqa": 3.879671335220337
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3417,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10963816940784454,
        "ag_news": 0.13200245797634125,
        "amazon_polarity": 0.1320105493068695,
        "cnn_dailymail/3.0.0": 0.14621421694755554,
        "common_gen": 0.11785956472158432,
        "cos_e/v1.11": 0.12319428473711014,
        "glue/mrpc": 0.12302609533071518,
        "kilt_tasks/hotpotqa": 0.11605457216501236
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7320,
        "ag_news": 7928,
        "amazon_polarity": 7656,
        "cnn_dailymail/3.0.0": 7688,
        "common_gen": 7720,
        "cos_e/v1.11": 7720,
        "glue/mrpc": 7344,
        "kilt_tasks/hotpotqa": 8056
      },
      "step": 480
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -29.631832122802734,
        "ag_news": 74.15831756591797,
        "amazon_polarity": 74.74512481689453,
        "cnn_dailymail/3.0.0": 135.057373046875,
        "common_gen": 11.754962921142578,
        "cos_e/v1.11": 36.674293518066406,
        "glue/mrpc": 36.57756423950195,
        "kilt_tasks/hotpotqa": 2.129682779312134
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1914,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10935552418231964,
        "ag_news": 0.13177485764026642,
        "amazon_polarity": 0.13191407918930054,
        "cnn_dailymail/3.0.0": 0.14704705774784088,
        "common_gen": 0.11779001355171204,
        "cos_e/v1.11": 0.12318435311317444,
        "glue/mrpc": 0.12316293269395828,
        "kilt_tasks/hotpotqa": 0.11577119678258896
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7432,
        "ag_news": 8096,
        "amazon_polarity": 7832,
        "cnn_dailymail/3.0.0": 7864,
        "common_gen": 7920,
        "cos_e/v1.11": 7864,
        "glue/mrpc": 7512,
        "kilt_tasks/hotpotqa": 8192
      },
      "step": 490
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -29.954326629638672,
        "ag_news": 74.04410552978516,
        "amazon_polarity": 74.72599792480469,
        "cnn_dailymail/3.0.0": 134.5882568359375,
        "common_gen": 13.856701850891113,
        "cos_e/v1.11": 38.897735595703125,
        "glue/mrpc": 37.16330337524414,
        "kilt_tasks/hotpotqa": -1.6939418315887451
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2704,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10943603515625,
        "ag_news": 0.13167650997638702,
        "amazon_polarity": 0.13183656334877014,
        "cnn_dailymail/3.0.0": 0.14668375253677368,
        "common_gen": 0.11829882860183716,
        "cos_e/v1.11": 0.12368854880332947,
        "glue/mrpc": 0.12330732494592667,
        "kilt_tasks/hotpotqa": 0.11507241427898407
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7584,
        "ag_news": 8264,
        "amazon_polarity": 7992,
        "cnn_dailymail/3.0.0": 8080,
        "common_gen": 8032,
        "cos_e/v1.11": 7984,
        "glue/mrpc": 7680,
        "kilt_tasks/hotpotqa": 8376
      },
      "step": 500
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.75,
      "eval_runtime": 0.1929,
      "eval_samples_per_second": 82.933,
      "eval_steps_per_second": 5.183,
      "step": 500
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -26.265470504760742,
        "ag_news": 73.9742202758789,
        "amazon_polarity": 74.5617446899414,
        "cnn_dailymail/3.0.0": 132.4575958251953,
        "common_gen": 11.459136962890625,
        "cos_e/v1.11": 41.07297134399414,
        "glue/mrpc": 37.875953674316406,
        "kilt_tasks/hotpotqa": -2.0931732654571533
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1421,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1102776750922203,
        "ag_news": 0.13157740235328674,
        "amazon_polarity": 0.1317138522863388,
        "cnn_dailymail/3.0.0": 0.14588671922683716,
        "common_gen": 0.11784922331571579,
        "cos_e/v1.11": 0.12416128814220428,
        "glue/mrpc": 0.12346364557743073,
        "kilt_tasks/hotpotqa": 0.11507021635770798
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7800,
        "ag_news": 8440,
        "amazon_polarity": 8168,
        "cnn_dailymail/3.0.0": 8224,
        "common_gen": 8192,
        "cos_e/v1.11": 8088,
        "glue/mrpc": 7872,
        "kilt_tasks/hotpotqa": 8488
      },
      "step": 510
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -27.32895851135254,
        "ag_news": 73.92936706542969,
        "amazon_polarity": 74.43285369873047,
        "cnn_dailymail/3.0.0": 131.36878967285156,
        "common_gen": 17.748706817626953,
        "cos_e/v1.11": 37.49122619628906,
        "glue/mrpc": 33.420433044433594,
        "kilt_tasks/hotpotqa": -6.310116767883301
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2184,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1104067713022232,
        "ag_news": 0.13174371421337128,
        "amazon_polarity": 0.1318596601486206,
        "cnn_dailymail/3.0.0": 0.14566071331501007,
        "common_gen": 0.11943479627370834,
        "cos_e/v1.11": 0.12362143397331238,
        "glue/mrpc": 0.12274616211652756,
        "kilt_tasks/hotpotqa": 0.11452678591012955
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7976,
        "ag_news": 8576,
        "amazon_polarity": 8296,
        "cnn_dailymail/3.0.0": 8320,
        "common_gen": 8448,
        "cos_e/v1.11": 8224,
        "glue/mrpc": 8088,
        "kilt_tasks/hotpotqa": 8624
      },
      "step": 520
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -25.15724754333496,
        "ag_news": 73.86402130126953,
        "amazon_polarity": 74.4273681640625,
        "cnn_dailymail/3.0.0": 130.8063201904297,
        "common_gen": 17.19063949584961,
        "cos_e/v1.11": 38.69963073730469,
        "glue/mrpc": 33.29487228393555,
        "kilt_tasks/hotpotqa": -6.886891841888428
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1945,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11092524230480194,
        "ag_news": 0.13163399696350098,
        "amazon_polarity": 0.13176240026950836,
        "cnn_dailymail/3.0.0": 0.14527671039104462,
        "common_gen": 0.11934354901313782,
        "cos_e/v1.11": 0.12386482954025269,
        "glue/mrpc": 0.1227126270532608,
        "kilt_tasks/hotpotqa": 0.1144806295633316
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8120,
        "ag_news": 8768,
        "amazon_polarity": 8464,
        "cnn_dailymail/3.0.0": 8464,
        "common_gen": 8608,
        "cos_e/v1.11": 8368,
        "glue/mrpc": 8232,
        "kilt_tasks/hotpotqa": 8808
      },
      "step": 530
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -25.010997772216797,
        "ag_news": 73.74686431884766,
        "amazon_polarity": 74.33452606201172,
        "cnn_dailymail/3.0.0": 129.95632934570312,
        "common_gen": 16.040512084960938,
        "cos_e/v1.11": 32.081024169921875,
        "glue/mrpc": 33.987144470214844,
        "kilt_tasks/hotpotqa": -5.518569469451904
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1771,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11123920232057571,
        "ag_news": 0.13173998892307281,
        "amazon_polarity": 0.13187280297279358,
        "cnn_dailymail/3.0.0": 0.14507897198200226,
        "common_gen": 0.11933598667383194,
        "cos_e/v1.11": 0.12266002595424652,
        "glue/mrpc": 0.12306122481822968,
        "kilt_tasks/hotpotqa": 0.11501181125640869
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8272,
        "ag_news": 8888,
        "amazon_polarity": 8680,
        "cnn_dailymail/3.0.0": 8664,
        "common_gen": 8736,
        "cos_e/v1.11": 8576,
        "glue/mrpc": 8376,
        "kilt_tasks/hotpotqa": 8920
      },
      "step": 540
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -21.645383834838867,
        "ag_news": 73.65646362304688,
        "amazon_polarity": 74.25606536865234,
        "cnn_dailymail/3.0.0": 129.3055419921875,
        "common_gen": 18.89196014404297,
        "cos_e/v1.11": 33.482643127441406,
        "glue/mrpc": 33.61001968383789,
        "kilt_tasks/hotpotqa": -5.576112747192383
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1819,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11186053603887558,
        "ag_news": 0.13150052726268768,
        "amazon_polarity": 0.13163459300994873,
        "cnn_dailymail/3.0.0": 0.1445506513118744,
        "common_gen": 0.11982251703739166,
        "cos_e/v1.11": 0.12282703816890717,
        "glue/mrpc": 0.1228535994887352,
        "kilt_tasks/hotpotqa": 0.11495039612054825
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8504,
        "ag_news": 9104,
        "amazon_polarity": 8800,
        "cnn_dailymail/3.0.0": 8832,
        "common_gen": 8912,
        "cos_e/v1.11": 8704,
        "glue/mrpc": 8496,
        "kilt_tasks/hotpotqa": 9040
      },
      "step": 550
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -21.83600616455078,
        "ag_news": 73.68864440917969,
        "amazon_polarity": 74.17910766601562,
        "cnn_dailymail/3.0.0": 132.2835693359375,
        "common_gen": 19.677980422973633,
        "cos_e/v1.11": 32.44977569580078,
        "glue/mrpc": 31.68418312072754,
        "kilt_tasks/hotpotqa": -6.025119781494141
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3512,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11192207783460617,
        "ag_news": 0.13143345713615417,
        "amazon_polarity": 0.13154207170009613,
        "cnn_dailymail/3.0.0": 0.14507415890693665,
        "common_gen": 0.12001238018274307,
        "cos_e/v1.11": 0.12261887639760971,
        "glue/mrpc": 0.12246102839708328,
        "kilt_tasks/hotpotqa": 0.11493595689535141
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8608,
        "ag_news": 9256,
        "amazon_polarity": 8944,
        "cnn_dailymail/3.0.0": 9048,
        "common_gen": 9064,
        "cos_e/v1.11": 8912,
        "glue/mrpc": 8648,
        "kilt_tasks/hotpotqa": 9192
      },
      "step": 560
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -22.056041717529297,
        "ag_news": 73.62126159667969,
        "amazon_polarity": 74.3808364868164,
        "cnn_dailymail/3.0.0": 138.65771484375,
        "common_gen": 22.830862045288086,
        "cos_e/v1.11": 29.431007385253906,
        "glue/mrpc": 32.71281051635742,
        "kilt_tasks/hotpotqa": -4.575379371643066
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2921,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1117636039853096,
        "ag_news": 0.13109640777111053,
        "amazon_polarity": 0.13126274943351746,
        "cnn_dailymail/3.0.0": 0.14614194631576538,
        "common_gen": 0.1204448863863945,
        "cos_e/v1.11": 0.12177787721157074,
        "glue/mrpc": 0.12244623154401779,
        "kilt_tasks/hotpotqa": 0.11506630480289459
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8784,
        "ag_news": 9432,
        "amazon_polarity": 9088,
        "cnn_dailymail/3.0.0": 9232,
        "common_gen": 9208,
        "cos_e/v1.11": 9088,
        "glue/mrpc": 8776,
        "kilt_tasks/hotpotqa": 9344
      },
      "step": 570
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -21.962329864501953,
        "ag_news": 73.4336166381836,
        "amazon_polarity": 74.26887512207031,
        "cnn_dailymail/3.0.0": 141.74392700195312,
        "common_gen": 26.973806381225586,
        "cos_e/v1.11": 30.845054626464844,
        "glue/mrpc": 32.812461853027344,
        "kilt_tasks/hotpotqa": -4.659768104553223
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2781,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11168847978115082,
        "ag_news": 0.1307680457830429,
        "amazon_polarity": 0.13094894587993622,
        "cnn_dailymail/3.0.0": 0.1464318335056305,
        "common_gen": 0.12109467387199402,
        "cos_e/v1.11": 0.12187224626541138,
        "glue/mrpc": 0.12226935476064682,
        "kilt_tasks/hotpotqa": 0.11492643505334854
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8944,
        "ag_news": 9568,
        "amazon_polarity": 9232,
        "cnn_dailymail/3.0.0": 9432,
        "common_gen": 9408,
        "cos_e/v1.11": 9248,
        "glue/mrpc": 8960,
        "kilt_tasks/hotpotqa": 9440
      },
      "step": 580
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -24.85797882080078,
        "ag_news": 73.33209228515625,
        "amazon_polarity": 74.21217346191406,
        "cnn_dailymail/3.0.0": 147.37486267089844,
        "common_gen": 27.658082962036133,
        "cos_e/v1.11": 26.528417587280273,
        "glue/mrpc": 31.267932891845703,
        "kilt_tasks/hotpotqa": -7.273540496826172
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2307,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11134950816631317,
        "ag_news": 0.13079547882080078,
        "amazon_polarity": 0.13098451495170593,
        "cnn_dailymail/3.0.0": 0.1477077454328537,
        "common_gen": 0.12135469168424606,
        "cos_e/v1.11": 0.12113015353679657,
        "glue/mrpc": 0.12207504361867905,
        "kilt_tasks/hotpotqa": 0.11460286378860474
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9136,
        "ag_news": 9736,
        "amazon_polarity": 9352,
        "cnn_dailymail/3.0.0": 9600,
        "common_gen": 9536,
        "cos_e/v1.11": 9432,
        "glue/mrpc": 9088,
        "kilt_tasks/hotpotqa": 9632
      },
      "step": 590
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -26.159399032592773,
        "ag_news": 73.44793701171875,
        "amazon_polarity": 73.91987609863281,
        "cnn_dailymail/3.0.0": 149.46856689453125,
        "common_gen": 27.237863540649414,
        "cos_e/v1.11": 24.10101318359375,
        "glue/mrpc": 30.992544174194336,
        "kilt_tasks/hotpotqa": -6.398579120635986
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2932,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11124860495328903,
        "ag_news": 0.13080379366874695,
        "amazon_polarity": 0.13090430200099945,
        "cnn_dailymail/3.0.0": 0.14804460108280182,
        "common_gen": 0.12133193016052246,
        "cos_e/v1.11": 0.12071473151445389,
        "glue/mrpc": 0.1220749020576477,
        "kilt_tasks/hotpotqa": 0.1148771345615387
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9264,
        "ag_news": 9912,
        "amazon_polarity": 9480,
        "cnn_dailymail/3.0.0": 9744,
        "common_gen": 9712,
        "cos_e/v1.11": 9600,
        "glue/mrpc": 9288,
        "kilt_tasks/hotpotqa": 9792
      },
      "step": 600
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1985,
      "eval_samples_per_second": 80.623,
      "eval_steps_per_second": 5.039,
      "step": 600
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -27.478721618652344,
        "ag_news": 73.14014434814453,
        "amazon_polarity": 73.96484375,
        "cnn_dailymail/3.0.0": 148.75320434570312,
        "common_gen": 27.437957763671875,
        "cos_e/v1.11": 25.30365562438965,
        "glue/mrpc": 32.16692352294922,
        "kilt_tasks/hotpotqa": -4.614872932434082
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3514,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11107973754405975,
        "ag_news": 0.13064561784267426,
        "amazon_polarity": 0.1308196485042572,
        "cnn_dailymail/3.0.0": 0.1476186066865921,
        "common_gen": 0.12135892361402512,
        "cos_e/v1.11": 0.12094195932149887,
        "glue/mrpc": 0.12228798866271973,
        "kilt_tasks/hotpotqa": 0.11524753272533417
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9392,
        "ag_news": 10072,
        "amazon_polarity": 9608,
        "cnn_dailymail/3.0.0": 10016,
        "common_gen": 9912,
        "cos_e/v1.11": 9696,
        "glue/mrpc": 9432,
        "kilt_tasks/hotpotqa": 9944
      },
      "step": 610
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -19.85074234008789,
        "ag_news": 73.09320831298828,
        "amazon_polarity": 74.32567596435547,
        "cnn_dailymail/3.0.0": 149.04356384277344,
        "common_gen": 26.438854217529297,
        "cos_e/v1.11": 20.590473175048828,
        "glue/mrpc": 29.20083999633789,
        "kilt_tasks/hotpotqa": -1.3703901767730713
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0822,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11250469833612442,
        "ag_news": 0.1305389553308487,
        "amazon_polarity": 0.13079681992530823,
        "cnn_dailymail/3.0.0": 0.14743293821811676,
        "common_gen": 0.12114692479372025,
        "cos_e/v1.11": 0.12001890689134598,
        "glue/mrpc": 0.12168338149785995,
        "kilt_tasks/hotpotqa": 0.11587737500667572
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9552,
        "ag_news": 10280,
        "amazon_polarity": 9752,
        "cnn_dailymail/3.0.0": 10136,
        "common_gen": 10032,
        "cos_e/v1.11": 9853,
        "glue/mrpc": 9584,
        "kilt_tasks/hotpotqa": 10160
      },
      "step": 620
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -18.747316360473633,
        "ag_news": 73.0107421875,
        "amazon_polarity": 74.3604736328125,
        "cnn_dailymail/3.0.0": 153.19390869140625,
        "common_gen": 25.333641052246094,
        "cos_e/v1.11": 19.275367736816406,
        "glue/mrpc": 31.9228515625,
        "kilt_tasks/hotpotqa": -1.7355722188949585
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1025,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11266777664422989,
        "ag_news": 0.1303294599056244,
        "amazon_polarity": 0.1306091994047165,
        "cnn_dailymail/3.0.0": 0.1480480283498764,
        "common_gen": 0.12082767486572266,
        "cos_e/v1.11": 0.11967162042856216,
        "glue/mrpc": 0.12209787219762802,
        "kilt_tasks/hotpotqa": 0.11574848741292953
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9688,
        "ag_news": 10472,
        "amazon_polarity": 9920,
        "cnn_dailymail/3.0.0": 10320,
        "common_gen": 10160,
        "cos_e/v1.11": 10053,
        "glue/mrpc": 9720,
        "kilt_tasks/hotpotqa": 10296
      },
      "step": 630
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -18.582660675048828,
        "ag_news": 72.82132720947266,
        "amazon_polarity": 74.31939697265625,
        "cnn_dailymail/3.0.0": 156.78536987304688,
        "common_gen": 24.968595504760742,
        "cos_e/v1.11": 18.23800277709961,
        "glue/mrpc": 28.898761749267578,
        "kilt_tasks/hotpotqa": -4.294053077697754
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1399,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11284583061933517,
        "ag_news": 0.13031545281410217,
        "amazon_polarity": 0.13062353432178497,
        "cnn_dailymail/3.0.0": 0.14877058565616608,
        "common_gen": 0.1208522766828537,
        "cos_e/v1.11": 0.1195782870054245,
        "glue/mrpc": 0.12160255759954453,
        "kilt_tasks/hotpotqa": 0.11541155725717545
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9896,
        "ag_news": 10616,
        "amazon_polarity": 10048,
        "cnn_dailymail/3.0.0": 10464,
        "common_gen": 10328,
        "cos_e/v1.11": 10213,
        "glue/mrpc": 9888,
        "kilt_tasks/hotpotqa": 10456
      },
      "step": 640
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -20.14947509765625,
        "ag_news": 72.8045654296875,
        "amazon_polarity": 74.34742736816406,
        "cnn_dailymail/3.0.0": 157.316650390625,
        "common_gen": 25.14227867126465,
        "cos_e/v1.11": 17.029050827026367,
        "glue/mrpc": 28.996244430541992,
        "kilt_tasks/hotpotqa": -7.587686538696289
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1478,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11276447027921677,
        "ag_news": 0.13039372861385345,
        "amazon_polarity": 0.13070879876613617,
        "cnn_dailymail/3.0.0": 0.14883682131767273,
        "common_gen": 0.1210305392742157,
        "cos_e/v1.11": 0.11950589716434479,
        "glue/mrpc": 0.12176167219877243,
        "kilt_tasks/hotpotqa": 0.11499800533056259
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10008,
        "ag_news": 10760,
        "amazon_polarity": 10224,
        "cnn_dailymail/3.0.0": 10640,
        "common_gen": 10480,
        "cos_e/v1.11": 10405,
        "glue/mrpc": 10024,
        "kilt_tasks/hotpotqa": 10648
      },
      "step": 650
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -22.679731369018555,
        "ag_news": 73.14140319824219,
        "amazon_polarity": 74.5382308959961,
        "cnn_dailymail/3.0.0": 158.01551818847656,
        "common_gen": 25.501541137695312,
        "cos_e/v1.11": 18.6774959564209,
        "glue/mrpc": 29.395305633544922,
        "kilt_tasks/hotpotqa": -6.795443058013916
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1747,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11236664652824402,
        "ag_news": 0.1303696632385254,
        "amazon_polarity": 0.13065266609191895,
        "cnn_dailymail/3.0.0": 0.14874450862407684,
        "common_gen": 0.12108031660318375,
        "cos_e/v1.11": 0.1198057308793068,
        "glue/mrpc": 0.12181374430656433,
        "kilt_tasks/hotpotqa": 0.11516678333282471
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10144,
        "ag_news": 10944,
        "amazon_polarity": 10360,
        "cnn_dailymail/3.0.0": 10832,
        "common_gen": 10656,
        "cos_e/v1.11": 10533,
        "glue/mrpc": 10200,
        "kilt_tasks/hotpotqa": 10800
      },
      "step": 660
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -22.039920806884766,
        "ag_news": 72.75777435302734,
        "amazon_polarity": 74.57087707519531,
        "cnn_dailymail/3.0.0": 158.48489379882812,
        "common_gen": 28.577749252319336,
        "cos_e/v1.11": 15.303085327148438,
        "glue/mrpc": 25.706193923950195,
        "kilt_tasks/hotpotqa": -6.403933048248291
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.161,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11262749880552292,
        "ag_news": 0.1303231418132782,
        "amazon_polarity": 0.13068774342536926,
        "cnn_dailymail/3.0.0": 0.14874134957790375,
        "common_gen": 0.12175027281045914,
        "cos_e/v1.11": 0.11928770691156387,
        "glue/mrpc": 0.12121324986219406,
        "kilt_tasks/hotpotqa": 0.11536908894777298
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10312,
        "ag_news": 11072,
        "amazon_polarity": 10512,
        "cnn_dailymail/3.0.0": 11008,
        "common_gen": 10808,
        "cos_e/v1.11": 10709,
        "glue/mrpc": 10424,
        "kilt_tasks/hotpotqa": 10904
      },
      "step": 670
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -25.017425537109375,
        "ag_news": 72.59182739257812,
        "amazon_polarity": 74.5621566772461,
        "cnn_dailymail/3.0.0": 159.65122985839844,
        "common_gen": 24.766990661621094,
        "cos_e/v1.11": 10.403647422790527,
        "glue/mrpc": 22.868345260620117,
        "kilt_tasks/hotpotqa": -6.5555243492126465
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1293,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11247783899307251,
        "ag_news": 0.1305711269378662,
        "amazon_polarity": 0.1309652477502823,
        "cnn_dailymail/3.0.0": 0.14918474853038788,
        "common_gen": 0.12136451154947281,
        "cos_e/v1.11": 0.11872994899749756,
        "glue/mrpc": 0.12101288884878159,
        "kilt_tasks/hotpotqa": 0.11569373309612274
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10456,
        "ag_news": 11216,
        "amazon_polarity": 10712,
        "cnn_dailymail/3.0.0": 11168,
        "common_gen": 11000,
        "cos_e/v1.11": 10869,
        "glue/mrpc": 10584,
        "kilt_tasks/hotpotqa": 11024
      },
      "step": 680
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -24.97257423400879,
        "ag_news": 72.46470642089844,
        "amazon_polarity": 74.56672668457031,
        "cnn_dailymail/3.0.0": 160.44110107421875,
        "common_gen": 24.996408462524414,
        "cos_e/v1.11": 11.372660636901855,
        "glue/mrpc": 22.195676803588867,
        "kilt_tasks/hotpotqa": -9.404994010925293
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1144,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11260134726762772,
        "ag_news": 0.13054023683071136,
        "amazon_polarity": 0.13095761835575104,
        "cnn_dailymail/3.0.0": 0.14921395480632782,
        "common_gen": 0.12146542966365814,
        "cos_e/v1.11": 0.11898081004619598,
        "glue/mrpc": 0.12095038592815399,
        "kilt_tasks/hotpotqa": 0.11529027670621872
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10616,
        "ag_news": 11376,
        "amazon_polarity": 10896,
        "cnn_dailymail/3.0.0": 11288,
        "common_gen": 11168,
        "cos_e/v1.11": 11037,
        "glue/mrpc": 10728,
        "kilt_tasks/hotpotqa": 11200
      },
      "step": 690
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -21.491029739379883,
        "ag_news": 70.52975463867188,
        "amazon_polarity": 74.343505859375,
        "cnn_dailymail/3.0.0": 158.8723602294922,
        "common_gen": 28.50914764404297,
        "cos_e/v1.11": 9.718682289123535,
        "glue/mrpc": 20.418432235717773,
        "kilt_tasks/hotpotqa": -7.016243934631348
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0795,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11325088888406754,
        "ag_news": 0.13009010255336761,
        "amazon_polarity": 0.13084030151367188,
        "cnn_dailymail/3.0.0": 0.14863942563533783,
        "common_gen": 0.12210685014724731,
        "cos_e/v1.11": 0.11869922280311584,
        "glue/mrpc": 0.12062763422727585,
        "kilt_tasks/hotpotqa": 0.11574555188417435
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10760,
        "ag_news": 11576,
        "amazon_polarity": 11024,
        "cnn_dailymail/3.0.0": 11440,
        "common_gen": 11368,
        "cos_e/v1.11": 11181,
        "glue/mrpc": 10920,
        "kilt_tasks/hotpotqa": 11320
      },
      "step": 700
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1813,
      "eval_samples_per_second": 88.262,
      "eval_steps_per_second": 5.516,
      "step": 700
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -23.2271671295166,
        "ag_news": 70.30490112304688,
        "amazon_polarity": 74.50220489501953,
        "cnn_dailymail/3.0.0": 162.73094177246094,
        "common_gen": 26.114974975585938,
        "cos_e/v1.11": 9.899224281311035,
        "glue/mrpc": 17.852676391601562,
        "kilt_tasks/hotpotqa": -8.134851455688477
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0586,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11309531331062317,
        "ag_news": 0.1300790011882782,
        "amazon_polarity": 0.13089901208877563,
        "cnn_dailymail/3.0.0": 0.1493997722864151,
        "common_gen": 0.12175478041172028,
        "cos_e/v1.11": 0.11883724480867386,
        "glue/mrpc": 0.12025927752256393,
        "kilt_tasks/hotpotqa": 0.11567562073469162
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10920,
        "ag_news": 11792,
        "amazon_polarity": 11128,
        "cnn_dailymail/3.0.0": 11616,
        "common_gen": 11504,
        "cos_e/v1.11": 11325,
        "glue/mrpc": 11100,
        "kilt_tasks/hotpotqa": 11480
      },
      "step": 710
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -25.13641357421875,
        "ag_news": 70.24390411376953,
        "amazon_polarity": 74.37306213378906,
        "cnn_dailymail/3.0.0": 162.9207763671875,
        "common_gen": 27.453102111816406,
        "cos_e/v1.11": 8.378643035888672,
        "glue/mrpc": 18.016353607177734,
        "kilt_tasks/hotpotqa": -9.049446105957031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0722,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11290891468524933,
        "ag_news": 0.13009580969810486,
        "amazon_polarity": 0.13089700043201447,
        "cnn_dailymail/3.0.0": 0.14933180809020996,
        "common_gen": 0.12207958847284317,
        "cos_e/v1.11": 0.11866919696331024,
        "glue/mrpc": 0.12038013339042664,
        "kilt_tasks/hotpotqa": 0.11563757807016373
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11088,
        "ag_news": 12000,
        "amazon_polarity": 11296,
        "cnn_dailymail/3.0.0": 11768,
        "common_gen": 11656,
        "cos_e/v1.11": 11461,
        "glue/mrpc": 11220,
        "kilt_tasks/hotpotqa": 11656
      },
      "step": 720
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -22.710464477539062,
        "ag_news": 70.22727966308594,
        "amazon_polarity": 74.19635009765625,
        "cnn_dailymail/3.0.0": 162.058837890625,
        "common_gen": 27.648197174072266,
        "cos_e/v1.11": 7.289038181304932,
        "glue/mrpc": 16.218769073486328,
        "kilt_tasks/hotpotqa": -10.977217674255371
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2044,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11346560716629028,
        "ag_news": 0.1301419734954834,
        "amazon_polarity": 0.13090699911117554,
        "cnn_dailymail/3.0.0": 0.14905793964862823,
        "common_gen": 0.1222139373421669,
        "cos_e/v1.11": 0.11859770119190216,
        "glue/mrpc": 0.12017028033733368,
        "kilt_tasks/hotpotqa": 0.11544550210237503
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11264,
        "ag_news": 12136,
        "amazon_polarity": 11456,
        "cnn_dailymail/3.0.0": 11920,
        "common_gen": 11840,
        "cos_e/v1.11": 11645,
        "glue/mrpc": 11316,
        "kilt_tasks/hotpotqa": 11848
      },
      "step": 730
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -19.16468048095703,
        "ag_news": 70.2281265258789,
        "amazon_polarity": 74.3022689819336,
        "cnn_dailymail/3.0.0": 162.7747039794922,
        "common_gen": 28.955598831176758,
        "cos_e/v1.11": 6.909472942352295,
        "glue/mrpc": 16.076862335205078,
        "kilt_tasks/hotpotqa": -8.542341232299805
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0946,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1139824390411377,
        "ag_news": 0.12993796169757843,
        "amazon_polarity": 0.13071677088737488,
        "cnn_dailymail/3.0.0": 0.14884433150291443,
        "common_gen": 0.12230800092220306,
        "cos_e/v1.11": 0.1184198334813118,
        "glue/mrpc": 0.12002120912075043,
        "kilt_tasks/hotpotqa": 0.11576949805021286
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11440,
        "ag_news": 12296,
        "amazon_polarity": 11616,
        "cnn_dailymail/3.0.0": 12096,
        "common_gen": 11984,
        "cos_e/v1.11": 11805,
        "glue/mrpc": 11476,
        "kilt_tasks/hotpotqa": 11992
      },
      "step": 740
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -19.664142608642578,
        "ag_news": 70.2134780883789,
        "amazon_polarity": 74.2850341796875,
        "cnn_dailymail/3.0.0": 163.66627502441406,
        "common_gen": 30.369850158691406,
        "cos_e/v1.11": 5.393794536590576,
        "glue/mrpc": 14.806498527526855,
        "kilt_tasks/hotpotqa": -7.429760932922363
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1206,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11396492272615433,
        "ag_news": 0.129896879196167,
        "amazon_polarity": 0.13066978752613068,
        "cnn_dailymail/3.0.0": 0.14885975420475006,
        "common_gen": 0.12257315218448639,
        "cos_e/v1.11": 0.11819673329591751,
        "glue/mrpc": 0.11982718855142593,
        "kilt_tasks/hotpotqa": 0.11601156741380692
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11576,
        "ag_news": 12504,
        "amazon_polarity": 11736,
        "cnn_dailymail/3.0.0": 12280,
        "common_gen": 12136,
        "cos_e/v1.11": 11965,
        "glue/mrpc": 11628,
        "kilt_tasks/hotpotqa": 12160
      },
      "step": 750
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -19.912525177001953,
        "ag_news": 70.17691040039062,
        "amazon_polarity": 74.25526428222656,
        "cnn_dailymail/3.0.0": 167.21945190429688,
        "common_gen": 31.42724609375,
        "cos_e/v1.11": 5.046401023864746,
        "glue/mrpc": 13.915523529052734,
        "kilt_tasks/hotpotqa": -7.429201126098633
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.205,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11391713470220566,
        "ag_news": 0.12977100908756256,
        "amazon_polarity": 0.13053937256336212,
        "cnn_dailymail/3.0.0": 0.14935778081417084,
        "common_gen": 0.12269492447376251,
        "cos_e/v1.11": 0.11810211092233658,
        "glue/mrpc": 0.11962643265724182,
        "kilt_tasks/hotpotqa": 0.11599116027355194
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11736,
        "ag_news": 12640,
        "amazon_polarity": 11912,
        "cnn_dailymail/3.0.0": 12496,
        "common_gen": 12304,
        "cos_e/v1.11": 12165,
        "glue/mrpc": 11732,
        "kilt_tasks/hotpotqa": 12280
      },
      "step": 760
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -21.822912216186523,
        "ag_news": 70.09691619873047,
        "amazon_polarity": 74.27610778808594,
        "cnn_dailymail/3.0.0": 168.6048126220703,
        "common_gen": 31.487506866455078,
        "cos_e/v1.11": 3.189034938812256,
        "glue/mrpc": 12.898876190185547,
        "kilt_tasks/hotpotqa": -6.411986827850342
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1737,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1137138158082962,
        "ag_news": 0.12977121770381927,
        "amazon_polarity": 0.13055354356765747,
        "cnn_dailymail/3.0.0": 0.14953753352165222,
        "common_gen": 0.12276425212621689,
        "cos_e/v1.11": 0.11787275969982147,
        "glue/mrpc": 0.11952849477529526,
        "kilt_tasks/hotpotqa": 0.1162583976984024
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11896,
        "ag_news": 12776,
        "amazon_polarity": 12056,
        "cnn_dailymail/3.0.0": 12680,
        "common_gen": 12456,
        "cos_e/v1.11": 12349,
        "glue/mrpc": 11876,
        "kilt_tasks/hotpotqa": 12456
      },
      "step": 770
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -21.472003936767578,
        "ag_news": 70.09578704833984,
        "amazon_polarity": 74.171875,
        "cnn_dailymail/3.0.0": 169.78273010253906,
        "common_gen": 30.76963996887207,
        "cos_e/v1.11": 1.3430253267288208,
        "glue/mrpc": 15.868362426757812,
        "kilt_tasks/hotpotqa": -7.346324443817139
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0846,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11381855607032776,
        "ag_news": 0.12971633672714233,
        "amazon_polarity": 0.13047410547733307,
        "cnn_dailymail/3.0.0": 0.14959117770195007,
        "common_gen": 0.12263020128011703,
        "cos_e/v1.11": 0.11758510768413544,
        "glue/mrpc": 0.12004861980676651,
        "kilt_tasks/hotpotqa": 0.11613592505455017
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12144,
        "ag_news": 12944,
        "amazon_polarity": 12184,
        "cnn_dailymail/3.0.0": 12824,
        "common_gen": 12616,
        "cos_e/v1.11": 12493,
        "glue/mrpc": 12044,
        "kilt_tasks/hotpotqa": 12576
      },
      "step": 780
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -22.046602249145508,
        "ag_news": 70.04872131347656,
        "amazon_polarity": 73.85282897949219,
        "cnn_dailymail/3.0.0": 168.22088623046875,
        "common_gen": 25.626262664794922,
        "cos_e/v1.11": 0.3002750873565674,
        "glue/mrpc": 16.160696029663086,
        "kilt_tasks/hotpotqa": -6.985988616943359
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1877,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11396043002605438,
        "ag_news": 0.12986867129802704,
        "amazon_polarity": 0.130572110414505,
        "cnn_dailymail/3.0.0": 0.1493106186389923,
        "common_gen": 0.12193254381418228,
        "cos_e/v1.11": 0.1176295056939125,
        "glue/mrpc": 0.12030596286058426,
        "kilt_tasks/hotpotqa": 0.11642023921012878
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12320,
        "ag_news": 13040,
        "amazon_polarity": 12400,
        "cnn_dailymail/3.0.0": 13008,
        "common_gen": 12824,
        "cos_e/v1.11": 12661,
        "glue/mrpc": 12148,
        "kilt_tasks/hotpotqa": 12704
      },
      "step": 790
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -21.9287109375,
        "ag_news": 69.97232818603516,
        "amazon_polarity": 73.6033935546875,
        "cnn_dailymail/3.0.0": 169.22276306152344,
        "common_gen": 26.434690475463867,
        "cos_e/v1.11": -2.7967238426208496,
        "glue/mrpc": 14.62592601776123,
        "kilt_tasks/hotpotqa": -5.826076507568359
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0459,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11407843232154846,
        "ag_news": 0.12986218929290771,
        "amazon_polarity": 0.13052932918071747,
        "cnn_dailymail/3.0.0": 0.14940103888511658,
        "common_gen": 0.12212652713060379,
        "cos_e/v1.11": 0.11719592660665512,
        "glue/mrpc": 0.12010990083217621,
        "kilt_tasks/hotpotqa": 0.11669661849737167
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12480,
        "ag_news": 13272,
        "amazon_polarity": 12560,
        "cnn_dailymail/3.0.0": 13176,
        "common_gen": 12928,
        "cos_e/v1.11": 12821,
        "glue/mrpc": 12252,
        "kilt_tasks/hotpotqa": 12896
      },
      "step": 800
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.185,
      "eval_samples_per_second": 86.466,
      "eval_steps_per_second": 5.404,
      "step": 800
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -22.064733505249023,
        "ag_news": 69.85598754882812,
        "amazon_polarity": 73.57682037353516,
        "cnn_dailymail/3.0.0": 171.82781982421875,
        "common_gen": 23.671781539916992,
        "cos_e/v1.11": -3.9914753437042236,
        "glue/mrpc": 15.086256980895996,
        "kilt_tasks/hotpotqa": -3.809030055999756
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9616,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11409596353769302,
        "ag_news": 0.12978249788284302,
        "amazon_polarity": 0.13046154379844666,
        "cnn_dailymail/3.0.0": 0.14975190162658691,
        "common_gen": 0.12164558470249176,
        "cos_e/v1.11": 0.11702089756727219,
        "glue/mrpc": 0.1201908215880394,
        "kilt_tasks/hotpotqa": 0.11705081909894943
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12680,
        "ag_news": 13520,
        "amazon_polarity": 12712,
        "cnn_dailymail/3.0.0": 13280,
        "common_gen": 13032,
        "cos_e/v1.11": 12973,
        "glue/mrpc": 12436,
        "kilt_tasks/hotpotqa": 13032
      },
      "step": 810
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -20.86444664001465,
        "ag_news": 69.73050689697266,
        "amazon_polarity": 73.57813262939453,
        "cnn_dailymail/3.0.0": 173.03726196289062,
        "common_gen": 26.05457305908203,
        "cos_e/v1.11": -1.544616460800171,
        "glue/mrpc": 17.067888259887695,
        "kilt_tasks/hotpotqa": -7.984705924987793
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.082,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11425218731164932,
        "ag_news": 0.12961922585964203,
        "amazon_polarity": 0.13031631708145142,
        "cnn_dailymail/3.0.0": 0.14971202611923218,
        "common_gen": 0.12196573615074158,
        "cos_e/v1.11": 0.11736675351858139,
        "glue/mrpc": 0.12044855952262878,
        "kilt_tasks/hotpotqa": 0.11631910502910614
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12832,
        "ag_news": 13664,
        "amazon_polarity": 12920,
        "cnn_dailymail/3.0.0": 13496,
        "common_gen": 13176,
        "cos_e/v1.11": 13125,
        "glue/mrpc": 12588,
        "kilt_tasks/hotpotqa": 13144
      },
      "step": 820
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -16.021846771240234,
        "ag_news": 69.87378692626953,
        "amazon_polarity": 73.60133361816406,
        "cnn_dailymail/3.0.0": 173.32742309570312,
        "common_gen": 24.15133285522461,
        "cos_e/v1.11": -3.3660318851470947,
        "glue/mrpc": 18.56009292602539,
        "kilt_tasks/hotpotqa": -9.804780006408691
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1225,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11506190150976181,
        "ag_news": 0.12959393858909607,
        "amazon_polarity": 0.130265012383461,
        "cnn_dailymail/3.0.0": 0.14958390593528748,
        "common_gen": 0.12164121121168137,
        "cos_e/v1.11": 0.11709478497505188,
        "glue/mrpc": 0.12070319801568985,
        "kilt_tasks/hotpotqa": 0.11605604737997055
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12960,
        "ag_news": 13800,
        "amazon_polarity": 13088,
        "cnn_dailymail/3.0.0": 13680,
        "common_gen": 13360,
        "cos_e/v1.11": 13237,
        "glue/mrpc": 12788,
        "kilt_tasks/hotpotqa": 13312
      },
      "step": 830
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -18.99272346496582,
        "ag_news": 69.8402328491211,
        "amazon_polarity": 73.5071029663086,
        "cnn_dailymail/3.0.0": 174.837890625,
        "common_gen": 25.985387802124023,
        "cos_e/v1.11": -2.9604153633117676,
        "glue/mrpc": 18.485754013061523,
        "kilt_tasks/hotpotqa": -13.239697456359863
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0577,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11469338834285736,
        "ag_news": 0.12961071729660034,
        "amazon_polarity": 0.13026700913906097,
        "cnn_dailymail/3.0.0": 0.149794802069664,
        "common_gen": 0.12201577425003052,
        "cos_e/v1.11": 0.11725099384784698,
        "glue/mrpc": 0.12076275795698166,
        "kilt_tasks/hotpotqa": 0.11560458689928055
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13128,
        "ag_news": 13952,
        "amazon_polarity": 13240,
        "cnn_dailymail/3.0.0": 13832,
        "common_gen": 13472,
        "cos_e/v1.11": 13413,
        "glue/mrpc": 12996,
        "kilt_tasks/hotpotqa": 13472
      },
      "step": 840
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -18.64530372619629,
        "ag_news": 69.5417709350586,
        "amazon_polarity": 73.33821868896484,
        "cnn_dailymail/3.0.0": 176.3778076171875,
        "common_gen": 23.49543571472168,
        "cos_e/v1.11": -5.87020206451416,
        "glue/mrpc": 16.897661209106445,
        "kilt_tasks/hotpotqa": -17.309551239013672
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.219,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1149800717830658,
        "ag_news": 0.12972742319107056,
        "amazon_polarity": 0.13040360808372498,
        "cnn_dailymail/3.0.0": 0.15018096566200256,
        "common_gen": 0.12180289626121521,
        "cos_e/v1.11": 0.1170065626502037,
        "glue/mrpc": 0.12070821970701218,
        "kilt_tasks/hotpotqa": 0.1151902824640274
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13264,
        "ag_news": 14112,
        "amazon_polarity": 13376,
        "cnn_dailymail/3.0.0": 14056,
        "common_gen": 13632,
        "cos_e/v1.11": 13541,
        "glue/mrpc": 13180,
        "kilt_tasks/hotpotqa": 13624
      },
      "step": 850
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -21.120708465576172,
        "ag_news": 69.53950500488281,
        "amazon_polarity": 73.29505157470703,
        "cnn_dailymail/3.0.0": 176.92462158203125,
        "common_gen": 24.095888137817383,
        "cos_e/v1.11": -5.853118419647217,
        "glue/mrpc": 17.061538696289062,
        "kilt_tasks/hotpotqa": -16.373184204101562
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0733,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1146523505449295,
        "ag_news": 0.12970291078090668,
        "amazon_polarity": 0.13036778569221497,
        "cnn_dailymail/3.0.0": 0.15013764798641205,
        "common_gen": 0.12192416936159134,
        "cos_e/v1.11": 0.11705729365348816,
        "glue/mrpc": 0.12076297402381897,
        "kilt_tasks/hotpotqa": 0.11539476364850998
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13416,
        "ag_news": 14288,
        "amazon_polarity": 13568,
        "cnn_dailymail/3.0.0": 14224,
        "common_gen": 13800,
        "cos_e/v1.11": 13653,
        "glue/mrpc": 13324,
        "kilt_tasks/hotpotqa": 13792
      },
      "step": 860
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -19.8447265625,
        "ag_news": 69.29088592529297,
        "amazon_polarity": 73.22537231445312,
        "cnn_dailymail/3.0.0": 174.69137573242188,
        "common_gen": 27.762653350830078,
        "cos_e/v1.11": -2.9172754287719727,
        "glue/mrpc": 18.423519134521484,
        "kilt_tasks/hotpotqa": -18.409212112426758
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2186,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11483299732208252,
        "ag_news": 0.12954838573932648,
        "amazon_polarity": 0.13024018704891205,
        "cnn_dailymail/3.0.0": 0.14943042397499084,
        "common_gen": 0.12246900051832199,
        "cos_e/v1.11": 0.11749129742383957,
        "glue/mrpc": 0.12093158811330795,
        "kilt_tasks/hotpotqa": 0.11505605280399323
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13520,
        "ag_news": 14440,
        "amazon_polarity": 13688,
        "cnn_dailymail/3.0.0": 14432,
        "common_gen": 14016,
        "cos_e/v1.11": 13837,
        "glue/mrpc": 13444,
        "kilt_tasks/hotpotqa": 13968
      },
      "step": 870
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -21.07809829711914,
        "ag_news": 69.22818756103516,
        "amazon_polarity": 73.34243774414062,
        "cnn_dailymail/3.0.0": 178.31533813476562,
        "common_gen": 24.756290435791016,
        "cos_e/v1.11": -6.658720016479492,
        "glue/mrpc": 21.9553165435791,
        "kilt_tasks/hotpotqa": -13.472622871398926
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2012,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11460746824741364,
        "ag_news": 0.1294092983007431,
        "amazon_polarity": 0.1301279217004776,
        "cnn_dailymail/3.0.0": 0.14989222586154938,
        "common_gen": 0.12189281731843948,
        "cos_e/v1.11": 0.11685064435005188,
        "glue/mrpc": 0.12143445014953613,
        "kilt_tasks/hotpotqa": 0.1157851442694664
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13616,
        "ag_news": 14608,
        "amazon_polarity": 13864,
        "cnn_dailymail/3.0.0": 14624,
        "common_gen": 14208,
        "cos_e/v1.11": 14021,
        "glue/mrpc": 13564,
        "kilt_tasks/hotpotqa": 14120
      },
      "step": 880
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -23.63828468322754,
        "ag_news": 69.33971405029297,
        "amazon_polarity": 73.3630599975586,
        "cnn_dailymail/3.0.0": 180.66307067871094,
        "common_gen": 24.44753074645996,
        "cos_e/v1.11": -8.653389930725098,
        "glue/mrpc": 22.283754348754883,
        "kilt_tasks/hotpotqa": -13.231138229370117
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2223,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11429280042648315,
        "ag_news": 0.1294279396533966,
        "amazon_polarity": 0.13012683391571045,
        "cnn_dailymail/3.0.0": 0.15024030208587646,
        "common_gen": 0.12188258022069931,
        "cos_e/v1.11": 0.11660526692867279,
        "glue/mrpc": 0.12153033912181854,
        "kilt_tasks/hotpotqa": 0.11589384078979492
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13768,
        "ag_news": 14704,
        "amazon_polarity": 14016,
        "cnn_dailymail/3.0.0": 14808,
        "common_gen": 14432,
        "cos_e/v1.11": 14133,
        "glue/mrpc": 13724,
        "kilt_tasks/hotpotqa": 14320
      },
      "step": 890
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -27.56435203552246,
        "ag_news": 69.20220947265625,
        "amazon_polarity": 73.3073501586914,
        "cnn_dailymail/3.0.0": 180.4525146484375,
        "common_gen": 26.636613845825195,
        "cos_e/v1.11": -6.809117317199707,
        "glue/mrpc": 21.59503173828125,
        "kilt_tasks/hotpotqa": -13.361286163330078
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1539,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11377472430467606,
        "ag_news": 0.12940287590026855,
        "amazon_polarity": 0.13011188805103302,
        "cnn_dailymail/3.0.0": 0.15007266402244568,
        "common_gen": 0.12227722257375717,
        "cos_e/v1.11": 0.11695758253335953,
        "glue/mrpc": 0.12145993858575821,
        "kilt_tasks/hotpotqa": 0.11594318598508835
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13968,
        "ag_news": 14816,
        "amazon_polarity": 14160,
        "cnn_dailymail/3.0.0": 14888,
        "common_gen": 14656,
        "cos_e/v1.11": 14341,
        "glue/mrpc": 13900,
        "kilt_tasks/hotpotqa": 14456
      },
      "step": 900
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1937,
      "eval_samples_per_second": 82.597,
      "eval_steps_per_second": 5.162,
      "step": 900
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -29.214111328125,
        "ag_news": 69.12757110595703,
        "amazon_polarity": 73.22468566894531,
        "cnn_dailymail/3.0.0": 183.15736389160156,
        "common_gen": 27.08374786376953,
        "cos_e/v1.11": -6.860013008117676,
        "glue/mrpc": 21.529720306396484,
        "kilt_tasks/hotpotqa": -14.3056001663208
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1592,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11356791853904724,
        "ag_news": 0.12934589385986328,
        "amazon_polarity": 0.13004934787750244,
        "cnn_dailymail/3.0.0": 0.15043821930885315,
        "common_gen": 0.12234567105770111,
        "cos_e/v1.11": 0.116974376142025,
        "glue/mrpc": 0.1214500218629837,
        "kilt_tasks/hotpotqa": 0.11582843214273453
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14152,
        "ag_news": 14936,
        "amazon_polarity": 14328,
        "cnn_dailymail/3.0.0": 15072,
        "common_gen": 14784,
        "cos_e/v1.11": 14541,
        "glue/mrpc": 14044,
        "kilt_tasks/hotpotqa": 14608
      },
      "step": 910
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -29.424327850341797,
        "ag_news": 68.84589385986328,
        "amazon_polarity": 73.49652862548828,
        "cnn_dailymail/3.0.0": 181.8583526611328,
        "common_gen": 26.487276077270508,
        "cos_e/v1.11": -8.972410202026367,
        "glue/mrpc": 19.00699806213379,
        "kilt_tasks/hotpotqa": -12.458054542541504
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1207,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11369212716817856,
        "ag_news": 0.129384383559227,
        "amazon_polarity": 0.13017909228801727,
        "cnn_dailymail/3.0.0": 0.15015849471092224,
        "common_gen": 0.12236813455820084,
        "cos_e/v1.11": 0.11679112911224365,
        "glue/mrpc": 0.12116966396570206,
        "kilt_tasks/hotpotqa": 0.11625698208808899
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14296,
        "ag_news": 15056,
        "amazon_polarity": 14512,
        "cnn_dailymail/3.0.0": 15224,
        "common_gen": 14952,
        "cos_e/v1.11": 14637,
        "glue/mrpc": 14252,
        "kilt_tasks/hotpotqa": 14816
      },
      "step": 920
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -29.366554260253906,
        "ag_news": 68.80303192138672,
        "amazon_polarity": 72.52349090576172,
        "cnn_dailymail/3.0.0": 182.8446502685547,
        "common_gen": 30.745641708374023,
        "cos_e/v1.11": -9.155811309814453,
        "glue/mrpc": 17.832660675048828,
        "kilt_tasks/hotpotqa": -12.70737075805664
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0821,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11370816826820374,
        "ag_news": 0.129296213388443,
        "amazon_polarity": 0.12992770969867706,
        "cnn_dailymail/3.0.0": 0.15013892948627472,
        "common_gen": 0.12301179021596909,
        "cos_e/v1.11": 0.11675400286912918,
        "glue/mrpc": 0.1209503710269928,
        "kilt_tasks/hotpotqa": 0.11621285229921341
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14408,
        "ag_news": 15208,
        "amazon_polarity": 14712,
        "cnn_dailymail/3.0.0": 15376,
        "common_gen": 15096,
        "cos_e/v1.11": 14845,
        "glue/mrpc": 14420,
        "kilt_tasks/hotpotqa": 14960
      },
      "step": 930
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -28.167098999023438,
        "ag_news": 68.66600036621094,
        "amazon_polarity": 72.61336517333984,
        "cnn_dailymail/3.0.0": 184.90753173828125,
        "common_gen": 38.45558166503906,
        "cos_e/v1.11": -9.470318794250488,
        "glue/mrpc": 17.398151397705078,
        "kilt_tasks/hotpotqa": -13.779970169067383
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0851,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11377033591270447,
        "ag_news": 0.1290542185306549,
        "amazon_polarity": 0.12971952557563782,
        "cnn_dailymail/3.0.0": 0.1501692533493042,
        "common_gen": 0.12407524883747101,
        "cos_e/v1.11": 0.11657165735960007,
        "glue/mrpc": 0.12071999907493591,
        "kilt_tasks/hotpotqa": 0.1159198209643364
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14616,
        "ag_news": 15376,
        "amazon_polarity": 14880,
        "cnn_dailymail/3.0.0": 15536,
        "common_gen": 15248,
        "cos_e/v1.11": 14989,
        "glue/mrpc": 14540,
        "kilt_tasks/hotpotqa": 15120
      },
      "step": 940
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -30.341339111328125,
        "ag_news": 68.21907806396484,
        "amazon_polarity": 72.43659210205078,
        "cnn_dailymail/3.0.0": 186.43331909179688,
        "common_gen": 36.87132263183594,
        "cos_e/v1.11": -4.111956596374512,
        "glue/mrpc": 14.588757514953613,
        "kilt_tasks/hotpotqa": -15.074493408203125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0921,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.113531693816185,
        "ag_news": 0.12898661196231842,
        "amazon_polarity": 0.12969346344470978,
        "cnn_dailymail/3.0.0": 0.15035571157932281,
        "common_gen": 0.12385320663452148,
        "cos_e/v1.11": 0.11745192855596542,
        "glue/mrpc": 0.12033027410507202,
        "kilt_tasks/hotpotqa": 0.11579708009958267
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14792,
        "ag_news": 15512,
        "amazon_polarity": 15032,
        "cnn_dailymail/3.0.0": 15696,
        "common_gen": 15392,
        "cos_e/v1.11": 15125,
        "glue/mrpc": 14744,
        "kilt_tasks/hotpotqa": 15288
      },
      "step": 950
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -35.95429229736328,
        "ag_news": 68.0776596069336,
        "amazon_polarity": 72.1927261352539,
        "cnn_dailymail/3.0.0": 187.6683349609375,
        "common_gen": 34.024169921875,
        "cos_e/v1.11": -4.557455062866211,
        "glue/mrpc": 18.499557495117188,
        "kilt_tasks/hotpotqa": -16.611572265625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9167,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11286116391420364,
        "ag_news": 0.12904596328735352,
        "amazon_polarity": 0.12973234057426453,
        "cnn_dailymail/3.0.0": 0.1505727618932724,
        "common_gen": 0.1235048845410347,
        "cos_e/v1.11": 0.11751686781644821,
        "glue/mrpc": 0.12105917185544968,
        "kilt_tasks/hotpotqa": 0.11570686846971512
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14976,
        "ag_news": 15712,
        "amazon_polarity": 15232,
        "cnn_dailymail/3.0.0": 15816,
        "common_gen": 15552,
        "cos_e/v1.11": 15269,
        "glue/mrpc": 14904,
        "kilt_tasks/hotpotqa": 15400
      },
      "step": 960
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -34.72599792480469,
        "ag_news": 67.75541687011719,
        "amazon_polarity": 72.13818359375,
        "cnn_dailymail/3.0.0": 189.01296997070312,
        "common_gen": 31.118621826171875,
        "cos_e/v1.11": -5.233577728271484,
        "glue/mrpc": 17.246437072753906,
        "kilt_tasks/hotpotqa": -18.689016342163086
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1736,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11317794770002365,
        "ag_news": 0.1290629357099533,
        "amazon_polarity": 0.12979042530059814,
        "cnn_dailymail/3.0.0": 0.1507958471775055,
        "common_gen": 0.12314045429229736,
        "cos_e/v1.11": 0.11753533780574799,
        "glue/mrpc": 0.12097031623125076,
        "kilt_tasks/hotpotqa": 0.11552668362855911
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15128,
        "ag_news": 15880,
        "amazon_polarity": 15376,
        "cnn_dailymail/3.0.0": 16008,
        "common_gen": 15720,
        "cos_e/v1.11": 15437,
        "glue/mrpc": 15016,
        "kilt_tasks/hotpotqa": 15576
      },
      "step": 970
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -39.204261779785156,
        "ag_news": 67.51514434814453,
        "amazon_polarity": 72.247314453125,
        "cnn_dailymail/3.0.0": 194.35870361328125,
        "common_gen": 33.42544937133789,
        "cos_e/v1.11": -7.776023864746094,
        "glue/mrpc": 18.845359802246094,
        "kilt_tasks/hotpotqa": -18.944860458374023
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1919,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11253014206886292,
        "ag_news": 0.12893299758434296,
        "amazon_polarity": 0.12971387803554535,
        "cnn_dailymail/3.0.0": 0.15160301327705383,
        "common_gen": 0.12344621121883392,
        "cos_e/v1.11": 0.11712860316038132,
        "glue/mrpc": 0.12117213010787964,
        "kilt_tasks/hotpotqa": 0.11547304689884186
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15320,
        "ag_news": 16048,
        "amazon_polarity": 15496,
        "cnn_dailymail/3.0.0": 16232,
        "common_gen": 15848,
        "cos_e/v1.11": 15621,
        "glue/mrpc": 15152,
        "kilt_tasks/hotpotqa": 15704
      },
      "step": 980
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -38.53495788574219,
        "ag_news": 67.1856460571289,
        "amazon_polarity": 72.13411712646484,
        "cnn_dailymail/3.0.0": 197.3679962158203,
        "common_gen": 36.7348518371582,
        "cos_e/v1.11": -12.852056503295898,
        "glue/mrpc": 18.521530151367188,
        "kilt_tasks/hotpotqa": -18.220069885253906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1241,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11263929307460785,
        "ag_news": 0.12880662083625793,
        "amazon_polarity": 0.12961839139461517,
        "cnn_dailymail/3.0.0": 0.1519746482372284,
        "common_gen": 0.12392312288284302,
        "cos_e/v1.11": 0.11636769771575928,
        "glue/mrpc": 0.12109202891588211,
        "kilt_tasks/hotpotqa": 0.11557823419570923
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15512,
        "ag_news": 16256,
        "amazon_polarity": 15608,
        "cnn_dailymail/3.0.0": 16376,
        "common_gen": 15960,
        "cos_e/v1.11": 15829,
        "glue/mrpc": 15312,
        "kilt_tasks/hotpotqa": 15848
      },
      "step": 990
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -37.488826751708984,
        "ag_news": 67.0012435913086,
        "amazon_polarity": 71.99320220947266,
        "cnn_dailymail/3.0.0": 200.21917724609375,
        "common_gen": 42.67620849609375,
        "cos_e/v1.11": -10.729076385498047,
        "glue/mrpc": 18.797168731689453,
        "kilt_tasks/hotpotqa": -24.01216697692871
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1348,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11272599548101425,
        "ag_news": 0.12861989438533783,
        "amazon_polarity": 0.1294335275888443,
        "cnn_dailymail/3.0.0": 0.1522124856710434,
        "common_gen": 0.12472841143608093,
        "cos_e/v1.11": 0.11659681051969528,
        "glue/mrpc": 0.12102397531270981,
        "kilt_tasks/hotpotqa": 0.1146588921546936
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15648,
        "ag_news": 16384,
        "amazon_polarity": 15768,
        "cnn_dailymail/3.0.0": 16552,
        "common_gen": 16096,
        "cos_e/v1.11": 16037,
        "glue/mrpc": 15520,
        "kilt_tasks/hotpotqa": 15976
      },
      "step": 1000
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1922,
      "eval_samples_per_second": 83.258,
      "eval_steps_per_second": 5.204,
      "step": 1000
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -42.26828384399414,
        "ag_news": 66.7642593383789,
        "amazon_polarity": 72.02545928955078,
        "cnn_dailymail/3.0.0": 200.8966522216797,
        "common_gen": 43.463356018066406,
        "cos_e/v1.11": -9.591611862182617,
        "glue/mrpc": 17.71317481994629,
        "kilt_tasks/hotpotqa": -26.204822540283203
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1577,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11219717562198639,
        "ag_news": 0.12866510450839996,
        "amazon_polarity": 0.12951885163784027,
        "cnn_dailymail/3.0.0": 0.1523149460554123,
        "common_gen": 0.12495182454586029,
        "cos_e/v1.11": 0.1168956458568573,
        "glue/mrpc": 0.12097398936748505,
        "kilt_tasks/hotpotqa": 0.11448254436254501
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15800,
        "ag_news": 16512,
        "amazon_polarity": 15920,
        "cnn_dailymail/3.0.0": 16688,
        "common_gen": 16256,
        "cos_e/v1.11": 16277,
        "glue/mrpc": 15712,
        "kilt_tasks/hotpotqa": 16096
      },
      "step": 1010
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -41.75947189331055,
        "ag_news": 67.01488494873047,
        "amazon_polarity": 71.96149444580078,
        "cnn_dailymail/3.0.0": 201.52459716796875,
        "common_gen": 42.69778823852539,
        "cos_e/v1.11": -11.503511428833008,
        "glue/mrpc": 17.50143051147461,
        "kilt_tasks/hotpotqa": -25.850317001342773
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.107,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11234782636165619,
        "ag_news": 0.12871053814888,
        "amazon_polarity": 0.12950944900512695,
        "cnn_dailymail/3.0.0": 0.15231531858444214,
        "common_gen": 0.12485503405332565,
        "cos_e/v1.11": 0.11667581647634506,
        "glue/mrpc": 0.12098309397697449,
        "kilt_tasks/hotpotqa": 0.1146029382944107
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15952,
        "ag_news": 16688,
        "amazon_polarity": 16128,
        "cnn_dailymail/3.0.0": 16824,
        "common_gen": 16400,
        "cos_e/v1.11": 16437,
        "glue/mrpc": 15808,
        "kilt_tasks/hotpotqa": 16304
      },
      "step": 1020
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.224727630615234,
        "ag_news": 66.88219451904297,
        "amazon_polarity": 71.87857818603516,
        "cnn_dailymail/3.0.0": 204.28167724609375,
        "common_gen": 43.729347229003906,
        "cos_e/v1.11": -4.338849067687988,
        "glue/mrpc": 17.348346710205078,
        "kilt_tasks/hotpotqa": -24.880590438842773
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.111,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11190029233694077,
        "ag_news": 0.1284855157136917,
        "amazon_polarity": 0.12928715348243713,
        "cnn_dailymail/3.0.0": 0.15247319638729095,
        "common_gen": 0.12483581155538559,
        "cos_e/v1.11": 0.11758947372436523,
        "glue/mrpc": 0.12080469727516174,
        "kilt_tasks/hotpotqa": 0.11462385207414627
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16104,
        "ag_news": 16880,
        "amazon_polarity": 16280,
        "cnn_dailymail/3.0.0": 17016,
        "common_gen": 16544,
        "cos_e/v1.11": 16581,
        "glue/mrpc": 15952,
        "kilt_tasks/hotpotqa": 16464
      },
      "step": 1030
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -43.86647033691406,
        "ag_news": 66.8002700805664,
        "amazon_polarity": 71.75871276855469,
        "cnn_dailymail/3.0.0": 204.6385040283203,
        "common_gen": 44.724056243896484,
        "cos_e/v1.11": -6.398616790771484,
        "glue/mrpc": 20.300939559936523,
        "kilt_tasks/hotpotqa": -26.824541091918945
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0692,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11199958622455597,
        "ag_news": 0.12844467163085938,
        "amazon_polarity": 0.1292361319065094,
        "cnn_dailymail/3.0.0": 0.15238270163536072,
        "common_gen": 0.1249798834323883,
        "cos_e/v1.11": 0.11731436103582382,
        "glue/mrpc": 0.12125661224126816,
        "kilt_tasks/hotpotqa": 0.11438610404729843
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16248,
        "ag_news": 17096,
        "amazon_polarity": 16448,
        "cnn_dailymail/3.0.0": 17184,
        "common_gen": 16704,
        "cos_e/v1.11": 16717,
        "glue/mrpc": 16072,
        "kilt_tasks/hotpotqa": 16632
      },
      "step": 1040
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.987892150878906,
        "ag_news": 66.77008056640625,
        "amazon_polarity": 71.80229949951172,
        "cnn_dailymail/3.0.0": 205.42799377441406,
        "common_gen": 42.120540618896484,
        "cos_e/v1.11": -3.14675235748291,
        "glue/mrpc": 22.844675064086914,
        "kilt_tasks/hotpotqa": -27.558330535888672
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0852,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11186705529689789,
        "ag_news": 0.1283818781375885,
        "amazon_polarity": 0.1291809380054474,
        "cnn_dailymail/3.0.0": 0.15233880281448364,
        "common_gen": 0.12453930079936981,
        "cos_e/v1.11": 0.1177826002240181,
        "glue/mrpc": 0.12161551415920258,
        "kilt_tasks/hotpotqa": 0.11429387331008911
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16392,
        "ag_news": 17280,
        "amazon_polarity": 16632,
        "cnn_dailymail/3.0.0": 17288,
        "common_gen": 16880,
        "cos_e/v1.11": 16869,
        "glue/mrpc": 16224,
        "kilt_tasks/hotpotqa": 16816
      },
      "step": 1050
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -48.09892654418945,
        "ag_news": 66.67945098876953,
        "amazon_polarity": 71.81800079345703,
        "cnn_dailymail/3.0.0": 205.64642333984375,
        "common_gen": 45.980125427246094,
        "cos_e/v1.11": -1.727374792098999,
        "glue/mrpc": 23.777252197265625,
        "kilt_tasks/hotpotqa": -33.044898986816406
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9945,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11152701079845428,
        "ag_news": 0.12838341295719147,
        "amazon_polarity": 0.12919558584690094,
        "cnn_dailymail/3.0.0": 0.15227606892585754,
        "common_gen": 0.12516367435455322,
        "cos_e/v1.11": 0.11804994940757751,
        "glue/mrpc": 0.12180063128471375,
        "kilt_tasks/hotpotqa": 0.11360366642475128
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16616,
        "ag_news": 17472,
        "amazon_polarity": 16816,
        "cnn_dailymail/3.0.0": 17416,
        "common_gen": 16968,
        "cos_e/v1.11": 17021,
        "glue/mrpc": 16384,
        "kilt_tasks/hotpotqa": 16968
      },
      "step": 1060
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -46.89651870727539,
        "ag_news": 66.70588684082031,
        "amazon_polarity": 71.85818481445312,
        "cnn_dailymail/3.0.0": 206.9009552001953,
        "common_gen": 46.90549087524414,
        "cos_e/v1.11": -3.4727301597595215,
        "glue/mrpc": 22.65386199951172,
        "kilt_tasks/hotpotqa": -27.243303298950195
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1585,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11164749413728714,
        "ag_news": 0.12825390696525574,
        "amazon_polarity": 0.12906363606452942,
        "cnn_dailymail/3.0.0": 0.15222994983196259,
        "common_gen": 0.12518955767154694,
        "cos_e/v1.11": 0.11772208660840988,
        "glue/mrpc": 0.12153684347867966,
        "kilt_tasks/hotpotqa": 0.11435654759407043
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16776,
        "ag_news": 17632,
        "amazon_polarity": 16904,
        "cnn_dailymail/3.0.0": 17560,
        "common_gen": 17152,
        "cos_e/v1.11": 17197,
        "glue/mrpc": 16584,
        "kilt_tasks/hotpotqa": 17136
      },
      "step": 1070
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -45.20695114135742,
        "ag_news": 66.60030364990234,
        "amazon_polarity": 71.73563385009766,
        "cnn_dailymail/3.0.0": 209.2367706298828,
        "common_gen": 45.661521911621094,
        "cos_e/v1.11": -5.458803176879883,
        "glue/mrpc": 23.190414428710938,
        "kilt_tasks/hotpotqa": -27.736698150634766
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0394,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11191873252391815,
        "ag_news": 0.12820374965667725,
        "amazon_polarity": 0.1290067583322525,
        "cnn_dailymail/3.0.0": 0.15250281989574432,
        "common_gen": 0.12498146295547485,
        "cos_e/v1.11": 0.11745387315750122,
        "glue/mrpc": 0.12161428481340408,
        "kilt_tasks/hotpotqa": 0.11431832611560822
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16912,
        "ag_news": 17800,
        "amazon_polarity": 17128,
        "cnn_dailymail/3.0.0": 17712,
        "common_gen": 17336,
        "cos_e/v1.11": 17333,
        "glue/mrpc": 16720,
        "kilt_tasks/hotpotqa": 17280
      },
      "step": 1080
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -50.12815475463867,
        "ag_news": 66.4026107788086,
        "amazon_polarity": 71.5196304321289,
        "cnn_dailymail/3.0.0": 211.3376007080078,
        "common_gen": 44.32200241088867,
        "cos_e/v1.11": -5.497809410095215,
        "glue/mrpc": 23.631107330322266,
        "kilt_tasks/hotpotqa": -29.702207565307617
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1324,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11139730364084244,
        "ag_news": 0.12825767695903778,
        "amazon_polarity": 0.1290544867515564,
        "cnn_dailymail/3.0.0": 0.15287145972251892,
        "common_gen": 0.12487588822841644,
        "cos_e/v1.11": 0.11757270246744156,
        "glue/mrpc": 0.12178869545459747,
        "kilt_tasks/hotpotqa": 0.11418183147907257
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17088,
        "ag_news": 17936,
        "amazon_polarity": 17296,
        "cnn_dailymail/3.0.0": 17952,
        "common_gen": 17424,
        "cos_e/v1.11": 17501,
        "glue/mrpc": 16872,
        "kilt_tasks/hotpotqa": 17432
      },
      "step": 1090
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.6950798034668,
        "ag_news": 66.36236572265625,
        "amazon_polarity": 71.31549835205078,
        "cnn_dailymail/3.0.0": 210.33981323242188,
        "common_gen": 44.685333251953125,
        "cos_e/v1.11": -5.971712589263916,
        "glue/mrpc": 23.419902801513672,
        "kilt_tasks/hotpotqa": -30.273601531982422
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0111,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11214511841535568,
        "ag_news": 0.12818953394889832,
        "amazon_polarity": 0.1289568394422531,
        "cnn_dailymail/3.0.0": 0.1524924337863922,
        "common_gen": 0.12488533556461334,
        "cos_e/v1.11": 0.11749511957168579,
        "glue/mrpc": 0.12172743678092957,
        "kilt_tasks/hotpotqa": 0.11410819739103317
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17208,
        "ag_news": 18168,
        "amazon_polarity": 17448,
        "cnn_dailymail/3.0.0": 18096,
        "common_gen": 17520,
        "cos_e/v1.11": 17661,
        "glue/mrpc": 17056,
        "kilt_tasks/hotpotqa": 17624
      },
      "step": 1100
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1755,
      "eval_samples_per_second": 91.186,
      "eval_steps_per_second": 5.699,
      "step": 1100
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -45.587615966796875,
        "ag_news": 66.31440734863281,
        "amazon_polarity": 71.19734191894531,
        "cnn_dailymail/3.0.0": 210.48052978515625,
        "common_gen": 40.93166732788086,
        "cos_e/v1.11": -9.342846870422363,
        "glue/mrpc": 23.271207809448242,
        "kilt_tasks/hotpotqa": -26.239267349243164
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1819,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11215170472860336,
        "ag_news": 0.12825016677379608,
        "amazon_polarity": 0.12900350987911224,
        "cnn_dailymail/3.0.0": 0.15248045325279236,
        "common_gen": 0.12440496683120728,
        "cos_e/v1.11": 0.11712910234928131,
        "glue/mrpc": 0.12179847806692123,
        "kilt_tasks/hotpotqa": 0.11478158086538315
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17424,
        "ag_news": 18288,
        "amazon_polarity": 17592,
        "cnn_dailymail/3.0.0": 18240,
        "common_gen": 17688,
        "cos_e/v1.11": 17853,
        "glue/mrpc": 17192,
        "kilt_tasks/hotpotqa": 17784
      },
      "step": 1110
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -46.633243560791016,
        "ag_news": 66.35682678222656,
        "amazon_polarity": 71.06182861328125,
        "cnn_dailymail/3.0.0": 210.24819946289062,
        "common_gen": 39.886322021484375,
        "cos_e/v1.11": -8.659019470214844,
        "glue/mrpc": 19.99249267578125,
        "kilt_tasks/hotpotqa": -26.51029396057129
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.084,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11215416342020035,
        "ag_news": 0.12834325432777405,
        "amazon_polarity": 0.1290663778781891,
        "cnn_dailymail/3.0.0": 0.15242382884025574,
        "common_gen": 0.12435048073530197,
        "cos_e/v1.11": 0.1173509806394577,
        "glue/mrpc": 0.12143246829509735,
        "kilt_tasks/hotpotqa": 0.11487836390733719
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17632,
        "ag_news": 18384,
        "amazon_polarity": 17728,
        "cnn_dailymail/3.0.0": 18416,
        "common_gen": 17776,
        "cos_e/v1.11": 18013,
        "glue/mrpc": 17488,
        "kilt_tasks/hotpotqa": 17904
      },
      "step": 1120
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -53.076290130615234,
        "ag_news": 66.28515625,
        "amazon_polarity": 70.95952606201172,
        "cnn_dailymail/3.0.0": 212.29286193847656,
        "common_gen": 39.533973693847656,
        "cos_e/v1.11": -7.167669296264648,
        "glue/mrpc": 21.95313835144043,
        "kilt_tasks/hotpotqa": -29.54349136352539
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.958,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11140862852334976,
        "ag_news": 0.1283821016550064,
        "amazon_polarity": 0.12909755110740662,
        "cnn_dailymail/3.0.0": 0.15273889899253845,
        "common_gen": 0.12436389923095703,
        "cos_e/v1.11": 0.11765090376138687,
        "glue/mrpc": 0.12179252505302429,
        "kilt_tasks/hotpotqa": 0.11456545442342758
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17736,
        "ag_news": 18616,
        "amazon_polarity": 17952,
        "cnn_dailymail/3.0.0": 18536,
        "common_gen": 17928,
        "cos_e/v1.11": 18229,
        "glue/mrpc": 17616,
        "kilt_tasks/hotpotqa": 18008
      },
      "step": 1130
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -55.76275634765625,
        "ag_news": 66.21084594726562,
        "amazon_polarity": 70.88488006591797,
        "cnn_dailymail/3.0.0": 214.81039428710938,
        "common_gen": 33.223514556884766,
        "cos_e/v1.11": -16.771896362304688,
        "glue/mrpc": 20.481273651123047,
        "kilt_tasks/hotpotqa": -29.138715744018555
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0794,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11137267202138901,
        "ag_news": 0.12865842878818512,
        "amazon_polarity": 0.1293722540140152,
        "cnn_dailymail/3.0.0": 0.15342271327972412,
        "common_gen": 0.12373235076665878,
        "cos_e/v1.11": 0.11662691086530685,
        "glue/mrpc": 0.1218808963894844,
        "kilt_tasks/hotpotqa": 0.11493383347988129
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17968,
        "ag_news": 18776,
        "amazon_polarity": 18128,
        "cnn_dailymail/3.0.0": 18688,
        "common_gen": 18048,
        "cos_e/v1.11": 18373,
        "glue/mrpc": 17784,
        "kilt_tasks/hotpotqa": 18136
      },
      "step": 1140
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -56.835906982421875,
        "ag_news": 66.09805297851562,
        "amazon_polarity": 70.94524383544922,
        "cnn_dailymail/3.0.0": 216.78688049316406,
        "common_gen": 34.6954460144043,
        "cos_e/v1.11": -20.101547241210938,
        "glue/mrpc": 16.987619400024414,
        "kilt_tasks/hotpotqa": -31.799930572509766
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.153,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11138911545276642,
        "ag_news": 0.12874282896518707,
        "amazon_polarity": 0.12948045134544373,
        "cnn_dailymail/3.0.0": 0.15378530323505402,
        "common_gen": 0.1240658238530159,
        "cos_e/v1.11": 0.1163114681839943,
        "glue/mrpc": 0.12150449305772781,
        "kilt_tasks/hotpotqa": 0.11472050100564957
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18104,
        "ag_news": 18912,
        "amazon_polarity": 18288,
        "cnn_dailymail/3.0.0": 18848,
        "common_gen": 18216,
        "cos_e/v1.11": 18541,
        "glue/mrpc": 17936,
        "kilt_tasks/hotpotqa": 18336
      },
      "step": 1150
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -55.56575012207031,
        "ag_news": 66.07276916503906,
        "amazon_polarity": 71.0256576538086,
        "cnn_dailymail/3.0.0": 218.45016479492188,
        "common_gen": 34.62876892089844,
        "cos_e/v1.11": -16.500642776489258,
        "glue/mrpc": 17.192712783813477,
        "kilt_tasks/hotpotqa": -34.42269515991211
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1541,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11154171824455261,
        "ag_news": 0.12864375114440918,
        "amazon_polarity": 0.12939368188381195,
        "cnn_dailymail/3.0.0": 0.1538545936346054,
        "common_gen": 0.12398400902748108,
        "cos_e/v1.11": 0.11676798015832901,
        "glue/mrpc": 0.12147396802902222,
        "kilt_tasks/hotpotqa": 0.11434027552604675
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18248,
        "ag_news": 19024,
        "amazon_polarity": 18448,
        "cnn_dailymail/3.0.0": 19024,
        "common_gen": 18352,
        "cos_e/v1.11": 18765,
        "glue/mrpc": 18096,
        "kilt_tasks/hotpotqa": 18504
      },
      "step": 1160
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -59.655757904052734,
        "ag_news": 66.0983657836914,
        "amazon_polarity": 70.9780502319336,
        "cnn_dailymail/3.0.0": 222.486572265625,
        "common_gen": 34.45098876953125,
        "cos_e/v1.11": -16.737712860107422,
        "glue/mrpc": 15.20118522644043,
        "kilt_tasks/hotpotqa": -32.29478073120117
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1149,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11105138808488846,
        "ag_news": 0.12861688435077667,
        "amazon_polarity": 0.1293523907661438,
        "cnn_dailymail/3.0.0": 0.15442843735218048,
        "common_gen": 0.1239481046795845,
        "cos_e/v1.11": 0.11675582081079483,
        "glue/mrpc": 0.1211923360824585,
        "kilt_tasks/hotpotqa": 0.11465463042259216
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18392,
        "ag_news": 19176,
        "amazon_polarity": 18584,
        "cnn_dailymail/3.0.0": 19192,
        "common_gen": 18496,
        "cos_e/v1.11": 18957,
        "glue/mrpc": 18288,
        "kilt_tasks/hotpotqa": 18656
      },
      "step": 1170
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -54.674808502197266,
        "ag_news": 65.83930206298828,
        "amazon_polarity": 70.25395965576172,
        "cnn_dailymail/3.0.0": 222.0990447998047,
        "common_gen": 32.2907600402832,
        "cos_e/v1.11": -15.066936492919922,
        "glue/mrpc": 13.743399620056152,
        "kilt_tasks/hotpotqa": -39.781585693359375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.105,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11184956878423691,
        "ag_news": 0.12867549061775208,
        "amazon_polarity": 0.12933821976184845,
        "cnn_dailymail/3.0.0": 0.15435658395290375,
        "common_gen": 0.12374991923570633,
        "cos_e/v1.11": 0.11711905151605606,
        "glue/mrpc": 0.12110894173383713,
        "kilt_tasks/hotpotqa": 0.11380228400230408
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18528,
        "ag_news": 19336,
        "amazon_polarity": 18752,
        "cnn_dailymail/3.0.0": 19384,
        "common_gen": 18640,
        "cos_e/v1.11": 19117,
        "glue/mrpc": 18412,
        "kilt_tasks/hotpotqa": 18848
      },
      "step": 1180
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -56.19298553466797,
        "ag_news": 65.83695220947266,
        "amazon_polarity": 69.75951385498047,
        "cnn_dailymail/3.0.0": 222.00656127929688,
        "common_gen": 29.08418083190918,
        "cos_e/v1.11": -10.497516632080078,
        "glue/mrpc": 12.850812911987305,
        "kilt_tasks/hotpotqa": -41.51813507080078
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2022,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11176077276468277,
        "ag_news": 0.12872382998466492,
        "amazon_polarity": 0.1293102651834488,
        "cnn_dailymail/3.0.0": 0.15428096055984497,
        "common_gen": 0.1233578622341156,
        "cos_e/v1.11": 0.11783108115196228,
        "glue/mrpc": 0.12106022983789444,
        "kilt_tasks/hotpotqa": 0.11367497593164444
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18720,
        "ag_news": 19448,
        "amazon_polarity": 18864,
        "cnn_dailymail/3.0.0": 19512,
        "common_gen": 18848,
        "cos_e/v1.11": 19317,
        "glue/mrpc": 18580,
        "kilt_tasks/hotpotqa": 19008
      },
      "step": 1190
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -54.089962005615234,
        "ag_news": 65.75945281982422,
        "amazon_polarity": 69.71701049804688,
        "cnn_dailymail/3.0.0": 223.63580322265625,
        "common_gen": 27.830427169799805,
        "cos_e/v1.11": -5.827673435211182,
        "glue/mrpc": 10.341591835021973,
        "kilt_tasks/hotpotqa": -36.237369537353516
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0925,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11193560063838959,
        "ag_news": 0.12852619588375092,
        "amazon_polarity": 0.12911450862884521,
        "cnn_dailymail/3.0.0": 0.15423190593719482,
        "common_gen": 0.12302324175834656,
        "cos_e/v1.11": 0.11833937466144562,
        "glue/mrpc": 0.12056659162044525,
        "kilt_tasks/hotpotqa": 0.11426257342100143
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18840,
        "ag_news": 19632,
        "amazon_polarity": 18992,
        "cnn_dailymail/3.0.0": 19664,
        "common_gen": 19056,
        "cos_e/v1.11": 19453,
        "glue/mrpc": 18764,
        "kilt_tasks/hotpotqa": 19176
      },
      "step": 1200
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.2089,
      "eval_samples_per_second": 76.582,
      "eval_steps_per_second": 4.786,
      "step": 1200
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -62.65269470214844,
        "ag_news": 65.59465026855469,
        "amazon_polarity": 69.63671112060547,
        "cnn_dailymail/3.0.0": 226.6465301513672,
        "common_gen": 24.39453887939453,
        "cos_e/v1.11": -6.777770519256592,
        "glue/mrpc": 13.485872268676758,
        "kilt_tasks/hotpotqa": -38.27195358276367
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0789,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11100883036851883,
        "ag_news": 0.12862356007099152,
        "amazon_polarity": 0.12922245264053345,
        "cnn_dailymail/3.0.0": 0.15479788184165955,
        "common_gen": 0.12267671525478363,
        "cos_e/v1.11": 0.11836235970258713,
        "glue/mrpc": 0.12114914506673813,
        "kilt_tasks/hotpotqa": 0.114158995449543
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18976,
        "ag_news": 19800,
        "amazon_polarity": 19152,
        "cnn_dailymail/3.0.0": 19832,
        "common_gen": 19200,
        "cos_e/v1.11": 19642,
        "glue/mrpc": 18940,
        "kilt_tasks/hotpotqa": 19312
      },
      "step": 1210
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -61.95122146606445,
        "ag_news": 65.50870513916016,
        "amazon_polarity": 69.41817474365234,
        "cnn_dailymail/3.0.0": 226.93467712402344,
        "common_gen": 24.06749725341797,
        "cos_e/v1.11": -9.43673324584961,
        "glue/mrpc": 9.628715515136719,
        "kilt_tasks/hotpotqa": -35.48575973510742
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0523,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11120707541704178,
        "ag_news": 0.12866026163101196,
        "amazon_polarity": 0.12923726439476013,
        "cnn_dailymail/3.0.0": 0.15479141473770142,
        "common_gen": 0.12270151078701019,
        "cos_e/v1.11": 0.11808820068836212,
        "glue/mrpc": 0.12069147825241089,
        "kilt_tasks/hotpotqa": 0.11462276428937912
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19128,
        "ag_news": 20008,
        "amazon_polarity": 19280,
        "cnn_dailymail/3.0.0": 19936,
        "common_gen": 19376,
        "cos_e/v1.11": 19834,
        "glue/mrpc": 19100,
        "kilt_tasks/hotpotqa": 19472
      },
      "step": 1220
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.36015319824219,
        "ag_news": 65.2980728149414,
        "amazon_polarity": 69.40522003173828,
        "cnn_dailymail/3.0.0": 227.93423461914062,
        "common_gen": 24.431806564331055,
        "cos_e/v1.11": -12.952783584594727,
        "glue/mrpc": 12.330047607421875,
        "kilt_tasks/hotpotqa": -35.643985748291016
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9736,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11143284291028976,
        "ag_news": 0.12858150899410248,
        "amazon_polarity": 0.12918491661548615,
        "cnn_dailymail/3.0.0": 0.15479446947574615,
        "common_gen": 0.1227303296327591,
        "cos_e/v1.11": 0.11761325597763062,
        "glue/mrpc": 0.12104973196983337,
        "kilt_tasks/hotpotqa": 0.11461298912763596
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19328,
        "ag_news": 20200,
        "amazon_polarity": 19416,
        "cnn_dailymail/3.0.0": 20088,
        "common_gen": 19480,
        "cos_e/v1.11": 19986,
        "glue/mrpc": 19300,
        "kilt_tasks/hotpotqa": 19616
      },
      "step": 1230
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -61.56828689575195,
        "ag_news": 65.2398452758789,
        "amazon_polarity": 69.32535552978516,
        "cnn_dailymail/3.0.0": 227.10775756835938,
        "common_gen": 25.295726776123047,
        "cos_e/v1.11": -8.97279167175293,
        "glue/mrpc": 12.526496887207031,
        "kilt_tasks/hotpotqa": -32.66307067871094
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0748,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11125043034553528,
        "ag_news": 0.12846465408802032,
        "amazon_polarity": 0.12906192243099213,
        "cnn_dailymail/3.0.0": 0.154403418302536,
        "common_gen": 0.12277014553546906,
        "cos_e/v1.11": 0.11808817833662033,
        "glue/mrpc": 0.12100402265787125,
        "kilt_tasks/hotpotqa": 0.11495725810527802
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19464,
        "ag_news": 20368,
        "amazon_polarity": 19536,
        "cnn_dailymail/3.0.0": 20264,
        "common_gen": 19656,
        "cos_e/v1.11": 20090,
        "glue/mrpc": 19492,
        "kilt_tasks/hotpotqa": 19824
      },
      "step": 1240
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -62.52009963989258,
        "ag_news": 65.18524169921875,
        "amazon_polarity": 69.0112533569336,
        "cnn_dailymail/3.0.0": 226.9787139892578,
        "common_gen": 24.88431167602539,
        "cos_e/v1.11": -9.25220012664795,
        "glue/mrpc": 9.87962818145752,
        "kilt_tasks/hotpotqa": -37.626834869384766
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0551,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11132851243019104,
        "ag_news": 0.12861181795597076,
        "amazon_polarity": 0.12916947901248932,
        "cnn_dailymail/3.0.0": 0.1544542908668518,
        "common_gen": 0.12288330495357513,
        "cos_e/v1.11": 0.11823287606239319,
        "glue/mrpc": 0.12081687897443771,
        "kilt_tasks/hotpotqa": 0.11450289189815521
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19632,
        "ag_news": 20520,
        "amazon_polarity": 19640,
        "cnn_dailymail/3.0.0": 20472,
        "common_gen": 19744,
        "cos_e/v1.11": 20250,
        "glue/mrpc": 19716,
        "kilt_tasks/hotpotqa": 20000
      },
      "step": 1250
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -63.02324295043945,
        "ag_news": 65.05258178710938,
        "amazon_polarity": 69.23030090332031,
        "cnn_dailymail/3.0.0": 226.69720458984375,
        "common_gen": 26.080528259277344,
        "cos_e/v1.11": -13.03759479522705,
        "glue/mrpc": 9.946468353271484,
        "kilt_tasks/hotpotqa": -39.73276138305664
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9734,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11139620095491409,
        "ag_news": 0.12867051362991333,
        "amazon_polarity": 0.12927742302417755,
        "cnn_dailymail/3.0.0": 0.15438717603683472,
        "common_gen": 0.12314558029174805,
        "cos_e/v1.11": 0.11784062534570694,
        "glue/mrpc": 0.12092896550893784,
        "kilt_tasks/hotpotqa": 0.11435342580080032
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19760,
        "ag_news": 20712,
        "amazon_polarity": 19808,
        "cnn_dailymail/3.0.0": 20656,
        "common_gen": 19880,
        "cos_e/v1.11": 20434,
        "glue/mrpc": 19868,
        "kilt_tasks/hotpotqa": 20136
      },
      "step": 1260
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.65855407714844,
        "ag_news": 65.10047912597656,
        "amazon_polarity": 69.27448272705078,
        "cnn_dailymail/3.0.0": 229.9076690673828,
        "common_gen": 32.67079544067383,
        "cos_e/v1.11": -14.01223373413086,
        "glue/mrpc": 9.88897705078125,
        "kilt_tasks/hotpotqa": -42.51130294799805
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9399,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11060470342636108,
        "ag_news": 0.12864388525485992,
        "amazon_polarity": 0.1292477548122406,
        "cnn_dailymail/3.0.0": 0.15479400753974915,
        "common_gen": 0.1240481287240982,
        "cos_e/v1.11": 0.11772177368402481,
        "glue/mrpc": 0.12091901898384094,
        "kilt_tasks/hotpotqa": 0.11402080953121185
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19968,
        "ag_news": 20848,
        "amazon_polarity": 20008,
        "cnn_dailymail/3.0.0": 20760,
        "common_gen": 20032,
        "cos_e/v1.11": 20570,
        "glue/mrpc": 20052,
        "kilt_tasks/hotpotqa": 20296
      },
      "step": 1270
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -71.08800506591797,
        "ag_news": 65.21490478515625,
        "amazon_polarity": 69.17525482177734,
        "cnn_dailymail/3.0.0": 229.4476776123047,
        "common_gen": 32.27783203125,
        "cos_e/v1.11": -12.860687255859375,
        "glue/mrpc": 9.829330444335938,
        "kilt_tasks/hotpotqa": -41.7210693359375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9503,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1104901060461998,
        "ag_news": 0.1286567747592926,
        "amazon_polarity": 0.12922750413417816,
        "cnn_dailymail/3.0.0": 0.15459869801998138,
        "common_gen": 0.12400778383016586,
        "cos_e/v1.11": 0.11791060864925385,
        "glue/mrpc": 0.12093672156333923,
        "kilt_tasks/hotpotqa": 0.11417174339294434
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20104,
        "ag_news": 20960,
        "amazon_polarity": 20192,
        "cnn_dailymail/3.0.0": 20904,
        "common_gen": 20184,
        "cos_e/v1.11": 20658,
        "glue/mrpc": 20300,
        "kilt_tasks/hotpotqa": 20512
      },
      "step": 1280
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -71.55769348144531,
        "ag_news": 65.34442138671875,
        "amazon_polarity": 69.05330657958984,
        "cnn_dailymail/3.0.0": 230.22872924804688,
        "common_gen": 27.224184036254883,
        "cos_e/v1.11": -9.793428421020508,
        "glue/mrpc": 9.728793144226074,
        "kilt_tasks/hotpotqa": -41.967628479003906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0288,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11051570624113083,
        "ag_news": 0.1286969631910324,
        "amazon_polarity": 0.12922944128513336,
        "cnn_dailymail/3.0.0": 0.15464968979358673,
        "common_gen": 0.12335050106048584,
        "cos_e/v1.11": 0.11837323009967804,
        "glue/mrpc": 0.12097233533859253,
        "kilt_tasks/hotpotqa": 0.11421211808919907
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20288,
        "ag_news": 21120,
        "amazon_polarity": 20376,
        "cnn_dailymail/3.0.0": 21144,
        "common_gen": 20360,
        "cos_e/v1.11": 20770,
        "glue/mrpc": 20420,
        "kilt_tasks/hotpotqa": 20616
      },
      "step": 1290
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -71.2533187866211,
        "ag_news": 65.37117004394531,
        "amazon_polarity": 69.05550384521484,
        "cnn_dailymail/3.0.0": 230.5292205810547,
        "common_gen": 27.770179748535156,
        "cos_e/v1.11": -8.492525100708008,
        "glue/mrpc": 15.524316787719727,
        "kilt_tasks/hotpotqa": -42.998416900634766
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9055,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1104981079697609,
        "ag_news": 0.12856191396713257,
        "amazon_polarity": 0.12908828258514404,
        "cnn_dailymail/3.0.0": 0.15442541241645813,
        "common_gen": 0.1233120709657669,
        "cos_e/v1.11": 0.11845404654741287,
        "glue/mrpc": 0.12164942920207977,
        "kilt_tasks/hotpotqa": 0.11401083320379257
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20496,
        "ag_news": 21288,
        "amazon_polarity": 20552,
        "cnn_dailymail/3.0.0": 21272,
        "common_gen": 20504,
        "cos_e/v1.11": 20914,
        "glue/mrpc": 20604,
        "kilt_tasks/hotpotqa": 20744
      },
      "step": 1300
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1944,
      "eval_samples_per_second": 82.301,
      "eval_steps_per_second": 5.144,
      "step": 1300
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -73.22674560546875,
        "ag_news": 65.34318542480469,
        "amazon_polarity": 69.02095031738281,
        "cnn_dailymail/3.0.0": 230.16067504882812,
        "common_gen": 28.8435115814209,
        "cos_e/v1.11": -11.151890754699707,
        "glue/mrpc": 16.518484115600586,
        "kilt_tasks/hotpotqa": -43.52278518676758
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0573,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11036056280136108,
        "ag_news": 0.1286039650440216,
        "amazon_polarity": 0.12912756204605103,
        "cnn_dailymail/3.0.0": 0.1543102264404297,
        "common_gen": 0.1235220655798912,
        "cos_e/v1.11": 0.11818576604127884,
        "glue/mrpc": 0.12185219675302505,
        "kilt_tasks/hotpotqa": 0.11403755843639374
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20640,
        "ag_news": 21432,
        "amazon_polarity": 20680,
        "cnn_dailymail/3.0.0": 21432,
        "common_gen": 20672,
        "cos_e/v1.11": 21130,
        "glue/mrpc": 20796,
        "kilt_tasks/hotpotqa": 20872
      },
      "step": 1310
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -72.70640563964844,
        "ag_news": 65.23705291748047,
        "amazon_polarity": 69.13975524902344,
        "cnn_dailymail/3.0.0": 229.01683044433594,
        "common_gen": 30.756004333496094,
        "cos_e/v1.11": -16.578779220581055,
        "glue/mrpc": 14.463817596435547,
        "kilt_tasks/hotpotqa": -38.046600341796875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9675,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11049506068229675,
        "ag_news": 0.12859801948070526,
        "amazon_polarity": 0.1291516125202179,
        "cnn_dailymail/3.0.0": 0.154020756483078,
        "common_gen": 0.12380979210138321,
        "cos_e/v1.11": 0.11752816289663315,
        "glue/mrpc": 0.1216103658080101,
        "kilt_tasks/hotpotqa": 0.11478625237941742
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20832,
        "ag_news": 21552,
        "amazon_polarity": 20872,
        "cnn_dailymail/3.0.0": 21528,
        "common_gen": 20840,
        "cos_e/v1.11": 21338,
        "glue/mrpc": 20932,
        "kilt_tasks/hotpotqa": 21040
      },
      "step": 1320
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -74.01209259033203,
        "ag_news": 64.43514251708984,
        "amazon_polarity": 69.0156478881836,
        "cnn_dailymail/3.0.0": 228.5929718017578,
        "common_gen": 27.46645736694336,
        "cos_e/v1.11": -15.662784576416016,
        "glue/mrpc": 6.621242523193359,
        "kilt_tasks/hotpotqa": -38.73807144165039
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9652,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1105906069278717,
        "ag_news": 0.12870745360851288,
        "amazon_polarity": 0.1293555498123169,
        "cnn_dailymail/3.0.0": 0.15411189198493958,
        "common_gen": 0.1235952153801918,
        "cos_e/v1.11": 0.11788933724164963,
        "glue/mrpc": 0.12080346792936325,
        "kilt_tasks/hotpotqa": 0.11494650691747665
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20952,
        "ag_news": 21720,
        "amazon_polarity": 21040,
        "cnn_dailymail/3.0.0": 21680,
        "common_gen": 21000,
        "cos_e/v1.11": 21530,
        "glue/mrpc": 21092,
        "kilt_tasks/hotpotqa": 21200
      },
      "step": 1330
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -67.7540512084961,
        "ag_news": 64.37730407714844,
        "amazon_polarity": 68.8261489868164,
        "cnn_dailymail/3.0.0": 229.46815490722656,
        "common_gen": 32.02667236328125,
        "cos_e/v1.11": -18.216007232666016,
        "glue/mrpc": 6.743654251098633,
        "kilt_tasks/hotpotqa": -35.455657958984375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.986,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11122434586286545,
        "ag_news": 0.1284835934638977,
        "amazon_polarity": 0.12910956144332886,
        "cnn_dailymail/3.0.0": 0.1538974791765213,
        "common_gen": 0.12402278184890747,
        "cos_e/v1.11": 0.11740254610776901,
        "glue/mrpc": 0.12064555287361145,
        "kilt_tasks/hotpotqa": 0.11521412432193756
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21136,
        "ag_news": 21824,
        "amazon_polarity": 21208,
        "cnn_dailymail/3.0.0": 21864,
        "common_gen": 21144,
        "cos_e/v1.11": 21682,
        "glue/mrpc": 21268,
        "kilt_tasks/hotpotqa": 21368
      },
      "step": 1340
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -66.72064208984375,
        "ag_news": 64.27079010009766,
        "amazon_polarity": 69.2025375366211,
        "cnn_dailymail/3.0.0": 229.69789123535156,
        "common_gen": 26.37669563293457,
        "cos_e/v1.11": -15.983007431030273,
        "glue/mrpc": 3.5896148681640625,
        "kilt_tasks/hotpotqa": -36.72133255004883
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0173,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11149325221776962,
        "ag_news": 0.12856660783290863,
        "amazon_polarity": 0.12925860285758972,
        "cnn_dailymail/3.0.0": 0.15395095944404602,
        "common_gen": 0.1233726516366005,
        "cos_e/v1.11": 0.1178167387843132,
        "glue/mrpc": 0.12035180628299713,
        "kilt_tasks/hotpotqa": 0.11518946290016174
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21304,
        "ag_news": 22016,
        "amazon_polarity": 21312,
        "cnn_dailymail/3.0.0": 22064,
        "common_gen": 21328,
        "cos_e/v1.11": 21786,
        "glue/mrpc": 21436,
        "kilt_tasks/hotpotqa": 21528
      },
      "step": 1350
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -61.76783752441406,
        "ag_news": 64.11201477050781,
        "amazon_polarity": 69.06172180175781,
        "cnn_dailymail/3.0.0": 230.9503936767578,
        "common_gen": 24.826400756835938,
        "cos_e/v1.11": -17.410152435302734,
        "glue/mrpc": 2.5671744346618652,
        "kilt_tasks/hotpotqa": -37.003929138183594
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9599,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11211822181940079,
        "ag_news": 0.12850652635097504,
        "amazon_polarity": 0.12919816374778748,
        "cnn_dailymail/3.0.0": 0.1540132761001587,
        "common_gen": 0.12314772605895996,
        "cos_e/v1.11": 0.11763753741979599,
        "glue/mrpc": 0.12021206319332123,
        "kilt_tasks/hotpotqa": 0.11516647785902023
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21472,
        "ag_news": 22200,
        "amazon_polarity": 21464,
        "cnn_dailymail/3.0.0": 22216,
        "common_gen": 21496,
        "cos_e/v1.11": 21946,
        "glue/mrpc": 21588,
        "kilt_tasks/hotpotqa": 21672
      },
      "step": 1360
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -59.06283950805664,
        "ag_news": 64.10394287109375,
        "amazon_polarity": 69.07902526855469,
        "cnn_dailymail/3.0.0": 230.89205932617188,
        "common_gen": 20.369709014892578,
        "cos_e/v1.11": -17.315017700195312,
        "glue/mrpc": 3.3722898960113525,
        "kilt_tasks/hotpotqa": -35.56111526489258
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8991,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11248955130577087,
        "ag_news": 0.12849161028862,
        "amazon_polarity": 0.12918418645858765,
        "cnn_dailymail/3.0.0": 0.1538856476545334,
        "common_gen": 0.12256213277578354,
        "cos_e/v1.11": 0.11767468601465225,
        "glue/mrpc": 0.12033282220363617,
        "kilt_tasks/hotpotqa": 0.1153794601559639
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21672,
        "ag_news": 22352,
        "amazon_polarity": 21624,
        "cnn_dailymail/3.0.0": 22368,
        "common_gen": 21640,
        "cos_e/v1.11": 22066,
        "glue/mrpc": 21780,
        "kilt_tasks/hotpotqa": 21832
      },
      "step": 1370
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -55.58675765991211,
        "ag_news": 64.13416290283203,
        "amazon_polarity": 68.8834457397461,
        "cnn_dailymail/3.0.0": 236.6702423095703,
        "common_gen": 23.502376556396484,
        "cos_e/v1.11": -17.93889617919922,
        "glue/mrpc": 2.0478243827819824,
        "kilt_tasks/hotpotqa": -35.76002883911133
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9499,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11278674751520157,
        "ag_news": 0.12829290330410004,
        "amazon_polarity": 0.1289505660533905,
        "cnn_dailymail/3.0.0": 0.15450187027454376,
        "common_gen": 0.12280284613370895,
        "cos_e/v1.11": 0.11744740605354309,
        "glue/mrpc": 0.1200002133846283,
        "kilt_tasks/hotpotqa": 0.11521746218204498
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21864,
        "ag_news": 22512,
        "amazon_polarity": 21736,
        "cnn_dailymail/3.0.0": 22520,
        "common_gen": 21800,
        "cos_e/v1.11": 22226,
        "glue/mrpc": 21956,
        "kilt_tasks/hotpotqa": 22000
      },
      "step": 1380
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -52.94341278076172,
        "ag_news": 63.88895797729492,
        "amazon_polarity": 68.72418975830078,
        "cnn_dailymail/3.0.0": 236.56431579589844,
        "common_gen": 23.543277740478516,
        "cos_e/v1.11": -14.26010513305664,
        "glue/mrpc": 3.8815510272979736,
        "kilt_tasks/hotpotqa": -35.854454040527344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9235,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1130438894033432,
        "ag_news": 0.12812885642051697,
        "amazon_polarity": 0.12879517674446106,
        "cnn_dailymail/3.0.0": 0.15422435104846954,
        "common_gen": 0.12270268052816391,
        "cos_e/v1.11": 0.11782895028591156,
        "glue/mrpc": 0.12014295905828476,
        "kilt_tasks/hotpotqa": 0.11513309925794601
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22048,
        "ag_news": 22696,
        "amazon_polarity": 21904,
        "cnn_dailymail/3.0.0": 22640,
        "common_gen": 21976,
        "cos_e/v1.11": 22338,
        "glue/mrpc": 22096,
        "kilt_tasks/hotpotqa": 22192
      },
      "step": 1390
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -53.79731369018555,
        "ag_news": 63.854576110839844,
        "amazon_polarity": 68.61767578125,
        "cnn_dailymail/3.0.0": 235.5980987548828,
        "common_gen": 24.840328216552734,
        "cos_e/v1.11": -13.029293060302734,
        "glue/mrpc": 2.767860174179077,
        "kilt_tasks/hotpotqa": -36.97234344482422
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9854,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11300978809595108,
        "ag_news": 0.12814536690711975,
        "amazon_polarity": 0.12879949808120728,
        "cnn_dailymail/3.0.0": 0.15398888289928436,
        "common_gen": 0.12291210144758224,
        "cos_e/v1.11": 0.118038609623909,
        "glue/mrpc": 0.12004741281270981,
        "kilt_tasks/hotpotqa": 0.11505843698978424
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22152,
        "ag_news": 22912,
        "amazon_polarity": 22032,
        "cnn_dailymail/3.0.0": 22832,
        "common_gen": 22152,
        "cos_e/v1.11": 22514,
        "glue/mrpc": 22168,
        "kilt_tasks/hotpotqa": 22408
      },
      "step": 1400
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1924,
      "eval_samples_per_second": 83.18,
      "eval_steps_per_second": 5.199,
      "step": 1400
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -53.68148422241211,
        "ag_news": 63.829219818115234,
        "amazon_polarity": 68.5286636352539,
        "cnn_dailymail/3.0.0": 237.09654235839844,
        "common_gen": 24.0861759185791,
        "cos_e/v1.11": -13.498359680175781,
        "glue/mrpc": 1.9082436561584473,
        "kilt_tasks/hotpotqa": -37.39934158325195
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9195,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11307421326637268,
        "ag_news": 0.12814240157604218,
        "amazon_polarity": 0.12878546118736267,
        "cnn_dailymail/3.0.0": 0.15413574874401093,
        "common_gen": 0.12283197790384293,
        "cos_e/v1.11": 0.11801431328058243,
        "glue/mrpc": 0.11996567249298096,
        "kilt_tasks/hotpotqa": 0.1150502860546112
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22272,
        "ag_news": 23088,
        "amazon_polarity": 22232,
        "cnn_dailymail/3.0.0": 23024,
        "common_gen": 22296,
        "cos_e/v1.11": 22650,
        "glue/mrpc": 22368,
        "kilt_tasks/hotpotqa": 22520
      },
      "step": 1410
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.609580993652344,
        "ag_news": 63.809322357177734,
        "amazon_polarity": 68.55040740966797,
        "cnn_dailymail/3.0.0": 236.8411407470703,
        "common_gen": 24.58785057067871,
        "cos_e/v1.11": -14.141825675964355,
        "glue/mrpc": 6.003265380859375,
        "kilt_tasks/hotpotqa": -35.75004196166992
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9854,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11230594664812088,
        "ag_news": 0.12815122306346893,
        "amazon_polarity": 0.1287977546453476,
        "cnn_dailymail/3.0.0": 0.15400798618793488,
        "common_gen": 0.12292665988206863,
        "cos_e/v1.11": 0.11797840148210526,
        "glue/mrpc": 0.12052661180496216,
        "kilt_tasks/hotpotqa": 0.11530551314353943
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22448,
        "ag_news": 23256,
        "amazon_polarity": 22344,
        "cnn_dailymail/3.0.0": 23160,
        "common_gen": 22472,
        "cos_e/v1.11": 22794,
        "glue/mrpc": 22528,
        "kilt_tasks/hotpotqa": 22728
      },
      "step": 1420
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -61.32057189941406,
        "ag_news": 63.76175308227539,
        "amazon_polarity": 68.84109497070312,
        "cnn_dailymail/3.0.0": 237.22898864746094,
        "common_gen": 21.34644889831543,
        "cos_e/v1.11": -13.799422264099121,
        "glue/mrpc": 6.638174057006836,
        "kilt_tasks/hotpotqa": -35.70486068725586
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0006,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11229652166366577,
        "ag_news": 0.12817156314849854,
        "amazon_polarity": 0.12886203825473785,
        "cnn_dailymail/3.0.0": 0.15400491654872894,
        "common_gen": 0.12254940718412399,
        "cos_e/v1.11": 0.11807968467473984,
        "glue/mrpc": 0.12065845727920532,
        "kilt_tasks/hotpotqa": 0.11537742614746094
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22648,
        "ag_news": 23408,
        "amazon_polarity": 22504,
        "cnn_dailymail/3.0.0": 23328,
        "common_gen": 22632,
        "cos_e/v1.11": 22946,
        "glue/mrpc": 22680,
        "kilt_tasks/hotpotqa": 22864
      },
      "step": 1430
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -61.460174560546875,
        "ag_news": 63.62712478637695,
        "amazon_polarity": 68.77814483642578,
        "cnn_dailymail/3.0.0": 238.80030822753906,
        "common_gen": 18.59549903869629,
        "cos_e/v1.11": -17.13574981689453,
        "glue/mrpc": 3.947533130645752,
        "kilt_tasks/hotpotqa": -34.680816650390625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8981,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11241023242473602,
        "ag_news": 0.1282435953617096,
        "amazon_polarity": 0.12894180417060852,
        "cnn_dailymail/3.0.0": 0.15427130460739136,
        "common_gen": 0.12229962646961212,
        "cos_e/v1.11": 0.11778157204389572,
        "glue/mrpc": 0.12042668461799622,
        "kilt_tasks/hotpotqa": 0.11562512069940567
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22832,
        "ag_news": 23544,
        "amazon_polarity": 22744,
        "cnn_dailymail/3.0.0": 23472,
        "common_gen": 22736,
        "cos_e/v1.11": 23098,
        "glue/mrpc": 22856,
        "kilt_tasks/hotpotqa": 23008
      },
      "step": 1440
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.15724563598633,
        "ag_news": 63.58794403076172,
        "amazon_polarity": 68.40520477294922,
        "cnn_dailymail/3.0.0": 237.4130859375,
        "common_gen": 22.07799530029297,
        "cos_e/v1.11": -17.86222267150879,
        "glue/mrpc": 3.272979497909546,
        "kilt_tasks/hotpotqa": -34.61092758178711
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9937,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11258938908576965,
        "ag_news": 0.12820927798748016,
        "amazon_polarity": 0.1288597136735916,
        "cnn_dailymail/3.0.0": 0.153913676738739,
        "common_gen": 0.12273986637592316,
        "cos_e/v1.11": 0.11769948899745941,
        "glue/mrpc": 0.12034013867378235,
        "kilt_tasks/hotpotqa": 0.11564849317073822
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22952,
        "ag_news": 23672,
        "amazon_polarity": 22960,
        "cnn_dailymail/3.0.0": 23688,
        "common_gen": 22920,
        "cos_e/v1.11": 23226,
        "glue/mrpc": 23016,
        "kilt_tasks/hotpotqa": 23136
      },
      "step": 1450
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -58.70866012573242,
        "ag_news": 63.461097717285156,
        "amazon_polarity": 68.09395599365234,
        "cnn_dailymail/3.0.0": 237.76828002929688,
        "common_gen": 19.705821990966797,
        "cos_e/v1.11": -16.54480743408203,
        "glue/mrpc": 2.976689100265503,
        "kilt_tasks/hotpotqa": -38.865596771240234
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9183,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1128610149025917,
        "ag_news": 0.128250390291214,
        "amazon_polarity": 0.12887392938137054,
        "cnn_dailymail/3.0.0": 0.1539449244737625,
        "common_gen": 0.12250924110412598,
        "cos_e/v1.11": 0.11794956028461456,
        "glue/mrpc": 0.12038332968950272,
        "kilt_tasks/hotpotqa": 0.1152275800704956
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23104,
        "ag_news": 23848,
        "amazon_polarity": 23128,
        "cnn_dailymail/3.0.0": 23792,
        "common_gen": 23104,
        "cos_e/v1.11": 23442,
        "glue/mrpc": 23192,
        "kilt_tasks/hotpotqa": 23240
      },
      "step": 1460
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.419498443603516,
        "ag_news": 63.4229621887207,
        "amazon_polarity": 67.95185089111328,
        "cnn_dailymail/3.0.0": 237.60394287109375,
        "common_gen": 20.50241470336914,
        "cos_e/v1.11": -21.339508056640625,
        "glue/mrpc": 4.177821636199951,
        "kilt_tasks/hotpotqa": -34.51395797729492
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0473,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11270774900913239,
        "ag_news": 0.12824425101280212,
        "amazon_polarity": 0.12885168194770813,
        "cnn_dailymail/3.0.0": 0.15382206439971924,
        "common_gen": 0.1226290762424469,
        "cos_e/v1.11": 0.11739370971918106,
        "glue/mrpc": 0.12055904418230057,
        "kilt_tasks/hotpotqa": 0.11579243093729019
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23272,
        "ag_news": 23960,
        "amazon_polarity": 23304,
        "cnn_dailymail/3.0.0": 23984,
        "common_gen": 23248,
        "cos_e/v1.11": 23594,
        "glue/mrpc": 23376,
        "kilt_tasks/hotpotqa": 23392
      },
      "step": 1470
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.64617156982422,
        "ag_news": 63.270729064941406,
        "amazon_polarity": 67.9613265991211,
        "cnn_dailymail/3.0.0": 236.59170532226562,
        "common_gen": 22.38016700744629,
        "cos_e/v1.11": -26.560338973999023,
        "glue/mrpc": 5.593656539916992,
        "kilt_tasks/hotpotqa": -33.39128494262695
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0149,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11275482922792435,
        "ag_news": 0.12825213372707367,
        "amazon_polarity": 0.12887923419475555,
        "cnn_dailymail/3.0.0": 0.1535997986793518,
        "common_gen": 0.1229141429066658,
        "cos_e/v1.11": 0.11681894212961197,
        "glue/mrpc": 0.12078816443681717,
        "kilt_tasks/hotpotqa": 0.11599280685186386
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23392,
        "ag_news": 24160,
        "amazon_polarity": 23440,
        "cnn_dailymail/3.0.0": 24184,
        "common_gen": 23344,
        "cos_e/v1.11": 23802,
        "glue/mrpc": 23528,
        "kilt_tasks/hotpotqa": 23560
      },
      "step": 1480
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -62.01506423950195,
        "ag_news": 62.962379455566406,
        "amazon_polarity": 67.9502182006836,
        "cnn_dailymail/3.0.0": 237.26039123535156,
        "common_gen": 25.11951446533203,
        "cos_e/v1.11": -27.281238555908203,
        "glue/mrpc": 4.292769908905029,
        "kilt_tasks/hotpotqa": -36.409278869628906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9683,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11267589032649994,
        "ag_news": 0.12824805080890656,
        "amazon_polarity": 0.12891273200511932,
        "cnn_dailymail/3.0.0": 0.15365803241729736,
        "common_gen": 0.12331640720367432,
        "cos_e/v1.11": 0.11680170148611069,
        "glue/mrpc": 0.12068434804677963,
        "kilt_tasks/hotpotqa": 0.11570289731025696
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23520,
        "ag_news": 24296,
        "amazon_polarity": 23600,
        "cnn_dailymail/3.0.0": 24336,
        "common_gen": 23528,
        "cos_e/v1.11": 23954,
        "glue/mrpc": 23736,
        "kilt_tasks/hotpotqa": 23720
      },
      "step": 1490
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -57.76000213623047,
        "ag_news": 62.94292068481445,
        "amazon_polarity": 67.90235137939453,
        "cnn_dailymail/3.0.0": 236.5647735595703,
        "common_gen": 22.55315589904785,
        "cos_e/v1.11": -27.380510330200195,
        "glue/mrpc": 7.204276084899902,
        "kilt_tasks/hotpotqa": -39.26124572753906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0435,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11320535093545914,
        "ag_news": 0.12822863459587097,
        "amazon_polarity": 0.12888722121715546,
        "cnn_dailymail/3.0.0": 0.15343523025512695,
        "common_gen": 0.12298990041017532,
        "cos_e/v1.11": 0.11681059002876282,
        "glue/mrpc": 0.12105616182088852,
        "kilt_tasks/hotpotqa": 0.11538706719875336
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23640,
        "ag_news": 24456,
        "amazon_polarity": 23728,
        "cnn_dailymail/3.0.0": 24496,
        "common_gen": 23712,
        "cos_e/v1.11": 24122,
        "glue/mrpc": 23904,
        "kilt_tasks/hotpotqa": 23912
      },
      "step": 1500
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1804,
      "eval_samples_per_second": 88.714,
      "eval_steps_per_second": 5.545,
      "step": 1500
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -57.85823440551758,
        "ag_news": 63.25580978393555,
        "amazon_polarity": 67.84770965576172,
        "cnn_dailymail/3.0.0": 236.37582397460938,
        "common_gen": 21.10051155090332,
        "cos_e/v1.11": -28.097248077392578,
        "glue/mrpc": 6.781355857849121,
        "kilt_tasks/hotpotqa": -39.27857208251953
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8774,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11327005177736282,
        "ag_news": 0.1283036321401596,
        "amazon_polarity": 0.12891164422035217,
        "cnn_dailymail/3.0.0": 0.15335486829280853,
        "common_gen": 0.1228552907705307,
        "cos_e/v1.11": 0.11679096519947052,
        "glue/mrpc": 0.12105818837881088,
        "kilt_tasks/hotpotqa": 0.11545538157224655
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23784,
        "ag_news": 24680,
        "amazon_polarity": 23872,
        "cnn_dailymail/3.0.0": 24608,
        "common_gen": 23864,
        "cos_e/v1.11": 24330,
        "glue/mrpc": 24072,
        "kilt_tasks/hotpotqa": 24040
      },
      "step": 1510
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -54.145511627197266,
        "ag_news": 63.24584197998047,
        "amazon_polarity": 67.76986694335938,
        "cnn_dailymail/3.0.0": 235.68960571289062,
        "common_gen": 20.200841903686523,
        "cos_e/v1.11": -29.00995635986328,
        "glue/mrpc": 10.844040870666504,
        "kilt_tasks/hotpotqa": -38.449092864990234
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8624,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11366146802902222,
        "ag_news": 0.12820427119731903,
        "amazon_polarity": 0.12880085408687592,
        "cnn_dailymail/3.0.0": 0.1530400514602661,
        "common_gen": 0.12266562134027481,
        "cos_e/v1.11": 0.116628497838974,
        "glue/mrpc": 0.12149394303560257,
        "kilt_tasks/hotpotqa": 0.11550523340702057
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23904,
        "ag_news": 24904,
        "amazon_polarity": 24048,
        "cnn_dailymail/3.0.0": 24744,
        "common_gen": 23976,
        "cos_e/v1.11": 24530,
        "glue/mrpc": 24240,
        "kilt_tasks/hotpotqa": 24184
      },
      "step": 1520
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -56.09046173095703,
        "ag_news": 63.230369567871094,
        "amazon_polarity": 68.19864654541016,
        "cnn_dailymail/3.0.0": 234.22592163085938,
        "common_gen": 20.286388397216797,
        "cos_e/v1.11": -33.053558349609375,
        "glue/mrpc": 9.643537521362305,
        "kilt_tasks/hotpotqa": -37.429229736328125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0065,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11357450485229492,
        "ag_news": 0.12830893695354462,
        "amazon_polarity": 0.12896263599395752,
        "cnn_dailymail/3.0.0": 0.15285000205039978,
        "common_gen": 0.12279601395130157,
        "cos_e/v1.11": 0.11627982556819916,
        "glue/mrpc": 0.12146707624197006,
        "kilt_tasks/hotpotqa": 0.11576101928949356
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24088,
        "ag_news": 25064,
        "amazon_polarity": 24184,
        "cnn_dailymail/3.0.0": 24872,
        "common_gen": 24168,
        "cos_e/v1.11": 24730,
        "glue/mrpc": 24368,
        "kilt_tasks/hotpotqa": 24336
      },
      "step": 1530
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -56.08396911621094,
        "ag_news": 63.22294998168945,
        "amazon_polarity": 67.89640808105469,
        "cnn_dailymail/3.0.0": 236.0069580078125,
        "common_gen": 22.92674446105957,
        "cos_e/v1.11": -29.24738883972168,
        "glue/mrpc": 11.018709182739258,
        "kilt_tasks/hotpotqa": -39.299049377441406
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9933,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11350187659263611,
        "ag_news": 0.12817446887493134,
        "amazon_polarity": 0.12878665328025818,
        "cnn_dailymail/3.0.0": 0.15288208425045013,
        "common_gen": 0.12301627546548843,
        "cos_e/v1.11": 0.11664725095033646,
        "glue/mrpc": 0.12153241783380508,
        "kilt_tasks/hotpotqa": 0.11545898765325546
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24248,
        "ag_news": 25224,
        "amazon_polarity": 24344,
        "cnn_dailymail/3.0.0": 25048,
        "common_gen": 24264,
        "cos_e/v1.11": 24970,
        "glue/mrpc": 24504,
        "kilt_tasks/hotpotqa": 24488
      },
      "step": 1540
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -54.481361389160156,
        "ag_news": 63.179508209228516,
        "amazon_polarity": 67.69490051269531,
        "cnn_dailymail/3.0.0": 236.38255310058594,
        "common_gen": 22.695838928222656,
        "cos_e/v1.11": -30.515304565429688,
        "glue/mrpc": 9.620161056518555,
        "kilt_tasks/hotpotqa": -40.66194534301758
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0153,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11375752836465836,
        "ag_news": 0.1281987428665161,
        "amazon_polarity": 0.12878836691379547,
        "cnn_dailymail/3.0.0": 0.15288963913917542,
        "common_gen": 0.1230323314666748,
        "cos_e/v1.11": 0.11655956506729126,
        "glue/mrpc": 0.12140892446041107,
        "kilt_tasks/hotpotqa": 0.11536484956741333
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24368,
        "ag_news": 25384,
        "amazon_polarity": 24488,
        "cnn_dailymail/3.0.0": 25192,
        "common_gen": 24464,
        "cos_e/v1.11": 25154,
        "glue/mrpc": 24632,
        "kilt_tasks/hotpotqa": 24688
      },
      "step": 1550
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -50.78069305419922,
        "ag_news": 63.15435028076172,
        "amazon_polarity": 67.64093780517578,
        "cnn_dailymail/3.0.0": 235.72520446777344,
        "common_gen": 21.91620445251465,
        "cos_e/v1.11": -34.98876190185547,
        "glue/mrpc": 13.323352813720703,
        "kilt_tasks/hotpotqa": -38.22578811645508
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9347,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11417092382907867,
        "ag_news": 0.12813152372837067,
        "amazon_polarity": 0.12871521711349487,
        "cnn_dailymail/3.0.0": 0.15262557566165924,
        "common_gen": 0.12289007753133774,
        "cos_e/v1.11": 0.11601034551858902,
        "glue/mrpc": 0.12182541191577911,
        "kilt_tasks/hotpotqa": 0.11563087999820709
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24576,
        "ag_news": 25552,
        "amazon_polarity": 24632,
        "cnn_dailymail/3.0.0": 25344,
        "common_gen": 24568,
        "cos_e/v1.11": 25306,
        "glue/mrpc": 24792,
        "kilt_tasks/hotpotqa": 24880
      },
      "step": 1560
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -51.10764694213867,
        "ag_news": 63.11821746826172,
        "amazon_polarity": 67.47158813476562,
        "cnn_dailymail/3.0.0": 235.21922302246094,
        "common_gen": 24.13518524169922,
        "cos_e/v1.11": -34.75904846191406,
        "glue/mrpc": 10.06399154663086,
        "kilt_tasks/hotpotqa": -38.161251068115234
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8654,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11419407278299332,
        "ag_news": 0.12814834713935852,
        "amazon_polarity": 0.12871292233467102,
        "cnn_dailymail/3.0.0": 0.15248848497867584,
        "common_gen": 0.12320257723331451,
        "cos_e/v1.11": 0.11609318107366562,
        "glue/mrpc": 0.1214650347828865,
        "kilt_tasks/hotpotqa": 0.11569535732269287
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24752,
        "ag_news": 25712,
        "amazon_polarity": 24880,
        "cnn_dailymail/3.0.0": 25432,
        "common_gen": 24728,
        "cos_e/v1.11": 25434,
        "glue/mrpc": 24952,
        "kilt_tasks/hotpotqa": 25040
      },
      "step": 1570
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -49.80345916748047,
        "ag_news": 63.08293151855469,
        "amazon_polarity": 67.54518127441406,
        "cnn_dailymail/3.0.0": 235.2788543701172,
        "common_gen": 24.209901809692383,
        "cos_e/v1.11": -34.1136589050293,
        "glue/mrpc": 10.14300537109375,
        "kilt_tasks/hotpotqa": -40.109859466552734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8263,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11437434703111649,
        "ag_news": 0.12813138961791992,
        "amazon_polarity": 0.12870822846889496,
        "cnn_dailymail/3.0.0": 0.15239928662776947,
        "common_gen": 0.12321518361568451,
        "cos_e/v1.11": 0.11619342863559723,
        "glue/mrpc": 0.12148341536521912,
        "kilt_tasks/hotpotqa": 0.11549481004476547
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24920,
        "ag_news": 25880,
        "amazon_polarity": 25112,
        "cnn_dailymail/3.0.0": 25504,
        "common_gen": 24832,
        "cos_e/v1.11": 25594,
        "glue/mrpc": 25128,
        "kilt_tasks/hotpotqa": 25240
      },
      "step": 1580
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -51.60743713378906,
        "ag_news": 63.00313186645508,
        "amazon_polarity": 67.62187194824219,
        "cnn_dailymail/3.0.0": 234.4978485107422,
        "common_gen": 25.59095001220703,
        "cos_e/v1.11": -36.02504348754883,
        "glue/mrpc": 10.558863639831543,
        "kilt_tasks/hotpotqa": -40.57939529418945
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8702,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11424446105957031,
        "ag_news": 0.12816183269023895,
        "amazon_polarity": 0.12875719368457794,
        "cnn_dailymail/3.0.0": 0.1522454470396042,
        "common_gen": 0.12344028055667877,
        "cos_e/v1.11": 0.11604324728250504,
        "glue/mrpc": 0.1215929314494133,
        "kilt_tasks/hotpotqa": 0.11551456898450851
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25072,
        "ag_news": 26080,
        "amazon_polarity": 25312,
        "cnn_dailymail/3.0.0": 25624,
        "common_gen": 24928,
        "cos_e/v1.11": 25794,
        "glue/mrpc": 25256,
        "kilt_tasks/hotpotqa": 25424
      },
      "step": 1590
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -50.5191535949707,
        "ag_news": 62.97806167602539,
        "amazon_polarity": 67.6330795288086,
        "cnn_dailymail/3.0.0": 233.64572143554688,
        "common_gen": 25.793731689453125,
        "cos_e/v1.11": -34.08970642089844,
        "glue/mrpc": 6.580755233764648,
        "kilt_tasks/hotpotqa": -41.16825485229492
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9005,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11443746089935303,
        "ag_news": 0.128189817070961,
        "amazon_polarity": 0.12878815829753876,
        "cnn_dailymail/3.0.0": 0.15207111835479736,
        "common_gen": 0.12350979447364807,
        "cos_e/v1.11": 0.11633212864398956,
        "glue/mrpc": 0.12115952372550964,
        "kilt_tasks/hotpotqa": 0.11551196873188019
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25264,
        "ag_news": 26312,
        "amazon_polarity": 25448,
        "cnn_dailymail/3.0.0": 25760,
        "common_gen": 25056,
        "cos_e/v1.11": 25954,
        "glue/mrpc": 25416,
        "kilt_tasks/hotpotqa": 25560
      },
      "step": 1600
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.1812,
      "eval_samples_per_second": 88.316,
      "eval_steps_per_second": 5.52,
      "step": 1600
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -50.14449691772461,
        "ag_news": 62.973819732666016,
        "amazon_polarity": 67.60737609863281,
        "cnn_dailymail/3.0.0": 235.4046630859375,
        "common_gen": 26.432010650634766,
        "cos_e/v1.11": -37.21199417114258,
        "glue/mrpc": 7.052395343780518,
        "kilt_tasks/hotpotqa": -38.54845428466797
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0935,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11446913331747055,
        "ag_news": 0.1281319409608841,
        "amazon_polarity": 0.12872540950775146,
        "cnn_dailymail/3.0.0": 0.15218977630138397,
        "common_gen": 0.12354733794927597,
        "cos_e/v1.11": 0.11595366895198822,
        "glue/mrpc": 0.12118341773748398,
        "kilt_tasks/hotpotqa": 0.11579935997724533
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25464,
        "ag_news": 26432,
        "amazon_polarity": 25592,
        "cnn_dailymail/3.0.0": 25904,
        "common_gen": 25288,
        "cos_e/v1.11": 26146,
        "glue/mrpc": 25512,
        "kilt_tasks/hotpotqa": 25712
      },
      "step": 1610
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -51.84946060180664,
        "ag_news": 62.970054626464844,
        "amazon_polarity": 67.5237045288086,
        "cnn_dailymail/3.0.0": 235.1769561767578,
        "common_gen": 23.796077728271484,
        "cos_e/v1.11": -39.11503601074219,
        "glue/mrpc": 5.008082866668701,
        "kilt_tasks/hotpotqa": -39.56201934814453
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9115,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11443857848644257,
        "ag_news": 0.12827014923095703,
        "amazon_polarity": 0.12885217368602753,
        "cnn_dailymail/3.0.0": 0.152239590883255,
        "common_gen": 0.1233711987733841,
        "cos_e/v1.11": 0.1158953383564949,
        "glue/mrpc": 0.12108903378248215,
        "kilt_tasks/hotpotqa": 0.11584388464689255
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25672,
        "ag_news": 26600,
        "amazon_polarity": 25752,
        "cnn_dailymail/3.0.0": 26016,
        "common_gen": 25432,
        "cos_e/v1.11": 26338,
        "glue/mrpc": 25676,
        "kilt_tasks/hotpotqa": 25840
      },
      "step": 1620
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -52.81882095336914,
        "ag_news": 62.95792007446289,
        "amazon_polarity": 67.46681213378906,
        "cnn_dailymail/3.0.0": 237.0125732421875,
        "common_gen": 23.877351760864258,
        "cos_e/v1.11": -39.4716682434082,
        "glue/mrpc": 3.669729709625244,
        "kilt_tasks/hotpotqa": -38.6622428894043
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9366,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11435294896364212,
        "ag_news": 0.12825104594230652,
        "amazon_polarity": 0.12882548570632935,
        "cnn_dailymail/3.0.0": 0.15241648256778717,
        "common_gen": 0.1233789324760437,
        "cos_e/v1.11": 0.11587441712617874,
        "glue/mrpc": 0.12093330919742584,
        "kilt_tasks/hotpotqa": 0.11596734076738358
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25840,
        "ag_news": 26808,
        "amazon_polarity": 25896,
        "cnn_dailymail/3.0.0": 26184,
        "common_gen": 25600,
        "cos_e/v1.11": 26450,
        "glue/mrpc": 25820,
        "kilt_tasks/hotpotqa": 26008
      },
      "step": 1630
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -54.47916030883789,
        "ag_news": 62.37870407104492,
        "amazon_polarity": 67.35529327392578,
        "cnn_dailymail/3.0.0": 236.54742431640625,
        "common_gen": 26.80881118774414,
        "cos_e/v1.11": -40.86777114868164,
        "glue/mrpc": 5.049520492553711,
        "kilt_tasks/hotpotqa": -39.54917907714844
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8984,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.114207424223423,
        "ag_news": 0.12818001210689545,
        "amazon_polarity": 0.12881191074848175,
        "cnn_dailymail/3.0.0": 0.15226928889751434,
        "common_gen": 0.12375351786613464,
        "cos_e/v1.11": 0.11575250327587128,
        "glue/mrpc": 0.12112201005220413,
        "kilt_tasks/hotpotqa": 0.11590330302715302
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26008,
        "ag_news": 26984,
        "amazon_polarity": 26088,
        "cnn_dailymail/3.0.0": 26352,
        "common_gen": 25776,
        "cos_e/v1.11": 26602,
        "glue/mrpc": 25948,
        "kilt_tasks/hotpotqa": 26128
      },
      "step": 1640
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -55.943328857421875,
        "ag_news": 62.27085494995117,
        "amazon_polarity": 67.28841400146484,
        "cnn_dailymail/3.0.0": 237.56210327148438,
        "common_gen": 30.24561309814453,
        "cos_e/v1.11": -40.03998947143555,
        "glue/mrpc": 9.605180740356445,
        "kilt_tasks/hotpotqa": -39.839813232421875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0349,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11396253854036331,
        "ag_news": 0.12803135812282562,
        "amazon_polarity": 0.12866580486297607,
        "cnn_dailymail/3.0.0": 0.15218183398246765,
        "common_gen": 0.12405548244714737,
        "cos_e/v1.11": 0.11576046049594879,
        "glue/mrpc": 0.12155921012163162,
        "kilt_tasks/hotpotqa": 0.11578328162431717
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26144,
        "ag_news": 27112,
        "amazon_polarity": 26264,
        "cnn_dailymail/3.0.0": 26528,
        "common_gen": 25928,
        "cos_e/v1.11": 26818,
        "glue/mrpc": 26084,
        "kilt_tasks/hotpotqa": 26288
      },
      "step": 1650
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -53.894287109375,
        "ag_news": 61.58587646484375,
        "amazon_polarity": 67.15650177001953,
        "cnn_dailymail/3.0.0": 238.06776428222656,
        "common_gen": 31.834657669067383,
        "cos_e/v1.11": -41.524452209472656,
        "glue/mrpc": 11.477655410766602,
        "kilt_tasks/hotpotqa": -40.765140533447266
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0742,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11418544501066208,
        "ag_news": 0.1278933733701706,
        "amazon_polarity": 0.12859508395195007,
        "cnn_dailymail/3.0.0": 0.15211685001850128,
        "common_gen": 0.12421059608459473,
        "cos_e/v1.11": 0.11557997763156891,
        "glue/mrpc": 0.12175245583057404,
        "kilt_tasks/hotpotqa": 0.11566615104675293
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26256,
        "ag_news": 27288,
        "amazon_polarity": 26376,
        "cnn_dailymail/3.0.0": 26736,
        "common_gen": 26112,
        "cos_e/v1.11": 26978,
        "glue/mrpc": 26244,
        "kilt_tasks/hotpotqa": 26456
      },
      "step": 1660
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -53.972232818603516,
        "ag_news": 61.58230209350586,
        "amazon_polarity": 67.43731689453125,
        "cnn_dailymail/3.0.0": 237.42202758789062,
        "common_gen": 32.83515930175781,
        "cos_e/v1.11": -37.421409606933594,
        "glue/mrpc": 7.609447956085205,
        "kilt_tasks/hotpotqa": -41.00159454345703
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9017,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1142054945230484,
        "ag_news": 0.1278819739818573,
        "amazon_polarity": 0.1286173164844513,
        "cnn_dailymail/3.0.0": 0.15192890167236328,
        "common_gen": 0.124332495033741,
        "cos_e/v1.11": 0.1160699874162674,
        "glue/mrpc": 0.12129969894886017,
        "kilt_tasks/hotpotqa": 0.11566408723592758
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26400,
        "ag_news": 27496,
        "amazon_polarity": 26576,
        "cnn_dailymail/3.0.0": 26864,
        "common_gen": 26216,
        "cos_e/v1.11": 27170,
        "glue/mrpc": 26388,
        "kilt_tasks/hotpotqa": 26616
      },
      "step": 1670
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -53.492122650146484,
        "ag_news": 61.47775650024414,
        "amazon_polarity": 67.2269058227539,
        "cnn_dailymail/3.0.0": 237.17152404785156,
        "common_gen": 31.49675941467285,
        "cos_e/v1.11": -36.58869552612305,
        "glue/mrpc": 3.531801462173462,
        "kilt_tasks/hotpotqa": -41.40727615356445
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0491,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11436160653829575,
        "ag_news": 0.12794099748134613,
        "amazon_polarity": 0.12866120040416718,
        "cnn_dailymail/3.0.0": 0.1518998146057129,
        "common_gen": 0.12425049394369125,
        "cos_e/v1.11": 0.11626307666301727,
        "glue/mrpc": 0.12090492248535156,
        "kilt_tasks/hotpotqa": 0.1157178059220314
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26528,
        "ag_news": 27584,
        "amazon_polarity": 26736,
        "cnn_dailymail/3.0.0": 27048,
        "common_gen": 26440,
        "cos_e/v1.11": 27330,
        "glue/mrpc": 26516,
        "kilt_tasks/hotpotqa": 26824
      },
      "step": 1680
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -54.683284759521484,
        "ag_news": 61.472312927246094,
        "amazon_polarity": 66.75090789794922,
        "cnn_dailymail/3.0.0": 236.41778564453125,
        "common_gen": 27.5913028717041,
        "cos_e/v1.11": -33.14652633666992,
        "glue/mrpc": 1.2324563264846802,
        "kilt_tasks/hotpotqa": -40.262596130371094
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.983,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11432062834501266,
        "ag_news": 0.12800055742263794,
        "amazon_polarity": 0.12866002321243286,
        "cnn_dailymail/3.0.0": 0.15178298950195312,
        "common_gen": 0.12384802103042603,
        "cos_e/v1.11": 0.11674075573682785,
        "glue/mrpc": 0.1207115650177002,
        "kilt_tasks/hotpotqa": 0.11593545228242874
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26688,
        "ag_news": 27728,
        "amazon_polarity": 26904,
        "cnn_dailymail/3.0.0": 27208,
        "common_gen": 26584,
        "cos_e/v1.11": 27458,
        "glue/mrpc": 26700,
        "kilt_tasks/hotpotqa": 27016
      },
      "step": 1690
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -55.54961013793945,
        "ag_news": 61.40415573120117,
        "amazon_polarity": 66.79437255859375,
        "cnn_dailymail/3.0.0": 236.41346740722656,
        "common_gen": 29.586536407470703,
        "cos_e/v1.11": -36.16022491455078,
        "glue/mrpc": 0.7281325459480286,
        "kilt_tasks/hotpotqa": -42.13671112060547
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9576,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11430947482585907,
        "ag_news": 0.12804490327835083,
        "amazon_polarity": 0.1287166029214859,
        "cnn_dailymail/3.0.0": 0.1517692655324936,
        "common_gen": 0.12415122985839844,
        "cos_e/v1.11": 0.11647938191890717,
        "glue/mrpc": 0.12072297930717468,
        "kilt_tasks/hotpotqa": 0.11580614745616913
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26856,
        "ag_news": 27920,
        "amazon_polarity": 27056,
        "cnn_dailymail/3.0.0": 27384,
        "common_gen": 26760,
        "cos_e/v1.11": 27594,
        "glue/mrpc": 26860,
        "kilt_tasks/hotpotqa": 27136
      },
      "step": 1700
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.2017,
      "eval_samples_per_second": 79.315,
      "eval_steps_per_second": 4.957,
      "step": 1700
    },
    {
      "epoch": 0.0,
      "step": 1700,
      "total_flos": 6.583680336078766e+17,
      "train_loss": 1.2034369939916274,
      "train_runtime": 20824.9144,
      "train_samples_per_second": 61.465,
      "train_steps_per_second": 0.48
    }
  ],
  "max_steps": 10000,
  "num_train_epochs": 18,
  "total_flos": 6.583680336078766e+17,
  "trial_name": null,
  "trial_params": null
}
