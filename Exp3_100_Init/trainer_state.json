{
  "best_metric": 1.0,
  "best_model_checkpoint": "src/../outputs/T5_LM_3B/T0Mixture/weighted_batch_exp3/42/copa/cosine/1.0/16/0.0001/100/100/checkpoint-1200",
  "epoch": 0.00021793614470960008,
  "global_step": 2200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 34.84192657470703,
        "ag_news": 40.59477615356445,
        "amazon_polarity": 37.19737243652344,
        "cnn_dailymail/3.0.0": -59.862831115722656,
        "common_gen": 28.39838218688965,
        "cos_e/v1.11": 29.571889877319336,
        "glue/mrpc": 33.149658203125,
        "kilt_tasks/hotpotqa": 34.94050598144531
      },
      "epoch": 0.0,
      "learning_rate": 1e-05,
      "loss": 5.0363,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13745559751987457,
        "ag_news": 0.14804719388484955,
        "amazon_polarity": 0.1416875571012497,
        "cnn_dailymail/3.0.0": 0.04561369866132736,
        "common_gen": 0.12657859921455383,
        "cos_e/v1.11": 0.12848591804504395,
        "glue/mrpc": 0.1345016062259674,
        "kilt_tasks/hotpotqa": 0.13762988150119781
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 184,
        "ag_news": 144,
        "amazon_polarity": 152,
        "cnn_dailymail/3.0.0": 88,
        "common_gen": 224,
        "cos_e/v1.11": 152,
        "glue/mrpc": 184,
        "kilt_tasks/hotpotqa": 152
      },
      "step": 10
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 64.16357421875,
        "ag_news": 73.54492950439453,
        "amazon_polarity": 72.22808074951172,
        "cnn_dailymail/3.0.0": -352.31884765625,
        "common_gen": 56.3901252746582,
        "cos_e/v1.11": 65.65032196044922,
        "glue/mrpc": 69.4158935546875,
        "kilt_tasks/hotpotqa": 73.42436981201172
      },
      "epoch": 0.0,
      "learning_rate": 2e-05,
      "loss": 4.5224,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13648146390914917,
        "ag_news": 0.1483398824930191,
        "amazon_polarity": 0.14661090075969696,
        "cnn_dailymail/3.0.0": 0.011680585332214832,
        "common_gen": 0.12742525339126587,
        "cos_e/v1.11": 0.13829103112220764,
        "glue/mrpc": 0.14299020171165466,
        "kilt_tasks/hotpotqa": 0.14818069338798523
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 344,
        "ag_news": 264,
        "amazon_polarity": 280,
        "cnn_dailymail/3.0.0": 248,
        "common_gen": 416,
        "cos_e/v1.11": 328,
        "glue/mrpc": 392,
        "kilt_tasks/hotpotqa": 288
      },
      "step": 20
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 84.38127899169922,
        "ag_news": 95.0651626586914,
        "amazon_polarity": 95.08812713623047,
        "cnn_dailymail/3.0.0": -556.1480712890625,
        "common_gen": 57.21168518066406,
        "cos_e/v1.11": 82.33894348144531,
        "glue/mrpc": 82.80672454833984,
        "kilt_tasks/hotpotqa": 95.94197845458984
      },
      "epoch": 0.0,
      "learning_rate": 3e-05,
      "loss": 3.0568,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.14073894917964935,
        "ag_news": 0.1520354449748993,
        "amazon_polarity": 0.15206073224544525,
        "cnn_dailymail/3.0.0": 0.00849774107336998,
        "common_gen": 0.11583041399717331,
        "cos_e/v1.11": 0.13868221640586853,
        "glue/mrpc": 0.139150470495224,
        "kilt_tasks/hotpotqa": 0.153003990650177
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 504,
        "ag_news": 480,
        "amazon_polarity": 488,
        "cnn_dailymail/3.0.0": 336,
        "common_gen": 576,
        "cos_e/v1.11": 456,
        "glue/mrpc": 560,
        "kilt_tasks/hotpotqa": 440
      },
      "step": 30
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 65.95795440673828,
        "ag_news": 87.42615509033203,
        "amazon_polarity": 90.04468536376953,
        "cnn_dailymail/3.0.0": -316.32318115234375,
        "common_gen": 35.25111389160156,
        "cos_e/v1.11": 70.8009262084961,
        "glue/mrpc": 72.57808685302734,
        "kilt_tasks/hotpotqa": 82.10304260253906
      },
      "epoch": 0.0,
      "learning_rate": 4e-05,
      "loss": 2.1913,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13445240259170532,
        "ag_news": 0.15373994410037994,
        "amazon_polarity": 0.1562831699848175,
        "cnn_dailymail/3.0.0": 0.016967404633760452,
        "common_gen": 0.11117059737443924,
        "cos_e/v1.11": 0.13857007026672363,
        "glue/mrpc": 0.14011408388614655,
        "kilt_tasks/hotpotqa": 0.1487022340297699
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 656,
        "ag_news": 680,
        "amazon_polarity": 632,
        "cnn_dailymail/3.0.0": 480,
        "common_gen": 712,
        "cos_e/v1.11": 608,
        "glue/mrpc": 744,
        "kilt_tasks/hotpotqa": 608
      },
      "step": 40
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 61.460411071777344,
        "ag_news": 84.49446105957031,
        "amazon_polarity": 88.05224609375,
        "cnn_dailymail/3.0.0": -246.1605987548828,
        "common_gen": 18.499252319335938,
        "cos_e/v1.11": 65.07942199707031,
        "glue/mrpc": 70.11495971679688,
        "kilt_tasks/hotpotqa": 70.21623229980469
      },
      "epoch": 0.0,
      "learning_rate": 5e-05,
      "loss": 1.7051,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13498687744140625,
        "ag_news": 0.1535167396068573,
        "amazon_polarity": 0.15660671889781952,
        "cnn_dailymail/3.0.0": 0.02734421007335186,
        "common_gen": 0.10640984773635864,
        "cos_e/v1.11": 0.13773635029792786,
        "glue/mrpc": 0.14165960252285004,
        "kilt_tasks/hotpotqa": 0.14173969626426697
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 776,
        "ag_news": 864,
        "amazon_polarity": 896,
        "cnn_dailymail/3.0.0": 568,
        "common_gen": 800,
        "cos_e/v1.11": 792,
        "glue/mrpc": 904,
        "kilt_tasks/hotpotqa": 800
      },
      "step": 50
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 56.392189025878906,
        "ag_news": 83.42279052734375,
        "amazon_polarity": 86.73694610595703,
        "cnn_dailymail/3.0.0": -195.70114135742188,
        "common_gen": 10.07045841217041,
        "cos_e/v1.11": 63.69549560546875,
        "glue/mrpc": 68.3582534790039,
        "kilt_tasks/hotpotqa": 66.29822540283203
      },
      "epoch": 0.0,
      "learning_rate": 6e-05,
      "loss": 1.6535,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1324310600757599,
        "ag_news": 0.15199029445648193,
        "amazon_polarity": 0.15458673238754272,
        "cnn_dailymail/3.0.0": 0.03874633088707924,
        "common_gen": 0.10478053987026215,
        "cos_e/v1.11": 0.1374429613351822,
        "glue/mrpc": 0.140745609998703,
        "kilt_tasks/hotpotqa": 0.1392764300107956
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 952,
        "ag_news": 1024,
        "amazon_polarity": 1096,
        "cnn_dailymail/3.0.0": 752,
        "common_gen": 912,
        "cos_e/v1.11": 920,
        "glue/mrpc": 1032,
        "kilt_tasks/hotpotqa": 992
      },
      "step": 60
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 50.423728942871094,
        "ag_news": 82.66209411621094,
        "amazon_polarity": 86.08250427246094,
        "cnn_dailymail/3.0.0": -144.10711669921875,
        "common_gen": 3.304347038269043,
        "cos_e/v1.11": 68.16702270507812,
        "glue/mrpc": 64.98087310791016,
        "kilt_tasks/hotpotqa": 58.19524002075195
      },
      "epoch": 0.0,
      "learning_rate": 7e-05,
      "loss": 1.5207,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12895843386650085,
        "ag_news": 0.15013840794563293,
        "amazon_polarity": 0.1525876671075821,
        "cnn_dailymail/3.0.0": 0.0528113953769207,
        "common_gen": 0.1034291684627533,
        "cos_e/v1.11": 0.1402016282081604,
        "glue/mrpc": 0.1381102055311203,
        "kilt_tasks/hotpotqa": 0.1337631493806839
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1144,
        "ag_news": 1256,
        "amazon_polarity": 1248,
        "cnn_dailymail/3.0.0": 872,
        "common_gen": 1064,
        "cos_e/v1.11": 1048,
        "glue/mrpc": 1136,
        "kilt_tasks/hotpotqa": 1192
      },
      "step": 70
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 45.42353820800781,
        "ag_news": 82.80432891845703,
        "amazon_polarity": 85.8030014038086,
        "cnn_dailymail/3.0.0": -109.57884216308594,
        "common_gen": -0.4228443205356598,
        "cos_e/v1.11": 67.96190643310547,
        "glue/mrpc": 65.11884307861328,
        "kilt_tasks/hotpotqa": 55.28241729736328
      },
      "epoch": 0.0,
      "learning_rate": 8e-05,
      "loss": 1.5139,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12589657306671143,
        "ag_news": 0.14847037196159363,
        "amazon_polarity": 0.1504536122083664,
        "cnn_dailymail/3.0.0": 0.06435908377170563,
        "common_gen": 0.1029852032661438,
        "cos_e/v1.11": 0.13904382288455963,
        "glue/mrpc": 0.13730990886688232,
        "kilt_tasks/hotpotqa": 0.13148154318332672
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1312,
        "ag_news": 1440,
        "amazon_polarity": 1392,
        "cnn_dailymail/3.0.0": 1000,
        "common_gen": 1200,
        "cos_e/v1.11": 1264,
        "glue/mrpc": 1272,
        "kilt_tasks/hotpotqa": 1360
      },
      "step": 80
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 37.884891510009766,
        "ag_news": 82.38020324707031,
        "amazon_polarity": 85.71041870117188,
        "cnn_dailymail/3.0.0": -101.95450592041016,
        "common_gen": 3.0237066745758057,
        "cos_e/v1.11": 69.97180938720703,
        "glue/mrpc": 65.49054718017578,
        "kilt_tasks/hotpotqa": 51.05107879638672
      },
      "epoch": 0.0,
      "learning_rate": 9e-05,
      "loss": 1.4283,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12234359979629517,
        "ag_news": 0.1472175121307373,
        "amazon_polarity": 0.1492774933576584,
        "cnn_dailymail/3.0.0": 0.06901837140321732,
        "common_gen": 0.10591956228017807,
        "cos_e/v1.11": 0.13979636132717133,
        "glue/mrpc": 0.13721197843551636,
        "kilt_tasks/hotpotqa": 0.12921519577503204
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1496,
        "ag_news": 1616,
        "amazon_polarity": 1504,
        "cnn_dailymail/3.0.0": 1144,
        "common_gen": 1376,
        "cos_e/v1.11": 1416,
        "glue/mrpc": 1464,
        "kilt_tasks/hotpotqa": 1504
      },
      "step": 90
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 28.045333862304688,
        "ag_news": 82.49333953857422,
        "amazon_polarity": 85.01155090332031,
        "cnn_dailymail/3.0.0": -72.72421264648438,
        "common_gen": -2.79848051071167,
        "cos_e/v1.11": 71.84139251708984,
        "glue/mrpc": 63.048187255859375,
        "kilt_tasks/hotpotqa": 53.512725830078125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2806,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11772117018699646,
        "ag_news": 0.14593075215816498,
        "amazon_polarity": 0.1473928838968277,
        "cnn_dailymail/3.0.0": 0.07946772873401642,
        "common_gen": 0.10430669784545898,
        "cos_e/v1.11": 0.13990922272205353,
        "glue/mrpc": 0.13513144850730896,
        "kilt_tasks/hotpotqa": 0.13014008104801178
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1656,
        "ag_news": 1760,
        "amazon_polarity": 1752,
        "cnn_dailymail/3.0.0": 1336,
        "common_gen": 1480,
        "cos_e/v1.11": 1576,
        "glue/mrpc": 1632,
        "kilt_tasks/hotpotqa": 1608
      },
      "step": 100
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.75,
      "eval_runtime": 0.4654,
      "eval_samples_per_second": 34.381,
      "eval_steps_per_second": 2.149,
      "step": 100
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 25.198511123657227,
        "ag_news": 82.35230255126953,
        "amazon_polarity": 84.7499008178711,
        "cnn_dailymail/3.0.0": -54.040096282958984,
        "common_gen": -5.214512825012207,
        "cos_e/v1.11": 68.9211196899414,
        "glue/mrpc": 62.39195251464844,
        "kilt_tasks/hotpotqa": 48.139801025390625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4358,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11700712144374847,
        "ag_news": 0.1450842320919037,
        "amazon_polarity": 0.14640353620052338,
        "cnn_dailymail/3.0.0": 0.08707083761692047,
        "common_gen": 0.1044183224439621,
        "cos_e/v1.11": 0.13791611790657043,
        "glue/mrpc": 0.13456416130065918,
        "kilt_tasks/hotpotqa": 0.1275356262922287
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1776,
        "ag_news": 1904,
        "amazon_polarity": 1928,
        "cnn_dailymail/3.0.0": 1584,
        "common_gen": 1592,
        "cos_e/v1.11": 1736,
        "glue/mrpc": 1816,
        "kilt_tasks/hotpotqa": 1744
      },
      "step": 110
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 17.397125244140625,
        "ag_news": 81.84452056884766,
        "amazon_polarity": 84.02637481689453,
        "cnn_dailymail/3.0.0": -32.49113082885742,
        "common_gen": -3.582038164138794,
        "cos_e/v1.11": 67.91100311279297,
        "glue/mrpc": 60.70828628540039,
        "kilt_tasks/hotpotqa": 42.69389343261719
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3262,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11415298283100128,
        "ag_news": 0.1439915895462036,
        "amazon_polarity": 0.14513197541236877,
        "cnn_dailymail/3.0.0": 0.0954875722527504,
        "common_gen": 0.10588101297616959,
        "cos_e/v1.11": 0.13692277669906616,
        "glue/mrpc": 0.13340945541858673,
        "kilt_tasks/hotpotqa": 0.1250227391719818
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1952,
        "ag_news": 2000,
        "amazon_polarity": 2192,
        "cnn_dailymail/3.0.0": 1744,
        "common_gen": 1744,
        "cos_e/v1.11": 1840,
        "glue/mrpc": 1960,
        "kilt_tasks/hotpotqa": 1928
      },
      "step": 120
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 16.234203338623047,
        "ag_news": 81.04910278320312,
        "amazon_polarity": 84.10157775878906,
        "cnn_dailymail/3.0.0": -18.417686462402344,
        "common_gen": -9.879430770874023,
        "cos_e/v1.11": 68.42676544189453,
        "glue/mrpc": 57.75150680541992,
        "kilt_tasks/hotpotqa": 40.24843215942383
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3757,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11419354379177094,
        "ag_news": 0.1429319828748703,
        "amazon_polarity": 0.1444559544324875,
        "cnn_dailymail/3.0.0": 0.10134420543909073,
        "common_gen": 0.10436458885669708,
        "cos_e/v1.11": 0.13680317997932434,
        "glue/mrpc": 0.1318306028842926,
        "kilt_tasks/hotpotqa": 0.12407594174146652
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2080,
        "ag_news": 2224,
        "amazon_polarity": 2320,
        "cnn_dailymail/3.0.0": 1880,
        "common_gen": 1952,
        "cos_e/v1.11": 2000,
        "glue/mrpc": 2096,
        "kilt_tasks/hotpotqa": 2088
      },
      "step": 130
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 10.484793663024902,
        "ag_news": 80.09918212890625,
        "amazon_polarity": 83.8991928100586,
        "cnn_dailymail/3.0.0": -4.99697732925415,
        "common_gen": -7.6339335441589355,
        "cos_e/v1.11": 67.3255615234375,
        "glue/mrpc": 57.99394226074219,
        "kilt_tasks/hotpotqa": 39.9653434753418
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.435,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11217927932739258,
        "ag_news": 0.14152105152606964,
        "amazon_polarity": 0.14333339035511017,
        "cnn_dailymail/3.0.0": 0.10655291378498077,
        "common_gen": 0.10562402755022049,
        "cos_e/v1.11": 0.1355992704629898,
        "glue/mrpc": 0.13143432140350342,
        "kilt_tasks/hotpotqa": 0.12375573813915253
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2288,
        "ag_news": 2320,
        "amazon_polarity": 2472,
        "cnn_dailymail/3.0.0": 2032,
        "common_gen": 2144,
        "cos_e/v1.11": 2152,
        "glue/mrpc": 2280,
        "kilt_tasks/hotpotqa": 2232
      },
      "step": 140
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 7.666872978210449,
        "ag_news": 80.41071319580078,
        "amazon_polarity": 83.1076431274414,
        "cnn_dailymail/3.0.0": 8.19124984741211,
        "common_gen": -4.858184814453125,
        "cos_e/v1.11": 63.98013687133789,
        "glue/mrpc": 57.16481399536133,
        "kilt_tasks/hotpotqa": 36.49845886230469
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4312,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11146469414234161,
        "ag_news": 0.14094190299510956,
        "amazon_polarity": 0.14217722415924072,
        "cnn_dailymail/3.0.0": 0.11165277659893036,
        "common_gen": 0.10706820338964462,
        "cos_e/v1.11": 0.13364969193935394,
        "glue/mrpc": 0.1307394802570343,
        "kilt_tasks/hotpotqa": 0.12230600416660309
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2432,
        "ag_news": 2504,
        "amazon_polarity": 2616,
        "cnn_dailymail/3.0.0": 2200,
        "common_gen": 2312,
        "cos_e/v1.11": 2320,
        "glue/mrpc": 2408,
        "kilt_tasks/hotpotqa": 2408
      },
      "step": 150
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 5.6462082862854,
        "ag_news": 79.26277923583984,
        "amazon_polarity": 83.17915344238281,
        "cnn_dailymail/3.0.0": 25.285537719726562,
        "common_gen": 2.3561758995056152,
        "cos_e/v1.11": 52.266292572021484,
        "glue/mrpc": 55.115543365478516,
        "kilt_tasks/hotpotqa": 36.38597106933594
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.349,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11099065840244293,
        "ag_news": 0.13968975841999054,
        "amazon_polarity": 0.14141462743282318,
        "cnn_dailymail/3.0.0": 0.11799713969230652,
        "common_gen": 0.10985946655273438,
        "cos_e/v1.11": 0.12837126851081848,
        "glue/mrpc": 0.12952011823654175,
        "kilt_tasks/hotpotqa": 0.12215689569711685
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2608,
        "ag_news": 2648,
        "amazon_polarity": 2800,
        "cnn_dailymail/3.0.0": 2360,
        "common_gen": 2480,
        "cos_e/v1.11": 2472,
        "glue/mrpc": 2528,
        "kilt_tasks/hotpotqa": 2584
      },
      "step": 160
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 2.1637115478515625,
        "ag_news": 79.3574447631836,
        "amazon_polarity": 83.29998016357422,
        "cnn_dailymail/3.0.0": 38.39927291870117,
        "common_gen": 2.0741710662841797,
        "cos_e/v1.11": 48.41735076904297,
        "glue/mrpc": 53.992923736572266,
        "kilt_tasks/hotpotqa": 37.140865325927734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3811,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1100093349814415,
        "ag_news": 0.13901402056217194,
        "amazon_polarity": 0.14069055020809174,
        "cnn_dailymail/3.0.0": 0.12276057153940201,
        "common_gen": 0.10997956246137619,
        "cos_e/v1.11": 0.12654690444469452,
        "glue/mrpc": 0.12870587408542633,
        "kilt_tasks/hotpotqa": 0.12229321897029877
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2768,
        "ag_news": 2872,
        "amazon_polarity": 2896,
        "cnn_dailymail/3.0.0": 2504,
        "common_gen": 2648,
        "cos_e/v1.11": 2592,
        "glue/mrpc": 2688,
        "kilt_tasks/hotpotqa": 2792
      },
      "step": 170
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 0.8422014713287354,
        "ag_news": 79.6224594116211,
        "amazon_polarity": 83.07139587402344,
        "cnn_dailymail/3.0.0": 44.468807220458984,
        "common_gen": -0.47712624073028564,
        "cos_e/v1.11": 53.254520416259766,
        "glue/mrpc": 54.2285270690918,
        "kilt_tasks/hotpotqa": 34.966590881347656
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3293,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10975271463394165,
        "ag_news": 0.13843412697315216,
        "amazon_polarity": 0.13985249400138855,
        "cnn_dailymail/3.0.0": 0.12478980422019958,
        "common_gen": 0.10932812839746475,
        "cos_e/v1.11": 0.12806522846221924,
        "glue/mrpc": 0.12843374907970428,
        "kilt_tasks/hotpotqa": 0.12134373188018799
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2904,
        "ag_news": 3032,
        "amazon_polarity": 3080,
        "cnn_dailymail/3.0.0": 2616,
        "common_gen": 2864,
        "cos_e/v1.11": 2744,
        "glue/mrpc": 2824,
        "kilt_tasks/hotpotqa": 2976
      },
      "step": 180
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -2.3747920989990234,
        "ag_news": 79.60002899169922,
        "amazon_polarity": 82.79463195800781,
        "cnn_dailymail/3.0.0": 53.951454162597656,
        "common_gen": -1.2403532266616821,
        "cos_e/v1.11": 56.0435676574707,
        "glue/mrpc": 53.093528747558594,
        "kilt_tasks/hotpotqa": 33.313907623291016
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3964,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10890021175146103,
        "ag_news": 0.1377747803926468,
        "amazon_polarity": 0.13904701173305511,
        "cnn_dailymail/3.0.0": 0.1279820203781128,
        "common_gen": 0.10925418138504028,
        "cos_e/v1.11": 0.1287534534931183,
        "glue/mrpc": 0.12766703963279724,
        "kilt_tasks/hotpotqa": 0.12062134593725204
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3000,
        "ag_news": 3232,
        "amazon_polarity": 3232,
        "cnn_dailymail/3.0.0": 2776,
        "common_gen": 3040,
        "cos_e/v1.11": 2912,
        "glue/mrpc": 2960,
        "kilt_tasks/hotpotqa": 3168
      },
      "step": 190
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -2.9665985107421875,
        "ag_news": 79.3297119140625,
        "amazon_polarity": 82.6838607788086,
        "cnn_dailymail/3.0.0": 61.05463790893555,
        "common_gen": -3.9251351356506348,
        "cos_e/v1.11": 56.0893669128418,
        "glue/mrpc": 52.60076141357422,
        "kilt_tasks/hotpotqa": 31.260107040405273
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.5532,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10904235392808914,
        "ag_news": 0.13726943731307983,
        "amazon_polarity": 0.1385670155286789,
        "cnn_dailymail/3.0.0": 0.13041438162326813,
        "common_gen": 0.10875120759010315,
        "cos_e/v1.11": 0.12861305475234985,
        "glue/mrpc": 0.1273626834154129,
        "kilt_tasks/hotpotqa": 0.11997992545366287
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3136,
        "ag_news": 3352,
        "amazon_polarity": 3344,
        "cnn_dailymail/3.0.0": 2992,
        "common_gen": 3216,
        "cos_e/v1.11": 3112,
        "glue/mrpc": 3088,
        "kilt_tasks/hotpotqa": 3360
      },
      "step": 200
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.372,
      "eval_samples_per_second": 43.011,
      "eval_steps_per_second": 2.688,
      "step": 200
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -2.1269397735595703,
        "ag_news": 78.87004089355469,
        "amazon_polarity": 82.47438049316406,
        "cnn_dailymail/3.0.0": 67.41957092285156,
        "common_gen": -5.5360941886901855,
        "cos_e/v1.11": 51.989742279052734,
        "glue/mrpc": 53.286293029785156,
        "kilt_tasks/hotpotqa": 29.544601440429688
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4399,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10965034365653992,
        "ag_news": 0.13679622113704681,
        "amazon_polarity": 0.13815291225910187,
        "cnn_dailymail/3.0.0": 0.13257580995559692,
        "common_gen": 0.10863704979419708,
        "cos_e/v1.11": 0.12709815800189972,
        "glue/mrpc": 0.12754939496517181,
        "kilt_tasks/hotpotqa": 0.11954011023044586
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3280,
        "ag_news": 3488,
        "amazon_polarity": 3520,
        "cnn_dailymail/3.0.0": 3136,
        "common_gen": 3416,
        "cos_e/v1.11": 3256,
        "glue/mrpc": 3192,
        "kilt_tasks/hotpotqa": 3592
      },
      "step": 210
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -2.6292991638183594,
        "ag_news": 78.58065795898438,
        "amazon_polarity": 82.31775665283203,
        "cnn_dailymail/3.0.0": 69.90565490722656,
        "common_gen": -5.416243553161621,
        "cos_e/v1.11": 53.118614196777344,
        "glue/mrpc": 53.988285064697266,
        "kilt_tasks/hotpotqa": 27.47071647644043
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3227,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10977577418088913,
        "ag_news": 0.13634425401687622,
        "amazon_polarity": 0.13771438598632812,
        "cnn_dailymail/3.0.0": 0.13321712613105774,
        "common_gen": 0.10896442830562592,
        "cos_e/v1.11": 0.127372145652771,
        "glue/mrpc": 0.12766841053962708,
        "kilt_tasks/hotpotqa": 0.1189434826374054
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3424,
        "ag_news": 3632,
        "amazon_polarity": 3640,
        "cnn_dailymail/3.0.0": 3344,
        "common_gen": 3528,
        "cos_e/v1.11": 3456,
        "glue/mrpc": 3392,
        "kilt_tasks/hotpotqa": 3744
      },
      "step": 220
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -6.178213119506836,
        "ag_news": 78.34059143066406,
        "amazon_polarity": 82.04275512695312,
        "cnn_dailymail/3.0.0": 73.4415512084961,
        "common_gen": -8.755563735961914,
        "cos_e/v1.11": 54.17066192626953,
        "glue/mrpc": 53.48312759399414,
        "kilt_tasks/hotpotqa": 27.83619499206543
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3251,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10914702713489532,
        "ag_news": 0.13609592616558075,
        "amazon_polarity": 0.13742107152938843,
        "cnn_dailymail/3.0.0": 0.13436241447925568,
        "common_gen": 0.10841696709394455,
        "cos_e/v1.11": 0.1277591735124588,
        "glue/mrpc": 0.1275297999382019,
        "kilt_tasks/hotpotqa": 0.11926761269569397
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3592,
        "ag_news": 3712,
        "amazon_polarity": 3800,
        "cnn_dailymail/3.0.0": 3520,
        "common_gen": 3664,
        "cos_e/v1.11": 3616,
        "glue/mrpc": 3664,
        "kilt_tasks/hotpotqa": 3872
      },
      "step": 230
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -7.9807610511779785,
        "ag_news": 78.09626007080078,
        "amazon_polarity": 82.03616333007812,
        "cnn_dailymail/3.0.0": 77.57717895507812,
        "common_gen": -13.079720497131348,
        "cos_e/v1.11": 44.85148620605469,
        "glue/mrpc": 50.51077651977539,
        "kilt_tasks/hotpotqa": 30.272563934326172
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.452,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10935144126415253,
        "ag_news": 0.13627013564109802,
        "amazon_polarity": 0.13765309751033783,
        "cnn_dailymail/3.0.0": 0.1360890120267868,
        "common_gen": 0.10793886333703995,
        "cos_e/v1.11": 0.125150665640831,
        "glue/mrpc": 0.12697598338127136,
        "kilt_tasks/hotpotqa": 0.12057086825370789
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3728,
        "ag_news": 3864,
        "amazon_polarity": 3928,
        "cnn_dailymail/3.0.0": 3728,
        "common_gen": 3840,
        "cos_e/v1.11": 3736,
        "glue/mrpc": 3756,
        "kilt_tasks/hotpotqa": 4136
      },
      "step": 240
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -11.642439842224121,
        "ag_news": 77.80540466308594,
        "amazon_polarity": 82.0157699584961,
        "cnn_dailymail/3.0.0": 82.31981658935547,
        "common_gen": -11.104777336120605,
        "cos_e/v1.11": 45.215049743652344,
        "glue/mrpc": 49.422447204589844,
        "kilt_tasks/hotpotqa": 30.42829132080078
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3184,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10855787992477417,
        "ag_news": 0.13582804799079895,
        "amazon_polarity": 0.1372719705104828,
        "cnn_dailymail/3.0.0": 0.1373768448829651,
        "common_gen": 0.1087038516998291,
        "cos_e/v1.11": 0.12516246736049652,
        "glue/mrpc": 0.12648989260196686,
        "kilt_tasks/hotpotqa": 0.12060905992984772
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3872,
        "ag_news": 4024,
        "amazon_polarity": 4080,
        "cnn_dailymail/3.0.0": 3888,
        "common_gen": 4008,
        "cos_e/v1.11": 3880,
        "glue/mrpc": 3916,
        "kilt_tasks/hotpotqa": 4328
      },
      "step": 250
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -10.587920188903809,
        "ag_news": 77.80069732666016,
        "amazon_polarity": 81.94906616210938,
        "cnn_dailymail/3.0.0": 89.44587707519531,
        "common_gen": -8.433154106140137,
        "cos_e/v1.11": 47.366241455078125,
        "glue/mrpc": 55.91212844848633,
        "kilt_tasks/hotpotqa": 26.698152542114258
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3445,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10859967023134232,
        "ag_news": 0.1349446028470993,
        "amazon_polarity": 0.13633044064044952,
        "cnn_dailymail/3.0.0": 0.13887177407741547,
        "common_gen": 0.10917488485574722,
        "cos_e/v1.11": 0.1252068132162094,
        "glue/mrpc": 0.1278664916753769,
        "kilt_tasks/hotpotqa": 0.11900536715984344
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3968,
        "ag_news": 4208,
        "amazon_polarity": 4208,
        "cnn_dailymail/3.0.0": 4032,
        "common_gen": 4176,
        "cos_e/v1.11": 4088,
        "glue/mrpc": 4068,
        "kilt_tasks/hotpotqa": 4528
      },
      "step": 260
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -9.59599494934082,
        "ag_news": 77.60668182373047,
        "amazon_polarity": 81.75872802734375,
        "cnn_dailymail/3.0.0": 96.2482681274414,
        "common_gen": -16.905302047729492,
        "cos_e/v1.11": 49.708431243896484,
        "glue/mrpc": 52.49143600463867,
        "kilt_tasks/hotpotqa": 27.849210739135742
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3659,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10912611335515976,
        "ag_news": 0.13467177748680115,
        "amazon_polarity": 0.13603027164936066,
        "cnn_dailymail/3.0.0": 0.14088135957717896,
        "common_gen": 0.10722369700670242,
        "cos_e/v1.11": 0.12589526176452637,
        "glue/mrpc": 0.12674395740032196,
        "kilt_tasks/hotpotqa": 0.1194276362657547
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4120,
        "ag_news": 4312,
        "amazon_polarity": 4384,
        "cnn_dailymail/3.0.0": 4208,
        "common_gen": 4328,
        "cos_e/v1.11": 4264,
        "glue/mrpc": 4228,
        "kilt_tasks/hotpotqa": 4712
      },
      "step": 270
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -12.488814353942871,
        "ag_news": 77.4345474243164,
        "amazon_polarity": 81.40059661865234,
        "cnn_dailymail/3.0.0": 98.71244812011719,
        "common_gen": -13.891853332519531,
        "cos_e/v1.11": 50.383087158203125,
        "glue/mrpc": 49.53105545043945,
        "kilt_tasks/hotpotqa": 27.802661895751953
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3205,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10865460336208344,
        "ag_news": 0.13445138931274414,
        "amazon_polarity": 0.13572339713573456,
        "cnn_dailymail/3.0.0": 0.1414206624031067,
        "common_gen": 0.10829488188028336,
        "cos_e/v1.11": 0.12609326839447021,
        "glue/mrpc": 0.12583878636360168,
        "kilt_tasks/hotpotqa": 0.11952313035726547
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4256,
        "ag_news": 4512,
        "amazon_polarity": 4528,
        "cnn_dailymail/3.0.0": 4344,
        "common_gen": 4464,
        "cos_e/v1.11": 4464,
        "glue/mrpc": 4380,
        "kilt_tasks/hotpotqa": 4888
      },
      "step": 280
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -16.852766036987305,
        "ag_news": 77.35096740722656,
        "amazon_polarity": 81.28052520751953,
        "cnn_dailymail/3.0.0": 97.26799011230469,
        "common_gen": -12.632718086242676,
        "cos_e/v1.11": 43.15393829345703,
        "glue/mrpc": 49.94564437866211,
        "kilt_tasks/hotpotqa": 30.75466537475586
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2104,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1080923080444336,
        "ag_news": 0.1346009373664856,
        "amazon_polarity": 0.13584081828594208,
        "cnn_dailymail/3.0.0": 0.14100617170333862,
        "common_gen": 0.1091572493314743,
        "cos_e/v1.11": 0.12428595870733261,
        "glue/mrpc": 0.1262684464454651,
        "kilt_tasks/hotpotqa": 0.12074808031320572
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4456,
        "ag_news": 4688,
        "amazon_polarity": 4696,
        "cnn_dailymail/3.0.0": 4480,
        "common_gen": 4584,
        "cos_e/v1.11": 4656,
        "glue/mrpc": 4516,
        "kilt_tasks/hotpotqa": 5040
      },
      "step": 290
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -15.30046272277832,
        "ag_news": 77.29802703857422,
        "amazon_polarity": 81.17595672607422,
        "cnn_dailymail/3.0.0": 100.84896850585938,
        "common_gen": -17.30670166015625,
        "cos_e/v1.11": 38.487606048583984,
        "glue/mrpc": 51.470672607421875,
        "kilt_tasks/hotpotqa": 30.860504150390625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2938,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1088009849190712,
        "ag_news": 0.13449786603450775,
        "amazon_polarity": 0.13569998741149902,
        "cnn_dailymail/3.0.0": 0.14196893572807312,
        "common_gen": 0.10830342769622803,
        "cos_e/v1.11": 0.12304803729057312,
        "glue/mrpc": 0.12676340341567993,
        "kilt_tasks/hotpotqa": 0.12091734260320663
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4592,
        "ag_news": 4816,
        "amazon_polarity": 4904,
        "cnn_dailymail/3.0.0": 4720,
        "common_gen": 4720,
        "cos_e/v1.11": 4848,
        "glue/mrpc": 4668,
        "kilt_tasks/hotpotqa": 5128
      },
      "step": 300
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.75,
      "eval_runtime": 0.1921,
      "eval_samples_per_second": 83.286,
      "eval_steps_per_second": 5.205,
      "step": 300
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -16.28234100341797,
        "ag_news": 77.05486297607422,
        "amazon_polarity": 81.11019134521484,
        "cnn_dailymail/3.0.0": 102.71802520751953,
        "common_gen": -20.000879287719727,
        "cos_e/v1.11": 43.412841796875,
        "glue/mrpc": 54.90895080566406,
        "kilt_tasks/hotpotqa": 29.76991081237793
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3369,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10862898826599121,
        "ag_news": 0.13405059278011322,
        "amazon_polarity": 0.1352834552526474,
        "cnn_dailymail/3.0.0": 0.1420496106147766,
        "common_gen": 0.10772474855184555,
        "cos_e/v1.11": 0.12425395101308823,
        "glue/mrpc": 0.12751686573028564,
        "kilt_tasks/hotpotqa": 0.12049183249473572
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4760,
        "ag_news": 4976,
        "amazon_polarity": 5016,
        "cnn_dailymail/3.0.0": 4936,
        "common_gen": 4896,
        "cos_e/v1.11": 5000,
        "glue/mrpc": 4788,
        "kilt_tasks/hotpotqa": 5304
      },
      "step": 310
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -19.869890213012695,
        "ag_news": 76.97962188720703,
        "amazon_polarity": 80.85597229003906,
        "cnn_dailymail/3.0.0": 102.38231658935547,
        "common_gen": -19.41482925415039,
        "cos_e/v1.11": 42.464988708496094,
        "glue/mrpc": 49.42269515991211,
        "kilt_tasks/hotpotqa": 28.94058609008789
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2952,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1083311066031456,
        "ag_news": 0.13428838551044464,
        "amazon_polarity": 0.13545025885105133,
        "cnn_dailymail/3.0.0": 0.14209093153476715,
        "common_gen": 0.10844026505947113,
        "cos_e/v1.11": 0.12438000738620758,
        "glue/mrpc": 0.12631569802761078,
        "kilt_tasks/hotpotqa": 0.12070340663194656
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4944,
        "ag_news": 5120,
        "amazon_polarity": 5176,
        "cnn_dailymail/3.0.0": 5128,
        "common_gen": 5088,
        "cos_e/v1.11": 5136,
        "glue/mrpc": 4948,
        "kilt_tasks/hotpotqa": 5416
      },
      "step": 320
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -24.285329818725586,
        "ag_news": 76.92604064941406,
        "amazon_polarity": 79.79348754882812,
        "cnn_dailymail/3.0.0": 105.8392562866211,
        "common_gen": -17.43682861328125,
        "cos_e/v1.11": 40.57398223876953,
        "glue/mrpc": 49.24324417114258,
        "kilt_tasks/hotpotqa": 24.088788986206055
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2959,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10770982503890991,
        "ag_news": 0.13435925543308258,
        "amazon_polarity": 0.13520517945289612,
        "cnn_dailymail/3.0.0": 0.14314129948616028,
        "common_gen": 0.10932991653680801,
        "cos_e/v1.11": 0.12409014254808426,
        "glue/mrpc": 0.12646421790122986,
        "kilt_tasks/hotpotqa": 0.1197001039981842
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5096,
        "ag_news": 5288,
        "amazon_polarity": 5328,
        "cnn_dailymail/3.0.0": 5256,
        "common_gen": 5272,
        "cos_e/v1.11": 5296,
        "glue/mrpc": 5116,
        "kilt_tasks/hotpotqa": 5584
      },
      "step": 330
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -22.02442741394043,
        "ag_news": 76.86697387695312,
        "amazon_polarity": 79.6675796508789,
        "cnn_dailymail/3.0.0": 109.34172821044922,
        "common_gen": -22.250450134277344,
        "cos_e/v1.11": 38.03019714355469,
        "glue/mrpc": 51.8394660949707,
        "kilt_tasks/hotpotqa": 27.0572509765625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2766,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10834407806396484,
        "ag_news": 0.1340440958738327,
        "amazon_polarity": 0.13485614955425262,
        "cnn_dailymail/3.0.0": 0.14377379417419434,
        "common_gen": 0.10829149186611176,
        "cos_e/v1.11": 0.12328220158815384,
        "glue/mrpc": 0.12700429558753967,
        "kilt_tasks/hotpotqa": 0.12040390819311142
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5216,
        "ag_news": 5488,
        "amazon_polarity": 5488,
        "cnn_dailymail/3.0.0": 5472,
        "common_gen": 5424,
        "cos_e/v1.11": 5400,
        "glue/mrpc": 5284,
        "kilt_tasks/hotpotqa": 5744
      },
      "step": 340
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -20.209720611572266,
        "ag_news": 76.8281478881836,
        "amazon_polarity": 79.71762084960938,
        "cnn_dailymail/3.0.0": 108.81737518310547,
        "common_gen": -22.030929565429688,
        "cos_e/v1.11": 35.67890548706055,
        "glue/mrpc": 50.89750671386719,
        "kilt_tasks/hotpotqa": 23.763164520263672
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2937,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10914097726345062,
        "ag_news": 0.13409583270549774,
        "amazon_polarity": 0.1349221169948578,
        "cnn_dailymail/3.0.0": 0.14353741705417633,
        "common_gen": 0.10872083902359009,
        "cos_e/v1.11": 0.12287190556526184,
        "glue/mrpc": 0.1269071400165558,
        "kilt_tasks/hotpotqa": 0.1198037713766098
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5376,
        "ag_news": 5664,
        "amazon_polarity": 5656,
        "cnn_dailymail/3.0.0": 5664,
        "common_gen": 5568,
        "cos_e/v1.11": 5536,
        "glue/mrpc": 5404,
        "kilt_tasks/hotpotqa": 5928
      },
      "step": 350
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -23.968036651611328,
        "ag_news": 77.01039123535156,
        "amazon_polarity": 79.85128021240234,
        "cnn_dailymail/3.0.0": 112.33898162841797,
        "common_gen": -21.373672485351562,
        "cos_e/v1.11": 37.50780487060547,
        "glue/mrpc": 48.70113754272461,
        "kilt_tasks/hotpotqa": 22.56426429748535
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2803,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10849315673112869,
        "ag_news": 0.13402022421360016,
        "amazon_polarity": 0.13482080399990082,
        "cnn_dailymail/3.0.0": 0.14432919025421143,
        "common_gen": 0.10908263176679611,
        "cos_e/v1.11": 0.12337571382522583,
        "glue/mrpc": 0.12630151212215424,
        "kilt_tasks/hotpotqa": 0.11957679688930511
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5520,
        "ag_news": 5864,
        "amazon_polarity": 5808,
        "cnn_dailymail/3.0.0": 5816,
        "common_gen": 5672,
        "cos_e/v1.11": 5696,
        "glue/mrpc": 5588,
        "kilt_tasks/hotpotqa": 6112
      },
      "step": 360
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -21.805578231811523,
        "ag_news": 76.8227310180664,
        "amazon_polarity": 79.83213806152344,
        "cnn_dailymail/3.0.0": 116.69343566894531,
        "common_gen": -15.372516632080078,
        "cos_e/v1.11": 38.6098747253418,
        "glue/mrpc": 48.305015563964844,
        "kilt_tasks/hotpotqa": 22.250938415527344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2692,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1088448166847229,
        "ag_news": 0.13342420756816864,
        "amazon_polarity": 0.1342572271823883,
        "cnn_dailymail/3.0.0": 0.14489950239658356,
        "common_gen": 0.11029744148254395,
        "cos_e/v1.11": 0.12329252064228058,
        "glue/mrpc": 0.12578657269477844,
        "kilt_tasks/hotpotqa": 0.11919768154621124
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5632,
        "ag_news": 6008,
        "amazon_polarity": 6016,
        "cnn_dailymail/3.0.0": 5944,
        "common_gen": 5824,
        "cos_e/v1.11": 5904,
        "glue/mrpc": 5764,
        "kilt_tasks/hotpotqa": 6264
      },
      "step": 370
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -24.770328521728516,
        "ag_news": 76.50021362304688,
        "amazon_polarity": 79.75040435791016,
        "cnn_dailymail/3.0.0": 118.13842010498047,
        "common_gen": -16.365596771240234,
        "cos_e/v1.11": 36.65900802612305,
        "glue/mrpc": 48.39085006713867,
        "kilt_tasks/hotpotqa": 23.8834171295166
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2407,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1084606796503067,
        "ag_news": 0.133314311504364,
        "amazon_polarity": 0.13420161604881287,
        "cnn_dailymail/3.0.0": 0.14514662325382233,
        "common_gen": 0.11033064872026443,
        "cos_e/v1.11": 0.12290988117456436,
        "glue/mrpc": 0.12588487565517426,
        "kilt_tasks/hotpotqa": 0.1197514608502388
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5816,
        "ag_news": 6208,
        "amazon_polarity": 6176,
        "cnn_dailymail/3.0.0": 6064,
        "common_gen": 6000,
        "cos_e/v1.11": 6040,
        "glue/mrpc": 5940,
        "kilt_tasks/hotpotqa": 6392
      },
      "step": 380
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -31.74551773071289,
        "ag_news": 76.46659088134766,
        "amazon_polarity": 79.8717041015625,
        "cnn_dailymail/3.0.0": 119.9168472290039,
        "common_gen": -20.684236526489258,
        "cos_e/v1.11": 31.42470359802246,
        "glue/mrpc": 45.50177001953125,
        "kilt_tasks/hotpotqa": 23.71422576904297
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2195,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10757879912853241,
        "ag_news": 0.13373595476150513,
        "amazon_polarity": 0.13465674221515656,
        "cnn_dailymail/3.0.0": 0.14598076045513153,
        "common_gen": 0.10999467968940735,
        "cos_e/v1.11": 0.12214107811450958,
        "glue/mrpc": 0.12565071880817413,
        "kilt_tasks/hotpotqa": 0.12026114761829376
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5984,
        "ag_news": 6384,
        "amazon_polarity": 6344,
        "cnn_dailymail/3.0.0": 6256,
        "common_gen": 6168,
        "cos_e/v1.11": 6200,
        "glue/mrpc": 6044,
        "kilt_tasks/hotpotqa": 6536
      },
      "step": 390
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -32.265933990478516,
        "ag_news": 76.36540222167969,
        "amazon_polarity": 79.08625793457031,
        "cnn_dailymail/3.0.0": 125.1317367553711,
        "common_gen": -15.724475860595703,
        "cos_e/v1.11": 33.10718536376953,
        "glue/mrpc": 43.45458221435547,
        "kilt_tasks/hotpotqa": 23.166913986206055
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4232,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10745679587125778,
        "ag_news": 0.1333334743976593,
        "amazon_polarity": 0.13405732810497284,
        "cnn_dailymail/3.0.0": 0.14693008363246918,
        "common_gen": 0.11104003340005875,
        "cos_e/v1.11": 0.12234421074390411,
        "glue/mrpc": 0.12488614767789841,
        "kilt_tasks/hotpotqa": 0.11995183676481247
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6104,
        "ag_news": 6496,
        "amazon_polarity": 6520,
        "cnn_dailymail/3.0.0": 6432,
        "common_gen": 6392,
        "cos_e/v1.11": 6376,
        "glue/mrpc": 6140,
        "kilt_tasks/hotpotqa": 6736
      },
      "step": 400
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1981,
      "eval_samples_per_second": 80.758,
      "eval_steps_per_second": 5.047,
      "step": 400
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -41.191986083984375,
        "ag_news": 76.0867691040039,
        "amazon_polarity": 78.93151092529297,
        "cnn_dailymail/3.0.0": 127.70323181152344,
        "common_gen": -10.992992401123047,
        "cos_e/v1.11": 34.31856155395508,
        "glue/mrpc": 47.68288803100586,
        "kilt_tasks/hotpotqa": 23.557723999023438
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2335,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10566524416208267,
        "ag_news": 0.13300058245658875,
        "amazon_polarity": 0.13374634087085724,
        "cnn_dailymail/3.0.0": 0.14721329510211945,
        "common_gen": 0.11210457980632782,
        "cos_e/v1.11": 0.12252435088157654,
        "glue/mrpc": 0.1257818639278412,
        "kilt_tasks/hotpotqa": 0.11996383219957352
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6304,
        "ag_news": 6728,
        "amazon_polarity": 6616,
        "cnn_dailymail/3.0.0": 6576,
        "common_gen": 6544,
        "cos_e/v1.11": 6560,
        "glue/mrpc": 6284,
        "kilt_tasks/hotpotqa": 6864
      },
      "step": 410
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.116573333740234,
        "ag_news": 75.78231811523438,
        "amazon_polarity": 78.74551391601562,
        "cnn_dailymail/3.0.0": 129.5906524658203,
        "common_gen": -10.46005630493164,
        "cos_e/v1.11": 26.545318603515625,
        "glue/mrpc": 48.109737396240234,
        "kilt_tasks/hotpotqa": 18.98554801940918
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1897,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10558460652828217,
        "ag_news": 0.13321293890476227,
        "amazon_polarity": 0.1339818686246872,
        "cnn_dailymail/3.0.0": 0.1479003131389618,
        "common_gen": 0.11269278079271317,
        "cos_e/v1.11": 0.12107233703136444,
        "glue/mrpc": 0.12624485790729523,
        "kilt_tasks/hotpotqa": 0.11931044608354568
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6456,
        "ag_news": 6952,
        "amazon_polarity": 6784,
        "cnn_dailymail/3.0.0": 6736,
        "common_gen": 6672,
        "cos_e/v1.11": 6720,
        "glue/mrpc": 6380,
        "kilt_tasks/hotpotqa": 7056
      },
      "step": 420
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -47.37849426269531,
        "ag_news": 75.70267486572266,
        "amazon_polarity": 77.96428680419922,
        "cnn_dailymail/3.0.0": 131.10064697265625,
        "common_gen": -19.051231384277344,
        "cos_e/v1.11": 27.948232650756836,
        "glue/mrpc": 50.29514694213867,
        "kilt_tasks/hotpotqa": 25.30413055419922
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3132,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1051364541053772,
        "ag_news": 0.1330995112657547,
        "amazon_polarity": 0.13367868959903717,
        "cnn_dailymail/3.0.0": 0.14804688096046448,
        "common_gen": 0.1109914556145668,
        "cos_e/v1.11": 0.12144776433706284,
        "glue/mrpc": 0.12676547467708588,
        "kilt_tasks/hotpotqa": 0.12083376199007034
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6616,
        "ag_news": 7096,
        "amazon_polarity": 6904,
        "cnn_dailymail/3.0.0": 6880,
        "common_gen": 6864,
        "cos_e/v1.11": 6920,
        "glue/mrpc": 6532,
        "kilt_tasks/hotpotqa": 7224
      },
      "step": 430
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -55.747344970703125,
        "ag_news": 75.6464614868164,
        "amazon_polarity": 78.14994049072266,
        "cnn_dailymail/3.0.0": 134.31173706054688,
        "common_gen": -23.00988006591797,
        "cos_e/v1.11": 26.7725830078125,
        "glue/mrpc": 50.454776763916016,
        "kilt_tasks/hotpotqa": 19.2819766998291
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3369,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10402093082666397,
        "ag_news": 0.13341933488845825,
        "amazon_polarity": 0.13405486941337585,
        "cnn_dailymail/3.0.0": 0.14914777874946594,
        "common_gen": 0.11066524684429169,
        "cos_e/v1.11": 0.12160696089267731,
        "glue/mrpc": 0.12719199061393738,
        "kilt_tasks/hotpotqa": 0.11989279836416245
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6776,
        "ag_news": 7256,
        "amazon_polarity": 7056,
        "cnn_dailymail/3.0.0": 7136,
        "common_gen": 7048,
        "cos_e/v1.11": 7080,
        "glue/mrpc": 6636,
        "kilt_tasks/hotpotqa": 7328
      },
      "step": 440
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -57.78720474243164,
        "ag_news": 75.5748519897461,
        "amazon_polarity": 77.9723892211914,
        "cnn_dailymail/3.0.0": 134.0334014892578,
        "common_gen": -15.860564231872559,
        "cos_e/v1.11": 29.49567413330078,
        "glue/mrpc": 53.91159439086914,
        "kilt_tasks/hotpotqa": 18.94428062438965
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.124,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10360099375247955,
        "ag_news": 0.13300366699695587,
        "amazon_polarity": 0.13360357284545898,
        "cnn_dailymail/3.0.0": 0.14844124019145966,
        "common_gen": 0.11205347627401352,
        "cos_e/v1.11": 0.12199020385742188,
        "glue/mrpc": 0.1277054250240326,
        "kilt_tasks/hotpotqa": 0.11960140615701675
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6912,
        "ag_news": 7448,
        "amazon_polarity": 7216,
        "cnn_dailymail/3.0.0": 7256,
        "common_gen": 7184,
        "cos_e/v1.11": 7216,
        "glue/mrpc": 6852,
        "kilt_tasks/hotpotqa": 7512
      },
      "step": 450
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -64.69752502441406,
        "ag_news": 75.36415100097656,
        "amazon_polarity": 77.30326080322266,
        "cnn_dailymail/3.0.0": 136.9166717529297,
        "common_gen": -15.313509941101074,
        "cos_e/v1.11": 30.934545516967773,
        "glue/mrpc": 55.90248107910156,
        "kilt_tasks/hotpotqa": 15.832879066467285
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3244,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10255160927772522,
        "ag_news": 0.1329389065504074,
        "amazon_polarity": 0.13341842591762543,
        "cnn_dailymail/3.0.0": 0.14904749393463135,
        "common_gen": 0.11236396431922913,
        "cos_e/v1.11": 0.12241871654987335,
        "glue/mrpc": 0.12822221219539642,
        "kilt_tasks/hotpotqa": 0.11903871595859528
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7064,
        "ag_news": 7600,
        "amazon_polarity": 7328,
        "cnn_dailymail/3.0.0": 7368,
        "common_gen": 7320,
        "cos_e/v1.11": 7424,
        "glue/mrpc": 7036,
        "kilt_tasks/hotpotqa": 7736
      },
      "step": 460
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -61.360355377197266,
        "ag_news": 75.98722839355469,
        "amazon_polarity": 77.27001953125,
        "cnn_dailymail/3.0.0": 137.74334716796875,
        "common_gen": -17.592866897583008,
        "cos_e/v1.11": 27.602537155151367,
        "glue/mrpc": 57.38839340209961,
        "kilt_tasks/hotpotqa": 9.532137870788574
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1401,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10352886468172073,
        "ag_news": 0.1331770420074463,
        "amazon_polarity": 0.13349127769470215,
        "cnn_dailymail/3.0.0": 0.14918974041938782,
        "common_gen": 0.11216669529676437,
        "cos_e/v1.11": 0.12185722589492798,
        "glue/mrpc": 0.12870462238788605,
        "kilt_tasks/hotpotqa": 0.11788450926542282
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7224,
        "ag_news": 7744,
        "amazon_polarity": 7536,
        "cnn_dailymail/3.0.0": 7472,
        "common_gen": 7512,
        "cos_e/v1.11": 7592,
        "glue/mrpc": 7212,
        "kilt_tasks/hotpotqa": 7864
      },
      "step": 470
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -65.55304718017578,
        "ag_news": 75.92416381835938,
        "amazon_polarity": 77.1985855102539,
        "cnn_dailymail/3.0.0": 136.5869903564453,
        "common_gen": -14.914626121520996,
        "cos_e/v1.11": 25.302629470825195,
        "glue/mrpc": 55.64733123779297,
        "kilt_tasks/hotpotqa": 10.291525840759277
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3411,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10308942943811417,
        "ag_news": 0.13326045870780945,
        "amazon_polarity": 0.13356956839561462,
        "cnn_dailymail/3.0.0": 0.14881087839603424,
        "common_gen": 0.11299653351306915,
        "cos_e/v1.11": 0.12155098468065262,
        "glue/mrpc": 0.1284385621547699,
        "kilt_tasks/hotpotqa": 0.11828362196683884
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7368,
        "ag_news": 7920,
        "amazon_polarity": 7640,
        "cnn_dailymail/3.0.0": 7688,
        "common_gen": 7696,
        "cos_e/v1.11": 7696,
        "glue/mrpc": 7376,
        "kilt_tasks/hotpotqa": 8048
      },
      "step": 480
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -72.27350616455078,
        "ag_news": 75.76307678222656,
        "amazon_polarity": 77.04047393798828,
        "cnn_dailymail/3.0.0": 135.9985809326172,
        "common_gen": -17.750383377075195,
        "cos_e/v1.11": 20.668947219848633,
        "glue/mrpc": 55.29148483276367,
        "kilt_tasks/hotpotqa": 11.241116523742676
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1906,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10235916823148727,
        "ag_news": 0.13353510200977325,
        "amazon_polarity": 0.13384243845939636,
        "cnn_dailymail/3.0.0": 0.14883604645729065,
        "common_gen": 0.11287494003772736,
        "cos_e/v1.11": 0.12093880772590637,
        "glue/mrpc": 0.1287061870098114,
        "kilt_tasks/hotpotqa": 0.11890735477209091
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7472,
        "ag_news": 8088,
        "amazon_polarity": 7816,
        "cnn_dailymail/3.0.0": 7864,
        "common_gen": 7896,
        "cos_e/v1.11": 7840,
        "glue/mrpc": 7544,
        "kilt_tasks/hotpotqa": 8192
      },
      "step": 490
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -73.25422668457031,
        "ag_news": 75.51560974121094,
        "amazon_polarity": 77.00641632080078,
        "cnn_dailymail/3.0.0": 138.18399047851562,
        "common_gen": -19.212060928344727,
        "cos_e/v1.11": 18.179088592529297,
        "glue/mrpc": 52.73139572143555,
        "kilt_tasks/hotpotqa": 10.403034210205078
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2895,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10251803696155548,
        "ag_news": 0.13356415927410126,
        "amazon_polarity": 0.13391941785812378,
        "cnn_dailymail/3.0.0": 0.14935453236103058,
        "common_gen": 0.11284422874450684,
        "cos_e/v1.11": 0.12060216069221497,
        "glue/mrpc": 0.1282520890235901,
        "kilt_tasks/hotpotqa": 0.11894535273313522
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7624,
        "ag_news": 8256,
        "amazon_polarity": 7976,
        "cnn_dailymail/3.0.0": 8080,
        "common_gen": 8008,
        "cos_e/v1.11": 7960,
        "glue/mrpc": 7720,
        "kilt_tasks/hotpotqa": 8368
      },
      "step": 500
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.75,
      "eval_runtime": 0.2003,
      "eval_samples_per_second": 79.88,
      "eval_steps_per_second": 4.993,
      "step": 500
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -74.02811431884766,
        "ag_news": 75.33177185058594,
        "amazon_polarity": 77.05352783203125,
        "cnn_dailymail/3.0.0": 140.5841064453125,
        "common_gen": -13.210164070129395,
        "cos_e/v1.11": 15.744922637939453,
        "glue/mrpc": 49.450321197509766,
        "kilt_tasks/hotpotqa": 10.266688346862793
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1043,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10254359245300293,
        "ag_news": 0.13339200615882874,
        "amazon_polarity": 0.13379783928394318,
        "cnn_dailymail/3.0.0": 0.14968079328536987,
        "common_gen": 0.11411995440721512,
        "cos_e/v1.11": 0.12008975446224213,
        "glue/mrpc": 0.1274397075176239,
        "kilt_tasks/hotpotqa": 0.1189364567399025
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7840,
        "ag_news": 8432,
        "amazon_polarity": 8152,
        "cnn_dailymail/3.0.0": 8224,
        "common_gen": 8168,
        "cos_e/v1.11": 8064,
        "glue/mrpc": 7912,
        "kilt_tasks/hotpotqa": 8480
      },
      "step": 510
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -78.52189636230469,
        "ag_news": 75.50691986083984,
        "amazon_polarity": 77.0617446899414,
        "cnn_dailymail/3.0.0": 146.009765625,
        "common_gen": -11.982794761657715,
        "cos_e/v1.11": 13.786934852600098,
        "glue/mrpc": 41.22484588623047,
        "kilt_tasks/hotpotqa": 9.014934539794922
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2356,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1021028459072113,
        "ag_news": 0.13356778025627136,
        "amazon_polarity": 0.13393118977546692,
        "cnn_dailymail/3.0.0": 0.1510949730873108,
        "common_gen": 0.11465051770210266,
        "cos_e/v1.11": 0.11992135643959045,
        "glue/mrpc": 0.12580420076847076,
        "kilt_tasks/hotpotqa": 0.11892707645893097
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8016,
        "ag_news": 8568,
        "amazon_polarity": 8280,
        "cnn_dailymail/3.0.0": 8320,
        "common_gen": 8424,
        "cos_e/v1.11": 8200,
        "glue/mrpc": 8128,
        "kilt_tasks/hotpotqa": 8616
      },
      "step": 520
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -77.93408203125,
        "ag_news": 75.41006469726562,
        "amazon_polarity": 76.95569610595703,
        "cnn_dailymail/3.0.0": 144.98866271972656,
        "common_gen": -12.362130165100098,
        "cos_e/v1.11": 10.529768943786621,
        "glue/mrpc": 42.32731628417969,
        "kilt_tasks/hotpotqa": 9.02653694152832
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2226,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1024790033698082,
        "ag_news": 0.13356581330299377,
        "amazon_polarity": 0.13392366468906403,
        "cnn_dailymail/3.0.0": 0.15067604184150696,
        "common_gen": 0.11475695669651031,
        "cos_e/v1.11": 0.11938690394163132,
        "glue/mrpc": 0.12613442540168762,
        "kilt_tasks/hotpotqa": 0.11907713115215302
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8160,
        "ag_news": 8760,
        "amazon_polarity": 8448,
        "cnn_dailymail/3.0.0": 8464,
        "common_gen": 8584,
        "cos_e/v1.11": 8344,
        "glue/mrpc": 8272,
        "kilt_tasks/hotpotqa": 8800
      },
      "step": 530
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -82.21864318847656,
        "ag_news": 75.48108673095703,
        "amazon_polarity": 76.90501403808594,
        "cnn_dailymail/3.0.0": 146.35353088378906,
        "common_gen": -13.81075382232666,
        "cos_e/v1.11": 12.33144474029541,
        "glue/mrpc": 40.93070983886719,
        "kilt_tasks/hotpotqa": 12.796066284179688
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.18,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10190637409687042,
        "ag_news": 0.13348610699176788,
        "amazon_polarity": 0.13381251692771912,
        "cnn_dailymail/3.0.0": 0.1507532298564911,
        "common_gen": 0.11455048620700836,
        "cos_e/v1.11": 0.11979352682828903,
        "glue/mrpc": 0.12580883502960205,
        "kilt_tasks/hotpotqa": 0.11988887935876846
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8312,
        "ag_news": 8880,
        "amazon_polarity": 8664,
        "cnn_dailymail/3.0.0": 8664,
        "common_gen": 8712,
        "cos_e/v1.11": 8552,
        "glue/mrpc": 8416,
        "kilt_tasks/hotpotqa": 8912
      },
      "step": 540
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -81.98120880126953,
        "ag_news": 75.055419921875,
        "amazon_polarity": 76.79682922363281,
        "cnn_dailymail/3.0.0": 146.24993896484375,
        "common_gen": -14.274295806884766,
        "cos_e/v1.11": 13.292269706726074,
        "glue/mrpc": 39.85982131958008,
        "kilt_tasks/hotpotqa": 10.9720458984375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1666,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10220193862915039,
        "ag_news": 0.1333979070186615,
        "amazon_polarity": 0.13379330933094025,
        "cnn_dailymail/3.0.0": 0.15057004988193512,
        "common_gen": 0.11462578177452087,
        "cos_e/v1.11": 0.12011387199163437,
        "glue/mrpc": 0.12565535306930542,
        "kilt_tasks/hotpotqa": 0.11964184790849686
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8544,
        "ag_news": 9096,
        "amazon_polarity": 8784,
        "cnn_dailymail/3.0.0": 8832,
        "common_gen": 8888,
        "cos_e/v1.11": 8680,
        "glue/mrpc": 8536,
        "kilt_tasks/hotpotqa": 9032
      },
      "step": 550
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -81.89168548583984,
        "ag_news": 74.75675201416016,
        "amazon_polarity": 76.5687026977539,
        "cnn_dailymail/3.0.0": 146.5382537841797,
        "common_gen": -15.000120162963867,
        "cos_e/v1.11": 14.691868782043457,
        "glue/mrpc": 38.0214958190918,
        "kilt_tasks/hotpotqa": 8.22954273223877
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3065,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1024894043803215,
        "ag_news": 0.13337112963199615,
        "amazon_polarity": 0.13377882540225983,
        "cnn_dailymail/3.0.0": 0.15052664279937744,
        "common_gen": 0.1146746501326561,
        "cos_e/v1.11": 0.12054547667503357,
        "glue/mrpc": 0.1253715604543686,
        "kilt_tasks/hotpotqa": 0.11924226582050323
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8632,
        "ag_news": 9248,
        "amazon_polarity": 8936,
        "cnn_dailymail/3.0.0": 9048,
        "common_gen": 9040,
        "cos_e/v1.11": 8880,
        "glue/mrpc": 8688,
        "kilt_tasks/hotpotqa": 9200
      },
      "step": 560
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -87.19784545898438,
        "ag_news": 74.6979751586914,
        "amazon_polarity": 76.49652099609375,
        "cnn_dailymail/3.0.0": 144.3596954345703,
        "common_gen": -12.864167213439941,
        "cos_e/v1.11": 17.206878662109375,
        "glue/mrpc": 39.62831497192383,
        "kilt_tasks/hotpotqa": 6.689074516296387
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2707,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.101823590695858,
        "ag_news": 0.13336043059825897,
        "amazon_polarity": 0.13376155495643616,
        "cnn_dailymail/3.0.0": 0.14982344210147858,
        "common_gen": 0.11523710936307907,
        "cos_e/v1.11": 0.12116099148988724,
        "glue/mrpc": 0.1257781982421875,
        "kilt_tasks/hotpotqa": 0.11905467510223389
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8808,
        "ag_news": 9424,
        "amazon_polarity": 9080,
        "cnn_dailymail/3.0.0": 9232,
        "common_gen": 9184,
        "cos_e/v1.11": 9056,
        "glue/mrpc": 8816,
        "kilt_tasks/hotpotqa": 9352
      },
      "step": 570
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -88.65691375732422,
        "ag_news": 74.52448272705078,
        "amazon_polarity": 76.4361572265625,
        "cnn_dailymail/3.0.0": 146.9772491455078,
        "common_gen": -11.420433044433594,
        "cos_e/v1.11": 19.346012115478516,
        "glue/mrpc": 44.443416595458984,
        "kilt_tasks/hotpotqa": 6.274348258972168
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3217,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10156139731407166,
        "ag_news": 0.13299092650413513,
        "amazon_polarity": 0.1334124654531479,
        "cnn_dailymail/3.0.0": 0.14995059370994568,
        "common_gen": 0.11537006497383118,
        "cos_e/v1.11": 0.12138830870389938,
        "glue/mrpc": 0.12653277814388275,
        "kilt_tasks/hotpotqa": 0.11879338324069977
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8968,
        "ag_news": 9560,
        "amazon_polarity": 9224,
        "cnn_dailymail/3.0.0": 9432,
        "common_gen": 9384,
        "cos_e/v1.11": 9216,
        "glue/mrpc": 9000,
        "kilt_tasks/hotpotqa": 9448
      },
      "step": 580
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -95.06587982177734,
        "ag_news": 74.28294372558594,
        "amazon_polarity": 76.45133972167969,
        "cnn_dailymail/3.0.0": 149.23208618164062,
        "common_gen": -10.557443618774414,
        "cos_e/v1.11": 19.24748420715332,
        "glue/mrpc": 43.31203079223633,
        "kilt_tasks/hotpotqa": -0.004237696528434753
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2825,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10087038576602936,
        "ag_news": 0.13312341272830963,
        "amazon_polarity": 0.13359810411930084,
        "cnn_dailymail/3.0.0": 0.15056473016738892,
        "common_gen": 0.11583241075277328,
        "cos_e/v1.11": 0.12163105607032776,
        "glue/mrpc": 0.1265270859003067,
        "kilt_tasks/hotpotqa": 0.11785280704498291
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9160,
        "ag_news": 9728,
        "amazon_polarity": 9344,
        "cnn_dailymail/3.0.0": 9600,
        "common_gen": 9512,
        "cos_e/v1.11": 9400,
        "glue/mrpc": 9128,
        "kilt_tasks/hotpotqa": 9640
      },
      "step": 590
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -98.49720764160156,
        "ag_news": 74.21085357666016,
        "amazon_polarity": 76.15951538085938,
        "cnn_dailymail/3.0.0": 147.5979461669922,
        "common_gen": -9.334867477416992,
        "cos_e/v1.11": 22.465662002563477,
        "glue/mrpc": 43.075897216796875,
        "kilt_tasks/hotpotqa": -1.7707327604293823
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2117,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10054963082075119,
        "ag_news": 0.13311944901943207,
        "amazon_polarity": 0.13354240357875824,
        "cnn_dailymail/3.0.0": 0.1500239074230194,
        "common_gen": 0.11620661616325378,
        "cos_e/v1.11": 0.12237133830785751,
        "glue/mrpc": 0.1265428364276886,
        "kilt_tasks/hotpotqa": 0.1176438257098198
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9288,
        "ag_news": 9904,
        "amazon_polarity": 9472,
        "cnn_dailymail/3.0.0": 9744,
        "common_gen": 9688,
        "cos_e/v1.11": 9568,
        "glue/mrpc": 9328,
        "kilt_tasks/hotpotqa": 9800
      },
      "step": 600
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.192,
      "eval_samples_per_second": 83.318,
      "eval_steps_per_second": 5.207,
      "step": 600
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -102.4364242553711,
        "ag_news": 74.1636962890625,
        "amazon_polarity": 76.05815124511719,
        "cnn_dailymail/3.0.0": 149.15731811523438,
        "common_gen": -11.361848831176758,
        "cos_e/v1.11": 20.516399383544922,
        "glue/mrpc": 43.00069046020508,
        "kilt_tasks/hotpotqa": 0.36927562952041626
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3423,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10016259551048279,
        "ag_news": 0.1331358700990677,
        "amazon_polarity": 0.1335437297821045,
        "cnn_dailymail/3.0.0": 0.15028586983680725,
        "common_gen": 0.11597888916730881,
        "cos_e/v1.11": 0.1220952495932579,
        "glue/mrpc": 0.12660495936870575,
        "kilt_tasks/hotpotqa": 0.11819272488355637
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9408,
        "ag_news": 10064,
        "amazon_polarity": 9600,
        "cnn_dailymail/3.0.0": 10016,
        "common_gen": 9888,
        "cos_e/v1.11": 9664,
        "glue/mrpc": 9472,
        "kilt_tasks/hotpotqa": 9960
      },
      "step": 610
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -108.28617095947266,
        "ag_news": 73.65061950683594,
        "amazon_polarity": 75.92311096191406,
        "cnn_dailymail/3.0.0": 150.54640197753906,
        "common_gen": -11.831628799438477,
        "cos_e/v1.11": 20.506372451782227,
        "glue/mrpc": 45.701351165771484,
        "kilt_tasks/hotpotqa": -0.7184268832206726
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0638,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.0994608923792839,
        "ag_news": 0.13303004205226898,
        "amazon_polarity": 0.1335151046514511,
        "cnn_dailymail/3.0.0": 0.15047848224639893,
        "common_gen": 0.11602301150560379,
        "cos_e/v1.11": 0.12218125909566879,
        "glue/mrpc": 0.12720809876918793,
        "kilt_tasks/hotpotqa": 0.1181030347943306
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9568,
        "ag_news": 10272,
        "amazon_polarity": 9744,
        "cnn_dailymail/3.0.0": 10136,
        "common_gen": 10008,
        "cos_e/v1.11": 9821,
        "glue/mrpc": 9624,
        "kilt_tasks/hotpotqa": 10176
      },
      "step": 620
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -107.94490051269531,
        "ag_news": 73.15940856933594,
        "amazon_polarity": 75.65340423583984,
        "cnn_dailymail/3.0.0": 152.75782775878906,
        "common_gen": -10.433670997619629,
        "cos_e/v1.11": 17.699113845825195,
        "glue/mrpc": 48.39421081542969,
        "kilt_tasks/hotpotqa": 1.188965082168579
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0742,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09959544986486435,
        "ag_news": 0.13272954523563385,
        "amazon_polarity": 0.13325658440589905,
        "cnn_dailymail/3.0.0": 0.15063826739788055,
        "common_gen": 0.11623404175043106,
        "cos_e/v1.11": 0.12153981626033783,
        "glue/mrpc": 0.12760937213897705,
        "kilt_tasks/hotpotqa": 0.11839697510004044
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9704,
        "ag_news": 10464,
        "amazon_polarity": 9912,
        "cnn_dailymail/3.0.0": 10328,
        "common_gen": 10128,
        "cos_e/v1.11": 10021,
        "glue/mrpc": 9760,
        "kilt_tasks/hotpotqa": 10312
      },
      "step": 630
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -110.11096954345703,
        "ag_news": 73.14549255371094,
        "amazon_polarity": 75.85411834716797,
        "cnn_dailymail/3.0.0": 152.80662536621094,
        "common_gen": -7.408815383911133,
        "cos_e/v1.11": 15.942824363708496,
        "glue/mrpc": 46.856929779052734,
        "kilt_tasks/hotpotqa": 1.5925438404083252
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0955,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09946689009666443,
        "ag_news": 0.1327115148305893,
        "amazon_polarity": 0.1332794427871704,
        "cnn_dailymail/3.0.0": 0.1504843384027481,
        "common_gen": 0.11689573526382446,
        "cos_e/v1.11": 0.1212732195854187,
        "glue/mrpc": 0.12732502818107605,
        "kilt_tasks/hotpotqa": 0.11856383830308914
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9912,
        "ag_news": 10608,
        "amazon_polarity": 10040,
        "cnn_dailymail/3.0.0": 10472,
        "common_gen": 10296,
        "cos_e/v1.11": 10181,
        "glue/mrpc": 9928,
        "kilt_tasks/hotpotqa": 10472
      },
      "step": 640
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -106.75694274902344,
        "ag_news": 72.97050476074219,
        "amazon_polarity": 75.73881530761719,
        "cnn_dailymail/3.0.0": 153.1443634033203,
        "common_gen": -2.352656841278076,
        "cos_e/v1.11": 18.765228271484375,
        "glue/mrpc": 45.2827033996582,
        "kilt_tasks/hotpotqa": -2.141038417816162
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1854,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10006730258464813,
        "ag_news": 0.13248801231384277,
        "amazon_polarity": 0.13306306302547455,
        "cnn_dailymail/3.0.0": 0.1502065509557724,
        "common_gen": 0.11777079105377197,
        "cos_e/v1.11": 0.12172149121761322,
        "glue/mrpc": 0.12687310576438904,
        "kilt_tasks/hotpotqa": 0.1178097203373909
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10024,
        "ag_news": 10752,
        "amazon_polarity": 10216,
        "cnn_dailymail/3.0.0": 10648,
        "common_gen": 10448,
        "cos_e/v1.11": 10373,
        "glue/mrpc": 10064,
        "kilt_tasks/hotpotqa": 10664
      },
      "step": 650
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -113.52306365966797,
        "ag_news": 72.87635040283203,
        "amazon_polarity": 75.63373565673828,
        "cnn_dailymail/3.0.0": 152.0581817626953,
        "common_gen": -1.0353636741638184,
        "cos_e/v1.11": 19.66213035583496,
        "glue/mrpc": 43.88413619995117,
        "kilt_tasks/hotpotqa": 2.0462448596954346
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0929,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09923870116472244,
        "ag_news": 0.13247430324554443,
        "amazon_polarity": 0.13304267823696136,
        "cnn_dailymail/3.0.0": 0.14981749653816223,
        "common_gen": 0.1181211918592453,
        "cos_e/v1.11": 0.121973916888237,
        "glue/mrpc": 0.12664476037025452,
        "kilt_tasks/hotpotqa": 0.11868691444396973
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10160,
        "ag_news": 10936,
        "amazon_polarity": 10352,
        "cnn_dailymail/3.0.0": 10840,
        "common_gen": 10624,
        "cos_e/v1.11": 10501,
        "glue/mrpc": 10240,
        "kilt_tasks/hotpotqa": 10816
      },
      "step": 660
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -110.7850341796875,
        "ag_news": 72.78992462158203,
        "amazon_polarity": 75.7198257446289,
        "cnn_dailymail/3.0.0": 152.7172393798828,
        "common_gen": 1.7337584495544434,
        "cos_e/v1.11": 16.373374938964844,
        "glue/mrpc": 46.268287658691406,
        "kilt_tasks/hotpotqa": 0.9964290857315063
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1346,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09975847601890564,
        "ag_news": 0.1323084533214569,
        "amazon_polarity": 0.1329072266817093,
        "cnn_dailymail/3.0.0": 0.1496649831533432,
        "common_gen": 0.11859390139579773,
        "cos_e/v1.11": 0.12129655480384827,
        "glue/mrpc": 0.12701095640659332,
        "kilt_tasks/hotpotqa": 0.11845939606428146
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10320,
        "ag_news": 11064,
        "amazon_polarity": 10504,
        "cnn_dailymail/3.0.0": 11016,
        "common_gen": 10776,
        "cos_e/v1.11": 10677,
        "glue/mrpc": 10464,
        "kilt_tasks/hotpotqa": 10928
      },
      "step": 670
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -111.28746795654297,
        "ag_news": 72.63013458251953,
        "amazon_polarity": 76.0165023803711,
        "cnn_dailymail/3.0.0": 152.1735382080078,
        "common_gen": 3.5893285274505615,
        "cos_e/v1.11": 17.454097747802734,
        "glue/mrpc": 44.705108642578125,
        "kilt_tasks/hotpotqa": 0.8124097585678101
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0594,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09984766691923141,
        "ag_news": 0.13222326338291168,
        "amazon_polarity": 0.13291005790233612,
        "cnn_dailymail/3.0.0": 0.14934565126895905,
        "common_gen": 0.11897820234298706,
        "cos_e/v1.11": 0.12152571231126785,
        "glue/mrpc": 0.12669499218463898,
        "kilt_tasks/hotpotqa": 0.11847449839115143
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10464,
        "ag_news": 11208,
        "amazon_polarity": 10704,
        "cnn_dailymail/3.0.0": 11176,
        "common_gen": 10968,
        "cos_e/v1.11": 10837,
        "glue/mrpc": 10632,
        "kilt_tasks/hotpotqa": 11040
      },
      "step": 680
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -111.55403137207031,
        "ag_news": 72.39476776123047,
        "amazon_polarity": 75.89879608154297,
        "cnn_dailymail/3.0.0": 152.36346435546875,
        "common_gen": 5.761022090911865,
        "cos_e/v1.11": 16.27185821533203,
        "glue/mrpc": 42.177345275878906,
        "kilt_tasks/hotpotqa": -0.6044420003890991
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1329,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1000358983874321,
        "ag_news": 0.1322118490934372,
        "amazon_polarity": 0.1329173594713211,
        "cnn_dailymail/3.0.0": 0.1492980569601059,
        "common_gen": 0.11949384957551956,
        "cos_e/v1.11": 0.12141450494527817,
        "glue/mrpc": 0.12628282606601715,
        "kilt_tasks/hotpotqa": 0.11834567785263062
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10608,
        "ag_news": 11368,
        "amazon_polarity": 10888,
        "cnn_dailymail/3.0.0": 11296,
        "common_gen": 11136,
        "cos_e/v1.11": 11013,
        "glue/mrpc": 10776,
        "kilt_tasks/hotpotqa": 11224
      },
      "step": 690
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -111.73369598388672,
        "ag_news": 72.31038665771484,
        "amazon_polarity": 75.86212158203125,
        "cnn_dailymail/3.0.0": 153.5405731201172,
        "common_gen": 7.045901298522949,
        "cos_e/v1.11": 14.592212677001953,
        "glue/mrpc": 40.2303352355957,
        "kilt_tasks/hotpotqa": 1.617633581161499
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0776,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1001543179154396,
        "ag_news": 0.13212592899799347,
        "amazon_polarity": 0.1328355073928833,
        "cnn_dailymail/3.0.0": 0.1493561714887619,
        "common_gen": 0.11974871903657913,
        "cos_e/v1.11": 0.12111765891313553,
        "glue/mrpc": 0.12588803470134735,
        "kilt_tasks/hotpotqa": 0.11877372115850449
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10752,
        "ag_news": 11568,
        "amazon_polarity": 11016,
        "cnn_dailymail/3.0.0": 11448,
        "common_gen": 11336,
        "cos_e/v1.11": 11157,
        "glue/mrpc": 10976,
        "kilt_tasks/hotpotqa": 11336
      },
      "step": 700
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.186,
      "eval_samples_per_second": 86.015,
      "eval_steps_per_second": 5.376,
      "step": 700
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -109.60501861572266,
        "ag_news": 72.13844299316406,
        "amazon_polarity": 75.8883056640625,
        "cnn_dailymail/3.0.0": 154.4407958984375,
        "common_gen": 7.389394283294678,
        "cos_e/v1.11": 15.117417335510254,
        "glue/mrpc": 40.967830657958984,
        "kilt_tasks/hotpotqa": 1.13652765750885
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.056,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10056206583976746,
        "ag_news": 0.13195323944091797,
        "amazon_polarity": 0.132696270942688,
        "cnn_dailymail/3.0.0": 0.14927229285240173,
        "common_gen": 0.11976701766252518,
        "cos_e/v1.11": 0.12115946412086487,
        "glue/mrpc": 0.12593746185302734,
        "kilt_tasks/hotpotqa": 0.11865226179361343
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10912,
        "ag_news": 11784,
        "amazon_polarity": 11120,
        "cnn_dailymail/3.0.0": 11624,
        "common_gen": 11472,
        "cos_e/v1.11": 11301,
        "glue/mrpc": 11156,
        "kilt_tasks/hotpotqa": 11496
      },
      "step": 710
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -110.7235336303711,
        "ag_news": 72.06149291992188,
        "amazon_polarity": 76.14501953125,
        "cnn_dailymail/3.0.0": 153.3281707763672,
        "common_gen": 7.262979507446289,
        "cos_e/v1.11": 11.367639541625977,
        "glue/mrpc": 40.70623016357422,
        "kilt_tasks/hotpotqa": 4.378360748291016
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0625,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10060500353574753,
        "ag_news": 0.13196653127670288,
        "amazon_polarity": 0.1327703595161438,
        "cnn_dailymail/3.0.0": 0.14893020689487457,
        "common_gen": 0.11985037475824356,
        "cos_e/v1.11": 0.12058333307504654,
        "glue/mrpc": 0.12595616281032562,
        "kilt_tasks/hotpotqa": 0.11933799088001251
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11072,
        "ag_news": 11992,
        "amazon_polarity": 11288,
        "cnn_dailymail/3.0.0": 11776,
        "common_gen": 11624,
        "cos_e/v1.11": 11437,
        "glue/mrpc": 11276,
        "kilt_tasks/hotpotqa": 11680
      },
      "step": 720
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -109.58026885986328,
        "ag_news": 72.05994415283203,
        "amazon_polarity": 76.11376953125,
        "cnn_dailymail/3.0.0": 154.8929901123047,
        "common_gen": 6.101253986358643,
        "cos_e/v1.11": 9.787298202514648,
        "glue/mrpc": 40.29509353637695,
        "kilt_tasks/hotpotqa": -0.17552420496940613
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1555,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10101288557052612,
        "ag_news": 0.1320352852344513,
        "amazon_polarity": 0.13282820582389832,
        "cnn_dailymail/3.0.0": 0.14923030138015747,
        "common_gen": 0.11978618800640106,
        "cos_e/v1.11": 0.1204393208026886,
        "glue/mrpc": 0.12598556280136108,
        "kilt_tasks/hotpotqa": 0.11868219822645187
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11248,
        "ag_news": 12128,
        "amazon_polarity": 11448,
        "cnn_dailymail/3.0.0": 11928,
        "common_gen": 11808,
        "cos_e/v1.11": 11621,
        "glue/mrpc": 11372,
        "kilt_tasks/hotpotqa": 11872
      },
      "step": 730
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -113.9823989868164,
        "ag_news": 71.76368713378906,
        "amazon_polarity": 76.08464813232422,
        "cnn_dailymail/3.0.0": 158.62266540527344,
        "common_gen": 1.1589980125427246,
        "cos_e/v1.11": 8.713700294494629,
        "glue/mrpc": 38.961883544921875,
        "kilt_tasks/hotpotqa": -2.5721004009246826
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1148,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10067354142665863,
        "ag_news": 0.13214710354804993,
        "amazon_polarity": 0.13298746943473816,
        "cnn_dailymail/3.0.0": 0.15011905133724213,
        "common_gen": 0.11915197223424911,
        "cos_e/v1.11": 0.1204783096909523,
        "glue/mrpc": 0.12594030797481537,
        "kilt_tasks/hotpotqa": 0.11850239336490631
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11424,
        "ag_news": 12288,
        "amazon_polarity": 11608,
        "cnn_dailymail/3.0.0": 12104,
        "common_gen": 11952,
        "cos_e/v1.11": 11781,
        "glue/mrpc": 11532,
        "kilt_tasks/hotpotqa": 12016
      },
      "step": 740
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -113.07462310791016,
        "ag_news": 71.6689453125,
        "amazon_polarity": 76.3426513671875,
        "cnn_dailymail/3.0.0": 155.62586975097656,
        "common_gen": 4.207225322723389,
        "cos_e/v1.11": 11.453811645507812,
        "glue/mrpc": 37.7027702331543,
        "kilt_tasks/hotpotqa": -4.3809123039245605
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0966,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10095655173063278,
        "ag_news": 0.13208794593811035,
        "amazon_polarity": 0.13299070298671722,
        "cnn_dailymail/3.0.0": 0.14929120242595673,
        "common_gen": 0.11972685903310776,
        "cos_e/v1.11": 0.12099650502204895,
        "glue/mrpc": 0.12571072578430176,
        "kilt_tasks/hotpotqa": 0.11823959648609161
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11560,
        "ag_news": 12496,
        "amazon_polarity": 11736,
        "cnn_dailymail/3.0.0": 12288,
        "common_gen": 12104,
        "cos_e/v1.11": 11933,
        "glue/mrpc": 11684,
        "kilt_tasks/hotpotqa": 12184
      },
      "step": 750
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -111.60576629638672,
        "ag_news": 71.7117691040039,
        "amazon_polarity": 76.3275146484375,
        "cnn_dailymail/3.0.0": 154.21530151367188,
        "common_gen": 4.668085098266602,
        "cos_e/v1.11": 11.560782432556152,
        "glue/mrpc": 38.738525390625,
        "kilt_tasks/hotpotqa": -7.195088863372803
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2132,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1013435646891594,
        "ag_news": 0.13209006190299988,
        "amazon_polarity": 0.1329757422208786,
        "cnn_dailymail/3.0.0": 0.148859903216362,
        "common_gen": 0.1198781281709671,
        "cos_e/v1.11": 0.12107905745506287,
        "glue/mrpc": 0.12593422830104828,
        "kilt_tasks/hotpotqa": 0.11783932894468307
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11712,
        "ag_news": 12632,
        "amazon_polarity": 11912,
        "cnn_dailymail/3.0.0": 12504,
        "common_gen": 12272,
        "cos_e/v1.11": 12133,
        "glue/mrpc": 11788,
        "kilt_tasks/hotpotqa": 12312
      },
      "step": 760
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -113.43983459472656,
        "ag_news": 71.68649291992188,
        "amazon_polarity": 76.19463348388672,
        "cnn_dailymail/3.0.0": 156.54986572265625,
        "common_gen": 3.907815933227539,
        "cos_e/v1.11": 12.119610786437988,
        "glue/mrpc": 38.293113708496094,
        "kilt_tasks/hotpotqa": -9.250164985656738
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.178,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10124362260103226,
        "ag_news": 0.1320769041776657,
        "amazon_polarity": 0.13293616473674774,
        "cnn_dailymail/3.0.0": 0.14923641085624695,
        "common_gen": 0.11981464922428131,
        "cos_e/v1.11": 0.12123673409223557,
        "glue/mrpc": 0.12588442862033844,
        "kilt_tasks/hotpotqa": 0.11757110804319382
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11864,
        "ag_news": 12768,
        "amazon_polarity": 12056,
        "cnn_dailymail/3.0.0": 12688,
        "common_gen": 12424,
        "cos_e/v1.11": 12325,
        "glue/mrpc": 11932,
        "kilt_tasks/hotpotqa": 12488
      },
      "step": 770
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -115.09649658203125,
        "ag_news": 71.66943359375,
        "amazon_polarity": 76.10877227783203,
        "cnn_dailymail/3.0.0": 156.09336853027344,
        "common_gen": 5.4296793937683105,
        "cos_e/v1.11": 10.179367065429688,
        "glue/mrpc": 37.94990539550781,
        "kilt_tasks/hotpotqa": -11.336426734924316
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0721,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10122895240783691,
        "ag_news": 0.13214333355426788,
        "amazon_polarity": 0.1329844444990158,
        "cnn_dailymail/3.0.0": 0.1491013616323471,
        "common_gen": 0.1202130988240242,
        "cos_e/v1.11": 0.12103105336427689,
        "glue/mrpc": 0.12592758238315582,
        "kilt_tasks/hotpotqa": 0.11737018823623657
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12104,
        "ag_news": 12936,
        "amazon_polarity": 12184,
        "cnn_dailymail/3.0.0": 12832,
        "common_gen": 12584,
        "cos_e/v1.11": 12477,
        "glue/mrpc": 12100,
        "kilt_tasks/hotpotqa": 12608
      },
      "step": 780
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -115.74312591552734,
        "ag_news": 71.4383316040039,
        "amazon_polarity": 76.073486328125,
        "cnn_dailymail/3.0.0": 156.3274383544922,
        "common_gen": 8.243632316589355,
        "cos_e/v1.11": 13.336591720581055,
        "glue/mrpc": 35.99363708496094,
        "kilt_tasks/hotpotqa": -12.730269432067871
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1318,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1012384444475174,
        "ag_news": 0.13201211392879486,
        "amazon_polarity": 0.13288404047489166,
        "cnn_dailymail/3.0.0": 0.14893829822540283,
        "common_gen": 0.12068556994199753,
        "cos_e/v1.11": 0.12156080454587936,
        "glue/mrpc": 0.12553295493125916,
        "kilt_tasks/hotpotqa": 0.11714787036180496
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12280,
        "ag_news": 13032,
        "amazon_polarity": 12400,
        "cnn_dailymail/3.0.0": 13016,
        "common_gen": 12792,
        "cos_e/v1.11": 12645,
        "glue/mrpc": 12204,
        "kilt_tasks/hotpotqa": 12736
      },
      "step": 790
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -117.56880187988281,
        "ag_news": 71.41673278808594,
        "amazon_polarity": 76.36126708984375,
        "cnn_dailymail/3.0.0": 153.60569763183594,
        "common_gen": 9.608429908752441,
        "cos_e/v1.11": 12.627603530883789,
        "glue/mrpc": 33.864501953125,
        "kilt_tasks/hotpotqa": -14.192654609680176
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0887,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1012442409992218,
        "ag_news": 0.13213807344436646,
        "amazon_polarity": 0.13306348025798798,
        "cnn_dailymail/3.0.0": 0.14840131998062134,
        "common_gen": 0.12110442668199539,
        "cos_e/v1.11": 0.12162110209465027,
        "glue/mrpc": 0.12531885504722595,
        "kilt_tasks/hotpotqa": 0.11710843443870544
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12440,
        "ag_news": 13264,
        "amazon_polarity": 12560,
        "cnn_dailymail/3.0.0": 13184,
        "common_gen": 12896,
        "cos_e/v1.11": 12805,
        "glue/mrpc": 12308,
        "kilt_tasks/hotpotqa": 12928
      },
      "step": 800
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.197,
      "eval_samples_per_second": 81.201,
      "eval_steps_per_second": 5.075,
      "step": 800
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -118.93992614746094,
        "ag_news": 71.41973876953125,
        "amazon_polarity": 76.49755859375,
        "cnn_dailymail/3.0.0": 153.41262817382812,
        "common_gen": 8.86803913116455,
        "cos_e/v1.11": 12.298989295959473,
        "glue/mrpc": 32.614952087402344,
        "kilt_tasks/hotpotqa": -14.544601440429688
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9239,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10125146061182022,
        "ag_news": 0.1321861743927002,
        "amazon_polarity": 0.13313113152980804,
        "cnn_dailymail/3.0.0": 0.14830870926380157,
        "common_gen": 0.12108708918094635,
        "cos_e/v1.11": 0.1216706931591034,
        "glue/mrpc": 0.12518522143363953,
        "kilt_tasks/hotpotqa": 0.1171795129776001
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12640,
        "ag_news": 13512,
        "amazon_polarity": 12712,
        "cnn_dailymail/3.0.0": 13288,
        "common_gen": 13000,
        "cos_e/v1.11": 12957,
        "glue/mrpc": 12492,
        "kilt_tasks/hotpotqa": 13064
      },
      "step": 810
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -122.80232238769531,
        "ag_news": 71.5192642211914,
        "amazon_polarity": 76.27162170410156,
        "cnn_dailymail/3.0.0": 157.0668487548828,
        "common_gen": 7.723115921020508,
        "cos_e/v1.11": 12.857004165649414,
        "glue/mrpc": 33.97816848754883,
        "kilt_tasks/hotpotqa": -13.071959495544434
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.094,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10078366100788116,
        "ag_news": 0.13208846747875214,
        "amazon_polarity": 0.13296660780906677,
        "cnn_dailymail/3.0.0": 0.14883208274841309,
        "common_gen": 0.12085232138633728,
        "cos_e/v1.11": 0.12171962857246399,
        "glue/mrpc": 0.12535452842712402,
        "kilt_tasks/hotpotqa": 0.11740273982286453
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12792,
        "ag_news": 13656,
        "amazon_polarity": 12920,
        "cnn_dailymail/3.0.0": 13504,
        "common_gen": 13144,
        "cos_e/v1.11": 13109,
        "glue/mrpc": 12644,
        "kilt_tasks/hotpotqa": 13176
      },
      "step": 820
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -125.64664459228516,
        "ag_news": 71.03704833984375,
        "amazon_polarity": 76.30180358886719,
        "cnn_dailymail/3.0.0": 156.0475311279297,
        "common_gen": 8.120804786682129,
        "cos_e/v1.11": 10.219242095947266,
        "glue/mrpc": 33.96204376220703,
        "kilt_tasks/hotpotqa": -12.812718391418457
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1268,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1006239801645279,
        "ag_news": 0.13209664821624756,
        "amazon_polarity": 0.13306403160095215,
        "cnn_dailymail/3.0.0": 0.14862395823001862,
        "common_gen": 0.12107153236865997,
        "cos_e/v1.11": 0.12142379581928253,
        "glue/mrpc": 0.12548257410526276,
        "kilt_tasks/hotpotqa": 0.11761346459388733
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12920,
        "ag_news": 13792,
        "amazon_polarity": 13088,
        "cnn_dailymail/3.0.0": 13688,
        "common_gen": 13328,
        "cos_e/v1.11": 13221,
        "glue/mrpc": 12844,
        "kilt_tasks/hotpotqa": 13344
      },
      "step": 830
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -119.74386596679688,
        "ag_news": 71.0577163696289,
        "amazon_polarity": 76.6231689453125,
        "cnn_dailymail/3.0.0": 155.42156982421875,
        "common_gen": 8.224030494689941,
        "cos_e/v1.11": 9.39476203918457,
        "glue/mrpc": 32.566959381103516,
        "kilt_tasks/hotpotqa": -11.736536979675293
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0772,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10151870548725128,
        "ag_news": 0.131986603140831,
        "amazon_polarity": 0.13300251960754395,
        "cnn_dailymail/3.0.0": 0.14826399087905884,
        "common_gen": 0.12104688584804535,
        "cos_e/v1.11": 0.12124211341142654,
        "glue/mrpc": 0.1251719743013382,
        "kilt_tasks/hotpotqa": 0.11776724457740784
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13088,
        "ag_news": 13944,
        "amazon_polarity": 13240,
        "cnn_dailymail/3.0.0": 13840,
        "common_gen": 13440,
        "cos_e/v1.11": 13397,
        "glue/mrpc": 13052,
        "kilt_tasks/hotpotqa": 13504
      },
      "step": 840
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -121.22718811035156,
        "ag_news": 70.91030883789062,
        "amazon_polarity": 76.77899932861328,
        "cnn_dailymail/3.0.0": 155.66015625,
        "common_gen": 7.558376789093018,
        "cos_e/v1.11": 7.449672222137451,
        "glue/mrpc": 33.07836151123047,
        "kilt_tasks/hotpotqa": -12.257262229919434
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1744,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10149859637022018,
        "ag_news": 0.1319991797208786,
        "amazon_polarity": 0.13306447863578796,
        "cnn_dailymail/3.0.0": 0.1482556015253067,
        "common_gen": 0.12103382498025894,
        "cos_e/v1.11": 0.12101582437753677,
        "glue/mrpc": 0.1253356784582138,
        "kilt_tasks/hotpotqa": 0.11779677122831345
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13224,
        "ag_news": 14104,
        "amazon_polarity": 13376,
        "cnn_dailymail/3.0.0": 14064,
        "common_gen": 13600,
        "cos_e/v1.11": 13525,
        "glue/mrpc": 13236,
        "kilt_tasks/hotpotqa": 13656
      },
      "step": 850
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -120.55370330810547,
        "ag_news": 70.97686767578125,
        "amazon_polarity": 76.83686065673828,
        "cnn_dailymail/3.0.0": 155.2943115234375,
        "common_gen": 4.603865146636963,
        "cos_e/v1.11": 6.823019504547119,
        "glue/mrpc": 35.045555114746094,
        "kilt_tasks/hotpotqa": -11.600248336791992
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0536,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10172730684280396,
        "ag_news": 0.1319875717163086,
        "amazon_polarity": 0.1330450028181076,
        "cnn_dailymail/3.0.0": 0.14805559813976288,
        "common_gen": 0.12058724462985992,
        "cos_e/v1.11": 0.1209518164396286,
        "glue/mrpc": 0.1256868839263916,
        "kilt_tasks/hotpotqa": 0.11795856803655624
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13376,
        "ag_news": 14288,
        "amazon_polarity": 13568,
        "cnn_dailymail/3.0.0": 14224,
        "common_gen": 13768,
        "cos_e/v1.11": 13637,
        "glue/mrpc": 13380,
        "kilt_tasks/hotpotqa": 13824
      },
      "step": 860
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -121.49009704589844,
        "ag_news": 71.03221893310547,
        "amazon_polarity": 76.7582015991211,
        "cnn_dailymail/3.0.0": 156.148193359375,
        "common_gen": 4.542305946350098,
        "cos_e/v1.11": 6.224143028259277,
        "glue/mrpc": 33.82199478149414,
        "kilt_tasks/hotpotqa": -10.674310684204102
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2499,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10173435509204865,
        "ag_news": 0.13197746872901917,
        "amazon_polarity": 0.13300462067127228,
        "cnn_dailymail/3.0.0": 0.14810717105865479,
        "common_gen": 0.12062117457389832,
        "cos_e/v1.11": 0.1208958700299263,
        "glue/mrpc": 0.1254950314760208,
        "kilt_tasks/hotpotqa": 0.11816427856683731
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13472,
        "ag_news": 14440,
        "amazon_polarity": 13688,
        "cnn_dailymail/3.0.0": 14432,
        "common_gen": 13984,
        "cos_e/v1.11": 13821,
        "glue/mrpc": 13500,
        "kilt_tasks/hotpotqa": 14008
      },
      "step": 870
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -120.40065002441406,
        "ag_news": 70.96768188476562,
        "amazon_polarity": 76.74710845947266,
        "cnn_dailymail/3.0.0": 154.14865112304688,
        "common_gen": 4.030635356903076,
        "cos_e/v1.11": 4.434841632843018,
        "glue/mrpc": 34.3534049987793,
        "kilt_tasks/hotpotqa": -11.76729679107666
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1649,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10207781195640564,
        "ag_news": 0.13202451169490814,
        "amazon_polarity": 0.13305579125881195,
        "cnn_dailymail/3.0.0": 0.14767774939537048,
        "common_gen": 0.12065286189317703,
        "cos_e/v1.11": 0.12071845680475235,
        "glue/mrpc": 0.12567618489265442,
        "kilt_tasks/hotpotqa": 0.11811667680740356
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13568,
        "ag_news": 14608,
        "amazon_polarity": 13864,
        "cnn_dailymail/3.0.0": 14624,
        "common_gen": 14176,
        "cos_e/v1.11": 14005,
        "glue/mrpc": 13620,
        "kilt_tasks/hotpotqa": 14160
      },
      "step": 880
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -121.32748413085938,
        "ag_news": 70.86119079589844,
        "amazon_polarity": 76.80289459228516,
        "cnn_dailymail/3.0.0": 153.7303466796875,
        "common_gen": 1.6972652673721313,
        "cos_e/v1.11": 5.417903900146484,
        "glue/mrpc": 34.81855392456055,
        "kilt_tasks/hotpotqa": -11.087128639221191
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2491,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10209500044584274,
        "ag_news": 0.13200199604034424,
        "amazon_polarity": 0.13305622339248657,
        "cnn_dailymail/3.0.0": 0.14749836921691895,
        "common_gen": 0.12033406645059586,
        "cos_e/v1.11": 0.12093435227870941,
        "glue/mrpc": 0.12578552961349487,
        "kilt_tasks/hotpotqa": 0.11829432845115662
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13704,
        "ag_news": 14704,
        "amazon_polarity": 14016,
        "cnn_dailymail/3.0.0": 14808,
        "common_gen": 14400,
        "cos_e/v1.11": 14133,
        "glue/mrpc": 13780,
        "kilt_tasks/hotpotqa": 14360
      },
      "step": 890
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -126.63152313232422,
        "ag_news": 70.82621002197266,
        "amazon_polarity": 77.00299835205078,
        "cnn_dailymail/3.0.0": 155.38865661621094,
        "common_gen": -0.8504424691200256,
        "cos_e/v1.11": 2.6608428955078125,
        "glue/mrpc": 33.67421340942383,
        "kilt_tasks/hotpotqa": -12.444845199584961
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1085,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10165861994028091,
        "ag_news": 0.132173553109169,
        "amazon_polarity": 0.13326500356197357,
        "cnn_dailymail/3.0.0": 0.14793308079242706,
        "common_gen": 0.12014966458082199,
        "cos_e/v1.11": 0.12071207910776138,
        "glue/mrpc": 0.12579664587974548,
        "kilt_tasks/hotpotqa": 0.11831129342317581
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13896,
        "ag_news": 14816,
        "amazon_polarity": 14160,
        "cnn_dailymail/3.0.0": 14888,
        "common_gen": 14624,
        "cos_e/v1.11": 14341,
        "glue/mrpc": 13956,
        "kilt_tasks/hotpotqa": 14504
      },
      "step": 900
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.193,
      "eval_samples_per_second": 82.885,
      "eval_steps_per_second": 5.18,
      "step": 900
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -123.98731994628906,
        "ag_news": 70.86286163330078,
        "amazon_polarity": 76.73563385009766,
        "cnn_dailymail/3.0.0": 153.7763214111328,
        "common_gen": 1.8785021305084229,
        "cos_e/v1.11": 3.690308094024658,
        "glue/mrpc": 33.14885330200195,
        "kilt_tasks/hotpotqa": -12.25654411315918
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1423,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10207688063383102,
        "ag_news": 0.13207198679447174,
        "amazon_polarity": 0.13310299813747406,
        "cnn_dailymail/3.0.0": 0.14740566909313202,
        "common_gen": 0.12054848670959473,
        "cos_e/v1.11": 0.1208377555012703,
        "glue/mrpc": 0.12564049661159515,
        "kilt_tasks/hotpotqa": 0.11831574141979218
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14080,
        "ag_news": 14936,
        "amazon_polarity": 14328,
        "cnn_dailymail/3.0.0": 15072,
        "common_gen": 14752,
        "cos_e/v1.11": 14541,
        "glue/mrpc": 14108,
        "kilt_tasks/hotpotqa": 14648
      },
      "step": 910
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -126.48774719238281,
        "ag_news": 70.62692260742188,
        "amazon_polarity": 76.79846954345703,
        "cnn_dailymail/3.0.0": 156.87376403808594,
        "common_gen": 0.5665582418441772,
        "cos_e/v1.11": -1.4412798881530762,
        "glue/mrpc": 33.169273376464844,
        "kilt_tasks/hotpotqa": -12.99862289428711
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0954,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10194728523492813,
        "ag_news": 0.13211363554000854,
        "amazon_polarity": 0.1331917941570282,
        "cnn_dailymail/3.0.0": 0.14801359176635742,
        "common_gen": 0.12047527730464935,
        "cos_e/v1.11": 0.12015746533870697,
        "glue/mrpc": 0.12575644254684448,
        "kilt_tasks/hotpotqa": 0.1183445081114769
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14216,
        "ag_news": 15056,
        "amazon_polarity": 14512,
        "cnn_dailymail/3.0.0": 15224,
        "common_gen": 14920,
        "cos_e/v1.11": 14637,
        "glue/mrpc": 14316,
        "kilt_tasks/hotpotqa": 14864
      },
      "step": 920
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -124.55709075927734,
        "ag_news": 70.66926574707031,
        "amazon_polarity": 76.46481323242188,
        "cnn_dailymail/3.0.0": 158.1660919189453,
        "common_gen": 3.5414071083068848,
        "cos_e/v1.11": -4.690789222717285,
        "glue/mrpc": 35.19749450683594,
        "kilt_tasks/hotpotqa": -14.29500961303711
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0333,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10226238518953323,
        "ag_news": 0.13201266527175903,
        "amazon_polarity": 0.13301867246627808,
        "cnn_dailymail/3.0.0": 0.1480528712272644,
        "common_gen": 0.12090570479631424,
        "cos_e/v1.11": 0.1196102723479271,
        "glue/mrpc": 0.12602072954177856,
        "kilt_tasks/hotpotqa": 0.11811665445566177
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14328,
        "ag_news": 15208,
        "amazon_polarity": 14712,
        "cnn_dailymail/3.0.0": 15376,
        "common_gen": 15064,
        "cos_e/v1.11": 14845,
        "glue/mrpc": 14484,
        "kilt_tasks/hotpotqa": 15008
      },
      "step": 930
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -125.3681869506836,
        "ag_news": 70.56505584716797,
        "amazon_polarity": 76.315673828125,
        "cnn_dailymail/3.0.0": 157.6737518310547,
        "common_gen": 7.458301067352295,
        "cos_e/v1.11": -1.694239616394043,
        "glue/mrpc": 37.28247833251953,
        "kilt_tasks/hotpotqa": -14.630114555358887
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0993,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10215051472187042,
        "ag_news": 0.13181115686893463,
        "amazon_polarity": 0.13280248641967773,
        "cnn_dailymail/3.0.0": 0.14766207337379456,
        "common_gen": 0.1214112713932991,
        "cos_e/v1.11": 0.11997338384389877,
        "glue/mrpc": 0.12621869146823883,
        "kilt_tasks/hotpotqa": 0.11797044426202774
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14536,
        "ag_news": 15376,
        "amazon_polarity": 14880,
        "cnn_dailymail/3.0.0": 15536,
        "common_gen": 15216,
        "cos_e/v1.11": 14989,
        "glue/mrpc": 14604,
        "kilt_tasks/hotpotqa": 15168
      },
      "step": 940
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -125.45116424560547,
        "ag_news": 70.40018463134766,
        "amazon_polarity": 76.29994201660156,
        "cnn_dailymail/3.0.0": 157.1077117919922,
        "common_gen": 4.691281318664551,
        "cos_e/v1.11": 0.07107436656951904,
        "glue/mrpc": 35.687931060791016,
        "kilt_tasks/hotpotqa": -16.724885940551758
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0577,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10234078019857407,
        "ag_news": 0.13186724483966827,
        "amazon_polarity": 0.13287948071956635,
        "cnn_dailymail/3.0.0": 0.14756028354167938,
        "common_gen": 0.12110635638237,
        "cos_e/v1.11": 0.12038398534059525,
        "glue/mrpc": 0.12606732547283173,
        "kilt_tasks/hotpotqa": 0.11779442429542542
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14712,
        "ag_news": 15512,
        "amazon_polarity": 15032,
        "cnn_dailymail/3.0.0": 15696,
        "common_gen": 15360,
        "cos_e/v1.11": 15125,
        "glue/mrpc": 14808,
        "kilt_tasks/hotpotqa": 15336
      },
      "step": 950
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -126.67305755615234,
        "ag_news": 70.27265930175781,
        "amazon_polarity": 76.12635803222656,
        "cnn_dailymail/3.0.0": 156.16407775878906,
        "common_gen": 3.971945285797119,
        "cos_e/v1.11": -2.450171709060669,
        "glue/mrpc": 37.79724884033203,
        "kilt_tasks/hotpotqa": -15.27231502532959
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9862,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10232213139533997,
        "ag_news": 0.1318560540676117,
        "amazon_polarity": 0.13285505771636963,
        "cnn_dailymail/3.0.0": 0.14730648696422577,
        "common_gen": 0.12105712294578552,
        "cos_e/v1.11": 0.1200597807765007,
        "glue/mrpc": 0.12645001709461212,
        "kilt_tasks/hotpotqa": 0.11809331178665161
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14888,
        "ag_news": 15712,
        "amazon_polarity": 15232,
        "cnn_dailymail/3.0.0": 15816,
        "common_gen": 15520,
        "cos_e/v1.11": 15269,
        "glue/mrpc": 14968,
        "kilt_tasks/hotpotqa": 15456
      },
      "step": 960
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -126.07308959960938,
        "ag_news": 70.16764831542969,
        "amazon_polarity": 76.1136474609375,
        "cnn_dailymail/3.0.0": 156.6917724609375,
        "common_gen": 4.152294635772705,
        "cos_e/v1.11": -4.154799938201904,
        "glue/mrpc": 33.33913040161133,
        "kilt_tasks/hotpotqa": -18.452268600463867
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1465,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10263887792825699,
        "ag_news": 0.13197413086891174,
        "amazon_polarity": 0.13298463821411133,
        "cnn_dailymail/3.0.0": 0.147474467754364,
        "common_gen": 0.12126282602548599,
        "cos_e/v1.11": 0.11997868865728378,
        "glue/mrpc": 0.1258857697248459,
        "kilt_tasks/hotpotqa": 0.11780066043138504
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15032,
        "ag_news": 15880,
        "amazon_polarity": 15376,
        "cnn_dailymail/3.0.0": 16008,
        "common_gen": 15688,
        "cos_e/v1.11": 15437,
        "glue/mrpc": 15080,
        "kilt_tasks/hotpotqa": 15640
      },
      "step": 970
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -120.88555908203125,
        "ag_news": 70.08401489257812,
        "amazon_polarity": 76.21276092529297,
        "cnn_dailymail/3.0.0": 157.53317260742188,
        "common_gen": 2.057889223098755,
        "cos_e/v1.11": -3.4642293453216553,
        "glue/mrpc": 28.561166763305664,
        "kilt_tasks/hotpotqa": -18.646244049072266
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2212,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1034419909119606,
        "ag_news": 0.13194942474365234,
        "amazon_polarity": 0.13298559188842773,
        "cnn_dailymail/3.0.0": 0.14753791689872742,
        "common_gen": 0.1209815964102745,
        "cos_e/v1.11": 0.12013274431228638,
        "glue/mrpc": 0.1251407414674759,
        "kilt_tasks/hotpotqa": 0.11782990396022797
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15216,
        "ag_news": 16048,
        "amazon_polarity": 15496,
        "cnn_dailymail/3.0.0": 16232,
        "common_gen": 15816,
        "cos_e/v1.11": 15621,
        "glue/mrpc": 15216,
        "kilt_tasks/hotpotqa": 15776
      },
      "step": 980
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -118.47957611083984,
        "ag_news": 69.90840911865234,
        "amazon_polarity": 76.0168685913086,
        "cnn_dailymail/3.0.0": 159.3760528564453,
        "common_gen": -3.6492977142333984,
        "cos_e/v1.11": -4.767914772033691,
        "glue/mrpc": 27.684720993041992,
        "kilt_tasks/hotpotqa": -20.246973037719727
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0773,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10394684225320816,
        "ag_news": 0.1319996565580368,
        "amazon_polarity": 0.1330275684595108,
        "cnn_dailymail/3.0.0": 0.14789023995399475,
        "common_gen": 0.12023359537124634,
        "cos_e/v1.11": 0.12006308138370514,
        "glue/mrpc": 0.12511034309864044,
        "kilt_tasks/hotpotqa": 0.11772867292165756
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15400,
        "ag_news": 16256,
        "amazon_polarity": 15608,
        "cnn_dailymail/3.0.0": 16376,
        "common_gen": 15928,
        "cos_e/v1.11": 15829,
        "glue/mrpc": 15376,
        "kilt_tasks/hotpotqa": 15928
      },
      "step": 990
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -121.96791076660156,
        "ag_news": 70.36840057373047,
        "amazon_polarity": 75.82684326171875,
        "cnn_dailymail/3.0.0": 162.1477508544922,
        "common_gen": -2.13702654838562,
        "cos_e/v1.11": -8.428163528442383,
        "glue/mrpc": 27.613479614257812,
        "kilt_tasks/hotpotqa": -20.107744216918945
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1073,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10360947996377945,
        "ag_news": 0.1320711076259613,
        "amazon_polarity": 0.1329851597547531,
        "cnn_dailymail/3.0.0": 0.14831972122192383,
        "common_gen": 0.120514415204525,
        "cos_e/v1.11": 0.11956115812063217,
        "glue/mrpc": 0.1251274049282074,
        "kilt_tasks/hotpotqa": 0.11781159788370132
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15536,
        "ag_news": 16384,
        "amazon_polarity": 15768,
        "cnn_dailymail/3.0.0": 16552,
        "common_gen": 16064,
        "cos_e/v1.11": 16037,
        "glue/mrpc": 15584,
        "kilt_tasks/hotpotqa": 16056
      },
      "step": 1000
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1862,
      "eval_samples_per_second": 85.942,
      "eval_steps_per_second": 5.371,
      "step": 1000
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -123.39698028564453,
        "ag_news": 70.24819946289062,
        "amazon_polarity": 75.54730987548828,
        "cnn_dailymail/3.0.0": 161.44906616210938,
        "common_gen": -5.093738555908203,
        "cos_e/v1.11": -13.453441619873047,
        "glue/mrpc": 27.139341354370117,
        "kilt_tasks/hotpotqa": -24.71088981628418
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1239,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10376371443271637,
        "ag_news": 0.1323278248310089,
        "amazon_polarity": 0.13321246206760406,
        "cnn_dailymail/3.0.0": 0.14841525256633759,
        "common_gen": 0.1203732043504715,
        "cos_e/v1.11": 0.11911586672067642,
        "glue/mrpc": 0.1253480762243271,
        "kilt_tasks/hotpotqa": 0.11744363605976105
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15688,
        "ag_news": 16520,
        "amazon_polarity": 15920,
        "cnn_dailymail/3.0.0": 16680,
        "common_gen": 16224,
        "cos_e/v1.11": 16277,
        "glue/mrpc": 15776,
        "kilt_tasks/hotpotqa": 16176
      },
      "step": 1010
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -130.16946411132812,
        "ag_news": 70.18777465820312,
        "amazon_polarity": 75.506591796875,
        "cnn_dailymail/3.0.0": 160.5678253173828,
        "common_gen": -3.5387661457061768,
        "cos_e/v1.11": -12.463715553283691,
        "glue/mrpc": 26.052412033081055,
        "kilt_tasks/hotpotqa": -22.923831939697266
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.062,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10304588079452515,
        "ag_news": 0.13236112892627716,
        "amazon_polarity": 0.13324496150016785,
        "cnn_dailymail/3.0.0": 0.1482170820236206,
        "common_gen": 0.12070250511169434,
        "cos_e/v1.11": 0.1193634420633316,
        "glue/mrpc": 0.12525182962417603,
        "kilt_tasks/hotpotqa": 0.11781314760446548
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15840,
        "ag_news": 16696,
        "amazon_polarity": 16128,
        "cnn_dailymail/3.0.0": 16816,
        "common_gen": 16368,
        "cos_e/v1.11": 16437,
        "glue/mrpc": 15872,
        "kilt_tasks/hotpotqa": 16384
      },
      "step": 1020
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -132.2606964111328,
        "ag_news": 69.98936462402344,
        "amazon_polarity": 75.29126739501953,
        "cnn_dailymail/3.0.0": 159.3101043701172,
        "common_gen": -4.32956075668335,
        "cos_e/v1.11": -11.720307350158691,
        "glue/mrpc": 26.9251651763916,
        "kilt_tasks/hotpotqa": -23.64419174194336
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0948,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10293280333280563,
        "ag_news": 0.13236737251281738,
        "amazon_polarity": 0.133244127035141,
        "cnn_dailymail/3.0.0": 0.1479475349187851,
        "common_gen": 0.12067291885614395,
        "cos_e/v1.11": 0.11956856399774551,
        "glue/mrpc": 0.1254582405090332,
        "kilt_tasks/hotpotqa": 0.11780834943056107
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15992,
        "ag_news": 16888,
        "amazon_polarity": 16280,
        "cnn_dailymail/3.0.0": 17008,
        "common_gen": 16512,
        "cos_e/v1.11": 16581,
        "glue/mrpc": 16016,
        "kilt_tasks/hotpotqa": 16544
      },
      "step": 1030
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -131.70751953125,
        "ag_news": 70.10294342041016,
        "amazon_polarity": 75.29324340820312,
        "cnn_dailymail/3.0.0": 158.66244506835938,
        "common_gen": -5.302518367767334,
        "cos_e/v1.11": -14.587762832641602,
        "glue/mrpc": 25.248149871826172,
        "kilt_tasks/hotpotqa": -22.6673641204834
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0592,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10317488014698029,
        "ag_news": 0.13244783878326416,
        "amazon_polarity": 0.1333025097846985,
        "cnn_dailymail/3.0.0": 0.14781907200813293,
        "common_gen": 0.1206372082233429,
        "cos_e/v1.11": 0.11925842612981796,
        "glue/mrpc": 0.1252884864807129,
        "kilt_tasks/hotpotqa": 0.11807162314653397
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16136,
        "ag_news": 17104,
        "amazon_polarity": 16448,
        "cnn_dailymail/3.0.0": 17176,
        "common_gen": 16672,
        "cos_e/v1.11": 16717,
        "glue/mrpc": 16136,
        "kilt_tasks/hotpotqa": 16712
      },
      "step": 1040
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -132.29759216308594,
        "ag_news": 69.96749877929688,
        "amazon_polarity": 75.2277603149414,
        "cnn_dailymail/3.0.0": 158.77890014648438,
        "common_gen": -4.195684432983398,
        "cos_e/v1.11": -15.661623001098633,
        "glue/mrpc": 23.70265007019043,
        "kilt_tasks/hotpotqa": -24.099742889404297
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9979,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10325015336275101,
        "ag_news": 0.1324622631072998,
        "amazon_polarity": 0.13332447409629822,
        "cnn_dailymail/3.0.0": 0.14780421555042267,
        "common_gen": 0.1208885982632637,
        "cos_e/v1.11": 0.11919273436069489,
        "glue/mrpc": 0.1251174360513687,
        "kilt_tasks/hotpotqa": 0.11796007305383682
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16280,
        "ag_news": 17288,
        "amazon_polarity": 16640,
        "cnn_dailymail/3.0.0": 17280,
        "common_gen": 16840,
        "cos_e/v1.11": 16869,
        "glue/mrpc": 16288,
        "kilt_tasks/hotpotqa": 16896
      },
      "step": 1050
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -128.92880249023438,
        "ag_news": 69.68993377685547,
        "amazon_polarity": 75.19819641113281,
        "cnn_dailymail/3.0.0": 157.8518829345703,
        "common_gen": -2.9974987506866455,
        "cos_e/v1.11": -14.07711124420166,
        "glue/mrpc": 25.251436233520508,
        "kilt_tasks/hotpotqa": -22.158720016479492
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.926,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10365438461303711,
        "ag_news": 0.132233664393425,
        "amazon_polarity": 0.13313083350658417,
        "cnn_dailymail/3.0.0": 0.14735530316829681,
        "common_gen": 0.1209506094455719,
        "cos_e/v1.11": 0.11931826174259186,
        "glue/mrpc": 0.1252153068780899,
        "kilt_tasks/hotpotqa": 0.11814168095588684
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16504,
        "ag_news": 17480,
        "amazon_polarity": 16832,
        "cnn_dailymail/3.0.0": 17408,
        "common_gen": 16920,
        "cos_e/v1.11": 17021,
        "glue/mrpc": 16448,
        "kilt_tasks/hotpotqa": 17048
      },
      "step": 1060
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -126.26000213623047,
        "ag_news": 69.73074340820312,
        "amazon_polarity": 75.07533264160156,
        "cnn_dailymail/3.0.0": 159.94313049316406,
        "common_gen": -3.6368155479431152,
        "cos_e/v1.11": -16.25238800048828,
        "glue/mrpc": 24.089275360107422,
        "kilt_tasks/hotpotqa": -24.179140090942383
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1617,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10410315543413162,
        "ag_news": 0.13223209977149963,
        "amazon_polarity": 0.13309846818447113,
        "cnn_dailymail/3.0.0": 0.1476491540670395,
        "common_gen": 0.12089887261390686,
        "cos_e/v1.11": 0.11905136704444885,
        "glue/mrpc": 0.12506170570850372,
        "kilt_tasks/hotpotqa": 0.1179051473736763
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16664,
        "ag_news": 17640,
        "amazon_polarity": 16920,
        "cnn_dailymail/3.0.0": 17552,
        "common_gen": 17104,
        "cos_e/v1.11": 17197,
        "glue/mrpc": 16648,
        "kilt_tasks/hotpotqa": 17216
      },
      "step": 1070
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -128.59632873535156,
        "ag_news": 69.68466186523438,
        "amazon_polarity": 74.98178100585938,
        "cnn_dailymail/3.0.0": 160.0194549560547,
        "common_gen": -5.041251182556152,
        "cos_e/v1.11": -24.8284912109375,
        "glue/mrpc": 21.84360122680664,
        "kilt_tasks/hotpotqa": -23.657758712768555
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0323,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10410692542791367,
        "ag_news": 0.13245977461338043,
        "amazon_polarity": 0.13331593573093414,
        "cnn_dailymail/3.0.0": 0.14785046875476837,
        "common_gen": 0.12095697224140167,
        "cos_e/v1.11": 0.1180836632847786,
        "glue/mrpc": 0.12497446686029434,
        "kilt_tasks/hotpotqa": 0.1182517409324646
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16800,
        "ag_news": 17808,
        "amazon_polarity": 17144,
        "cnn_dailymail/3.0.0": 17704,
        "common_gen": 17288,
        "cos_e/v1.11": 17333,
        "glue/mrpc": 16792,
        "kilt_tasks/hotpotqa": 17352
      },
      "step": 1080
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -132.6400909423828,
        "ag_news": 69.49012756347656,
        "amazon_polarity": 75.0551528930664,
        "cnn_dailymail/3.0.0": 161.8340606689453,
        "common_gen": -6.492088794708252,
        "cos_e/v1.11": -19.57291603088379,
        "glue/mrpc": 21.136489868164062,
        "kilt_tasks/hotpotqa": -22.14817237854004
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1783,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10364194959402084,
        "ag_news": 0.1323370784521103,
        "amazon_polarity": 0.1332317292690277,
        "cnn_dailymail/3.0.0": 0.1479991376399994,
        "common_gen": 0.12071152031421661,
        "cos_e/v1.11": 0.11881676316261292,
        "glue/mrpc": 0.12481445074081421,
        "kilt_tasks/hotpotqa": 0.11844728887081146
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16976,
        "ag_news": 17944,
        "amazon_polarity": 17312,
        "cnn_dailymail/3.0.0": 17944,
        "common_gen": 17376,
        "cos_e/v1.11": 17501,
        "glue/mrpc": 16944,
        "kilt_tasks/hotpotqa": 17504
      },
      "step": 1090
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -130.0817413330078,
        "ag_news": 69.27957153320312,
        "amazon_polarity": 75.04395294189453,
        "cnn_dailymail/3.0.0": 161.53457641601562,
        "common_gen": -5.436723709106445,
        "cos_e/v1.11": -20.431011199951172,
        "glue/mrpc": 17.667190551757812,
        "kilt_tasks/hotpotqa": -24.548065185546875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9859,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10411380231380463,
        "ag_news": 0.13235187530517578,
        "amazon_polarity": 0.13327457010746002,
        "cnn_dailymail/3.0.0": 0.14792490005493164,
        "common_gen": 0.12095939368009567,
        "cos_e/v1.11": 0.1187952384352684,
        "glue/mrpc": 0.12437227368354797,
        "kilt_tasks/hotpotqa": 0.11820787936449051
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17096,
        "ag_news": 18176,
        "amazon_polarity": 17464,
        "cnn_dailymail/3.0.0": 18088,
        "common_gen": 17472,
        "cos_e/v1.11": 17661,
        "glue/mrpc": 17128,
        "kilt_tasks/hotpotqa": 17696
      },
      "step": 1100
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1871,
      "eval_samples_per_second": 85.535,
      "eval_steps_per_second": 5.346,
      "step": 1100
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -137.1444549560547,
        "ag_news": 69.25714111328125,
        "amazon_polarity": 74.67453002929688,
        "cnn_dailymail/3.0.0": 162.328857421875,
        "common_gen": -6.883987903594971,
        "cos_e/v1.11": -22.11118507385254,
        "glue/mrpc": 17.80866050720215,
        "kilt_tasks/hotpotqa": -27.691850662231445
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2187,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10349671542644501,
        "ag_news": 0.13253885507583618,
        "amazon_polarity": 0.13340315222740173,
        "cnn_dailymail/3.0.0": 0.1482054889202118,
        "common_gen": 0.1209721565246582,
        "cos_e/v1.11": 0.11878419667482376,
        "glue/mrpc": 0.12460705637931824,
        "kilt_tasks/hotpotqa": 0.11799238622188568
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17312,
        "ag_news": 18296,
        "amazon_polarity": 17608,
        "cnn_dailymail/3.0.0": 18232,
        "common_gen": 17640,
        "cos_e/v1.11": 17853,
        "glue/mrpc": 17264,
        "kilt_tasks/hotpotqa": 17856
      },
      "step": 1110
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -139.40103149414062,
        "ag_news": 69.27304077148438,
        "amazon_polarity": 74.6594009399414,
        "cnn_dailymail/3.0.0": 160.7822723388672,
        "common_gen": -6.1643290519714355,
        "cos_e/v1.11": -17.355491638183594,
        "glue/mrpc": 16.56551742553711,
        "kilt_tasks/hotpotqa": -31.825654983520508
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0593,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10336288064718246,
        "ag_news": 0.13258108496665955,
        "amazon_polarity": 0.1334368735551834,
        "cnn_dailymail/3.0.0": 0.14790257811546326,
        "common_gen": 0.12116142362356186,
        "cos_e/v1.11": 0.1195540502667427,
        "glue/mrpc": 0.12449362874031067,
        "kilt_tasks/hotpotqa": 0.11750759184360504
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17520,
        "ag_news": 18392,
        "amazon_polarity": 17744,
        "cnn_dailymail/3.0.0": 18408,
        "common_gen": 17728,
        "cos_e/v1.11": 18013,
        "glue/mrpc": 17560,
        "kilt_tasks/hotpotqa": 17976
      },
      "step": 1120
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -143.4985809326172,
        "ag_news": 69.20063781738281,
        "amazon_polarity": 74.69888305664062,
        "cnn_dailymail/3.0.0": 159.2606201171875,
        "common_gen": -4.051187038421631,
        "cos_e/v1.11": -13.239313125610352,
        "glue/mrpc": 19.3427677154541,
        "kilt_tasks/hotpotqa": -29.29752540588379
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9433,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10285929590463638,
        "ag_news": 0.1324213445186615,
        "amazon_polarity": 0.13329005241394043,
        "cnn_dailymail/3.0.0": 0.14739856123924255,
        "common_gen": 0.1213783249258995,
        "cos_e/v1.11": 0.12006044387817383,
        "glue/mrpc": 0.12480013072490692,
        "kilt_tasks/hotpotqa": 0.1177917867898941
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17624,
        "ag_news": 18624,
        "amazon_polarity": 17968,
        "cnn_dailymail/3.0.0": 18528,
        "common_gen": 17880,
        "cos_e/v1.11": 18229,
        "glue/mrpc": 17688,
        "kilt_tasks/hotpotqa": 18080
      },
      "step": 1130
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -147.43165588378906,
        "ag_news": 69.21147155761719,
        "amazon_polarity": 74.67432403564453,
        "cnn_dailymail/3.0.0": 158.0356903076172,
        "common_gen": -6.330050468444824,
        "cos_e/v1.11": -8.729951858520508,
        "glue/mrpc": 19.592416763305664,
        "kilt_tasks/hotpotqa": -30.54899787902832
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9982,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10252443701028824,
        "ag_news": 0.132460817694664,
        "amazon_polarity": 0.1333203911781311,
        "cnn_dailymail/3.0.0": 0.14715786278247833,
        "common_gen": 0.1211320012807846,
        "cos_e/v1.11": 0.1207885816693306,
        "glue/mrpc": 0.12490486353635788,
        "kilt_tasks/hotpotqa": 0.11771111190319061
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17856,
        "ag_news": 18784,
        "amazon_polarity": 18144,
        "cnn_dailymail/3.0.0": 18680,
        "common_gen": 18000,
        "cos_e/v1.11": 18373,
        "glue/mrpc": 17856,
        "kilt_tasks/hotpotqa": 18208
      },
      "step": 1140
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -150.1785430908203,
        "ag_news": 69.05900573730469,
        "amazon_polarity": 74.57353973388672,
        "cnn_dailymail/3.0.0": 158.31298828125,
        "common_gen": -6.143195152282715,
        "cos_e/v1.11": -12.133830070495605,
        "glue/mrpc": 17.877500534057617,
        "kilt_tasks/hotpotqa": -31.970958709716797
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1501,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10240895301103592,
        "ag_news": 0.13256952166557312,
        "amazon_polarity": 0.1334342062473297,
        "cnn_dailymail/3.0.0": 0.14728635549545288,
        "common_gen": 0.12132666260004044,
        "cos_e/v1.11": 0.12047357112169266,
        "glue/mrpc": 0.12480908632278442,
        "kilt_tasks/hotpotqa": 0.11769165098667145
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17992,
        "ag_news": 18920,
        "amazon_polarity": 18304,
        "cnn_dailymail/3.0.0": 18840,
        "common_gen": 18168,
        "cos_e/v1.11": 18541,
        "glue/mrpc": 18008,
        "kilt_tasks/hotpotqa": 18408
      },
      "step": 1150
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -147.03639221191406,
        "ag_news": 69.05846405029297,
        "amazon_polarity": 74.47142028808594,
        "cnn_dailymail/3.0.0": 160.10899353027344,
        "common_gen": -8.182998657226562,
        "cos_e/v1.11": -12.525749206542969,
        "glue/mrpc": 16.146587371826172,
        "kilt_tasks/hotpotqa": -33.003021240234375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.155,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10288325697183609,
        "ag_news": 0.13254791498184204,
        "amazon_polarity": 0.1333928406238556,
        "cnn_dailymail/3.0.0": 0.14750683307647705,
        "common_gen": 0.12106307595968246,
        "cos_e/v1.11": 0.120448037981987,
        "glue/mrpc": 0.12456788122653961,
        "kilt_tasks/hotpotqa": 0.11759019643068314
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18128,
        "ag_news": 19032,
        "amazon_polarity": 18464,
        "cnn_dailymail/3.0.0": 19016,
        "common_gen": 18304,
        "cos_e/v1.11": 18773,
        "glue/mrpc": 18168,
        "kilt_tasks/hotpotqa": 18576
      },
      "step": 1160
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -151.93386840820312,
        "ag_news": 68.87235260009766,
        "amazon_polarity": 74.4384765625,
        "cnn_dailymail/3.0.0": 160.3740692138672,
        "common_gen": -3.3039586544036865,
        "cos_e/v1.11": -9.441817283630371,
        "glue/mrpc": 16.2027645111084,
        "kilt_tasks/hotpotqa": -32.5451774597168
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1336,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10232052952051163,
        "ag_news": 0.1324062943458557,
        "amazon_polarity": 0.13327056169509888,
        "cnn_dailymail/3.0.0": 0.14735980331897736,
        "common_gen": 0.12169818580150604,
        "cos_e/v1.11": 0.12082892656326294,
        "glue/mrpc": 0.12450291961431503,
        "kilt_tasks/hotpotqa": 0.117612823843956
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18272,
        "ag_news": 19184,
        "amazon_polarity": 18600,
        "cnn_dailymail/3.0.0": 19184,
        "common_gen": 18448,
        "cos_e/v1.11": 18965,
        "glue/mrpc": 18356,
        "kilt_tasks/hotpotqa": 18728
      },
      "step": 1170
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -149.94351196289062,
        "ag_news": 68.83776092529297,
        "amazon_polarity": 74.06249237060547,
        "cnn_dailymail/3.0.0": 161.69760131835938,
        "common_gen": -1.4224967956542969,
        "cos_e/v1.11": -9.59988784790039,
        "glue/mrpc": 16.996505737304688,
        "kilt_tasks/hotpotqa": -35.342525482177734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1357,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10260703414678574,
        "ag_news": 0.1323215663433075,
        "amazon_polarity": 0.13312870264053345,
        "cnn_dailymail/3.0.0": 0.14743202924728394,
        "common_gen": 0.12193500995635986,
        "cos_e/v1.11": 0.12078088521957397,
        "glue/mrpc": 0.12457555532455444,
        "kilt_tasks/hotpotqa": 0.11721919476985931
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18408,
        "ag_news": 19344,
        "amazon_polarity": 18768,
        "cnn_dailymail/3.0.0": 19376,
        "common_gen": 18592,
        "cos_e/v1.11": 19125,
        "glue/mrpc": 18484,
        "kilt_tasks/hotpotqa": 18920
      },
      "step": 1180
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -150.00486755371094,
        "ag_news": 68.55465698242188,
        "amazon_polarity": 73.91136932373047,
        "cnn_dailymail/3.0.0": 160.15347290039062,
        "common_gen": -0.6030795574188232,
        "cos_e/v1.11": -2.2127203941345215,
        "glue/mrpc": 17.19015121459961,
        "kilt_tasks/hotpotqa": -29.919729232788086
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1471,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10252442955970764,
        "ag_news": 0.1320403516292572,
        "amazon_polarity": 0.13286270201206207,
        "cnn_dailymail/3.0.0": 0.14683692157268524,
        "common_gen": 0.1218731477856636,
        "cos_e/v1.11": 0.12164615839719772,
        "glue/mrpc": 0.12441097944974899,
        "kilt_tasks/hotpotqa": 0.11780522018671036
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18600,
        "ag_news": 19456,
        "amazon_polarity": 18888,
        "cnn_dailymail/3.0.0": 19504,
        "common_gen": 18792,
        "cos_e/v1.11": 19325,
        "glue/mrpc": 18652,
        "kilt_tasks/hotpotqa": 19080
      },
      "step": 1190
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -147.51077270507812,
        "ag_news": 68.46762084960938,
        "amazon_polarity": 73.82646942138672,
        "cnn_dailymail/3.0.0": 160.19363403320312,
        "common_gen": 0.11423145979642868,
        "cos_e/v1.11": -4.134120464324951,
        "glue/mrpc": 13.480730056762695,
        "kilt_tasks/hotpotqa": -31.109067916870117
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.08,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10296574980020523,
        "ag_news": 0.13207711279392242,
        "amazon_polarity": 0.13289660215377808,
        "cnn_dailymail/3.0.0": 0.14683470129966736,
        "common_gen": 0.12206068634986877,
        "cos_e/v1.11": 0.1214640662074089,
        "glue/mrpc": 0.12395718693733215,
        "kilt_tasks/hotpotqa": 0.11774390935897827
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18720,
        "ag_news": 19640,
        "amazon_polarity": 19016,
        "cnn_dailymail/3.0.0": 19656,
        "common_gen": 19000,
        "cos_e/v1.11": 19461,
        "glue/mrpc": 18836,
        "kilt_tasks/hotpotqa": 19248
      },
      "step": 1200
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 1.0,
      "eval_runtime": 0.1882,
      "eval_samples_per_second": 85.021,
      "eval_steps_per_second": 5.314,
      "step": 1200
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -150.9837646484375,
        "ag_news": 68.66380310058594,
        "amazon_polarity": 73.75630187988281,
        "cnn_dailymail/3.0.0": 161.41783142089844,
        "common_gen": -0.393696665763855,
        "cos_e/v1.11": -6.129434585571289,
        "glue/mrpc": 10.901473999023438,
        "kilt_tasks/hotpotqa": -31.40302276611328
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0617,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10273642092943192,
        "ag_news": 0.13220378756523132,
        "amazon_polarity": 0.13297997415065765,
        "cnn_dailymail/3.0.0": 0.14708547294139862,
        "common_gen": 0.12211846560239792,
        "cos_e/v1.11": 0.1213165670633316,
        "glue/mrpc": 0.12371329963207245,
        "kilt_tasks/hotpotqa": 0.11784599721431732
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18848,
        "ag_news": 19808,
        "amazon_polarity": 19176,
        "cnn_dailymail/3.0.0": 19824,
        "common_gen": 19144,
        "cos_e/v1.11": 19650,
        "glue/mrpc": 19012,
        "kilt_tasks/hotpotqa": 19392
      },
      "step": 1210
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -152.33187866210938,
        "ag_news": 68.58025360107422,
        "amazon_polarity": 73.96358489990234,
        "cnn_dailymail/3.0.0": 162.56503295898438,
        "common_gen": -3.116248369216919,
        "cos_e/v1.11": -10.831847190856934,
        "glue/mrpc": 10.664670944213867,
        "kilt_tasks/hotpotqa": -31.385944366455078
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0383,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10276560485363007,
        "ag_news": 0.13229693472385406,
        "amazon_polarity": 0.1331147998571396,
        "cnn_dailymail/3.0.0": 0.14733275771141052,
        "common_gen": 0.12187546491622925,
        "cos_e/v1.11": 0.12080452591180801,
        "glue/mrpc": 0.12381217628717422,
        "kilt_tasks/hotpotqa": 0.11799772828817368
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19000,
        "ag_news": 20016,
        "amazon_polarity": 19304,
        "cnn_dailymail/3.0.0": 19928,
        "common_gen": 19320,
        "cos_e/v1.11": 19842,
        "glue/mrpc": 19180,
        "kilt_tasks/hotpotqa": 19544
      },
      "step": 1220
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -155.41921997070312,
        "ag_news": 68.52172088623047,
        "amazon_polarity": 72.73143005371094,
        "cnn_dailymail/3.0.0": 163.11624145507812,
        "common_gen": -0.6784729957580566,
        "cos_e/v1.11": -10.995524406433105,
        "glue/mrpc": 11.536376953125,
        "kilt_tasks/hotpotqa": -30.956457138061523
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9946,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10248489677906036,
        "ag_news": 0.13225585222244263,
        "amazon_polarity": 0.1328922063112259,
        "cnn_dailymail/3.0.0": 0.1473253071308136,
        "common_gen": 0.12222521007061005,
        "cos_e/v1.11": 0.12079694122076035,
        "glue/mrpc": 0.12393822520971298,
        "kilt_tasks/hotpotqa": 0.11808128654956818
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19200,
        "ag_news": 20216,
        "amazon_polarity": 19432,
        "cnn_dailymail/3.0.0": 20072,
        "common_gen": 19424,
        "cos_e/v1.11": 20002,
        "glue/mrpc": 19380,
        "kilt_tasks/hotpotqa": 19688
      },
      "step": 1230
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -157.58351135253906,
        "ag_news": 68.32549285888672,
        "amazon_polarity": 72.90353393554688,
        "cnn_dailymail/3.0.0": 166.73817443847656,
        "common_gen": 0.2590983211994171,
        "cos_e/v1.11": -3.4695169925689697,
        "glue/mrpc": 8.718097686767578,
        "kilt_tasks/hotpotqa": -32.276187896728516
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1278,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10222066938877106,
        "ag_news": 0.13207398355007172,
        "amazon_polarity": 0.13276241719722748,
        "cnn_dailymail/3.0.0": 0.14769838750362396,
        "common_gen": 0.12225303053855896,
        "cos_e/v1.11": 0.12173684686422348,
        "glue/mrpc": 0.12343227118253708,
        "kilt_tasks/hotpotqa": 0.11782239377498627
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19328,
        "ag_news": 20384,
        "amazon_polarity": 19560,
        "cnn_dailymail/3.0.0": 20248,
        "common_gen": 19592,
        "cos_e/v1.11": 20106,
        "glue/mrpc": 19572,
        "kilt_tasks/hotpotqa": 19904
      },
      "step": 1240
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -158.75779724121094,
        "ag_news": 68.33060455322266,
        "amazon_polarity": 72.70630645751953,
        "cnn_dailymail/3.0.0": 169.4964141845703,
        "common_gen": -0.3099784255027771,
        "cos_e/v1.11": -0.5637685656547546,
        "glue/mrpc": 10.509913444519043,
        "kilt_tasks/hotpotqa": -32.66658020019531
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9935,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10208560526371002,
        "ag_news": 0.13194051384925842,
        "amazon_polarity": 0.13259515166282654,
        "cnn_dailymail/3.0.0": 0.14794370532035828,
        "common_gen": 0.12208783626556396,
        "cos_e/v1.11": 0.12205281853675842,
        "glue/mrpc": 0.12359015643596649,
        "kilt_tasks/hotpotqa": 0.11770426481962204
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19496,
        "ag_news": 20536,
        "amazon_polarity": 19664,
        "cnn_dailymail/3.0.0": 20456,
        "common_gen": 19680,
        "cos_e/v1.11": 20266,
        "glue/mrpc": 19796,
        "kilt_tasks/hotpotqa": 20080
      },
      "step": 1250
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -161.33424377441406,
        "ag_news": 68.35115051269531,
        "amazon_polarity": 72.62482452392578,
        "cnn_dailymail/3.0.0": 169.11239624023438,
        "common_gen": 1.2301089763641357,
        "cos_e/v1.11": 0.8270534873008728,
        "glue/mrpc": 12.25816822052002,
        "kilt_tasks/hotpotqa": -36.37808609008789
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9904,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1018953025341034,
        "ag_news": 0.13194608688354492,
        "amazon_polarity": 0.1325829178094864,
        "cnn_dailymail/3.0.0": 0.14781558513641357,
        "common_gen": 0.12233950197696686,
        "cos_e/v1.11": 0.12228399515151978,
        "glue/mrpc": 0.12386799603700638,
        "kilt_tasks/hotpotqa": 0.11726868152618408
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19624,
        "ag_news": 20728,
        "amazon_polarity": 19832,
        "cnn_dailymail/3.0.0": 20632,
        "common_gen": 19824,
        "cos_e/v1.11": 20450,
        "glue/mrpc": 19948,
        "kilt_tasks/hotpotqa": 20216
      },
      "step": 1260
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -164.96395874023438,
        "ag_news": 68.28129577636719,
        "amazon_polarity": 72.6410140991211,
        "cnn_dailymail/3.0.0": 172.3473663330078,
        "common_gen": 1.1912542581558228,
        "cos_e/v1.11": -3.779329299926758,
        "glue/mrpc": 12.350565910339355,
        "kilt_tasks/hotpotqa": -38.66489028930664
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8672,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1016470268368721,
        "ag_news": 0.13201694190502167,
        "amazon_polarity": 0.13266442716121674,
        "cnn_dailymail/3.0.0": 0.14837898313999176,
        "common_gen": 0.12244562059640884,
        "cos_e/v1.11": 0.12176499515771866,
        "glue/mrpc": 0.12398766726255417,
        "kilt_tasks/hotpotqa": 0.11709436774253845
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19832,
        "ag_news": 20864,
        "amazon_polarity": 20032,
        "cnn_dailymail/3.0.0": 20728,
        "common_gen": 19984,
        "cos_e/v1.11": 20586,
        "glue/mrpc": 20132,
        "kilt_tasks/hotpotqa": 20376
      },
      "step": 1270
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.684326171875,
        "ag_news": 68.30198669433594,
        "amazon_polarity": 72.68058013916016,
        "cnn_dailymail/3.0.0": 174.25364685058594,
        "common_gen": 1.655861258506775,
        "cos_e/v1.11": 0.085640549659729,
        "glue/mrpc": 13.883451461791992,
        "kilt_tasks/hotpotqa": -38.973243713378906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9014,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10175059735774994,
        "ag_news": 0.13183195888996124,
        "amazon_polarity": 0.13247880339622498,
        "cnn_dailymail/3.0.0": 0.14841634035110474,
        "common_gen": 0.12237057089805603,
        "cos_e/v1.11": 0.12215612083673477,
        "glue/mrpc": 0.12405362725257874,
        "kilt_tasks/hotpotqa": 0.11694197356700897
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19968,
        "ag_news": 20976,
        "amazon_polarity": 20216,
        "cnn_dailymail/3.0.0": 20872,
        "common_gen": 20136,
        "cos_e/v1.11": 20674,
        "glue/mrpc": 20380,
        "kilt_tasks/hotpotqa": 20592
      },
      "step": 1280
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -164.27650451660156,
        "ag_news": 68.27383422851562,
        "amazon_polarity": 72.5615463256836,
        "cnn_dailymail/3.0.0": 172.8545379638672,
        "common_gen": -0.9116456508636475,
        "cos_e/v1.11": -2.866755723953247,
        "glue/mrpc": 15.274429321289062,
        "kilt_tasks/hotpotqa": -41.15190505981445
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0236,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10188425332307816,
        "ag_news": 0.13195662200450897,
        "amazon_polarity": 0.13258816301822662,
        "cnn_dailymail/3.0.0": 0.14826218783855438,
        "common_gen": 0.1221756637096405,
        "cos_e/v1.11": 0.12191015481948853,
        "glue/mrpc": 0.12439630180597305,
        "kilt_tasks/hotpotqa": 0.11682669818401337
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20152,
        "ag_news": 21136,
        "amazon_polarity": 20408,
        "cnn_dailymail/3.0.0": 21112,
        "common_gen": 20304,
        "cos_e/v1.11": 20786,
        "glue/mrpc": 20500,
        "kilt_tasks/hotpotqa": 20696
      },
      "step": 1290
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -164.9707794189453,
        "ag_news": 68.21875762939453,
        "amazon_polarity": 72.49603271484375,
        "cnn_dailymail/3.0.0": 174.2599334716797,
        "common_gen": -0.9517756700515747,
        "cos_e/v1.11": -0.9519546031951904,
        "glue/mrpc": 18.306236267089844,
        "kilt_tasks/hotpotqa": -40.584877014160156
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9003,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10179796814918518,
        "ag_news": 0.1318076103925705,
        "amazon_polarity": 0.13243448734283447,
        "cnn_dailymail/3.0.0": 0.14826874434947968,
        "common_gen": 0.12207574397325516,
        "cos_e/v1.11": 0.12207572162151337,
        "glue/mrpc": 0.12471002340316772,
        "kilt_tasks/hotpotqa": 0.1168297529220581
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20352,
        "ag_news": 21304,
        "amazon_polarity": 20584,
        "cnn_dailymail/3.0.0": 21240,
        "common_gen": 20448,
        "cos_e/v1.11": 20930,
        "glue/mrpc": 20684,
        "kilt_tasks/hotpotqa": 20832
      },
      "step": 1300
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 1.0,
      "eval_runtime": 0.1924,
      "eval_samples_per_second": 83.158,
      "eval_steps_per_second": 5.197,
      "step": 1300
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.40679931640625,
        "ag_news": 67.9700698852539,
        "amazon_polarity": 72.53604125976562,
        "cnn_dailymail/3.0.0": 174.06849670410156,
        "common_gen": 0.010217636823654175,
        "cos_e/v1.11": 0.37398141622543335,
        "glue/mrpc": 19.542469024658203,
        "kilt_tasks/hotpotqa": -41.55191421508789
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0567,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10200724750757217,
        "ag_news": 0.13168568909168243,
        "amazon_polarity": 0.132351815700531,
        "cnn_dailymail/3.0.0": 0.14807461202144623,
        "common_gen": 0.1221616342663765,
        "cos_e/v1.11": 0.12221072614192963,
        "glue/mrpc": 0.12482548505067825,
        "kilt_tasks/hotpotqa": 0.11668268591165543
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20496,
        "ag_news": 21448,
        "amazon_polarity": 20712,
        "cnn_dailymail/3.0.0": 21400,
        "common_gen": 20616,
        "cos_e/v1.11": 21146,
        "glue/mrpc": 20876,
        "kilt_tasks/hotpotqa": 20960
      },
      "step": 1310
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -157.35562133789062,
        "ag_news": 67.91709899902344,
        "amazon_polarity": 72.42570495605469,
        "cnn_dailymail/3.0.0": 177.2431640625,
        "common_gen": -2.5199429988861084,
        "cos_e/v1.11": -0.5743696093559265,
        "glue/mrpc": 20.37598991394043,
        "kilt_tasks/hotpotqa": -41.63005828857422
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9505,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10268452763557434,
        "ag_news": 0.1315476894378662,
        "amazon_polarity": 0.13220225274562836,
        "cnn_dailymail/3.0.0": 0.14838065207004547,
        "common_gen": 0.12173599749803543,
        "cos_e/v1.11": 0.12199684232473373,
        "glue/mrpc": 0.12484157830476761,
        "kilt_tasks/hotpotqa": 0.11661039292812347
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20688,
        "ag_news": 21568,
        "amazon_polarity": 20912,
        "cnn_dailymail/3.0.0": 21496,
        "common_gen": 20776,
        "cos_e/v1.11": 21354,
        "glue/mrpc": 21012,
        "kilt_tasks/hotpotqa": 21128
      },
      "step": 1320
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -160.4185028076172,
        "ag_news": 67.72894287109375,
        "amazon_polarity": 72.42861938476562,
        "cnn_dailymail/3.0.0": 175.9193878173828,
        "common_gen": 0.14499831199645996,
        "cos_e/v1.11": 0.7225807309150696,
        "glue/mrpc": 16.169328689575195,
        "kilt_tasks/hotpotqa": -43.03109359741211
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.946,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10250082612037659,
        "ag_news": 0.13160449266433716,
        "amazon_polarity": 0.13228461146354675,
        "cnn_dailymail/3.0.0": 0.14819301664829254,
        "common_gen": 0.12220535427331924,
        "cos_e/v1.11": 0.12228274345397949,
        "glue/mrpc": 0.12437079846858978,
        "kilt_tasks/hotpotqa": 0.11655823886394501
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20800,
        "ag_news": 21736,
        "amazon_polarity": 21080,
        "cnn_dailymail/3.0.0": 21648,
        "common_gen": 20936,
        "cos_e/v1.11": 21546,
        "glue/mrpc": 21172,
        "kilt_tasks/hotpotqa": 21296
      },
      "step": 1330
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -160.29832458496094,
        "ag_news": 67.62215423583984,
        "amazon_polarity": 72.55438232421875,
        "cnn_dailymail/3.0.0": 176.92584228515625,
        "common_gen": -2.9274728298187256,
        "cos_e/v1.11": -1.3679285049438477,
        "glue/mrpc": 18.33357048034668,
        "kilt_tasks/hotpotqa": -42.53702163696289
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.955,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10260704904794693,
        "ag_news": 0.13158637285232544,
        "amazon_polarity": 0.13229747116565704,
        "cnn_dailymail/3.0.0": 0.14828768372535706,
        "common_gen": 0.12182698398828506,
        "cos_e/v1.11": 0.12203462421894073,
        "glue/mrpc": 0.12468866258859634,
        "kilt_tasks/hotpotqa": 0.11667119711637497
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20984,
        "ag_news": 21840,
        "amazon_polarity": 21248,
        "cnn_dailymail/3.0.0": 21832,
        "common_gen": 21080,
        "cos_e/v1.11": 21698,
        "glue/mrpc": 21348,
        "kilt_tasks/hotpotqa": 21464
      },
      "step": 1340
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -162.4628448486328,
        "ag_news": 67.4455795288086,
        "amazon_polarity": 72.6807861328125,
        "cnn_dailymail/3.0.0": 179.951904296875,
        "common_gen": -5.902078628540039,
        "cos_e/v1.11": -2.4988272190093994,
        "glue/mrpc": 17.604454040527344,
        "kilt_tasks/hotpotqa": -42.691646575927734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9677,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10248535871505737,
        "ag_news": 0.13159403204917908,
        "amazon_polarity": 0.13234618306159973,
        "cnn_dailymail/3.0.0": 0.14874917268753052,
        "common_gen": 0.1214982271194458,
        "cos_e/v1.11": 0.12194889783859253,
        "glue/mrpc": 0.1246456578373909,
        "kilt_tasks/hotpotqa": 0.11673241853713989
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21144,
        "ag_news": 22032,
        "amazon_polarity": 21360,
        "cnn_dailymail/3.0.0": 22032,
        "common_gen": 21256,
        "cos_e/v1.11": 21810,
        "glue/mrpc": 21516,
        "kilt_tasks/hotpotqa": 21624
      },
      "step": 1350
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -159.841796875,
        "ag_news": 67.40421295166016,
        "amazon_polarity": 72.42024993896484,
        "cnn_dailymail/3.0.0": 181.75218200683594,
        "common_gen": -10.305912017822266,
        "cos_e/v1.11": -2.19345760345459,
        "glue/mrpc": 16.80573272705078,
        "kilt_tasks/hotpotqa": -47.985111236572266
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9155,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10293249785900116,
        "ag_news": 0.13166794180870056,
        "amazon_polarity": 0.13238626718521118,
        "cnn_dailymail/3.0.0": 0.14906379580497742,
        "common_gen": 0.12102827429771423,
        "cos_e/v1.11": 0.1220971867442131,
        "glue/mrpc": 0.12463799864053726,
        "kilt_tasks/hotpotqa": 0.11618602275848389
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21312,
        "ag_news": 22216,
        "amazon_polarity": 21512,
        "cnn_dailymail/3.0.0": 22184,
        "common_gen": 21424,
        "cos_e/v1.11": 21970,
        "glue/mrpc": 21668,
        "kilt_tasks/hotpotqa": 21768
      },
      "step": 1360
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -159.42425537109375,
        "ag_news": 67.24365997314453,
        "amazon_polarity": 72.35609436035156,
        "cnn_dailymail/3.0.0": 178.70530700683594,
        "common_gen": -11.224424362182617,
        "cos_e/v1.11": -4.605217933654785,
        "glue/mrpc": 18.641984939575195,
        "kilt_tasks/hotpotqa": -50.61343765258789
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9559,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10315573215484619,
        "ag_news": 0.13175390660762787,
        "amazon_polarity": 0.13248389959335327,
        "cnn_dailymail/3.0.0": 0.14862915873527527,
        "common_gen": 0.12104514986276627,
        "cos_e/v1.11": 0.12191354483366013,
        "glue/mrpc": 0.1250135600566864,
        "kilt_tasks/hotpotqa": 0.11600511521100998
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21504,
        "ag_news": 22368,
        "amazon_polarity": 21672,
        "cnn_dailymail/3.0.0": 22336,
        "common_gen": 21568,
        "cos_e/v1.11": 22090,
        "glue/mrpc": 21860,
        "kilt_tasks/hotpotqa": 21936
      },
      "step": 1370
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.35769653320312,
        "ag_news": 67.2215576171875,
        "amazon_polarity": 72.21940612792969,
        "cnn_dailymail/3.0.0": 180.02157592773438,
        "common_gen": -11.253975868225098,
        "cos_e/v1.11": -6.633458137512207,
        "glue/mrpc": 20.210458755493164,
        "kilt_tasks/hotpotqa": -51.19816589355469
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9785,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10283242166042328,
        "ag_news": 0.1317780613899231,
        "amazon_polarity": 0.1324891895055771,
        "cnn_dailymail/3.0.0": 0.14880631864070892,
        "common_gen": 0.12110332399606705,
        "cos_e/v1.11": 0.12170696258544922,
        "glue/mrpc": 0.1252744197845459,
        "kilt_tasks/hotpotqa": 0.11600933223962784
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21696,
        "ag_news": 22528,
        "amazon_polarity": 21784,
        "cnn_dailymail/3.0.0": 22488,
        "common_gen": 21728,
        "cos_e/v1.11": 22250,
        "glue/mrpc": 22040,
        "kilt_tasks/hotpotqa": 22096
      },
      "step": 1380
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -159.3040008544922,
        "ag_news": 67.29120635986328,
        "amazon_polarity": 72.81078338623047,
        "cnn_dailymail/3.0.0": 178.30482482910156,
        "common_gen": -13.474661827087402,
        "cos_e/v1.11": -2.191307544708252,
        "glue/mrpc": 19.344850540161133,
        "kilt_tasks/hotpotqa": -48.8446159362793
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.898,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1032775267958641,
        "ag_news": 0.1316682994365692,
        "amazon_polarity": 0.1324504315853119,
        "cnn_dailymail/3.0.0": 0.14833267033100128,
        "common_gen": 0.12074221670627594,
        "cos_e/v1.11": 0.12221186608076096,
        "glue/mrpc": 0.12506724894046783,
        "kilt_tasks/hotpotqa": 0.11624982953071594
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21880,
        "ag_news": 22712,
        "amazon_polarity": 21952,
        "cnn_dailymail/3.0.0": 22608,
        "common_gen": 21904,
        "cos_e/v1.11": 22362,
        "glue/mrpc": 22184,
        "kilt_tasks/hotpotqa": 22288
      },
      "step": 1390
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -161.7037811279297,
        "ag_news": 66.7537612915039,
        "amazon_polarity": 72.75480651855469,
        "cnn_dailymail/3.0.0": 178.00967407226562,
        "common_gen": -8.690935134887695,
        "cos_e/v1.11": -4.284090518951416,
        "glue/mrpc": 20.048316955566406,
        "kilt_tasks/hotpotqa": -47.394309997558594
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0124,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10306183248758316,
        "ag_news": 0.13154099881649017,
        "amazon_polarity": 0.13238771259784698,
        "cnn_dailymail/3.0.0": 0.14816473424434662,
        "common_gen": 0.12135060131549835,
        "cos_e/v1.11": 0.12192331999540329,
        "glue/mrpc": 0.12513504922389984,
        "kilt_tasks/hotpotqa": 0.11643583327531815
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21984,
        "ag_news": 22928,
        "amazon_polarity": 22080,
        "cnn_dailymail/3.0.0": 22800,
        "common_gen": 22080,
        "cos_e/v1.11": 22538,
        "glue/mrpc": 22256,
        "kilt_tasks/hotpotqa": 22504
      },
      "step": 1400
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 1.0,
      "eval_runtime": 0.1946,
      "eval_samples_per_second": 82.219,
      "eval_steps_per_second": 5.139,
      "step": 1400
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -161.2024688720703,
        "ag_news": 66.62810516357422,
        "amazon_polarity": 72.6712646484375,
        "cnn_dailymail/3.0.0": 180.54714965820312,
        "common_gen": -5.619618892669678,
        "cos_e/v1.11": -3.099282741546631,
        "glue/mrpc": 17.070022583007812,
        "kilt_tasks/hotpotqa": -45.5536003112793
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8696,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10310523211956024,
        "ag_news": 0.13139547407627106,
        "amazon_polarity": 0.13224418461322784,
        "cnn_dailymail/3.0.0": 0.14835920929908752,
        "common_gen": 0.12166431546211243,
        "cos_e/v1.11": 0.12199122458696365,
        "glue/mrpc": 0.12463948130607605,
        "kilt_tasks/hotpotqa": 0.11660093069076538
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22104,
        "ag_news": 23104,
        "amazon_polarity": 22280,
        "cnn_dailymail/3.0.0": 22992,
        "common_gen": 22224,
        "cos_e/v1.11": 22674,
        "glue/mrpc": 22456,
        "kilt_tasks/hotpotqa": 22616
      },
      "step": 1410
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -160.58416748046875,
        "ag_news": 66.52978515625,
        "amazon_polarity": 72.40769958496094,
        "cnn_dailymail/3.0.0": 177.980224609375,
        "common_gen": -8.999777793884277,
        "cos_e/v1.11": -1.413588523864746,
        "glue/mrpc": 11.723970413208008,
        "kilt_tasks/hotpotqa": -48.92355728149414
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9507,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1034221202135086,
        "ag_news": 0.1315881758928299,
        "amazon_polarity": 0.1324119120836258,
        "cnn_dailymail/3.0.0": 0.14812466502189636,
        "common_gen": 0.12145184725522995,
        "cos_e/v1.11": 0.12243332713842392,
        "glue/mrpc": 0.12415196746587753,
        "kilt_tasks/hotpotqa": 0.11641596257686615
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22280,
        "ag_news": 23272,
        "amazon_polarity": 22392,
        "cnn_dailymail/3.0.0": 23128,
        "common_gen": 22400,
        "cos_e/v1.11": 22818,
        "glue/mrpc": 22616,
        "kilt_tasks/hotpotqa": 22824
      },
      "step": 1420
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.5666046142578,
        "ag_news": 66.52006530761719,
        "amazon_polarity": 72.05791473388672,
        "cnn_dailymail/3.0.0": 176.526611328125,
        "common_gen": -12.082481384277344,
        "cos_e/v1.11": -2.0175201892852783,
        "glue/mrpc": 9.943754196166992,
        "kilt_tasks/hotpotqa": -48.141990661621094
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9691,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10329177975654602,
        "ag_news": 0.1317255198955536,
        "amazon_polarity": 0.1324995756149292,
        "cnn_dailymail/3.0.0": 0.1479918658733368,
        "common_gen": 0.12121795117855072,
        "cos_e/v1.11": 0.1225147619843483,
        "glue/mrpc": 0.12407413125038147,
        "kilt_tasks/hotpotqa": 0.11668449640274048
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22480,
        "ag_news": 23424,
        "amazon_polarity": 22552,
        "cnn_dailymail/3.0.0": 23296,
        "common_gen": 22560,
        "cos_e/v1.11": 22970,
        "glue/mrpc": 22768,
        "kilt_tasks/hotpotqa": 22960
      },
      "step": 1430
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -166.8729705810547,
        "ag_news": 66.49688720703125,
        "amazon_polarity": 72.22705078125,
        "cnn_dailymail/3.0.0": 178.96096801757812,
        "common_gen": -12.664617538452148,
        "cos_e/v1.11": 3.9559922218322754,
        "glue/mrpc": 6.451529026031494,
        "kilt_tasks/hotpotqa": -48.007728576660156
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8458,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10297152400016785,
        "ag_news": 0.13166087865829468,
        "amazon_polarity": 0.13245871663093567,
        "cnn_dailymail/3.0.0": 0.14824357628822327,
        "common_gen": 0.12112192809581757,
        "cos_e/v1.11": 0.12326172739267349,
        "glue/mrpc": 0.12358628958463669,
        "kilt_tasks/hotpotqa": 0.11669545620679855
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22664,
        "ag_news": 23560,
        "amazon_polarity": 22792,
        "cnn_dailymail/3.0.0": 23440,
        "common_gen": 22664,
        "cos_e/v1.11": 23122,
        "glue/mrpc": 22944,
        "kilt_tasks/hotpotqa": 23104
      },
      "step": 1440
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -168.180419921875,
        "ag_news": 66.44412231445312,
        "amazon_polarity": 72.69310760498047,
        "cnn_dailymail/3.0.0": 176.54644775390625,
        "common_gen": -13.130577087402344,
        "cos_e/v1.11": -0.7857004404067993,
        "glue/mrpc": 7.4749674797058105,
        "kilt_tasks/hotpotqa": -49.45448303222656
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9553,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10302130877971649,
        "ag_news": 0.1317872554063797,
        "amazon_polarity": 0.13265541195869446,
        "cnn_dailymail/3.0.0": 0.14795762300491333,
        "common_gen": 0.1212201938033104,
        "cos_e/v1.11": 0.12280172854661942,
        "glue/mrpc": 0.12387163937091827,
        "kilt_tasks/hotpotqa": 0.11668482422828674
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22784,
        "ag_news": 23688,
        "amazon_polarity": 23008,
        "cnn_dailymail/3.0.0": 23656,
        "common_gen": 22848,
        "cos_e/v1.11": 23250,
        "glue/mrpc": 23104,
        "kilt_tasks/hotpotqa": 23232
      },
      "step": 1450
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -169.60214233398438,
        "ag_news": 66.34989166259766,
        "amazon_polarity": 72.51435852050781,
        "cnn_dailymail/3.0.0": 173.3652801513672,
        "common_gen": -12.575702667236328,
        "cos_e/v1.11": -1.6593586206436157,
        "glue/mrpc": 8.370377540588379,
        "kilt_tasks/hotpotqa": -51.54270935058594
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9418,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10302653908729553,
        "ag_news": 0.13186658918857574,
        "amazon_polarity": 0.13272057473659515,
        "cnn_dailymail/3.0.0": 0.1475103497505188,
        "common_gen": 0.12141008675098419,
        "cos_e/v1.11": 0.12280496209859848,
        "glue/mrpc": 0.12410079687833786,
        "kilt_tasks/hotpotqa": 0.11656001210212708
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22936,
        "ag_news": 23864,
        "amazon_polarity": 23176,
        "cnn_dailymail/3.0.0": 23760,
        "common_gen": 23032,
        "cos_e/v1.11": 23466,
        "glue/mrpc": 23280,
        "kilt_tasks/hotpotqa": 23336
      },
      "step": 1460
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -168.82977294921875,
        "ag_news": 66.33302307128906,
        "amazon_polarity": 72.95474243164062,
        "cnn_dailymail/3.0.0": 170.7496337890625,
        "common_gen": -9.710936546325684,
        "cos_e/v1.11": -2.2437856197357178,
        "glue/mrpc": 1.2488356828689575,
        "kilt_tasks/hotpotqa": -53.45623779296875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0087,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10329423099756241,
        "ag_news": 0.13199087977409363,
        "amazon_polarity": 0.13290615379810333,
        "cnn_dailymail/3.0.0": 0.14719334244728088,
        "common_gen": 0.12192423641681671,
        "cos_e/v1.11": 0.12287745624780655,
        "glue/mrpc": 0.1233258917927742,
        "kilt_tasks/hotpotqa": 0.11648785322904587
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23104,
        "ag_news": 23976,
        "amazon_polarity": 23352,
        "cnn_dailymail/3.0.0": 23952,
        "common_gen": 23176,
        "cos_e/v1.11": 23618,
        "glue/mrpc": 23464,
        "kilt_tasks/hotpotqa": 23488
      },
      "step": 1470
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -171.41232299804688,
        "ag_news": 66.29042053222656,
        "amazon_polarity": 72.95152282714844,
        "cnn_dailymail/3.0.0": 173.22073364257812,
        "common_gen": -11.562307357788086,
        "cos_e/v1.11": -6.2623467445373535,
        "glue/mrpc": -2.4760446548461914,
        "kilt_tasks/hotpotqa": -54.45261764526367
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0498,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10321389883756638,
        "ag_news": 0.13212792575359344,
        "amazon_polarity": 0.13304653763771057,
        "cnn_dailymail/3.0.0": 0.1476782113313675,
        "common_gen": 0.12185399234294891,
        "cos_e/v1.11": 0.122527115046978,
        "glue/mrpc": 0.1230103000998497,
        "kilt_tasks/hotpotqa": 0.11654208600521088
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23216,
        "ag_news": 24176,
        "amazon_polarity": 23488,
        "cnn_dailymail/3.0.0": 24152,
        "common_gen": 23272,
        "cos_e/v1.11": 23826,
        "glue/mrpc": 23616,
        "kilt_tasks/hotpotqa": 23664
      },
      "step": 1480
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -168.62303161621094,
        "ag_news": 66.32290649414062,
        "amazon_polarity": 72.73834991455078,
        "cnn_dailymail/3.0.0": 169.99986267089844,
        "common_gen": -13.048190116882324,
        "cos_e/v1.11": -2.004319190979004,
        "glue/mrpc": -2.586663007736206,
        "kilt_tasks/hotpotqa": -54.445526123046875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.939,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1035672053694725,
        "ag_news": 0.1320938915014267,
        "amazon_polarity": 0.13297531008720398,
        "cnn_dailymail/3.0.0": 0.1470879465341568,
        "common_gen": 0.12166401743888855,
        "cos_e/v1.11": 0.12306396663188934,
        "glue/mrpc": 0.12298975139856339,
        "kilt_tasks/hotpotqa": 0.11655783653259277
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23344,
        "ag_news": 24312,
        "amazon_polarity": 23648,
        "cnn_dailymail/3.0.0": 24304,
        "common_gen": 23456,
        "cos_e/v1.11": 23978,
        "glue/mrpc": 23824,
        "kilt_tasks/hotpotqa": 23824
      },
      "step": 1490
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -166.96963500976562,
        "ag_news": 66.13874816894531,
        "amazon_polarity": 72.67028045654297,
        "cnn_dailymail/3.0.0": 172.33575439453125,
        "common_gen": -15.971611022949219,
        "cos_e/v1.11": 1.1690669059753418,
        "glue/mrpc": -4.922305107116699,
        "kilt_tasks/hotpotqa": -51.81578826904297
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0323,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10375255346298218,
        "ag_news": 0.1319732815027237,
        "amazon_polarity": 0.13286690413951874,
        "cnn_dailymail/3.0.0": 0.1472844034433365,
        "common_gen": 0.12124277651309967,
        "cos_e/v1.11": 0.12340764701366425,
        "glue/mrpc": 0.12263387441635132,
        "kilt_tasks/hotpotqa": 0.11683863401412964
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23464,
        "ag_news": 24472,
        "amazon_polarity": 23776,
        "cnn_dailymail/3.0.0": 24464,
        "common_gen": 23640,
        "cos_e/v1.11": 24146,
        "glue/mrpc": 23992,
        "kilt_tasks/hotpotqa": 24016
      },
      "step": 1500
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.1843,
      "eval_samples_per_second": 86.831,
      "eval_steps_per_second": 5.427,
      "step": 1500
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.99285888671875,
        "ag_news": 66.19795227050781,
        "amazon_polarity": 72.44720458984375,
        "cnn_dailymail/3.0.0": 172.3619384765625,
        "common_gen": -12.235631942749023,
        "cos_e/v1.11": 0.5673966407775879,
        "glue/mrpc": -0.32347846031188965,
        "kilt_tasks/hotpotqa": -53.82090377807617
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8235,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10402865707874298,
        "ag_news": 0.13182373344898224,
        "amazon_polarity": 0.13267479836940765,
        "cnn_dailymail/3.0.0": 0.1470591127872467,
        "common_gen": 0.1215985044836998,
        "cos_e/v1.11": 0.12321129441261292,
        "glue/mrpc": 0.12309837341308594,
        "kilt_tasks/hotpotqa": 0.11650549620389938
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23608,
        "ag_news": 24696,
        "amazon_polarity": 23920,
        "cnn_dailymail/3.0.0": 24576,
        "common_gen": 23792,
        "cos_e/v1.11": 24354,
        "glue/mrpc": 24160,
        "kilt_tasks/hotpotqa": 24144
      },
      "step": 1510
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -162.0457000732422,
        "ag_news": 66.16850280761719,
        "amazon_polarity": 72.46450805664062,
        "cnn_dailymail/3.0.0": 172.05540466308594,
        "common_gen": -15.827159881591797,
        "cos_e/v1.11": -2.060605764389038,
        "glue/mrpc": -2.8824753761291504,
        "kilt_tasks/hotpotqa": -54.475826263427734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8776,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10440674424171448,
        "ag_news": 0.13193339109420776,
        "amazon_polarity": 0.1327887624502182,
        "cnn_dailymail/3.0.0": 0.147086963057518,
        "common_gen": 0.12128780037164688,
        "cos_e/v1.11": 0.12301265448331833,
        "glue/mrpc": 0.12290898710489273,
        "kilt_tasks/hotpotqa": 0.11657465249300003
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23728,
        "ag_news": 24920,
        "amazon_polarity": 24096,
        "cnn_dailymail/3.0.0": 24712,
        "common_gen": 23904,
        "cos_e/v1.11": 24554,
        "glue/mrpc": 24328,
        "kilt_tasks/hotpotqa": 24288
      },
      "step": 1520
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -166.75729370117188,
        "ag_news": 66.13821411132812,
        "amazon_polarity": 72.425048828125,
        "cnn_dailymail/3.0.0": 170.53712463378906,
        "common_gen": -15.771646499633789,
        "cos_e/v1.11": 1.2800464630126953,
        "glue/mrpc": -4.520363807678223,
        "kilt_tasks/hotpotqa": -56.844242095947266
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9101,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10405095666646957,
        "ag_news": 0.13201360404491425,
        "amazon_polarity": 0.13286545872688293,
        "cnn_dailymail/3.0.0": 0.14690040051937103,
        "common_gen": 0.12140531092882156,
        "cos_e/v1.11": 0.1235404759645462,
        "glue/mrpc": 0.12280994653701782,
        "kilt_tasks/hotpotqa": 0.11641383916139603
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23912,
        "ag_news": 25088,
        "amazon_polarity": 24232,
        "cnn_dailymail/3.0.0": 24832,
        "common_gen": 24096,
        "cos_e/v1.11": 24754,
        "glue/mrpc": 24456,
        "kilt_tasks/hotpotqa": 24440
      },
      "step": 1530
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -170.67266845703125,
        "ag_news": 66.0662612915039,
        "amazon_polarity": 72.40738677978516,
        "cnn_dailymail/3.0.0": 171.9764404296875,
        "common_gen": -15.661282539367676,
        "cos_e/v1.11": 3.1118526458740234,
        "glue/mrpc": -4.744553565979004,
        "kilt_tasks/hotpotqa": -58.47404479980469
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9779,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10371940582990646,
        "ag_news": 0.13200728595256805,
        "amazon_polarity": 0.13286368548870087,
        "cnn_dailymail/3.0.0": 0.14706926047801971,
        "common_gen": 0.12145490199327469,
        "cos_e/v1.11": 0.12380101531744003,
        "glue/mrpc": 0.12281367927789688,
        "kilt_tasks/hotpotqa": 0.11627085506916046
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24072,
        "ag_news": 25248,
        "amazon_polarity": 24392,
        "cnn_dailymail/3.0.0": 25008,
        "common_gen": 24192,
        "cos_e/v1.11": 24994,
        "glue/mrpc": 24592,
        "kilt_tasks/hotpotqa": 24592
      },
      "step": 1540
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -166.277099609375,
        "ag_news": 66.05525970458984,
        "amazon_polarity": 72.60442352294922,
        "cnn_dailymail/3.0.0": 171.57241821289062,
        "common_gen": -17.706127166748047,
        "cos_e/v1.11": 3.7625904083251953,
        "glue/mrpc": -5.647054195404053,
        "kilt_tasks/hotpotqa": -60.585914611816406
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0183,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1042574867606163,
        "ag_news": 0.13199831545352936,
        "amazon_polarity": 0.13287998735904694,
        "cnn_dailymail/3.0.0": 0.14694947004318237,
        "common_gen": 0.1212284043431282,
        "cos_e/v1.11": 0.1239013746380806,
        "glue/mrpc": 0.1227225661277771,
        "kilt_tasks/hotpotqa": 0.1160624548792839
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24192,
        "ag_news": 25408,
        "amazon_polarity": 24536,
        "cnn_dailymail/3.0.0": 25152,
        "common_gen": 24392,
        "cos_e/v1.11": 25178,
        "glue/mrpc": 24720,
        "kilt_tasks/hotpotqa": 24792
      },
      "step": 1550
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -169.9683380126953,
        "ag_news": 66.24180603027344,
        "amazon_polarity": 72.70411682128906,
        "cnn_dailymail/3.0.0": 169.0416259765625,
        "common_gen": -14.332352638244629,
        "cos_e/v1.11": 3.0433874130249023,
        "glue/mrpc": -6.086410999298096,
        "kilt_tasks/hotpotqa": -60.98897933959961
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9735,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10398292541503906,
        "ag_news": 0.13206882774829865,
        "amazon_polarity": 0.13293646275997162,
        "cnn_dailymail/3.0.0": 0.1465732604265213,
        "common_gen": 0.12171822041273117,
        "cos_e/v1.11": 0.12387886643409729,
        "glue/mrpc": 0.1227388083934784,
        "kilt_tasks/hotpotqa": 0.1161026880145073
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24400,
        "ag_news": 25584,
        "amazon_polarity": 24680,
        "cnn_dailymail/3.0.0": 25296,
        "common_gen": 24496,
        "cos_e/v1.11": 25330,
        "glue/mrpc": 24880,
        "kilt_tasks/hotpotqa": 24984
      },
      "step": 1560
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -167.1996307373047,
        "ag_news": 66.0982894897461,
        "amazon_polarity": 72.58587646484375,
        "cnn_dailymail/3.0.0": 167.1952667236328,
        "common_gen": -10.079622268676758,
        "cos_e/v1.11": 3.794668436050415,
        "glue/mrpc": -3.6928186416625977,
        "kilt_tasks/hotpotqa": -64.0436019897461
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.7823,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.104279525578022,
        "ag_news": 0.1319573074579239,
        "amazon_polarity": 0.1328248530626297,
        "cnn_dailymail/3.0.0": 0.14614923298358917,
        "common_gen": 0.12218794971704483,
        "cos_e/v1.11": 0.1239112913608551,
        "glue/mrpc": 0.12297823280096054,
        "kilt_tasks/hotpotqa": 0.11571171879768372
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24576,
        "ag_news": 25744,
        "amazon_polarity": 24928,
        "cnn_dailymail/3.0.0": 25376,
        "common_gen": 24664,
        "cos_e/v1.11": 25458,
        "glue/mrpc": 25040,
        "kilt_tasks/hotpotqa": 25144
      },
      "step": 1570
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -168.63943481445312,
        "ag_news": 66.01493835449219,
        "amazon_polarity": 72.52490997314453,
        "cnn_dailymail/3.0.0": 168.5387725830078,
        "common_gen": -11.227007865905762,
        "cos_e/v1.11": 3.7560858726501465,
        "glue/mrpc": -2.1720404624938965,
        "kilt_tasks/hotpotqa": -64.86145782470703
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8384,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10419211536645889,
        "ag_news": 0.13192883133888245,
        "amazon_polarity": 0.13279642164707184,
        "cnn_dailymail/3.0.0": 0.14628079533576965,
        "common_gen": 0.12206040322780609,
        "cos_e/v1.11": 0.1239146739244461,
        "glue/mrpc": 0.1231776550412178,
        "kilt_tasks/hotpotqa": 0.11564912647008896
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24744,
        "ag_news": 25912,
        "amazon_polarity": 25160,
        "cnn_dailymail/3.0.0": 25448,
        "common_gen": 24768,
        "cos_e/v1.11": 25618,
        "glue/mrpc": 25216,
        "kilt_tasks/hotpotqa": 25344
      },
      "step": 1580
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -170.28720092773438,
        "ag_news": 66.04216766357422,
        "amazon_polarity": 72.42578887939453,
        "cnn_dailymail/3.0.0": 171.01210021972656,
        "common_gen": -9.115676879882812,
        "cos_e/v1.11": 3.6606979370117188,
        "glue/mrpc": -2.570094108581543,
        "kilt_tasks/hotpotqa": -65.4107666015625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9302,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10404805094003677,
        "ag_news": 0.13187028467655182,
        "amazon_polarity": 0.13271795213222504,
        "cnn_dailymail/3.0.0": 0.14652813971042633,
        "common_gen": 0.12229131907224655,
        "cos_e/v1.11": 0.12386874854564667,
        "glue/mrpc": 0.12309692800045013,
        "kilt_tasks/hotpotqa": 0.11557862907648087
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24888,
        "ag_news": 26112,
        "amazon_polarity": 25368,
        "cnn_dailymail/3.0.0": 25568,
        "common_gen": 24856,
        "cos_e/v1.11": 25826,
        "glue/mrpc": 25344,
        "kilt_tasks/hotpotqa": 25528
      },
      "step": 1590
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -173.3771514892578,
        "ag_news": 66.03446197509766,
        "amazon_polarity": 72.3351058959961,
        "cnn_dailymail/3.0.0": 168.99729919433594,
        "common_gen": -9.713451385498047,
        "cos_e/v1.11": 2.305600881576538,
        "glue/mrpc": -6.001307487487793,
        "kilt_tasks/hotpotqa": -64.98018646240234
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9382,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10391687601804733,
        "ag_news": 0.13201315701007843,
        "amazon_polarity": 0.13284806907176971,
        "cnn_dailymail/3.0.0": 0.14634448289871216,
        "common_gen": 0.12238021194934845,
        "cos_e/v1.11": 0.12386000156402588,
        "glue/mrpc": 0.12283533811569214,
        "kilt_tasks/hotpotqa": 0.1158018410205841
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25080,
        "ag_news": 26344,
        "amazon_polarity": 25504,
        "cnn_dailymail/3.0.0": 25704,
        "common_gen": 24984,
        "cos_e/v1.11": 25986,
        "glue/mrpc": 25504,
        "kilt_tasks/hotpotqa": 25664
      },
      "step": 1600
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1897,
      "eval_samples_per_second": 84.365,
      "eval_steps_per_second": 5.273,
      "step": 1600
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -173.33615112304688,
        "ag_news": 65.98938751220703,
        "amazon_polarity": 72.601806640625,
        "cnn_dailymail/3.0.0": 170.3040008544922,
        "common_gen": -12.821453094482422,
        "cos_e/v1.11": 2.228318214416504,
        "glue/mrpc": -7.359309196472168,
        "kilt_tasks/hotpotqa": -64.44310760498047
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0276,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10400957614183426,
        "ag_news": 0.13202215731143951,
        "amazon_polarity": 0.13289585709571838,
        "cnn_dailymail/3.0.0": 0.14650538563728333,
        "common_gen": 0.12204397469758987,
        "cos_e/v1.11": 0.12388886511325836,
        "glue/mrpc": 0.12271033972501755,
        "kilt_tasks/hotpotqa": 0.11592379957437515
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25272,
        "ag_news": 26472,
        "amazon_polarity": 25648,
        "cnn_dailymail/3.0.0": 25840,
        "common_gen": 25216,
        "cos_e/v1.11": 26186,
        "glue/mrpc": 25600,
        "kilt_tasks/hotpotqa": 25816
      },
      "step": 1610
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -174.14788818359375,
        "ag_news": 65.99190521240234,
        "amazon_polarity": 72.81849670410156,
        "cnn_dailymail/3.0.0": 172.8867950439453,
        "common_gen": -14.701014518737793,
        "cos_e/v1.11": -2.688478708267212,
        "glue/mrpc": -7.63775634765625,
        "kilt_tasks/hotpotqa": -63.7131462097168
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.921,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10403357446193695,
        "ag_news": 0.1320628970861435,
        "amazon_polarity": 0.13296248018741608,
        "cnn_dailymail/3.0.0": 0.14688041806221008,
        "common_gen": 0.12188287824392319,
        "cos_e/v1.11": 0.12334670126438141,
        "glue/mrpc": 0.1227414533495903,
        "kilt_tasks/hotpotqa": 0.11608966439962387
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25480,
        "ag_news": 26640,
        "amazon_polarity": 25808,
        "cnn_dailymail/3.0.0": 25952,
        "common_gen": 25360,
        "cos_e/v1.11": 26378,
        "glue/mrpc": 25764,
        "kilt_tasks/hotpotqa": 25944
      },
      "step": 1620
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -176.7567596435547,
        "ag_news": 65.93197631835938,
        "amazon_polarity": 72.71881866455078,
        "cnn_dailymail/3.0.0": 174.90673828125,
        "common_gen": -11.73462963104248,
        "cos_e/v1.11": -0.21286329627037048,
        "glue/mrpc": -4.2617645263671875,
        "kilt_tasks/hotpotqa": -62.4143180847168
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9744,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10369779914617538,
        "ag_news": 0.13187275826931,
        "amazon_polarity": 0.1327630579471588,
        "cnn_dailymail/3.0.0": 0.14692401885986328,
        "common_gen": 0.12210286408662796,
        "cos_e/v1.11": 0.12350477278232574,
        "glue/mrpc": 0.12301028519868851,
        "kilt_tasks/hotpotqa": 0.11612444370985031
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25648,
        "ag_news": 26856,
        "amazon_polarity": 25960,
        "cnn_dailymail/3.0.0": 26112,
        "common_gen": 25520,
        "cos_e/v1.11": 26490,
        "glue/mrpc": 25908,
        "kilt_tasks/hotpotqa": 26112
      },
      "step": 1630
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -179.18719482421875,
        "ag_news": 65.99244689941406,
        "amazon_polarity": 72.63478088378906,
        "cnn_dailymail/3.0.0": 179.0351104736328,
        "common_gen": -7.397715091705322,
        "cos_e/v1.11": -0.6066528558731079,
        "glue/mrpc": -2.561880350112915,
        "kilt_tasks/hotpotqa": -63.17245864868164
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.943,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10341190546751022,
        "ag_news": 0.13173650205135345,
        "amazon_polarity": 0.1326042264699936,
        "cnn_dailymail/3.0.0": 0.14731551706790924,
        "common_gen": 0.12252169847488403,
        "cos_e/v1.11": 0.12334638833999634,
        "glue/mrpc": 0.1231083795428276,
        "kilt_tasks/hotpotqa": 0.11595553159713745
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25816,
        "ag_news": 27032,
        "amazon_polarity": 26160,
        "cnn_dailymail/3.0.0": 26280,
        "common_gen": 25688,
        "cos_e/v1.11": 26642,
        "glue/mrpc": 26036,
        "kilt_tasks/hotpotqa": 26232
      },
      "step": 1640
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -181.50807189941406,
        "ag_news": 65.99870300292969,
        "amazon_polarity": 72.5439682006836,
        "cnn_dailymail/3.0.0": 178.32752990722656,
        "common_gen": -2.4575119018554688,
        "cos_e/v1.11": 2.911223888397217,
        "glue/mrpc": -5.280731678009033,
        "kilt_tasks/hotpotqa": -60.351356506347656
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0283,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1031675636768341,
        "ag_news": 0.13163018226623535,
        "amazon_polarity": 0.1324819028377533,
        "cnn_dailymail/3.0.0": 0.14704333245754242,
        "common_gen": 0.12304607778787613,
        "cos_e/v1.11": 0.1236984059214592,
        "glue/mrpc": 0.12270442396402359,
        "kilt_tasks/hotpotqa": 0.11622819304466248
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25952,
        "ag_news": 27160,
        "amazon_polarity": 26336,
        "cnn_dailymail/3.0.0": 26456,
        "common_gen": 25840,
        "cos_e/v1.11": 26858,
        "glue/mrpc": 26172,
        "kilt_tasks/hotpotqa": 26392
      },
      "step": 1650
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -181.35025024414062,
        "ag_news": 65.81405639648438,
        "amazon_polarity": 72.51187896728516,
        "cnn_dailymail/3.0.0": 180.8894805908203,
        "common_gen": 2.4102413654327393,
        "cos_e/v1.11": -1.5302798748016357,
        "glue/mrpc": -5.8779616355896,
        "kilt_tasks/hotpotqa": -59.38402557373047
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0353,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10319802165031433,
        "ag_news": 0.13152875006198883,
        "amazon_polarity": 0.13239708542823792,
        "cnn_dailymail/3.0.0": 0.1472783088684082,
        "common_gen": 0.12358775734901428,
        "cos_e/v1.11": 0.12311048060655594,
        "glue/mrpc": 0.12258605659008026,
        "kilt_tasks/hotpotqa": 0.11631342768669128
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26064,
        "ag_news": 27336,
        "amazon_polarity": 26448,
        "cnn_dailymail/3.0.0": 26664,
        "common_gen": 26024,
        "cos_e/v1.11": 27018,
        "glue/mrpc": 26332,
        "kilt_tasks/hotpotqa": 26560
      },
      "step": 1660
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -179.74539184570312,
        "ag_news": 65.90016174316406,
        "amazon_polarity": 72.53953552246094,
        "cnn_dailymail/3.0.0": 181.68878173828125,
        "common_gen": 1.1205123662948608,
        "cos_e/v1.11": -2.9879212379455566,
        "glue/mrpc": -7.347135066986084,
        "kilt_tasks/hotpotqa": -59.07402801513672
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8891,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10343902558088303,
        "ag_news": 0.13154543936252594,
        "amazon_polarity": 0.13240371644496918,
        "cnn_dailymail/3.0.0": 0.14735034108161926,
        "common_gen": 0.12345996499061584,
        "cos_e/v1.11": 0.12296439707279205,
        "glue/mrpc": 0.12244076281785965,
        "kilt_tasks/hotpotqa": 0.11639626324176788
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26208,
        "ag_news": 27544,
        "amazon_polarity": 26648,
        "cnn_dailymail/3.0.0": 26792,
        "common_gen": 26128,
        "cos_e/v1.11": 27210,
        "glue/mrpc": 26476,
        "kilt_tasks/hotpotqa": 26720
      },
      "step": 1670
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -179.92283630371094,
        "ag_news": 65.9386215209961,
        "amazon_polarity": 72.45020294189453,
        "cnn_dailymail/3.0.0": 181.54953002929688,
        "common_gen": -0.5578485131263733,
        "cos_e/v1.11": -3.7487616539001465,
        "glue/mrpc": -7.756293773651123,
        "kilt_tasks/hotpotqa": -60.71524429321289
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0629,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10353969037532806,
        "ag_news": 0.131607785820961,
        "amazon_polarity": 0.13244737684726715,
        "cnn_dailymail/3.0.0": 0.14734503626823425,
        "common_gen": 0.12333477288484573,
        "cos_e/v1.11": 0.12295123189687729,
        "glue/mrpc": 0.12247122824192047,
        "kilt_tasks/hotpotqa": 0.11630278080701828
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26336,
        "ag_news": 27632,
        "amazon_polarity": 26808,
        "cnn_dailymail/3.0.0": 26976,
        "common_gen": 26352,
        "cos_e/v1.11": 27370,
        "glue/mrpc": 26604,
        "kilt_tasks/hotpotqa": 26928
      },
      "step": 1680
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -180.99710083007812,
        "ag_news": 65.88385772705078,
        "amazon_polarity": 72.46831512451172,
        "cnn_dailymail/3.0.0": 180.11082458496094,
        "common_gen": -1.0390263795852661,
        "cos_e/v1.11": -1.9090567827224731,
        "glue/mrpc": -8.767496109008789,
        "kilt_tasks/hotpotqa": -59.977333068847656
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8738,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10351033508777618,
        "ag_news": 0.13160808384418488,
        "amazon_polarity": 0.13245461881160736,
        "cnn_dailymail/3.0.0": 0.14709784090518951,
        "common_gen": 0.12330744415521622,
        "cos_e/v1.11": 0.12320307642221451,
        "glue/mrpc": 0.1223834827542305,
        "kilt_tasks/hotpotqa": 0.11643509566783905
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26488,
        "ag_news": 27776,
        "amazon_polarity": 26976,
        "cnn_dailymail/3.0.0": 27136,
        "common_gen": 26496,
        "cos_e/v1.11": 27498,
        "glue/mrpc": 26788,
        "kilt_tasks/hotpotqa": 27128
      },
      "step": 1690
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -181.0488739013672,
        "ag_news": 66.09346008300781,
        "amazon_polarity": 73.15289306640625,
        "cnn_dailymail/3.0.0": 177.4882049560547,
        "common_gen": 0.7569446563720703,
        "cos_e/v1.11": -9.595122337341309,
        "glue/mrpc": -6.241494178771973,
        "kilt_tasks/hotpotqa": -66.46966552734375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8895,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10370808839797974,
        "ag_news": 0.1318008154630661,
        "amazon_polarity": 0.13270728290081024,
        "cnn_dailymail/3.0.0": 0.146860733628273,
        "common_gen": 0.12370174378156662,
        "cos_e/v1.11": 0.1224653497338295,
        "glue/mrpc": 0.12286452203989029,
        "kilt_tasks/hotpotqa": 0.11589142680168152
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26656,
        "ag_news": 27968,
        "amazon_polarity": 27128,
        "cnn_dailymail/3.0.0": 27312,
        "common_gen": 26672,
        "cos_e/v1.11": 27634,
        "glue/mrpc": 26948,
        "kilt_tasks/hotpotqa": 27248
      },
      "step": 1700
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1981,
      "eval_samples_per_second": 80.747,
      "eval_steps_per_second": 5.047,
      "step": 1700
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -184.3194122314453,
        "ag_news": 66.0786361694336,
        "amazon_polarity": 73.11966705322266,
        "cnn_dailymail/3.0.0": 178.4562530517578,
        "common_gen": 0.810443639755249,
        "cos_e/v1.11": -8.232566833496094,
        "glue/mrpc": -8.448813438415527,
        "kilt_tasks/hotpotqa": -69.17445373535156
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8802,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1034996286034584,
        "ag_news": 0.13185857236385345,
        "amazon_polarity": 0.1327604204416275,
        "cnn_dailymail/3.0.0": 0.14701877534389496,
        "common_gen": 0.12378693372011185,
        "cos_e/v1.11": 0.12270858138799667,
        "glue/mrpc": 0.12268289923667908,
        "kilt_tasks/hotpotqa": 0.11568419635295868
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26760,
        "ag_news": 28176,
        "amazon_polarity": 27312,
        "cnn_dailymail/3.0.0": 27456,
        "common_gen": 26816,
        "cos_e/v1.11": 27786,
        "glue/mrpc": 27100,
        "kilt_tasks/hotpotqa": 27440
      },
      "step": 1710
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -184.22621154785156,
        "ag_news": 66.07593536376953,
        "amazon_polarity": 72.87090301513672,
        "cnn_dailymail/3.0.0": 178.28585815429688,
        "common_gen": 1.9980368614196777,
        "cos_e/v1.11": -7.505634307861328,
        "glue/mrpc": -6.5891242027282715,
        "kilt_tasks/hotpotqa": -67.85111999511719
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9941,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10351001471281052,
        "ag_news": 0.13176725804805756,
        "amazon_polarity": 0.13263435661792755,
        "cnn_dailymail/3.0.0": 0.14684683084487915,
        "common_gen": 0.1238660216331482,
        "cos_e/v1.11": 0.12273552268743515,
        "glue/mrpc": 0.12284409254789352,
        "kilt_tasks/hotpotqa": 0.11579587310552597
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26888,
        "ag_news": 28392,
        "amazon_polarity": 27504,
        "cnn_dailymail/3.0.0": 27688,
        "common_gen": 27000,
        "cos_e/v1.11": 27898,
        "glue/mrpc": 27212,
        "kilt_tasks/hotpotqa": 27544
      },
      "step": 1720
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -182.5996856689453,
        "ag_news": 65.73350524902344,
        "amazon_polarity": 72.72856903076172,
        "cnn_dailymail/3.0.0": 179.7879638671875,
        "common_gen": 3.681286096572876,
        "cos_e/v1.11": -4.785404682159424,
        "glue/mrpc": -4.079402923583984,
        "kilt_tasks/hotpotqa": -65.11190795898438
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9393,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10358070582151413,
        "ag_news": 0.1315164715051651,
        "amazon_polarity": 0.13240490853786469,
        "cnn_dailymail/3.0.0": 0.14678195118904114,
        "common_gen": 0.12389357388019562,
        "cos_e/v1.11": 0.12288857251405716,
        "glue/mrpc": 0.12297205626964569,
        "kilt_tasks/hotpotqa": 0.1159617155790329
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27064,
        "ag_news": 28520,
        "amazon_polarity": 27632,
        "cnn_dailymail/3.0.0": 27824,
        "common_gen": 27208,
        "cos_e/v1.11": 28074,
        "glue/mrpc": 27412,
        "kilt_tasks/hotpotqa": 27672
      },
      "step": 1730
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -185.62570190429688,
        "ag_news": 65.71257781982422,
        "amazon_polarity": 72.75176239013672,
        "cnn_dailymail/3.0.0": 179.4001007080078,
        "common_gen": 3.807292938232422,
        "cos_e/v1.11": -2.154109477996826,
        "glue/mrpc": -2.68302583694458,
        "kilt_tasks/hotpotqa": -63.40530014038086
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9158,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10330408066511154,
        "ag_news": 0.13145355880260468,
        "amazon_polarity": 0.13234463334083557,
        "cnn_dailymail/3.0.0": 0.1466139256954193,
        "common_gen": 0.12387292087078094,
        "cos_e/v1.11": 0.12316657602787018,
        "glue/mrpc": 0.12310411036014557,
        "kilt_tasks/hotpotqa": 0.11614017933607101
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27248,
        "ag_news": 28704,
        "amazon_polarity": 27776,
        "cnn_dailymail/3.0.0": 27968,
        "common_gen": 27296,
        "cos_e/v1.11": 28282,
        "glue/mrpc": 27524,
        "kilt_tasks/hotpotqa": 27888
      },
      "step": 1740
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -185.0228729248047,
        "ag_news": 65.69038391113281,
        "amazon_polarity": 72.75263214111328,
        "cnn_dailymail/3.0.0": 176.87005615234375,
        "common_gen": 3.114123582839966,
        "cos_e/v1.11": -0.6577793955802917,
        "glue/mrpc": -4.830183982849121,
        "kilt_tasks/hotpotqa": -64.65864562988281
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.102,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10348234325647354,
        "ag_news": 0.13151198625564575,
        "amazon_polarity": 0.13240382075309753,
        "cnn_dailymail/3.0.0": 0.14628180861473083,
        "common_gen": 0.12386934459209442,
        "cos_e/v1.11": 0.12342323362827301,
        "glue/mrpc": 0.12293165177106857,
        "kilt_tasks/hotpotqa": 0.1160959005355835
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27392,
        "ag_news": 28824,
        "amazon_polarity": 27928,
        "cnn_dailymail/3.0.0": 28208,
        "common_gen": 27472,
        "cos_e/v1.11": 28474,
        "glue/mrpc": 27652,
        "kilt_tasks/hotpotqa": 28016
      },
      "step": 1750
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -187.31271362304688,
        "ag_news": 65.59747314453125,
        "amazon_polarity": 72.50914764404297,
        "cnn_dailymail/3.0.0": 178.72850036621094,
        "common_gen": 2.009024143218994,
        "cos_e/v1.11": -2.431602716445923,
        "glue/mrpc": -3.200096368789673,
        "kilt_tasks/hotpotqa": -64.95489501953125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8909,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1033327579498291,
        "ag_news": 0.1315079629421234,
        "amazon_polarity": 0.1323782056570053,
        "cnn_dailymail/3.0.0": 0.14650604128837585,
        "common_gen": 0.1237669512629509,
        "cos_e/v1.11": 0.12324384599924088,
        "glue/mrpc": 0.12315353751182556,
        "kilt_tasks/hotpotqa": 0.11611073464155197
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27504,
        "ag_news": 29104,
        "amazon_polarity": 28064,
        "cnn_dailymail/3.0.0": 28376,
        "common_gen": 27568,
        "cos_e/v1.11": 28634,
        "glue/mrpc": 27820,
        "kilt_tasks/hotpotqa": 28176
      },
      "step": 1760
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -187.23004150390625,
        "ag_news": 65.51952362060547,
        "amazon_polarity": 72.38729858398438,
        "cnn_dailymail/3.0.0": 178.880126953125,
        "common_gen": -1.351553201675415,
        "cos_e/v1.11": 2.5815582275390625,
        "glue/mrpc": 0.11290547251701355,
        "kilt_tasks/hotpotqa": -65.31673431396484
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0012,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10334096848964691,
        "ag_news": 0.13140921294689178,
        "amazon_polarity": 0.13227084279060364,
        "cnn_dailymail/3.0.0": 0.14638347923755646,
        "common_gen": 0.12330955266952515,
        "cos_e/v1.11": 0.12377169728279114,
        "glue/mrpc": 0.12348142266273499,
        "kilt_tasks/hotpotqa": 0.11603288352489471
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27680,
        "ag_news": 29272,
        "amazon_polarity": 28216,
        "cnn_dailymail/3.0.0": 28544,
        "common_gen": 27680,
        "cos_e/v1.11": 28810,
        "glue/mrpc": 27964,
        "kilt_tasks/hotpotqa": 28360
      },
      "step": 1770
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -187.6089630126953,
        "ag_news": 65.69629669189453,
        "amazon_polarity": 71.99830627441406,
        "cnn_dailymail/3.0.0": 181.22265625,
        "common_gen": -0.5033792853355408,
        "cos_e/v1.11": 3.9791016578674316,
        "glue/mrpc": 0.09868744015693665,
        "kilt_tasks/hotpotqa": -62.86508560180664
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0334,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10327819734811783,
        "ag_news": 0.13131026923656464,
        "amazon_polarity": 0.13209789991378784,
        "cnn_dailymail/3.0.0": 0.14653009176254272,
        "common_gen": 0.1233171671628952,
        "cos_e/v1.11": 0.12384258210659027,
        "glue/mrpc": 0.12338759005069733,
        "kilt_tasks/hotpotqa": 0.11623631417751312
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27848,
        "ag_news": 29448,
        "amazon_polarity": 28336,
        "cnn_dailymail/3.0.0": 28728,
        "common_gen": 27880,
        "cos_e/v1.11": 28994,
        "glue/mrpc": 28068,
        "kilt_tasks/hotpotqa": 28504
      },
      "step": 1780
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -191.3502655029297,
        "ag_news": 65.6846923828125,
        "amazon_polarity": 71.66212463378906,
        "cnn_dailymail/3.0.0": 180.3446502685547,
        "common_gen": -0.07971924543380737,
        "cos_e/v1.11": 1.01744544506073,
        "glue/mrpc": -0.9926761388778687,
        "kilt_tasks/hotpotqa": -61.93533706665039
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0346,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10305734723806381,
        "ag_news": 0.13140444457530975,
        "amazon_polarity": 0.1321498304605484,
        "cnn_dailymail/3.0.0": 0.14647029340267181,
        "common_gen": 0.12347792088985443,
        "cos_e/v1.11": 0.1236061379313469,
        "glue/mrpc": 0.12337134033441544,
        "kilt_tasks/hotpotqa": 0.1164626032114029
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27992,
        "ag_news": 29576,
        "amazon_polarity": 28536,
        "cnn_dailymail/3.0.0": 28952,
        "common_gen": 27992,
        "cos_e/v1.11": 29178,
        "glue/mrpc": 28196,
        "kilt_tasks/hotpotqa": 28664
      },
      "step": 1790
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -193.5076446533203,
        "ag_news": 65.60462951660156,
        "amazon_polarity": 71.53548431396484,
        "cnn_dailymail/3.0.0": 183.11529541015625,
        "common_gen": -4.067858695983887,
        "cos_e/v1.11": 0.3699305057525635,
        "glue/mrpc": 0.6738965511322021,
        "kilt_tasks/hotpotqa": -61.40705871582031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0531,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10291849076747894,
        "ag_news": 0.13139623403549194,
        "amazon_polarity": 0.13213370740413666,
        "cnn_dailymail/3.0.0": 0.1468118578195572,
        "common_gen": 0.12303706258535385,
        "cos_e/v1.11": 0.12355314940214157,
        "glue/mrpc": 0.12358857691287994,
        "kilt_tasks/hotpotqa": 0.11656099557876587
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28144,
        "ag_news": 29712,
        "amazon_polarity": 28656,
        "cnn_dailymail/3.0.0": 29168,
        "common_gen": 28128,
        "cos_e/v1.11": 29375,
        "glue/mrpc": 28380,
        "kilt_tasks/hotpotqa": 28800
      },
      "step": 1800
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1969,
      "eval_samples_per_second": 81.264,
      "eval_steps_per_second": 5.079,
      "step": 1800
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -191.97415161132812,
        "ag_news": 65.42495727539062,
        "amazon_polarity": 71.57772064208984,
        "cnn_dailymail/3.0.0": 182.37889099121094,
        "common_gen": -6.351611614227295,
        "cos_e/v1.11": 2.438936948776245,
        "glue/mrpc": 3.9734628200531006,
        "kilt_tasks/hotpotqa": -63.496307373046875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9732,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10310643166303635,
        "ag_news": 0.13133640587329865,
        "amazon_polarity": 0.13209907710552216,
        "cnn_dailymail/3.0.0": 0.14662326872348785,
        "common_gen": 0.12276006489992142,
        "cos_e/v1.11": 0.12377933412790298,
        "glue/mrpc": 0.12395813316106796,
        "kilt_tasks/hotpotqa": 0.11633724719285965
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28304,
        "ag_news": 29848,
        "amazon_polarity": 28800,
        "cnn_dailymail/3.0.0": 29400,
        "common_gen": 28280,
        "cos_e/v1.11": 29567,
        "glue/mrpc": 28532,
        "kilt_tasks/hotpotqa": 28912
      },
      "step": 1810
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -192.9707794189453,
        "ag_news": 65.33790588378906,
        "amazon_polarity": 71.57403564453125,
        "cnn_dailymail/3.0.0": 181.59149169921875,
        "common_gen": -7.283156394958496,
        "cos_e/v1.11": 2.256211996078491,
        "glue/mrpc": 3.543362855911255,
        "kilt_tasks/hotpotqa": -66.31906127929688
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9205,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10313793271780014,
        "ag_news": 0.13140182197093964,
        "amazon_polarity": 0.13217313587665558,
        "cnn_dailymail/3.0.0": 0.14655576646327972,
        "common_gen": 0.12274658679962158,
        "cos_e/v1.11": 0.12384990602731705,
        "glue/mrpc": 0.12399954348802567,
        "kilt_tasks/hotpotqa": 0.11613543331623077
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28488,
        "ag_news": 29984,
        "amazon_polarity": 28968,
        "cnn_dailymail/3.0.0": 29568,
        "common_gen": 28432,
        "cos_e/v1.11": 29703,
        "glue/mrpc": 28700,
        "kilt_tasks/hotpotqa": 29080
      },
      "step": 1820
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -193.12351989746094,
        "ag_news": 65.30143737792969,
        "amazon_polarity": 71.49440002441406,
        "cnn_dailymail/3.0.0": 184.7139892578125,
        "common_gen": -7.71336555480957,
        "cos_e/v1.11": 0.2958826720714569,
        "glue/mrpc": 4.981450080871582,
        "kilt_tasks/hotpotqa": -66.86846160888672
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.903,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10315451771020889,
        "ag_news": 0.13135074079036713,
        "amazon_polarity": 0.13211432099342346,
        "cnn_dailymail/3.0.0": 0.14688923954963684,
        "common_gen": 0.12267644703388214,
        "cos_e/v1.11": 0.12359906733036041,
        "glue/mrpc": 0.12414205819368362,
        "kilt_tasks/hotpotqa": 0.1160736158490181
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28624,
        "ag_news": 30168,
        "amazon_polarity": 29160,
        "cnn_dailymail/3.0.0": 29744,
        "common_gen": 28560,
        "cos_e/v1.11": 29887,
        "glue/mrpc": 28820,
        "kilt_tasks/hotpotqa": 29240
      },
      "step": 1830
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -189.56597900390625,
        "ag_news": 65.28832244873047,
        "amazon_polarity": 72.04470825195312,
        "cnn_dailymail/3.0.0": 182.2629852294922,
        "common_gen": -5.066143035888672,
        "cos_e/v1.11": -0.17803353071212769,
        "glue/mrpc": 6.224228382110596,
        "kilt_tasks/hotpotqa": -67.59906768798828
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10351193696260452,
        "ag_news": 0.13128237426280975,
        "amazon_polarity": 0.13211293518543243,
        "cnn_dailymail/3.0.0": 0.14643444120883942,
        "common_gen": 0.12294001877307892,
        "cos_e/v1.11": 0.12350195646286011,
        "glue/mrpc": 0.124241903424263,
        "kilt_tasks/hotpotqa": 0.11597438156604767
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28768,
        "ag_news": 30312,
        "amazon_polarity": 29264,
        "cnn_dailymail/3.0.0": 29880,
        "common_gen": 28704,
        "cos_e/v1.11": 30071,
        "glue/mrpc": 29092,
        "kilt_tasks/hotpotqa": 29392
      },
      "step": 1840
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -185.70652770996094,
        "ag_news": 65.18679809570312,
        "amazon_polarity": 71.98179626464844,
        "cnn_dailymail/3.0.0": 183.2110137939453,
        "common_gen": -3.319027900695801,
        "cos_e/v1.11": -3.4587793350219727,
        "glue/mrpc": 8.088582038879395,
        "kilt_tasks/hotpotqa": -66.58623504638672
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9381,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10387234389781952,
        "ag_news": 0.1311715990304947,
        "amazon_polarity": 0.13200396299362183,
        "cnn_dailymail/3.0.0": 0.14641085267066956,
        "common_gen": 0.12306950986385345,
        "cos_e/v1.11": 0.12305351346731186,
        "glue/mrpc": 0.12438282370567322,
        "kilt_tasks/hotpotqa": 0.11603542417287827
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28936,
        "ag_news": 30448,
        "amazon_polarity": 29456,
        "cnn_dailymail/3.0.0": 30024,
        "common_gen": 28864,
        "cos_e/v1.11": 30215,
        "glue/mrpc": 29260,
        "kilt_tasks/hotpotqa": 29560
      },
      "step": 1850
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -185.905517578125,
        "ag_news": 65.10641479492188,
        "amazon_polarity": 71.82157135009766,
        "cnn_dailymail/3.0.0": 182.7124786376953,
        "common_gen": -7.547492980957031,
        "cos_e/v1.11": -0.7822799682617188,
        "glue/mrpc": 8.078042984008789,
        "kilt_tasks/hotpotqa": -65.215576171875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0507,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10392089188098907,
        "ag_news": 0.13116557896137238,
        "amazon_polarity": 0.1319858878850937,
        "cnn_dailymail/3.0.0": 0.1463042050600052,
        "common_gen": 0.12261196970939636,
        "cos_e/v1.11": 0.12338414043188095,
        "glue/mrpc": 0.12440285086631775,
        "kilt_tasks/hotpotqa": 0.11622445285320282
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29112,
        "ag_news": 30568,
        "amazon_polarity": 29592,
        "cnn_dailymail/3.0.0": 30208,
        "common_gen": 29056,
        "cos_e/v1.11": 30359,
        "glue/mrpc": 29384,
        "kilt_tasks/hotpotqa": 29760
      },
      "step": 1860
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -187.8235321044922,
        "ag_news": 65.10052490234375,
        "amazon_polarity": 71.73955535888672,
        "cnn_dailymail/3.0.0": 185.8187713623047,
        "common_gen": -11.216184616088867,
        "cos_e/v1.11": 2.2744550704956055,
        "glue/mrpc": 6.276832580566406,
        "kilt_tasks/hotpotqa": -65.63252258300781
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9592,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10379840433597565,
        "ag_news": 0.13116157054901123,
        "amazon_polarity": 0.1319703459739685,
        "cnn_dailymail/3.0.0": 0.1466795653104782,
        "common_gen": 0.12221522629261017,
        "cos_e/v1.11": 0.1237507164478302,
        "glue/mrpc": 0.12420998513698578,
        "kilt_tasks/hotpotqa": 0.11621406674385071
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29312,
        "ag_news": 30784,
        "amazon_polarity": 29696,
        "cnn_dailymail/3.0.0": 30384,
        "common_gen": 29200,
        "cos_e/v1.11": 30543,
        "glue/mrpc": 29528,
        "kilt_tasks/hotpotqa": 29872
      },
      "step": 1870
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -187.97410583496094,
        "ag_news": 65.07881927490234,
        "amazon_polarity": 71.87442779541016,
        "cnn_dailymail/3.0.0": 187.7273712158203,
        "common_gen": -7.053923606872559,
        "cos_e/v1.11": 2.1091463565826416,
        "glue/mrpc": 7.601657390594482,
        "kilt_tasks/hotpotqa": -62.43958282470703
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.87,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10371145606040955,
        "ag_news": 0.13098591566085815,
        "amazon_polarity": 0.1318105310201645,
        "cnn_dailymail/3.0.0": 0.14670108258724213,
        "common_gen": 0.12254682183265686,
        "cos_e/v1.11": 0.1235877126455307,
        "glue/mrpc": 0.12421591579914093,
        "kilt_tasks/hotpotqa": 0.11644057929515839
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29488,
        "ag_news": 30992,
        "amazon_polarity": 29848,
        "cnn_dailymail/3.0.0": 30560,
        "common_gen": 29360,
        "cos_e/v1.11": 30695,
        "glue/mrpc": 29640,
        "kilt_tasks/hotpotqa": 30016
      },
      "step": 1880
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -184.43565368652344,
        "ag_news": 65.04888916015625,
        "amazon_polarity": 71.54998779296875,
        "cnn_dailymail/3.0.0": 189.29788208007812,
        "common_gen": -9.564510345458984,
        "cos_e/v1.11": 1.5586538314819336,
        "glue/mrpc": 9.077549934387207,
        "kilt_tasks/hotpotqa": -64.7557601928711
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.895,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.104093037545681,
        "ag_news": 0.13095685839653015,
        "amazon_polarity": 0.13174335658550262,
        "cnn_dailymail/3.0.0": 0.14684118330478668,
        "common_gen": 0.12226157635450363,
        "cos_e/v1.11": 0.12351997941732407,
        "glue/mrpc": 0.1243780255317688,
        "kilt_tasks/hotpotqa": 0.11620606482028961
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29616,
        "ag_news": 31176,
        "amazon_polarity": 30032,
        "cnn_dailymail/3.0.0": 30704,
        "common_gen": 29552,
        "cos_e/v1.11": 30823,
        "glue/mrpc": 29824,
        "kilt_tasks/hotpotqa": 30152
      },
      "step": 1890
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -182.47064208984375,
        "ag_news": 65.0030746459961,
        "amazon_polarity": 69.83799743652344,
        "cnn_dailymail/3.0.0": 189.57904052734375,
        "common_gen": -8.6600980758667,
        "cos_e/v1.11": 4.8759765625,
        "glue/mrpc": 4.886706352233887,
        "kilt_tasks/hotpotqa": -65.55640411376953
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8547,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10433930158615112,
        "ag_news": 0.13094620406627655,
        "amazon_polarity": 0.13152912259101868,
        "cnn_dailymail/3.0.0": 0.14682932198047638,
        "common_gen": 0.12238038331270218,
        "cos_e/v1.11": 0.12391095608472824,
        "glue/mrpc": 0.12391216307878494,
        "kilt_tasks/hotpotqa": 0.11615250259637833
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29752,
        "ag_news": 31344,
        "amazon_polarity": 30192,
        "cnn_dailymail/3.0.0": 30856,
        "common_gen": 29712,
        "cos_e/v1.11": 30927,
        "glue/mrpc": 30024,
        "kilt_tasks/hotpotqa": 30352
      },
      "step": 1900
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 1.0,
      "eval_runtime": 0.1954,
      "eval_samples_per_second": 81.866,
      "eval_steps_per_second": 5.117,
      "step": 1900
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -181.17445373535156,
        "ag_news": 64.99696350097656,
        "amazon_polarity": 70.10592651367188,
        "cnn_dailymail/3.0.0": 191.8251495361328,
        "common_gen": -10.852005004882812,
        "cos_e/v1.11": 5.660362720489502,
        "glue/mrpc": -3.12449049949646,
        "kilt_tasks/hotpotqa": -65.3220443725586
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9204,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10457383096218109,
        "ag_news": 0.13100704550743103,
        "amazon_polarity": 0.13162173330783844,
        "cnn_dailymail/3.0.0": 0.14715732634067535,
        "common_gen": 0.12221387773752213,
        "cos_e/v1.11": 0.12407609820365906,
        "glue/mrpc": 0.12308183312416077,
        "kilt_tasks/hotpotqa": 0.11626825481653214
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29920,
        "ag_news": 31440,
        "amazon_polarity": 30336,
        "cnn_dailymail/3.0.0": 31048,
        "common_gen": 29904,
        "cos_e/v1.11": 31063,
        "glue/mrpc": 30264,
        "kilt_tasks/hotpotqa": 30464
      },
      "step": 1910
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -177.92344665527344,
        "ag_news": 64.94005584716797,
        "amazon_polarity": 69.70552825927734,
        "cnn_dailymail/3.0.0": 190.8890380859375,
        "common_gen": -8.542243957519531,
        "cos_e/v1.11": 4.425151824951172,
        "glue/mrpc": -2.4839091300964355,
        "kilt_tasks/hotpotqa": -62.358238220214844
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8517,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10486753284931183,
        "ag_news": 0.13090258836746216,
        "amazon_polarity": 0.13147392868995667,
        "cnn_dailymail/3.0.0": 0.1468774378299713,
        "common_gen": 0.12240278720855713,
        "cos_e/v1.11": 0.12386128306388855,
        "glue/mrpc": 0.12308202683925629,
        "kilt_tasks/hotpotqa": 0.11653251945972443
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30112,
        "ag_news": 31592,
        "amazon_polarity": 30472,
        "cnn_dailymail/3.0.0": 31200,
        "common_gen": 30048,
        "cos_e/v1.11": 31175,
        "glue/mrpc": 30440,
        "kilt_tasks/hotpotqa": 30680
      },
      "step": 1920
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -177.88296508789062,
        "ag_news": 64.9219970703125,
        "amazon_polarity": 69.66570281982422,
        "cnn_dailymail/3.0.0": 190.23085021972656,
        "common_gen": -9.202291488647461,
        "cos_e/v1.11": 6.911380290985107,
        "glue/mrpc": -0.7913841009140015,
        "kilt_tasks/hotpotqa": -63.442047119140625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.813,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10489991307258606,
        "ag_news": 0.13086125254631042,
        "amazon_polarity": 0.1314283162355423,
        "cnn_dailymail/3.0.0": 0.14670172333717346,
        "common_gen": 0.12231378257274628,
        "cos_e/v1.11": 0.1241227462887764,
        "glue/mrpc": 0.1232546716928482,
        "kilt_tasks/hotpotqa": 0.11641761660575867
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30312,
        "ag_news": 31784,
        "amazon_polarity": 30576,
        "cnn_dailymail/3.0.0": 31328,
        "common_gen": 30192,
        "cos_e/v1.11": 31279,
        "glue/mrpc": 30688,
        "kilt_tasks/hotpotqa": 30840
      },
      "step": 1930
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -176.75238037109375,
        "ag_news": 64.85143280029297,
        "amazon_polarity": 69.55958557128906,
        "cnn_dailymail/3.0.0": 190.40989685058594,
        "common_gen": -9.681553840637207,
        "cos_e/v1.11": 6.9632415771484375,
        "glue/mrpc": -3.6020777225494385,
        "kilt_tasks/hotpotqa": -62.742286682128906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8174,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10507448762655258,
        "ag_news": 0.13086210191249847,
        "amazon_polarity": 0.1314234584569931,
        "cnn_dailymail/3.0.0": 0.1466929316520691,
        "common_gen": 0.12229031324386597,
        "cos_e/v1.11": 0.12415417283773422,
        "glue/mrpc": 0.12296778708696365,
        "kilt_tasks/hotpotqa": 0.1165347620844841
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30440,
        "ag_news": 31936,
        "amazon_polarity": 30832,
        "cnn_dailymail/3.0.0": 31536,
        "common_gen": 30392,
        "cos_e/v1.11": 31399,
        "glue/mrpc": 30784,
        "kilt_tasks/hotpotqa": 30960
      },
      "step": 1940
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -175.95558166503906,
        "ag_news": 64.84728240966797,
        "amazon_polarity": 69.34166717529297,
        "cnn_dailymail/3.0.0": 190.534423828125,
        "common_gen": -15.177398681640625,
        "cos_e/v1.11": 10.136133193969727,
        "glue/mrpc": -3.3132364749908447,
        "kilt_tasks/hotpotqa": -60.40114212036133
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.818,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10518790036439896,
        "ag_news": 0.1308351755142212,
        "amazon_polarity": 0.13136951625347137,
        "cnn_dailymail/3.0.0": 0.14663708209991455,
        "common_gen": 0.12167911976575851,
        "cos_e/v1.11": 0.12450335174798965,
        "glue/mrpc": 0.12299468368291855,
        "kilt_tasks/hotpotqa": 0.1167931854724884
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30568,
        "ag_news": 32152,
        "amazon_polarity": 31032,
        "cnn_dailymail/3.0.0": 31664,
        "common_gen": 30608,
        "cos_e/v1.11": 31511,
        "glue/mrpc": 30872,
        "kilt_tasks/hotpotqa": 31152
      },
      "step": 1950
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -178.60816955566406,
        "ag_news": 64.80258178710938,
        "amazon_polarity": 69.06417083740234,
        "cnn_dailymail/3.0.0": 187.03414916992188,
        "common_gen": -13.990803718566895,
        "cos_e/v1.11": 10.760714530944824,
        "glue/mrpc": -8.365262985229492,
        "kilt_tasks/hotpotqa": -61.88258743286133
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8643,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10511653125286102,
        "ag_news": 0.13098245859146118,
        "amazon_polarity": 0.13148833811283112,
        "cnn_dailymail/3.0.0": 0.14630140364170074,
        "common_gen": 0.1219741627573967,
        "cos_e/v1.11": 0.12473461776971817,
        "glue/mrpc": 0.12259609997272491,
        "kilt_tasks/hotpotqa": 0.11680645495653152
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30744,
        "ag_news": 32312,
        "amazon_polarity": 31160,
        "cnn_dailymail/3.0.0": 31848,
        "common_gen": 30760,
        "cos_e/v1.11": 31679,
        "glue/mrpc": 30992,
        "kilt_tasks/hotpotqa": 31344
      },
      "step": 1960
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -175.61817932128906,
        "ag_news": 64.78697204589844,
        "amazon_polarity": 68.90797424316406,
        "cnn_dailymail/3.0.0": 189.62704467773438,
        "common_gen": -16.091306686401367,
        "cos_e/v1.11": 12.330900192260742,
        "glue/mrpc": -9.432807922363281,
        "kilt_tasks/hotpotqa": -64.4500503540039
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8799,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10542988032102585,
        "ag_news": 0.13094501197338104,
        "amazon_polarity": 0.13143281638622284,
        "cnn_dailymail/3.0.0": 0.14656345546245575,
        "common_gen": 0.12173216044902802,
        "cos_e/v1.11": 0.12489286810159683,
        "glue/mrpc": 0.12246531248092651,
        "kilt_tasks/hotpotqa": 0.11653846502304077
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30880,
        "ag_news": 32456,
        "amazon_polarity": 31328,
        "cnn_dailymail/3.0.0": 32016,
        "common_gen": 30952,
        "cos_e/v1.11": 31815,
        "glue/mrpc": 31184,
        "kilt_tasks/hotpotqa": 31488
      },
      "step": 1970
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -169.07009887695312,
        "ag_news": 64.79581451416016,
        "amazon_polarity": 68.8351058959961,
        "cnn_dailymail/3.0.0": 191.7930908203125,
        "common_gen": -13.540128707885742,
        "cos_e/v1.11": 7.987013816833496,
        "glue/mrpc": -9.115833282470703,
        "kilt_tasks/hotpotqa": -64.65473175048828
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8855,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10602356493473053,
        "ag_news": 0.13083958625793457,
        "amazon_polarity": 0.13131611049175262,
        "cnn_dailymail/3.0.0": 0.14668859541416168,
        "common_gen": 0.12193503975868225,
        "cos_e/v1.11": 0.1243194043636322,
        "glue/mrpc": 0.1224212795495987,
        "kilt_tasks/hotpotqa": 0.11645644158124924
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31040,
        "ag_news": 32624,
        "amazon_polarity": 31496,
        "cnn_dailymail/3.0.0": 32216,
        "common_gen": 31096,
        "cos_e/v1.11": 31967,
        "glue/mrpc": 31328,
        "kilt_tasks/hotpotqa": 31632
      },
      "step": 1980
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -168.45965576171875,
        "ag_news": 64.94405364990234,
        "amazon_polarity": 68.76245880126953,
        "cnn_dailymail/3.0.0": 193.97543334960938,
        "common_gen": -14.03715991973877,
        "cos_e/v1.11": 8.098336219787598,
        "glue/mrpc": -9.319853782653809,
        "kilt_tasks/hotpotqa": -64.45797729492188
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.869,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10609331727027893,
        "ag_news": 0.1308026909828186,
        "amazon_polarity": 0.13125184178352356,
        "cnn_dailymail/3.0.0": 0.1468733847141266,
        "common_gen": 0.12185157090425491,
        "cos_e/v1.11": 0.12429612874984741,
        "glue/mrpc": 0.12236843258142471,
        "kilt_tasks/hotpotqa": 0.1164625734090805
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31200,
        "ag_news": 32744,
        "amazon_polarity": 31696,
        "cnn_dailymail/3.0.0": 32384,
        "common_gen": 31232,
        "cos_e/v1.11": 32143,
        "glue/mrpc": 31464,
        "kilt_tasks/hotpotqa": 31816
      },
      "step": 1990
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -170.5949249267578,
        "ag_news": 64.94432067871094,
        "amazon_polarity": 68.85724639892578,
        "cnn_dailymail/3.0.0": 192.73291015625,
        "common_gen": -16.241424560546875,
        "cos_e/v1.11": 5.396223068237305,
        "glue/mrpc": -9.17339038848877,
        "kilt_tasks/hotpotqa": -61.054256439208984
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8206,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10599062591791153,
        "ag_news": 0.13085784018039703,
        "amazon_polarity": 0.1313171684741974,
        "cnn_dailymail/3.0.0": 0.14672943949699402,
        "common_gen": 0.12168405950069427,
        "cos_e/v1.11": 0.12406378984451294,
        "glue/mrpc": 0.12245631217956543,
        "kilt_tasks/hotpotqa": 0.1169007197022438
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31416,
        "ag_news": 32960,
        "amazon_polarity": 31800,
        "cnn_dailymail/3.0.0": 32536,
        "common_gen": 31320,
        "cos_e/v1.11": 32335,
        "glue/mrpc": 31600,
        "kilt_tasks/hotpotqa": 31992
      },
      "step": 2000
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 1.0,
      "eval_runtime": 0.1875,
      "eval_samples_per_second": 85.353,
      "eval_steps_per_second": 5.335,
      "step": 2000
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -171.52056884765625,
        "ag_news": 64.95507049560547,
        "amazon_polarity": 68.84810638427734,
        "cnn_dailymail/3.0.0": 193.428955078125,
        "common_gen": -17.48518180847168,
        "cos_e/v1.11": 0.2721904218196869,
        "glue/mrpc": -10.298942565917969,
        "kilt_tasks/hotpotqa": -57.51865005493164
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8894,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10599514096975327,
        "ag_news": 0.13090458512306213,
        "amazon_polarity": 0.13136062026023865,
        "cnn_dailymail/3.0.0": 0.146830216050148,
        "common_gen": 0.12161312997341156,
        "cos_e/v1.11": 0.12355667352676392,
        "glue/mrpc": 0.12239591777324677,
        "kilt_tasks/hotpotqa": 0.11734369397163391
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31560,
        "ag_news": 33136,
        "amazon_polarity": 31952,
        "cnn_dailymail/3.0.0": 32728,
        "common_gen": 31480,
        "cos_e/v1.11": 32503,
        "glue/mrpc": 31744,
        "kilt_tasks/hotpotqa": 32136
      },
      "step": 2010
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -171.9522705078125,
        "ag_news": 64.9372329711914,
        "amazon_polarity": 68.6692886352539,
        "cnn_dailymail/3.0.0": 191.14892578125,
        "common_gen": -16.986492156982422,
        "cos_e/v1.11": -3.4339728355407715,
        "glue/mrpc": -12.161909103393555,
        "kilt_tasks/hotpotqa": -58.65648651123047
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8853,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10610833764076233,
        "ag_news": 0.1310248225927353,
        "amazon_polarity": 0.13146129250526428,
        "cnn_dailymail/3.0.0": 0.1466274857521057,
        "common_gen": 0.12180283665657043,
        "cos_e/v1.11": 0.12328201532363892,
        "glue/mrpc": 0.12232735008001328,
        "kilt_tasks/hotpotqa": 0.11736588925123215
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31696,
        "ag_news": 33296,
        "amazon_polarity": 32152,
        "cnn_dailymail/3.0.0": 32840,
        "common_gen": 31672,
        "cos_e/v1.11": 32687,
        "glue/mrpc": 31864,
        "kilt_tasks/hotpotqa": 32312
      },
      "step": 2020
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -169.553955078125,
        "ag_news": 64.90830993652344,
        "amazon_polarity": 68.89865112304688,
        "cnn_dailymail/3.0.0": 191.76345825195312,
        "common_gen": -16.910308837890625,
        "cos_e/v1.11": -4.939816474914551,
        "glue/mrpc": -14.700839042663574,
        "kilt_tasks/hotpotqa": -59.71009826660156
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8071,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10640067607164383,
        "ag_news": 0.13103541731834412,
        "amazon_polarity": 0.13150103390216827,
        "cnn_dailymail/3.0.0": 0.14668281376361847,
        "common_gen": 0.12184585630893707,
        "cos_e/v1.11": 0.12314867973327637,
        "glue/mrpc": 0.12208527326583862,
        "kilt_tasks/hotpotqa": 0.11730024218559265
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31824,
        "ag_news": 33488,
        "amazon_polarity": 32360,
        "cnn_dailymail/3.0.0": 32968,
        "common_gen": 31872,
        "cos_e/v1.11": 32831,
        "glue/mrpc": 32048,
        "kilt_tasks/hotpotqa": 32408
      },
      "step": 2030
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -167.59719848632812,
        "ag_news": 64.83792877197266,
        "amazon_polarity": 66.52877807617188,
        "cnn_dailymail/3.0.0": 195.57679748535156,
        "common_gen": -14.965863227844238,
        "cos_e/v1.11": -3.9199330806732178,
        "glue/mrpc": -14.516829490661621,
        "kilt_tasks/hotpotqa": -60.42662811279297
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.7815,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10655730217695236,
        "ag_news": 0.13092641532421112,
        "amazon_polarity": 0.1311228722333908,
        "cnn_dailymail/3.0.0": 0.1470261961221695,
        "common_gen": 0.12198378145694733,
        "cos_e/v1.11": 0.12318388372659683,
        "glue/mrpc": 0.12203233689069748,
        "kilt_tasks/hotpotqa": 0.11716727912425995
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31952,
        "ag_news": 33640,
        "amazon_polarity": 32552,
        "cnn_dailymail/3.0.0": 33128,
        "common_gen": 32048,
        "cos_e/v1.11": 32959,
        "glue/mrpc": 32296,
        "kilt_tasks/hotpotqa": 32504
      },
      "step": 2040
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -171.36322021484375,
        "ag_news": 64.83291625976562,
        "amazon_polarity": 66.41060638427734,
        "cnn_dailymail/3.0.0": 197.8428497314453,
        "common_gen": -11.798042297363281,
        "cos_e/v1.11": -2.3559160232543945,
        "glue/mrpc": -8.48143196105957,
        "kilt_tasks/hotpotqa": -62.4415168762207
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8424,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10615187883377075,
        "ag_news": 0.13079668581485748,
        "amazon_polarity": 0.13097935914993286,
        "cnn_dailymail/3.0.0": 0.14713454246520996,
        "common_gen": 0.1222262978553772,
        "cos_e/v1.11": 0.12325098365545273,
        "glue/mrpc": 0.1225852444767952,
        "kilt_tasks/hotpotqa": 0.11687502264976501
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32088,
        "ag_news": 33840,
        "amazon_polarity": 32712,
        "cnn_dailymail/3.0.0": 33296,
        "common_gen": 32184,
        "cos_e/v1.11": 33063,
        "glue/mrpc": 32480,
        "kilt_tasks/hotpotqa": 32696
      },
      "step": 2050
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -175.88494873046875,
        "ag_news": 64.5760498046875,
        "amazon_polarity": 66.18873596191406,
        "cnn_dailymail/3.0.0": 199.83692932128906,
        "common_gen": -12.219382286071777,
        "cos_e/v1.11": -4.7031965255737305,
        "glue/mrpc": -7.976126670837402,
        "kilt_tasks/hotpotqa": -64.0309829711914
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8485,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10583888739347458,
        "ag_news": 0.13083615899085999,
        "amazon_polarity": 0.13102248311042786,
        "cnn_dailymail/3.0.0": 0.14742985367774963,
        "common_gen": 0.12226542085409164,
        "cos_e/v1.11": 0.12307868152856827,
        "glue/mrpc": 0.12272386997938156,
        "kilt_tasks/hotpotqa": 0.11680468171834946
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32240,
        "ag_news": 34032,
        "amazon_polarity": 32888,
        "cnn_dailymail/3.0.0": 33456,
        "common_gen": 32320,
        "cos_e/v1.11": 33255,
        "glue/mrpc": 32640,
        "kilt_tasks/hotpotqa": 32808
      },
      "step": 2060
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -175.0687255859375,
        "ag_news": 64.41146087646484,
        "amazon_polarity": 66.08033752441406,
        "cnn_dailymail/3.0.0": 200.4757080078125,
        "common_gen": -14.884175300598145,
        "cos_e/v1.11": -5.4907026290893555,
        "glue/mrpc": -9.83778190612793,
        "kilt_tasks/hotpotqa": -61.33537673950195
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8413,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10597594082355499,
        "ag_news": 0.13082607090473175,
        "amazon_polarity": 0.13101842999458313,
        "cnn_dailymail/3.0.0": 0.14748050272464752,
        "common_gen": 0.12200721353292465,
        "cos_e/v1.11": 0.12301982939243317,
        "glue/mrpc": 0.12255016714334488,
        "kilt_tasks/hotpotqa": 0.11712181568145752
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32400,
        "ag_news": 34232,
        "amazon_polarity": 33056,
        "cnn_dailymail/3.0.0": 33584,
        "common_gen": 32488,
        "cos_e/v1.11": 33455,
        "glue/mrpc": 32752,
        "kilt_tasks/hotpotqa": 32952
      },
      "step": 2070
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -179.6148223876953,
        "ag_news": 64.45130157470703,
        "amazon_polarity": 66.18814849853516,
        "cnn_dailymail/3.0.0": 200.2444610595703,
        "common_gen": -18.28345489501953,
        "cos_e/v1.11": -1.8069875240325928,
        "glue/mrpc": -4.923691272735596,
        "kilt_tasks/hotpotqa": -63.36313247680664
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8062,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10560528188943863,
        "ag_news": 0.1308279186487198,
        "amazon_polarity": 0.13102762401103973,
        "cnn_dailymail/3.0.0": 0.14740514755249023,
        "common_gen": 0.1216614693403244,
        "cos_e/v1.11": 0.12343388050794601,
        "glue/mrpc": 0.12309661507606506,
        "kilt_tasks/hotpotqa": 0.11694208532571793
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32584,
        "ag_news": 34416,
        "amazon_polarity": 33208,
        "cnn_dailymail/3.0.0": 33736,
        "common_gen": 32616,
        "cos_e/v1.11": 33607,
        "glue/mrpc": 32944,
        "kilt_tasks/hotpotqa": 33088
      },
      "step": 2080
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -179.9439697265625,
        "ag_news": 64.44600677490234,
        "amazon_polarity": 65.95735931396484,
        "cnn_dailymail/3.0.0": 198.34201049804688,
        "common_gen": -18.188913345336914,
        "cos_e/v1.11": -4.02370023727417,
        "glue/mrpc": -8.230229377746582,
        "kilt_tasks/hotpotqa": -66.88529968261719
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8437,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10575010627508163,
        "ag_news": 0.13097797334194183,
        "amazon_polarity": 0.13115152716636658,
        "cnn_dailymail/3.0.0": 0.14728718996047974,
        "common_gen": 0.12183266878128052,
        "cos_e/v1.11": 0.12335338443517685,
        "glue/mrpc": 0.12289980053901672,
        "kilt_tasks/hotpotqa": 0.11674739420413971
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32704,
        "ag_news": 34632,
        "amazon_polarity": 33384,
        "cnn_dailymail/3.0.0": 33920,
        "common_gen": 32752,
        "cos_e/v1.11": 33759,
        "glue/mrpc": 33100,
        "kilt_tasks/hotpotqa": 33224
      },
      "step": 2090
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -181.0653533935547,
        "ag_news": 64.34725952148438,
        "amazon_polarity": 65.7513656616211,
        "cnn_dailymail/3.0.0": 201.08338928222656,
        "common_gen": -15.260781288146973,
        "cos_e/v1.11": -3.9070701599121094,
        "glue/mrpc": -7.070006847381592,
        "kilt_tasks/hotpotqa": -67.12384796142578
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9036,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10562198609113693,
        "ag_news": 0.13086965680122375,
        "amazon_polarity": 0.1310303658246994,
        "cnn_dailymail/3.0.0": 0.14749027788639069,
        "common_gen": 0.12207520753145218,
        "cos_e/v1.11": 0.12329211831092834,
        "glue/mrpc": 0.12295188754796982,
        "kilt_tasks/hotpotqa": 0.1166684478521347
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32840,
        "ag_news": 34792,
        "amazon_polarity": 33520,
        "cnn_dailymail/3.0.0": 34136,
        "common_gen": 32928,
        "cos_e/v1.11": 33863,
        "glue/mrpc": 33236,
        "kilt_tasks/hotpotqa": 33440
      },
      "step": 2100
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1875,
      "eval_samples_per_second": 85.311,
      "eval_steps_per_second": 5.332,
      "step": 2100
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -182.72349548339844,
        "ag_news": 64.37033081054688,
        "amazon_polarity": 65.04625701904297,
        "cnn_dailymail/3.0.0": 203.46334838867188,
        "common_gen": -14.973825454711914,
        "cos_e/v1.11": -2.731907606124878,
        "glue/mrpc": -5.126382827758789,
        "kilt_tasks/hotpotqa": -66.37287902832031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9598,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10545796900987625,
        "ag_news": 0.13079166412353516,
        "amazon_polarity": 0.13086877763271332,
        "cnn_dailymail/3.0.0": 0.1476641148328781,
        "common_gen": 0.12205056846141815,
        "cos_e/v1.11": 0.123359814286232,
        "glue/mrpc": 0.12310262024402618,
        "kilt_tasks/hotpotqa": 0.1167045310139656
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32984,
        "ag_news": 34920,
        "amazon_polarity": 33672,
        "cnn_dailymail/3.0.0": 34328,
        "common_gen": 33104,
        "cos_e/v1.11": 34055,
        "glue/mrpc": 33380,
        "kilt_tasks/hotpotqa": 33592
      },
      "step": 2110
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -183.73226928710938,
        "ag_news": 64.38462829589844,
        "amazon_polarity": 65.05059814453125,
        "cnn_dailymail/3.0.0": 202.78662109375,
        "common_gen": -8.136648178100586,
        "cos_e/v1.11": -5.749664306640625,
        "glue/mrpc": -3.2820212841033936,
        "kilt_tasks/hotpotqa": -69.35384368896484
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9433,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10539571195840836,
        "ag_news": 0.13076460361480713,
        "amazon_polarity": 0.13084039092063904,
        "cnn_dailymail/3.0.0": 0.14750270545482635,
        "common_gen": 0.12277135252952576,
        "cos_e/v1.11": 0.12302643060684204,
        "glue/mrpc": 0.12329071015119553,
        "kilt_tasks/hotpotqa": 0.11640813201665878
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33112,
        "ag_news": 35096,
        "amazon_polarity": 33824,
        "cnn_dailymail/3.0.0": 34520,
        "common_gen": 33312,
        "cos_e/v1.11": 34231,
        "glue/mrpc": 33492,
        "kilt_tasks/hotpotqa": 33728
      },
      "step": 2120
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -178.58172607421875,
        "ag_news": 64.65056610107422,
        "amazon_polarity": 65.05830383300781,
        "cnn_dailymail/3.0.0": 201.74319458007812,
        "common_gen": -8.383132934570312,
        "cos_e/v1.11": -8.354915618896484,
        "glue/mrpc": -7.578500270843506,
        "kilt_tasks/hotpotqa": -72.43498992919922
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0355,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1059848740696907,
        "ag_news": 0.13087449967861176,
        "amazon_polarity": 0.13092081248760223,
        "cnn_dailymail/3.0.0": 0.14741744101047516,
        "common_gen": 0.12283795326948166,
        "cos_e/v1.11": 0.12284095585346222,
        "glue/mrpc": 0.12292373180389404,
        "kilt_tasks/hotpotqa": 0.11619974672794342
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33192,
        "ag_news": 35224,
        "amazon_polarity": 33984,
        "cnn_dailymail/3.0.0": 34768,
        "common_gen": 33440,
        "cos_e/v1.11": 34479,
        "glue/mrpc": 33596,
        "kilt_tasks/hotpotqa": 33912
      },
      "step": 2130
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -181.8458251953125,
        "ag_news": 64.70197296142578,
        "amazon_polarity": 64.6055908203125,
        "cnn_dailymail/3.0.0": 201.07127380371094,
        "common_gen": -8.981707572937012,
        "cos_e/v1.11": -7.060238361358643,
        "glue/mrpc": -8.814043045043945,
        "kilt_tasks/hotpotqa": -72.88957214355469
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.892,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10578402876853943,
        "ag_news": 0.1309373825788498,
        "amazon_polarity": 0.1309264749288559,
        "cnn_dailymail/3.0.0": 0.1473551094532013,
        "common_gen": 0.12284594029188156,
        "cos_e/v1.11": 0.12305040657520294,
        "glue/mrpc": 0.12286376953125,
        "kilt_tasks/hotpotqa": 0.11623678356409073
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33336,
        "ag_news": 35384,
        "amazon_polarity": 34160,
        "cnn_dailymail/3.0.0": 34896,
        "common_gen": 33696,
        "cos_e/v1.11": 34607,
        "glue/mrpc": 33748,
        "kilt_tasks/hotpotqa": 34048
      },
      "step": 2140
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -181.87869262695312,
        "ag_news": 64.40389251708984,
        "amazon_polarity": 63.725563049316406,
        "cnn_dailymail/3.0.0": 200.15338134765625,
        "common_gen": -8.239497184753418,
        "cos_e/v1.11": -10.34931755065918,
        "glue/mrpc": -6.996151447296143,
        "kilt_tasks/hotpotqa": -75.16697692871094
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8807,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1058819442987442,
        "ag_news": 0.13096405565738678,
        "amazon_polarity": 0.13088734447956085,
        "cnn_dailymail/3.0.0": 0.14726586639881134,
        "common_gen": 0.12299953401088715,
        "cos_e/v1.11": 0.12277565896511078,
        "glue/mrpc": 0.123131662607193,
        "kilt_tasks/hotpotqa": 0.1160939559340477
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33496,
        "ag_news": 35536,
        "amazon_polarity": 34328,
        "cnn_dailymail/3.0.0": 35104,
        "common_gen": 33840,
        "cos_e/v1.11": 34759,
        "glue/mrpc": 33932,
        "kilt_tasks/hotpotqa": 34160
      },
      "step": 2150
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -182.58285522460938,
        "ag_news": 64.40859985351562,
        "amazon_polarity": 64.04033660888672,
        "cnn_dailymail/3.0.0": 201.01576232910156,
        "common_gen": -7.247868061065674,
        "cos_e/v1.11": -15.653101921081543,
        "glue/mrpc": -8.475362777709961,
        "kilt_tasks/hotpotqa": -75.62866973876953
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8458,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10592016577720642,
        "ag_news": 0.13102729618549347,
        "amazon_polarity": 0.13098570704460144,
        "cnn_dailymail/3.0.0": 0.14740616083145142,
        "common_gen": 0.12318136543035507,
        "cos_e/v1.11": 0.12229260802268982,
        "glue/mrpc": 0.12305116653442383,
        "kilt_tasks/hotpotqa": 0.11613553017377853
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33632,
        "ag_news": 35664,
        "amazon_polarity": 34512,
        "cnn_dailymail/3.0.0": 35232,
        "common_gen": 33976,
        "cos_e/v1.11": 34983,
        "glue/mrpc": 34100,
        "kilt_tasks/hotpotqa": 34336
      },
      "step": 2160
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -180.16571044921875,
        "ag_news": 64.38179016113281,
        "amazon_polarity": 64.19158935546875,
        "cnn_dailymail/3.0.0": 203.8915557861328,
        "common_gen": -8.01534366607666,
        "cos_e/v1.11": -18.71075439453125,
        "glue/mrpc": -4.639830112457275,
        "kilt_tasks/hotpotqa": -75.97762298583984
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8815,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10612121969461441,
        "ag_news": 0.1309368759393692,
        "amazon_polarity": 0.13091547787189484,
        "cnn_dailymail/3.0.0": 0.1476328819990158,
        "common_gen": 0.1230354905128479,
        "cos_e/v1.11": 0.12190961092710495,
        "glue/mrpc": 0.1233929917216301,
        "kilt_tasks/hotpotqa": 0.1160554364323616
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33848,
        "ag_news": 35808,
        "amazon_polarity": 34648,
        "cnn_dailymail/3.0.0": 35472,
        "common_gen": 34152,
        "cos_e/v1.11": 35055,
        "glue/mrpc": 34284,
        "kilt_tasks/hotpotqa": 34448
      },
      "step": 2170
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -184.3587646484375,
        "ag_news": 64.25792694091797,
        "amazon_polarity": 64.26425170898438,
        "cnn_dailymail/3.0.0": 202.04258728027344,
        "common_gen": -8.80222225189209,
        "cos_e/v1.11": -18.453960418701172,
        "glue/mrpc": -6.496425628662109,
        "kilt_tasks/hotpotqa": -73.19844055175781
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8895,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10584421455860138,
        "ag_news": 0.13098841905593872,
        "amazon_polarity": 0.13098913431167603,
        "cnn_dailymail/3.0.0": 0.14743201434612274,
        "common_gen": 0.12303141504526138,
        "cos_e/v1.11": 0.1220172867178917,
        "glue/mrpc": 0.12327495217323303,
        "kilt_tasks/hotpotqa": 0.11642242223024368
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 34024,
        "ag_news": 35992,
        "amazon_polarity": 34768,
        "cnn_dailymail/3.0.0": 35600,
        "common_gen": 34352,
        "cos_e/v1.11": 35247,
        "glue/mrpc": 34372,
        "kilt_tasks/hotpotqa": 34640
      },
      "step": 2180
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -191.34317016601562,
        "ag_news": 64.15977478027344,
        "amazon_polarity": 64.2182846069336,
        "cnn_dailymail/3.0.0": 203.09478759765625,
        "common_gen": -9.278587341308594,
        "cos_e/v1.11": -19.641542434692383,
        "glue/mrpc": -7.1841721534729,
        "kilt_tasks/hotpotqa": -75.50399017333984
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8842,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10535913705825806,
        "ag_news": 0.13109450042247772,
        "amazon_polarity": 0.1311010718345642,
        "cnn_dailymail/3.0.0": 0.14765726029872894,
        "common_gen": 0.12310868501663208,
        "cos_e/v1.11": 0.12202192842960358,
        "glue/mrpc": 0.12332950532436371,
        "kilt_tasks/hotpotqa": 0.11632797867059708
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 34136,
        "ag_news": 36208,
        "amazon_polarity": 34920,
        "cnn_dailymail/3.0.0": 35768,
        "common_gen": 34504,
        "cos_e/v1.11": 35431,
        "glue/mrpc": 34508,
        "kilt_tasks/hotpotqa": 34800
      },
      "step": 2190
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -189.15170288085938,
        "ag_news": 63.93335723876953,
        "amazon_polarity": 63.566864013671875,
        "cnn_dailymail/3.0.0": 203.38211059570312,
        "common_gen": -9.329914093017578,
        "cos_e/v1.11": -21.804241180419922,
        "glue/mrpc": -6.007191181182861,
        "kilt_tasks/hotpotqa": -74.61143493652344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8429,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10558559745550156,
        "ag_news": 0.13104091584682465,
        "amazon_polarity": 0.13099990785121918,
        "cnn_dailymail/3.0.0": 0.14762189984321594,
        "common_gen": 0.12309427559375763,
        "cos_e/v1.11": 0.12179038673639297,
        "glue/mrpc": 0.12344393879175186,
        "kilt_tasks/hotpotqa": 0.11642300337553024
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 34304,
        "ag_news": 36384,
        "amazon_polarity": 35088,
        "cnn_dailymail/3.0.0": 35928,
        "common_gen": 34696,
        "cos_e/v1.11": 35559,
        "glue/mrpc": 34644,
        "kilt_tasks/hotpotqa": 34952
      },
      "step": 2200
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 1.0,
      "eval_runtime": 0.1957,
      "eval_samples_per_second": 81.768,
      "eval_steps_per_second": 5.111,
      "step": 2200
    },
    {
      "epoch": 0.0,
      "step": 2200,
      "total_flos": 8.539511291955855e+17,
      "train_loss": 1.1284370244633068,
      "train_runtime": 24656.8379,
      "train_samples_per_second": 51.913,
      "train_steps_per_second": 0.406
    }
  ],
  "max_steps": 10000,
  "num_train_epochs": 18,
  "total_flos": 8.539511291955855e+17,
  "trial_name": null,
  "trial_params": null
}
