{
  "best_metric": 1.0,
  "best_model_checkpoint": "src/../outputs/T5_LM_3B/T0Mixture/weighted_batch_exp3/42/copa/cosine/1.0/16/0.0001/0/0/checkpoint-1400",
  "epoch": 0.00021793614470960008,
  "global_step": 2400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 31.689990997314453,
        "ag_news": 38.13383102416992,
        "amazon_polarity": 34.15214157104492,
        "cnn_dailymail/3.0.0": -52.82991027832031,
        "common_gen": 22.215974807739258,
        "cos_e/v1.11": 31.119102478027344,
        "glue/mrpc": 25.738615036010742,
        "kilt_tasks/hotpotqa": 32.37123107910156
      },
      "epoch": 0.0,
      "learning_rate": 1e-05,
      "loss": 5.2333,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1369512379169464,
        "ag_news": 0.14882592856884003,
        "amazon_polarity": 0.1413602977991104,
        "cnn_dailymail/3.0.0": 0.0504872165620327,
        "common_gen": 0.12135744094848633,
        "cos_e/v1.11": 0.13595083355903625,
        "glue/mrpc": 0.12691128253936768,
        "kilt_tasks/hotpotqa": 0.1381557285785675
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 160,
        "ag_news": 160,
        "amazon_polarity": 176,
        "cnn_dailymail/3.0.0": 88,
        "common_gen": 192,
        "cos_e/v1.11": 176,
        "glue/mrpc": 176,
        "kilt_tasks/hotpotqa": 152
      },
      "step": 10
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 64.20833587646484,
        "ag_news": 76.55016326904297,
        "amazon_polarity": 69.23016357421875,
        "cnn_dailymail/3.0.0": -295.677001953125,
        "common_gen": 52.33624267578125,
        "cos_e/v1.11": 70.1746826171875,
        "glue/mrpc": 63.6438102722168,
        "kilt_tasks/hotpotqa": 72.69600677490234
      },
      "epoch": 0.0,
      "learning_rate": 2e-05,
      "loss": 4.5815,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13721683621406555,
        "ag_news": 0.1531336009502411,
        "amazon_polarity": 0.14346902072429657,
        "cnn_dailymail/3.0.0": 0.013438312336802483,
        "common_gen": 0.12356974929571152,
        "cos_e/v1.11": 0.14467863738536835,
        "glue/mrpc": 0.1365324705839157,
        "kilt_tasks/hotpotqa": 0.14796125888824463
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 320,
        "ag_news": 272,
        "amazon_polarity": 312,
        "cnn_dailymail/3.0.0": 256,
        "common_gen": 416,
        "cos_e/v1.11": 328,
        "glue/mrpc": 360,
        "kilt_tasks/hotpotqa": 296
      },
      "step": 20
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 82.32721710205078,
        "ag_news": 99.49148559570312,
        "amazon_polarity": 93.969482421875,
        "cnn_dailymail/3.0.0": -610.1751098632812,
        "common_gen": 55.380985260009766,
        "cos_e/v1.11": 86.2037124633789,
        "glue/mrpc": 82.09464263916016,
        "kilt_tasks/hotpotqa": 93.85417938232422
      },
      "epoch": 0.0,
      "learning_rate": 3e-05,
      "loss": 3.1339,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1385686695575714,
        "ag_news": 0.1568755805492401,
        "amazon_polarity": 0.15072289109230042,
        "cnn_dailymail/3.0.0": 0.008155185729265213,
        "common_gen": 0.11424727737903595,
        "cos_e/v1.11": 0.14249657094478607,
        "glue/mrpc": 0.1383366733789444,
        "kilt_tasks/hotpotqa": 0.15059718489646912
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 464,
        "ag_news": 480,
        "amazon_polarity": 504,
        "cnn_dailymail/3.0.0": 336,
        "common_gen": 576,
        "cos_e/v1.11": 456,
        "glue/mrpc": 576,
        "kilt_tasks/hotpotqa": 448
      },
      "step": 30
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 67.88338470458984,
        "ag_news": 94.27764892578125,
        "amazon_polarity": 89.86632537841797,
        "cnn_dailymail/3.0.0": -442.82244873046875,
        "common_gen": 32.91050338745117,
        "cos_e/v1.11": 76.8543701171875,
        "glue/mrpc": 76.7599868774414,
        "kilt_tasks/hotpotqa": 83.09677124023438
      },
      "epoch": 0.0,
      "learning_rate": 4e-05,
      "loss": 2.1351,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1346338838338852,
        "ag_news": 0.1587763875722885,
        "amazon_polarity": 0.15444600582122803,
        "cnn_dailymail/3.0.0": 0.0110006183385849,
        "common_gen": 0.10843467712402344,
        "cos_e/v1.11": 0.14237673580646515,
        "glue/mrpc": 0.14229288697242737,
        "kilt_tasks/hotpotqa": 0.148038849234581
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 656,
        "ag_news": 680,
        "amazon_polarity": 680,
        "cnn_dailymail/3.0.0": 464,
        "common_gen": 720,
        "cos_e/v1.11": 608,
        "glue/mrpc": 728,
        "kilt_tasks/hotpotqa": 584
      },
      "step": 40
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 60.50016403198242,
        "ag_news": 91.51139831542969,
        "amazon_polarity": 86.7690200805664,
        "cnn_dailymail/3.0.0": -300.8755187988281,
        "common_gen": 23.582523345947266,
        "cos_e/v1.11": 76.93604278564453,
        "glue/mrpc": 74.3239974975586,
        "kilt_tasks/hotpotqa": 68.11455535888672
      },
      "epoch": 0.0,
      "learning_rate": 5e-05,
      "loss": 1.7269,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13259293138980865,
        "ag_news": 0.15766790509223938,
        "amazon_polarity": 0.15353433787822723,
        "cnn_dailymail/3.0.0": 0.021254951134324074,
        "common_gen": 0.10808008909225464,
        "cos_e/v1.11": 0.14531856775283813,
        "glue/mrpc": 0.14321397244930267,
        "kilt_tasks/hotpotqa": 0.1383373737335205
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 776,
        "ag_news": 864,
        "amazon_polarity": 920,
        "cnn_dailymail/3.0.0": 584,
        "common_gen": 824,
        "cos_e/v1.11": 792,
        "glue/mrpc": 856,
        "kilt_tasks/hotpotqa": 784
      },
      "step": 50
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 49.87179183959961,
        "ag_news": 90.87557983398438,
        "amazon_polarity": 85.89771270751953,
        "cnn_dailymail/3.0.0": -212.42098999023438,
        "common_gen": 17.280475616455078,
        "cos_e/v1.11": 75.48617553710938,
        "glue/mrpc": 73.3916015625,
        "kilt_tasks/hotpotqa": 64.57408142089844
      },
      "epoch": 0.0,
      "learning_rate": 6e-05,
      "loss": 1.7028,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12648293375968933,
        "ag_news": 0.15586337447166443,
        "amazon_polarity": 0.15194742381572723,
        "cnn_dailymail/3.0.0": 0.035501714795827866,
        "common_gen": 0.10727640986442566,
        "cos_e/v1.11": 0.14408297836780548,
        "glue/mrpc": 0.14255252480506897,
        "kilt_tasks/hotpotqa": 0.13629256188869476
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 968,
        "ag_news": 1016,
        "amazon_polarity": 1104,
        "cnn_dailymail/3.0.0": 752,
        "common_gen": 928,
        "cos_e/v1.11": 936,
        "glue/mrpc": 1000,
        "kilt_tasks/hotpotqa": 976
      },
      "step": 60
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 47.252593994140625,
        "ag_news": 90.74540710449219,
        "amazon_polarity": 86.42417907714844,
        "cnn_dailymail/3.0.0": -200.0384063720703,
        "common_gen": 10.45254135131836,
        "cos_e/v1.11": 74.0159912109375,
        "glue/mrpc": 73.08574676513672,
        "kilt_tasks/hotpotqa": 62.5938835144043
      },
      "epoch": 0.0,
      "learning_rate": 7e-05,
      "loss": 1.5709,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12599879503250122,
        "ag_news": 0.15469343960285187,
        "amazon_polarity": 0.15156190097332,
        "cnn_dailymail/3.0.0": 0.04102630168199539,
        "common_gen": 0.10605614632368088,
        "cos_e/v1.11": 0.14292897284030914,
        "glue/mrpc": 0.14230260252952576,
        "kilt_tasks/hotpotqa": 0.13543182611465454
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1144,
        "ag_news": 1224,
        "amazon_polarity": 1264,
        "cnn_dailymail/3.0.0": 872,
        "common_gen": 1080,
        "cos_e/v1.11": 1104,
        "glue/mrpc": 1104,
        "kilt_tasks/hotpotqa": 1168
      },
      "step": 70
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 36.180328369140625,
        "ag_news": 90.42654418945312,
        "amazon_polarity": 84.72022247314453,
        "cnn_dailymail/3.0.0": -168.01235961914062,
        "common_gen": 10.145482063293457,
        "cos_e/v1.11": 73.49353790283203,
        "glue/mrpc": 69.28794860839844,
        "kilt_tasks/hotpotqa": 60.90425491333008
      },
      "epoch": 0.0,
      "learning_rate": 8e-05,
      "loss": 1.544,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12094265222549438,
        "ag_news": 0.15364061295986176,
        "amazon_polarity": 0.1498078554868698,
        "cnn_dailymail/3.0.0": 0.05037914589047432,
        "common_gen": 0.10790206491947174,
        "cos_e/v1.11": 0.1425524204969406,
        "glue/mrpc": 0.13992878794670105,
        "kilt_tasks/hotpotqa": 0.1348465234041214
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1320,
        "ag_news": 1424,
        "amazon_polarity": 1376,
        "cnn_dailymail/3.0.0": 1008,
        "common_gen": 1240,
        "cos_e/v1.11": 1288,
        "glue/mrpc": 1256,
        "kilt_tasks/hotpotqa": 1328
      },
      "step": 80
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 28.3994083404541,
        "ag_news": 90.1995849609375,
        "amazon_polarity": 84.2943115234375,
        "cnn_dailymail/3.0.0": -146.75099182128906,
        "common_gen": 11.62893295288086,
        "cos_e/v1.11": 74.31415557861328,
        "glue/mrpc": 67.73143005371094,
        "kilt_tasks/hotpotqa": 55.18619918823242
      },
      "epoch": 0.0,
      "learning_rate": 9e-05,
      "loss": 1.4617,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11788017302751541,
        "ag_news": 0.1524297147989273,
        "amazon_polarity": 0.1487179845571518,
        "cnn_dailymail/3.0.0": 0.057801343500614166,
        "common_gen": 0.10998224467039108,
        "cos_e/v1.11": 0.142655149102211,
        "glue/mrpc": 0.13879616558551788,
        "kilt_tasks/hotpotqa": 0.13173724710941315
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1496,
        "ag_news": 1608,
        "amazon_polarity": 1496,
        "cnn_dailymail/3.0.0": 1152,
        "common_gen": 1384,
        "cos_e/v1.11": 1464,
        "glue/mrpc": 1440,
        "kilt_tasks/hotpotqa": 1480
      },
      "step": 90
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 25.981630325317383,
        "ag_news": 90.6142807006836,
        "amazon_polarity": 83.7959976196289,
        "cnn_dailymail/3.0.0": -125.21833038330078,
        "common_gen": 9.963540077209473,
        "cos_e/v1.11": 73.11341857910156,
        "glue/mrpc": 65.14643859863281,
        "kilt_tasks/hotpotqa": 54.56433868408203
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2603,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11720088124275208,
        "ag_news": 0.151260644197464,
        "amazon_polarity": 0.147230327129364,
        "cnn_dailymail/3.0.0": 0.06518812477588654,
        "common_gen": 0.11005719006061554,
        "cos_e/v1.11": 0.1411365270614624,
        "glue/mrpc": 0.13676126301288605,
        "kilt_tasks/hotpotqa": 0.1311650276184082
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1648,
        "ag_news": 1760,
        "amazon_polarity": 1760,
        "cnn_dailymail/3.0.0": 1352,
        "common_gen": 1480,
        "cos_e/v1.11": 1600,
        "glue/mrpc": 1608,
        "kilt_tasks/hotpotqa": 1592
      },
      "step": 100
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.6875,
      "eval_runtime": 0.1923,
      "eval_samples_per_second": 83.222,
      "eval_steps_per_second": 5.201,
      "step": 100
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 23.927757263183594,
        "ag_news": 90.46487426757812,
        "amazon_polarity": 83.37869262695312,
        "cnn_dailymail/3.0.0": -88.26201629638672,
        "common_gen": 8.812122344970703,
        "cos_e/v1.11": 69.80702209472656,
        "glue/mrpc": 65.63720703125,
        "kilt_tasks/hotpotqa": 54.440826416015625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3776,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11602754890918732,
        "ag_news": 0.1490502655506134,
        "amazon_polarity": 0.14511442184448242,
        "cnn_dailymail/3.0.0": 0.07645441591739655,
        "common_gen": 0.10964097082614899,
        "cos_e/v1.11": 0.13787174224853516,
        "glue/mrpc": 0.13572198152542114,
        "kilt_tasks/hotpotqa": 0.13011866807937622
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1816,
        "ag_news": 1912,
        "amazon_polarity": 1952,
        "cnn_dailymail/3.0.0": 1576,
        "common_gen": 1568,
        "cos_e/v1.11": 1752,
        "glue/mrpc": 1784,
        "kilt_tasks/hotpotqa": 1720
      },
      "step": 110
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 16.704181671142578,
        "ag_news": 90.06138610839844,
        "amazon_polarity": 83.20158386230469,
        "cnn_dailymail/3.0.0": -63.78608703613281,
        "common_gen": 8.610381126403809,
        "cos_e/v1.11": 67.30555725097656,
        "glue/mrpc": 65.6476821899414,
        "kilt_tasks/hotpotqa": 46.165592193603516
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4233,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11364655196666718,
        "ag_news": 0.1480422466993332,
        "amazon_polarity": 0.14441463351249695,
        "cnn_dailymail/3.0.0": 0.08525926619768143,
        "common_gen": 0.11039368063211441,
        "cos_e/v1.11": 0.13635499775409698,
        "glue/mrpc": 0.13554146885871887,
        "kilt_tasks/hotpotqa": 0.12634716928005219
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1968,
        "ag_news": 2008,
        "amazon_polarity": 2168,
        "cnn_dailymail/3.0.0": 1768,
        "common_gen": 1744,
        "cos_e/v1.11": 1864,
        "glue/mrpc": 1952,
        "kilt_tasks/hotpotqa": 1888
      },
      "step": 120
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 6.3907856941223145,
        "ag_news": 89.89976501464844,
        "amazon_polarity": 83.15682220458984,
        "cnn_dailymail/3.0.0": -45.142940521240234,
        "common_gen": 2.9167213439941406,
        "cos_e/v1.11": 65.33946228027344,
        "glue/mrpc": 63.23808670043945,
        "kilt_tasks/hotpotqa": 42.405548095703125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3413,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11060075461864471,
        "ag_news": 0.1476929485797882,
        "amazon_polarity": 0.1442716270685196,
        "cnn_dailymail/3.0.0": 0.09264581650495529,
        "common_gen": 0.10928401350975037,
        "cos_e/v1.11": 0.1356169581413269,
        "glue/mrpc": 0.1346319615840912,
        "kilt_tasks/hotpotqa": 0.1252557784318924
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2112,
        "ag_news": 2224,
        "amazon_polarity": 2328,
        "cnn_dailymail/3.0.0": 1904,
        "common_gen": 1928,
        "cos_e/v1.11": 2008,
        "glue/mrpc": 2080,
        "kilt_tasks/hotpotqa": 2056
      },
      "step": 130
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -8.485957145690918,
        "ag_news": 89.0377426147461,
        "amazon_polarity": 82.95055389404297,
        "cnn_dailymail/3.0.0": -24.2288818359375,
        "common_gen": 0.014346867799758911,
        "cos_e/v1.11": 64.06359100341797,
        "glue/mrpc": 62.18790054321289,
        "kilt_tasks/hotpotqa": 39.17230987548828
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3592,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10604508221149445,
        "ag_news": 0.14682726562023163,
        "amazon_polarity": 0.1438632309436798,
        "cnn_dailymail/3.0.0": 0.10064888000488281,
        "common_gen": 0.1090821921825409,
        "cos_e/v1.11": 0.1350509077310562,
        "glue/mrpc": 0.13420650362968445,
        "kilt_tasks/hotpotqa": 0.12427593022584915
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2320,
        "ag_news": 2336,
        "amazon_polarity": 2464,
        "cnn_dailymail/3.0.0": 2064,
        "common_gen": 2128,
        "cos_e/v1.11": 2152,
        "glue/mrpc": 2264,
        "kilt_tasks/hotpotqa": 2192
      },
      "step": 140
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -9.696290969848633,
        "ag_news": 88.74693298339844,
        "amazon_polarity": 82.89239501953125,
        "cnn_dailymail/3.0.0": -1.318960189819336,
        "common_gen": -7.308968544006348,
        "cos_e/v1.11": 63.35103225708008,
        "glue/mrpc": 58.93768310546875,
        "kilt_tasks/hotpotqa": 32.70577621459961
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4127,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10621071606874466,
        "ag_news": 0.1458943784236908,
        "amazon_polarity": 0.1431552618741989,
        "cnn_dailymail/3.0.0": 0.10910690575838089,
        "common_gen": 0.10702787339687347,
        "cos_e/v1.11": 0.1343877911567688,
        "glue/mrpc": 0.1324850618839264,
        "kilt_tasks/hotpotqa": 0.12173205614089966
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2448,
        "ag_news": 2488,
        "amazon_polarity": 2624,
        "cnn_dailymail/3.0.0": 2248,
        "common_gen": 2296,
        "cos_e/v1.11": 2336,
        "glue/mrpc": 2384,
        "kilt_tasks/hotpotqa": 2376
      },
      "step": 150
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -12.785517692565918,
        "ag_news": 88.5031967163086,
        "amazon_polarity": 83.1619644165039,
        "cnn_dailymail/3.0.0": 5.668410778045654,
        "common_gen": -5.2917704582214355,
        "cos_e/v1.11": 61.086570739746094,
        "glue/mrpc": 57.251434326171875,
        "kilt_tasks/hotpotqa": 21.45335578918457
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3475,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10615425556898117,
        "ag_news": 0.14566220343112946,
        "amazon_polarity": 0.14324301481246948,
        "cnn_dailymail/3.0.0": 0.1124303862452507,
        "common_gen": 0.10865816473960876,
        "cos_e/v1.11": 0.1336725801229477,
        "glue/mrpc": 0.1320778876543045,
        "kilt_tasks/hotpotqa": 0.11810151487588882
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2624,
        "ag_news": 2664,
        "amazon_polarity": 2784,
        "cnn_dailymail/3.0.0": 2400,
        "common_gen": 2432,
        "cos_e/v1.11": 2504,
        "glue/mrpc": 2496,
        "kilt_tasks/hotpotqa": 2576
      },
      "step": 160
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -18.883432388305664,
        "ag_news": 88.78936004638672,
        "amazon_polarity": 83.27854919433594,
        "cnn_dailymail/3.0.0": 14.367984771728516,
        "common_gen": -4.993443489074707,
        "cos_e/v1.11": 60.99687576293945,
        "glue/mrpc": 58.783416748046875,
        "kilt_tasks/hotpotqa": 20.056371688842773
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2627,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10459278523921967,
        "ag_news": 0.14495520293712616,
        "amazon_polarity": 0.14254501461982727,
        "cnn_dailymail/3.0.0": 0.11564872413873672,
        "common_gen": 0.10907253623008728,
        "cos_e/v1.11": 0.13321040570735931,
        "glue/mrpc": 0.1323179304599762,
        "kilt_tasks/hotpotqa": 0.11765725910663605
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2784,
        "ag_news": 2880,
        "amazon_polarity": 2904,
        "cnn_dailymail/3.0.0": 2544,
        "common_gen": 2632,
        "cos_e/v1.11": 2624,
        "glue/mrpc": 2656,
        "kilt_tasks/hotpotqa": 2736
      },
      "step": 170
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -26.511354446411133,
        "ag_news": 88.43814849853516,
        "amazon_polarity": 83.19403839111328,
        "cnn_dailymail/3.0.0": 20.30373764038086,
        "common_gen": -12.525867462158203,
        "cos_e/v1.11": 61.145713806152344,
        "glue/mrpc": 57.95661163330078,
        "kilt_tasks/hotpotqa": 17.234066009521484
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3944,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10322438180446625,
        "ag_news": 0.144831120967865,
        "amazon_polarity": 0.1426020860671997,
        "cnn_dailymail/3.0.0": 0.11844836920499802,
        "common_gen": 0.10754906386137009,
        "cos_e/v1.11": 0.1336071938276291,
        "glue/mrpc": 0.13235504925251007,
        "kilt_tasks/hotpotqa": 0.11738281697034836
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2896,
        "ag_news": 3040,
        "amazon_polarity": 3072,
        "cnn_dailymail/3.0.0": 2680,
        "common_gen": 2848,
        "cos_e/v1.11": 2760,
        "glue/mrpc": 2824,
        "kilt_tasks/hotpotqa": 2920
      },
      "step": 180
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -29.059080123901367,
        "ag_news": 88.31166076660156,
        "amazon_polarity": 83.13488006591797,
        "cnn_dailymail/3.0.0": 23.243696212768555,
        "common_gen": -11.893170356750488,
        "cos_e/v1.11": 56.57502746582031,
        "glue/mrpc": 57.12507629394531,
        "kilt_tasks/hotpotqa": 14.634064674377441
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2609,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1032726913690567,
        "ag_news": 0.14461472630500793,
        "amazon_polarity": 0.14247499406337738,
        "cnn_dailymail/3.0.0": 0.11994893103837967,
        "common_gen": 0.10846584290266037,
        "cos_e/v1.11": 0.13199469447135925,
        "glue/mrpc": 0.13220354914665222,
        "kilt_tasks/hotpotqa": 0.11702457815408707
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3008,
        "ag_news": 3240,
        "amazon_polarity": 3264,
        "cnn_dailymail/3.0.0": 2792,
        "common_gen": 3024,
        "cos_e/v1.11": 2936,
        "glue/mrpc": 2936,
        "kilt_tasks/hotpotqa": 3120
      },
      "step": 190
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -34.71194839477539,
        "ag_news": 87.98545837402344,
        "amazon_polarity": 83.2712631225586,
        "cnn_dailymail/3.0.0": 32.91432571411133,
        "common_gen": -13.153003692626953,
        "cos_e/v1.11": 53.13190460205078,
        "glue/mrpc": 57.89028549194336,
        "kilt_tasks/hotpotqa": 12.1209077835083
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.5214,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10222034901380539,
        "ag_news": 0.14406493306159973,
        "amazon_polarity": 0.1421709805727005,
        "cnn_dailymail/3.0.0": 0.12345825135707855,
        "common_gen": 0.10854972898960114,
        "cos_e/v1.11": 0.13064852356910706,
        "glue/mrpc": 0.1324022114276886,
        "kilt_tasks/hotpotqa": 0.11648497730493546
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3168,
        "ag_news": 3368,
        "amazon_polarity": 3368,
        "cnn_dailymail/3.0.0": 3032,
        "common_gen": 3192,
        "cos_e/v1.11": 3104,
        "glue/mrpc": 3048,
        "kilt_tasks/hotpotqa": 3320
      },
      "step": 200
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.4597,
      "eval_samples_per_second": 34.804,
      "eval_steps_per_second": 2.175,
      "step": 200
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -38.607913970947266,
        "ag_news": 87.93804931640625,
        "amazon_polarity": 83.33997344970703,
        "cnn_dailymail/3.0.0": 36.2009162902832,
        "common_gen": -12.827394485473633,
        "cos_e/v1.11": 53.12599563598633,
        "glue/mrpc": 54.612483978271484,
        "kilt_tasks/hotpotqa": 10.210370063781738
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.444,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10180944204330444,
        "ag_news": 0.14382050931453705,
        "amazon_polarity": 0.1420198231935501,
        "cnn_dailymail/3.0.0": 0.12483453005552292,
        "common_gen": 0.10920703411102295,
        "cos_e/v1.11": 0.1307460218667984,
        "glue/mrpc": 0.13127869367599487,
        "kilt_tasks/hotpotqa": 0.11628396809101105
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3312,
        "ag_news": 3512,
        "amazon_polarity": 3544,
        "cnn_dailymail/3.0.0": 3208,
        "common_gen": 3376,
        "cos_e/v1.11": 3240,
        "glue/mrpc": 3168,
        "kilt_tasks/hotpotqa": 3520
      },
      "step": 210
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -40.136505126953125,
        "ag_news": 87.9702377319336,
        "amazon_polarity": 83.36495971679688,
        "cnn_dailymail/3.0.0": 36.88001251220703,
        "common_gen": -13.484247207641602,
        "cos_e/v1.11": 51.99599838256836,
        "glue/mrpc": 53.35519027709961,
        "kilt_tasks/hotpotqa": 6.458065986633301
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3641,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1021215170621872,
        "ag_news": 0.14373481273651123,
        "amazon_polarity": 0.14197318255901337,
        "cnn_dailymail/3.0.0": 0.12537819147109985,
        "common_gen": 0.10962287336587906,
        "cos_e/v1.11": 0.13054527342319489,
        "glue/mrpc": 0.1310204416513443,
        "kilt_tasks/hotpotqa": 0.11560367047786713
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3456,
        "ag_news": 3664,
        "amazon_polarity": 3640,
        "cnn_dailymail/3.0.0": 3408,
        "common_gen": 3496,
        "cos_e/v1.11": 3416,
        "glue/mrpc": 3376,
        "kilt_tasks/hotpotqa": 3704
      },
      "step": 220
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.32291030883789,
        "ag_news": 88.11621856689453,
        "amazon_polarity": 83.36187744140625,
        "cnn_dailymail/3.0.0": 45.09432601928711,
        "common_gen": -14.048394203186035,
        "cos_e/v1.11": 48.29582595825195,
        "glue/mrpc": 53.181602478027344,
        "kilt_tasks/hotpotqa": 5.103023529052734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2575,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10149437934160233,
        "ag_news": 0.14340545237064362,
        "amazon_polarity": 0.141630619764328,
        "cnn_dailymail/3.0.0": 0.12813647091388702,
        "common_gen": 0.10981260985136032,
        "cos_e/v1.11": 0.12921330332756042,
        "glue/mrpc": 0.13087451457977295,
        "kilt_tasks/hotpotqa": 0.11543256044387817
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3632,
        "ag_news": 3768,
        "amazon_polarity": 3808,
        "cnn_dailymail/3.0.0": 3552,
        "common_gen": 3664,
        "cos_e/v1.11": 3560,
        "glue/mrpc": 3632,
        "kilt_tasks/hotpotqa": 3824
      },
      "step": 230
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -47.46461486816406,
        "ag_news": 88.06492614746094,
        "amazon_polarity": 83.23192596435547,
        "cnn_dailymail/3.0.0": 51.12188720703125,
        "common_gen": -14.55427074432373,
        "cos_e/v1.11": 51.27650833129883,
        "glue/mrpc": 52.92262649536133,
        "kilt_tasks/hotpotqa": 2.9042885303497314
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4396,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10101079195737839,
        "ag_news": 0.14282023906707764,
        "amazon_polarity": 0.1410609483718872,
        "cnn_dailymail/3.0.0": 0.12991976737976074,
        "common_gen": 0.10984611511230469,
        "cos_e/v1.11": 0.1299712210893631,
        "glue/mrpc": 0.13052015006542206,
        "kilt_tasks/hotpotqa": 0.11485081166028976
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3776,
        "ag_news": 3912,
        "amazon_polarity": 3960,
        "cnn_dailymail/3.0.0": 3752,
        "common_gen": 3824,
        "cos_e/v1.11": 3696,
        "glue/mrpc": 3724,
        "kilt_tasks/hotpotqa": 4072
      },
      "step": 240
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.393131256103516,
        "ag_news": 88.04073333740234,
        "amazon_polarity": 83.19031524658203,
        "cnn_dailymail/3.0.0": 52.01875305175781,
        "common_gen": -12.774250984191895,
        "cos_e/v1.11": 50.34075164794922,
        "glue/mrpc": 54.37794876098633,
        "kilt_tasks/hotpotqa": 0.7854352593421936
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4024,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10212014615535736,
        "ag_news": 0.14229236543178558,
        "amazon_polarity": 0.140568345785141,
        "cnn_dailymail/3.0.0": 0.12998531758785248,
        "common_gen": 0.11051252484321594,
        "cos_e/v1.11": 0.12943923473358154,
        "glue/mrpc": 0.13075709342956543,
        "kilt_tasks/hotpotqa": 0.11432494223117828
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3904,
        "ag_news": 4064,
        "amazon_polarity": 4112,
        "cnn_dailymail/3.0.0": 3936,
        "common_gen": 4008,
        "cos_e/v1.11": 3840,
        "glue/mrpc": 3884,
        "kilt_tasks/hotpotqa": 4248
      },
      "step": 250
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -42.52517318725586,
        "ag_news": 87.8689956665039,
        "amazon_polarity": 83.22014617919922,
        "cnn_dailymail/3.0.0": 56.68357849121094,
        "common_gen": -16.376432418823242,
        "cos_e/v1.11": 49.91593933105469,
        "glue/mrpc": 53.92006301879883,
        "kilt_tasks/hotpotqa": -2.049004077911377
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3728,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1030101329088211,
        "ag_news": 0.1419135481119156,
        "amazon_polarity": 0.14029674232006073,
        "cnn_dailymail/3.0.0": 0.13142021000385284,
        "common_gen": 0.109825998544693,
        "cos_e/v1.11": 0.1292494237422943,
        "glue/mrpc": 0.13052934408187866,
        "kilt_tasks/hotpotqa": 0.11375459283590317
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4008,
        "ag_news": 4248,
        "amazon_polarity": 4240,
        "cnn_dailymail/3.0.0": 4088,
        "common_gen": 4152,
        "cos_e/v1.11": 4048,
        "glue/mrpc": 4020,
        "kilt_tasks/hotpotqa": 4472
      },
      "step": 260
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -39.67915725708008,
        "ag_news": 88.38211059570312,
        "amazon_polarity": 83.12454986572266,
        "cnn_dailymail/3.0.0": 58.23623275756836,
        "common_gen": -14.857837677001953,
        "cos_e/v1.11": 50.75331497192383,
        "glue/mrpc": 53.0230827331543,
        "kilt_tasks/hotpotqa": -3.851850986480713
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.401,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10397030413150787,
        "ag_news": 0.14159709215164185,
        "amazon_polarity": 0.13980761170387268,
        "cnn_dailymail/3.0.0": 0.13164401054382324,
        "common_gen": 0.11036735028028488,
        "cos_e/v1.11": 0.1292857676744461,
        "glue/mrpc": 0.12999649345874786,
        "kilt_tasks/hotpotqa": 0.1133313849568367
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4152,
        "ag_news": 4376,
        "amazon_polarity": 4376,
        "cnn_dailymail/3.0.0": 4248,
        "common_gen": 4328,
        "cos_e/v1.11": 4248,
        "glue/mrpc": 4180,
        "kilt_tasks/hotpotqa": 4648
      },
      "step": 270
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -38.3173828125,
        "ag_news": 88.3995361328125,
        "amazon_polarity": 79.67469024658203,
        "cnn_dailymail/3.0.0": 63.871551513671875,
        "common_gen": -10.107839584350586,
        "cos_e/v1.11": 54.344818115234375,
        "glue/mrpc": 50.36296081542969,
        "kilt_tasks/hotpotqa": -0.19243907928466797
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2125,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10429329425096512,
        "ag_news": 0.14080892503261566,
        "amazon_polarity": 0.1379205882549286,
        "cnn_dailymail/3.0.0": 0.1328415721654892,
        "common_gen": 0.1114831268787384,
        "cos_e/v1.11": 0.1298721879720688,
        "glue/mrpc": 0.1286512017250061,
        "kilt_tasks/hotpotqa": 0.11412902921438217
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4272,
        "ag_news": 4592,
        "amazon_polarity": 4552,
        "cnn_dailymail/3.0.0": 4392,
        "common_gen": 4440,
        "cos_e/v1.11": 4440,
        "glue/mrpc": 4340,
        "kilt_tasks/hotpotqa": 4808
      },
      "step": 280
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -51.54484176635742,
        "ag_news": 89.24174499511719,
        "amazon_polarity": 79.68170166015625,
        "cnn_dailymail/3.0.0": 66.41065216064453,
        "common_gen": -11.21291446685791,
        "cos_e/v1.11": 49.893096923828125,
        "glue/mrpc": 49.44456100463867,
        "kilt_tasks/hotpotqa": 3.5866329669952393
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1421,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10176647454500198,
        "ag_news": 0.14123262465000153,
        "amazon_polarity": 0.13811525702476501,
        "cnn_dailymail/3.0.0": 0.13390344381332397,
        "common_gen": 0.11175841838121414,
        "cos_e/v1.11": 0.12884339690208435,
        "glue/mrpc": 0.12870875000953674,
        "kilt_tasks/hotpotqa": 0.11567167937755585
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4456,
        "ag_news": 4792,
        "amazon_polarity": 4736,
        "cnn_dailymail/3.0.0": 4520,
        "common_gen": 4552,
        "cos_e/v1.11": 4608,
        "glue/mrpc": 4508,
        "kilt_tasks/hotpotqa": 4944
      },
      "step": 290
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -45.3052864074707,
        "ag_news": 89.12261199951172,
        "amazon_polarity": 79.3902816772461,
        "cnn_dailymail/3.0.0": 76.26763153076172,
        "common_gen": -9.626503944396973,
        "cos_e/v1.11": 43.69979476928711,
        "glue/mrpc": 48.05316162109375,
        "kilt_tasks/hotpotqa": 7.028329849243164
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3197,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10322793573141098,
        "ag_news": 0.14042937755584717,
        "amazon_polarity": 0.1373267024755478,
        "cnn_dailymail/3.0.0": 0.13634605705738068,
        "common_gen": 0.11199306696653366,
        "cos_e/v1.11": 0.12653329968452454,
        "glue/mrpc": 0.12780216336250305,
        "kilt_tasks/hotpotqa": 0.11634141206741333
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4608,
        "ag_news": 4880,
        "amazon_polarity": 4944,
        "cnn_dailymail/3.0.0": 4752,
        "common_gen": 4704,
        "cos_e/v1.11": 4792,
        "glue/mrpc": 4660,
        "kilt_tasks/hotpotqa": 5056
      },
      "step": 300
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.75,
      "eval_runtime": 0.1841,
      "eval_samples_per_second": 86.92,
      "eval_steps_per_second": 5.433,
      "step": 300
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -40.38495635986328,
        "ag_news": 88.22018432617188,
        "amazon_polarity": 79.21617889404297,
        "cnn_dailymail/3.0.0": 80.88758087158203,
        "common_gen": -7.381166458129883,
        "cos_e/v1.11": 41.93656539916992,
        "glue/mrpc": 50.085899353027344,
        "kilt_tasks/hotpotqa": 5.467986583709717
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3589,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10444530099630356,
        "ag_news": 0.13954544067382812,
        "amazon_polarity": 0.13673636317253113,
        "cnn_dailymail/3.0.0": 0.13725341856479645,
        "common_gen": 0.11248915642499924,
        "cos_e/v1.11": 0.12570470571517944,
        "glue/mrpc": 0.12803621590137482,
        "kilt_tasks/hotpotqa": 0.11578945070505142
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4760,
        "ag_news": 5040,
        "amazon_polarity": 5056,
        "cnn_dailymail/3.0.0": 4952,
        "common_gen": 4888,
        "cos_e/v1.11": 4960,
        "glue/mrpc": 4804,
        "kilt_tasks/hotpotqa": 5216
      },
      "step": 310
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -43.72883224487305,
        "ag_news": 88.1473617553711,
        "amazon_polarity": 79.2113037109375,
        "cnn_dailymail/3.0.0": 84.05419158935547,
        "common_gen": -9.352498054504395,
        "cos_e/v1.11": 42.80379104614258,
        "glue/mrpc": 49.03652572631836,
        "kilt_tasks/hotpotqa": 1.7894508838653564
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1829,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10410920530557632,
        "ag_news": 0.13947799801826477,
        "amazon_polarity": 0.136734277009964,
        "cnn_dailymail/3.0.0": 0.1382143497467041,
        "common_gen": 0.11233851313591003,
        "cos_e/v1.11": 0.12611132860183716,
        "glue/mrpc": 0.1278684437274933,
        "kilt_tasks/hotpotqa": 0.11514592915773392
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4936,
        "ag_news": 5216,
        "amazon_polarity": 5216,
        "cnn_dailymail/3.0.0": 5112,
        "common_gen": 5072,
        "cos_e/v1.11": 5104,
        "glue/mrpc": 4980,
        "kilt_tasks/hotpotqa": 5320
      },
      "step": 320
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -47.60050582885742,
        "ag_news": 88.0045166015625,
        "amazon_polarity": 79.17013549804688,
        "cnn_dailymail/3.0.0": 88.30919647216797,
        "common_gen": -10.739142417907715,
        "cos_e/v1.11": 44.83457565307617,
        "glue/mrpc": 47.01953125,
        "kilt_tasks/hotpotqa": 6.613306999206543
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3887,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10339945554733276,
        "ag_news": 0.13904176652431488,
        "amazon_polarity": 0.13637803494930267,
        "cnn_dailymail/3.0.0": 0.13913457095623016,
        "common_gen": 0.11204947531223297,
        "cos_e/v1.11": 0.12650856375694275,
        "glue/mrpc": 0.127114400267601,
        "kilt_tasks/hotpotqa": 0.11637374013662338
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5088,
        "ag_news": 5376,
        "amazon_polarity": 5360,
        "cnn_dailymail/3.0.0": 5280,
        "common_gen": 5264,
        "cos_e/v1.11": 5272,
        "glue/mrpc": 5124,
        "kilt_tasks/hotpotqa": 5472
      },
      "step": 330
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -49.419273376464844,
        "ag_news": 87.8018798828125,
        "amazon_polarity": 78.96255493164062,
        "cnn_dailymail/3.0.0": 94.5934829711914,
        "common_gen": -6.838151454925537,
        "cos_e/v1.11": 41.2098274230957,
        "glue/mrpc": 43.266517639160156,
        "kilt_tasks/hotpotqa": 3.7065181732177734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1796,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10333272814750671,
        "ag_news": 0.13883265852928162,
        "amazon_polarity": 0.13621018826961517,
        "cnn_dailymail/3.0.0": 0.14088241755962372,
        "common_gen": 0.11322943866252899,
        "cos_e/v1.11": 0.1255643516778946,
        "glue/mrpc": 0.1261219084262848,
        "kilt_tasks/hotpotqa": 0.1158263087272644
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5208,
        "ag_news": 5576,
        "amazon_polarity": 5544,
        "cnn_dailymail/3.0.0": 5488,
        "common_gen": 5392,
        "cos_e/v1.11": 5368,
        "glue/mrpc": 5300,
        "kilt_tasks/hotpotqa": 5640
      },
      "step": 340
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.995182037353516,
        "ag_news": 87.68850708007812,
        "amazon_polarity": 78.90350341796875,
        "cnn_dailymail/3.0.0": 94.78758239746094,
        "common_gen": -5.774703025817871,
        "cos_e/v1.11": 39.0579948425293,
        "glue/mrpc": 45.429786682128906,
        "kilt_tasks/hotpotqa": 5.72149133682251
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3692,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10441258549690247,
        "ag_news": 0.1383606195449829,
        "amazon_polarity": 0.13579975068569183,
        "cnn_dailymail/3.0.0": 0.1404658555984497,
        "common_gen": 0.11345541477203369,
        "cos_e/v1.11": 0.12477578222751617,
        "glue/mrpc": 0.126475527882576,
        "kilt_tasks/hotpotqa": 0.11625451594591141
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5344,
        "ag_news": 5744,
        "amazon_polarity": 5712,
        "cnn_dailymail/3.0.0": 5664,
        "common_gen": 5536,
        "cos_e/v1.11": 5528,
        "glue/mrpc": 5404,
        "kilt_tasks/hotpotqa": 5864
      },
      "step": 350
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -50.801849365234375,
        "ag_news": 87.59718322753906,
        "amazon_polarity": 78.80445098876953,
        "cnn_dailymail/3.0.0": 94.10012817382812,
        "common_gen": -8.492542266845703,
        "cos_e/v1.11": 40.033355712890625,
        "glue/mrpc": 43.021724700927734,
        "kilt_tasks/hotpotqa": 7.374269008636475
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2306,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10363892465829849,
        "ag_news": 0.138445645570755,
        "amazon_polarity": 0.1359160989522934,
        "cnn_dailymail/3.0.0": 0.14034715294837952,
        "common_gen": 0.11321291327476501,
        "cos_e/v1.11": 0.12531037628650665,
        "glue/mrpc": 0.12609703838825226,
        "kilt_tasks/hotpotqa": 0.11703174561262131
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5520,
        "ag_news": 5952,
        "amazon_polarity": 5848,
        "cnn_dailymail/3.0.0": 5816,
        "common_gen": 5648,
        "cos_e/v1.11": 5696,
        "glue/mrpc": 5564,
        "kilt_tasks/hotpotqa": 6032
      },
      "step": 360
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.30895233154297,
        "ag_news": 87.57836151123047,
        "amazon_polarity": 78.7394027709961,
        "cnn_dailymail/3.0.0": 97.78116607666016,
        "common_gen": -4.672701358795166,
        "cos_e/v1.11": 39.09447479248047,
        "glue/mrpc": 42.806766510009766,
        "kilt_tasks/hotpotqa": 12.886436462402344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2572,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10484659671783447,
        "ag_news": 0.1376546025276184,
        "amazon_polarity": 0.13516037166118622,
        "cnn_dailymail/3.0.0": 0.14059187471866608,
        "common_gen": 0.11376972496509552,
        "cos_e/v1.11": 0.12452579289674759,
        "glue/mrpc": 0.1254844218492508,
        "kilt_tasks/hotpotqa": 0.11796656996011734
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5632,
        "ag_news": 6088,
        "amazon_polarity": 6040,
        "cnn_dailymail/3.0.0": 5944,
        "common_gen": 5808,
        "cos_e/v1.11": 5896,
        "glue/mrpc": 5756,
        "kilt_tasks/hotpotqa": 6192
      },
      "step": 370
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -46.44834518432617,
        "ag_news": 87.47608947753906,
        "amazon_polarity": 78.35791015625,
        "cnn_dailymail/3.0.0": 97.73111724853516,
        "common_gen": -3.277222156524658,
        "cos_e/v1.11": 36.463661193847656,
        "glue/mrpc": 42.8369026184082,
        "kilt_tasks/hotpotqa": 14.644538879394531
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1412,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10469141602516174,
        "ag_news": 0.13753096759319305,
        "amazon_polarity": 0.13499443233013153,
        "cnn_dailymail/3.0.0": 0.1404416561126709,
        "common_gen": 0.11429930478334427,
        "cos_e/v1.11": 0.12393701076507568,
        "glue/mrpc": 0.12555783987045288,
        "kilt_tasks/hotpotqa": 0.11854741722345352
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5800,
        "ag_news": 6312,
        "amazon_polarity": 6216,
        "cnn_dailymail/3.0.0": 6048,
        "common_gen": 5976,
        "cos_e/v1.11": 6032,
        "glue/mrpc": 5932,
        "kilt_tasks/hotpotqa": 6320
      },
      "step": 380
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -46.26902389526367,
        "ag_news": 87.33582305908203,
        "amazon_polarity": 78.21440124511719,
        "cnn_dailymail/3.0.0": 96.72539520263672,
        "common_gen": -3.566802740097046,
        "cos_e/v1.11": 35.786888122558594,
        "glue/mrpc": 43.990535736083984,
        "kilt_tasks/hotpotqa": 14.568070411682129
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2428,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10500120371580124,
        "ag_news": 0.13737142086029053,
        "amazon_polarity": 0.1348690390586853,
        "cnn_dailymail/3.0.0": 0.13999661803245544,
        "common_gen": 0.11440211534500122,
        "cos_e/v1.11": 0.12382412701845169,
        "glue/mrpc": 0.12588562071323395,
        "kilt_tasks/hotpotqa": 0.11864979565143585
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5952,
        "ag_news": 6496,
        "amazon_polarity": 6384,
        "cnn_dailymail/3.0.0": 6232,
        "common_gen": 6152,
        "cos_e/v1.11": 6200,
        "glue/mrpc": 6044,
        "kilt_tasks/hotpotqa": 6456
      },
      "step": 390
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -45.30710983276367,
        "ag_news": 86.30435943603516,
        "amazon_polarity": 77.78038787841797,
        "cnn_dailymail/3.0.0": 99.3329849243164,
        "common_gen": 2.698941707611084,
        "cos_e/v1.11": 36.80060958862305,
        "glue/mrpc": 44.47906494140625,
        "kilt_tasks/hotpotqa": 9.56335735321045
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4047,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10531270503997803,
        "ag_news": 0.13677671551704407,
        "amazon_polarity": 0.13447585701942444,
        "cnn_dailymail/3.0.0": 0.14037096500396729,
        "common_gen": 0.11583303660154343,
        "cos_e/v1.11": 0.12395097315311432,
        "glue/mrpc": 0.12585727870464325,
        "kilt_tasks/hotpotqa": 0.11742246896028519
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6096,
        "ag_news": 6592,
        "amazon_polarity": 6568,
        "cnn_dailymail/3.0.0": 6424,
        "common_gen": 6368,
        "cos_e/v1.11": 6360,
        "glue/mrpc": 6140,
        "kilt_tasks/hotpotqa": 6648
      },
      "step": 400
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.75,
      "eval_runtime": 0.1657,
      "eval_samples_per_second": 96.539,
      "eval_steps_per_second": 6.034,
      "step": 400
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -47.18948745727539,
        "ag_news": 85.4053955078125,
        "amazon_polarity": 77.67464447021484,
        "cnn_dailymail/3.0.0": 98.5206069946289,
        "common_gen": 3.4856812953948975,
        "cos_e/v1.11": 40.02671813964844,
        "glue/mrpc": 40.584590911865234,
        "kilt_tasks/hotpotqa": 13.40321159362793
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3272,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10514666140079498,
        "ag_news": 0.13639061152935028,
        "amazon_polarity": 0.1343332678079605,
        "cnn_dailymail/3.0.0": 0.13995428383350372,
        "common_gen": 0.1161230057477951,
        "cos_e/v1.11": 0.12475566565990448,
        "glue/mrpc": 0.12489240616559982,
        "kilt_tasks/hotpotqa": 0.1184040904045105
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6288,
        "ag_news": 6792,
        "amazon_polarity": 6656,
        "cnn_dailymail/3.0.0": 6560,
        "common_gen": 6560,
        "cos_e/v1.11": 6552,
        "glue/mrpc": 6276,
        "kilt_tasks/hotpotqa": 6792
      },
      "step": 410
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -46.76142883300781,
        "ag_news": 85.16354370117188,
        "amazon_polarity": 77.53487396240234,
        "cnn_dailymail/3.0.0": 101.35205841064453,
        "common_gen": 3.241152048110962,
        "cos_e/v1.11": 40.07388687133789,
        "glue/mrpc": 39.990352630615234,
        "kilt_tasks/hotpotqa": 9.283289909362793
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2276,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10549291223287582,
        "ag_news": 0.13624276220798492,
        "amazon_polarity": 0.13423849642276764,
        "cnn_dailymail/3.0.0": 0.14059710502624512,
        "common_gen": 0.11621775478124619,
        "cos_e/v1.11": 0.12482225149869919,
        "glue/mrpc": 0.12480201572179794,
        "kilt_tasks/hotpotqa": 0.11758676916360855
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6424,
        "ag_news": 7032,
        "amazon_polarity": 6832,
        "cnn_dailymail/3.0.0": 6728,
        "common_gen": 6696,
        "cos_e/v1.11": 6720,
        "glue/mrpc": 6364,
        "kilt_tasks/hotpotqa": 6960
      },
      "step": 420
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -46.439308166503906,
        "ag_news": 85.06559753417969,
        "amazon_polarity": 77.43608856201172,
        "cnn_dailymail/3.0.0": 102.7020263671875,
        "common_gen": 3.2788991928100586,
        "cos_e/v1.11": 39.80256652832031,
        "glue/mrpc": 39.77156448364258,
        "kilt_tasks/hotpotqa": 8.305764198303223
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2832,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10576426237821579,
        "ag_news": 0.13608084619045258,
        "amazon_polarity": 0.13410179316997528,
        "cnn_dailymail/3.0.0": 0.1407698094844818,
        "common_gen": 0.11632359027862549,
        "cos_e/v1.11": 0.12475891411304474,
        "glue/mrpc": 0.1247514933347702,
        "kilt_tasks/hotpotqa": 0.11744923889636993
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6576,
        "ag_news": 7200,
        "amazon_polarity": 6952,
        "cnn_dailymail/3.0.0": 6864,
        "common_gen": 6880,
        "cos_e/v1.11": 6912,
        "glue/mrpc": 6548,
        "kilt_tasks/hotpotqa": 7104
      },
      "step": 430
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -50.5964241027832,
        "ag_news": 85.00370025634766,
        "amazon_polarity": 77.44386291503906,
        "cnn_dailymail/3.0.0": 104.147705078125,
        "common_gen": 4.962678909301758,
        "cos_e/v1.11": 40.2751350402832,
        "glue/mrpc": 42.05891036987305,
        "kilt_tasks/hotpotqa": 7.279372215270996
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3889,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10510297864675522,
        "ag_news": 0.13589385151863098,
        "amazon_polarity": 0.13395747542381287,
        "cnn_dailymail/3.0.0": 0.1409253627061844,
        "common_gen": 0.11675543338060379,
        "cos_e/v1.11": 0.1248365193605423,
        "glue/mrpc": 0.12525950372219086,
        "kilt_tasks/hotpotqa": 0.11726891994476318
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6760,
        "ag_news": 7368,
        "amazon_polarity": 7064,
        "cnn_dailymail/3.0.0": 7136,
        "common_gen": 7080,
        "cos_e/v1.11": 7048,
        "glue/mrpc": 6628,
        "kilt_tasks/hotpotqa": 7232
      },
      "step": 440
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -48.82255554199219,
        "ag_news": 85.0533676147461,
        "amazon_polarity": 77.18736267089844,
        "cnn_dailymail/3.0.0": 108.34679412841797,
        "common_gen": 7.041013717651367,
        "cos_e/v1.11": 42.46007537841797,
        "glue/mrpc": 41.35525894165039,
        "kilt_tasks/hotpotqa": 4.1812591552734375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2039,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1054968312382698,
        "ag_news": 0.13557834923267365,
        "amazon_polarity": 0.1335909515619278,
        "cnn_dailymail/3.0.0": 0.1416412740945816,
        "common_gen": 0.11712460964918137,
        "cos_e/v1.11": 0.12516410648822784,
        "glue/mrpc": 0.1249050498008728,
        "kilt_tasks/hotpotqa": 0.11649885773658752
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6872,
        "ag_news": 7552,
        "amazon_polarity": 7240,
        "cnn_dailymail/3.0.0": 7296,
        "common_gen": 7224,
        "cos_e/v1.11": 7184,
        "glue/mrpc": 6836,
        "kilt_tasks/hotpotqa": 7392
      },
      "step": 450
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -53.912689208984375,
        "ag_news": 84.75751495361328,
        "amazon_polarity": 77.130615234375,
        "cnn_dailymail/3.0.0": 109.61741638183594,
        "common_gen": 10.927268981933594,
        "cos_e/v1.11": 40.17958450317383,
        "glue/mrpc": 42.14468002319336,
        "kilt_tasks/hotpotqa": 4.150640964508057
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2556,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1047300398349762,
        "ag_news": 0.13542447984218597,
        "amazon_polarity": 0.1335199624300003,
        "cnn_dailymail/3.0.0": 0.14182566106319427,
        "common_gen": 0.11808866262435913,
        "cos_e/v1.11": 0.12467046827077866,
        "glue/mrpc": 0.12512575089931488,
        "kilt_tasks/hotpotqa": 0.11661495268344879
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7032,
        "ag_news": 7744,
        "amazon_polarity": 7344,
        "cnn_dailymail/3.0.0": 7384,
        "common_gen": 7352,
        "cos_e/v1.11": 7400,
        "glue/mrpc": 7020,
        "kilt_tasks/hotpotqa": 7600
      },
      "step": 460
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -57.098445892333984,
        "ag_news": 84.61917114257812,
        "amazon_polarity": 76.94863891601562,
        "cnn_dailymail/3.0.0": 112.22490692138672,
        "common_gen": 8.764460563659668,
        "cos_e/v1.11": 38.903045654296875,
        "glue/mrpc": 42.983863830566406,
        "kilt_tasks/hotpotqa": 0.5731744170188904
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1596,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10445958375930786,
        "ag_news": 0.13546255230903625,
        "amazon_polarity": 0.13356679677963257,
        "cnn_dailymail/3.0.0": 0.14251384139060974,
        "common_gen": 0.11785458773374557,
        "cos_e/v1.11": 0.12455419450998306,
        "glue/mrpc": 0.12549060583114624,
        "kilt_tasks/hotpotqa": 0.1160978153347969
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7200,
        "ag_news": 7896,
        "amazon_polarity": 7552,
        "cnn_dailymail/3.0.0": 7496,
        "common_gen": 7528,
        "cos_e/v1.11": 7552,
        "glue/mrpc": 7196,
        "kilt_tasks/hotpotqa": 7736
      },
      "step": 470
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.8742790222168,
        "ag_news": 84.54174041748047,
        "amazon_polarity": 77.02257537841797,
        "cnn_dailymail/3.0.0": 114.43172454833984,
        "common_gen": 11.843910217285156,
        "cos_e/v1.11": 36.223480224609375,
        "glue/mrpc": 42.24266815185547,
        "kilt_tasks/hotpotqa": -1.1853327751159668
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3547,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10400961339473724,
        "ag_news": 0.1354212760925293,
        "amazon_polarity": 0.13358238339424133,
        "cnn_dailymail/3.0.0": 0.14298853278160095,
        "common_gen": 0.11866661161184311,
        "cos_e/v1.11": 0.12403704226016998,
        "glue/mrpc": 0.12540055811405182,
        "kilt_tasks/hotpotqa": 0.11589392274618149
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7328,
        "ag_news": 8056,
        "amazon_polarity": 7664,
        "cnn_dailymail/3.0.0": 7704,
        "common_gen": 7696,
        "cos_e/v1.11": 7688,
        "glue/mrpc": 7360,
        "kilt_tasks/hotpotqa": 7936
      },
      "step": 480
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -59.53464126586914,
        "ag_news": 84.38929748535156,
        "amazon_polarity": 76.94127655029297,
        "cnn_dailymail/3.0.0": 117.93295288085938,
        "common_gen": 19.37298011779785,
        "cos_e/v1.11": 39.075279235839844,
        "glue/mrpc": 44.93925094604492,
        "kilt_tasks/hotpotqa": -2.682035446166992
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1947,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10407963395118713,
        "ag_news": 0.13478758931159973,
        "amazon_polarity": 0.13299289345741272,
        "cnn_dailymail/3.0.0": 0.1431794911623001,
        "common_gen": 0.11991417407989502,
        "cos_e/v1.11": 0.12423652410507202,
        "glue/mrpc": 0.12555328011512756,
        "kilt_tasks/hotpotqa": 0.11525645852088928
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7456,
        "ag_news": 8248,
        "amazon_polarity": 7824,
        "cnn_dailymail/3.0.0": 7864,
        "common_gen": 7896,
        "cos_e/v1.11": 7816,
        "glue/mrpc": 7536,
        "kilt_tasks/hotpotqa": 8072
      },
      "step": 490
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -64.436279296875,
        "ag_news": 84.19085693359375,
        "amazon_polarity": 76.82429504394531,
        "cnn_dailymail/3.0.0": 120.15076446533203,
        "common_gen": 15.391885757446289,
        "cos_e/v1.11": 39.365867614746094,
        "glue/mrpc": 45.01691818237305,
        "kilt_tasks/hotpotqa": -7.093592166900635
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2884,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10358469933271408,
        "ag_news": 0.13492532074451447,
        "amazon_polarity": 0.1331658661365509,
        "cnn_dailymail/3.0.0": 0.14385828375816345,
        "common_gen": 0.11937010288238525,
        "cos_e/v1.11": 0.12457256764173508,
        "glue/mrpc": 0.12583202123641968,
        "kilt_tasks/hotpotqa": 0.11469119042158127
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7616,
        "ag_news": 8384,
        "amazon_polarity": 7992,
        "cnn_dailymail/3.0.0": 8088,
        "common_gen": 8040,
        "cos_e/v1.11": 7952,
        "glue/mrpc": 7688,
        "kilt_tasks/hotpotqa": 8232
      },
      "step": 500
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.1666,
      "eval_samples_per_second": 96.058,
      "eval_steps_per_second": 6.004,
      "step": 500
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -64.28968811035156,
        "ag_news": 84.09542846679688,
        "amazon_polarity": 76.73818969726562,
        "cnn_dailymail/3.0.0": 119.62348937988281,
        "common_gen": 8.872217178344727,
        "cos_e/v1.11": 39.427677154541016,
        "glue/mrpc": 41.494178771972656,
        "kilt_tasks/hotpotqa": -2.8053946495056152
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0557,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10395148396492004,
        "ag_news": 0.13499851524829865,
        "amazon_polarity": 0.13325737416744232,
        "cnn_dailymail/3.0.0": 0.14373666048049927,
        "common_gen": 0.1182318776845932,
        "cos_e/v1.11": 0.12477168440818787,
        "glue/mrpc": 0.12522701919078827,
        "kilt_tasks/hotpotqa": 0.11582539975643158
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7808,
        "ag_news": 8560,
        "amazon_polarity": 8176,
        "cnn_dailymail/3.0.0": 8248,
        "common_gen": 8168,
        "cos_e/v1.11": 8064,
        "glue/mrpc": 7896,
        "kilt_tasks/hotpotqa": 8352
      },
      "step": 510
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -62.483802795410156,
        "ag_news": 84.0363998413086,
        "amazon_polarity": 76.66578674316406,
        "cnn_dailymail/3.0.0": 119.99735260009766,
        "common_gen": 7.414274215698242,
        "cos_e/v1.11": 39.493160247802734,
        "glue/mrpc": 41.522132873535156,
        "kilt_tasks/hotpotqa": -0.8144112229347229
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1978,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10441319644451141,
        "ag_news": 0.13482162356376648,
        "amazon_polarity": 0.13309620320796967,
        "cnn_dailymail/3.0.0": 0.14357058703899384,
        "common_gen": 0.11793877184391022,
        "cos_e/v1.11": 0.12472936511039734,
        "glue/mrpc": 0.125171959400177,
        "kilt_tasks/hotpotqa": 0.1162581816315651
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7968,
        "ag_news": 8696,
        "amazon_polarity": 8328,
        "cnn_dailymail/3.0.0": 8320,
        "common_gen": 8400,
        "cos_e/v1.11": 8216,
        "glue/mrpc": 8128,
        "kilt_tasks/hotpotqa": 8496
      },
      "step": 520
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -65.48199462890625,
        "ag_news": 84.02645111083984,
        "amazon_polarity": 76.63526916503906,
        "cnn_dailymail/3.0.0": 125.80961608886719,
        "common_gen": 8.160799026489258,
        "cos_e/v1.11": 32.22410583496094,
        "glue/mrpc": 40.343544006347656,
        "kilt_tasks/hotpotqa": 2.358440399169922
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2737,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10406623035669327,
        "ag_news": 0.13474509119987488,
        "amazon_polarity": 0.13303200900554657,
        "cnn_dailymail/3.0.0": 0.14485833048820496,
        "common_gen": 0.11817421764135361,
        "cos_e/v1.11": 0.12319344282150269,
        "glue/mrpc": 0.12493539601564407,
        "kilt_tasks/hotpotqa": 0.11699531227350235
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8112,
        "ag_news": 8888,
        "amazon_polarity": 8472,
        "cnn_dailymail/3.0.0": 8472,
        "common_gen": 8576,
        "cos_e/v1.11": 8352,
        "glue/mrpc": 8280,
        "kilt_tasks/hotpotqa": 8680
      },
      "step": 530
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -67.37577819824219,
        "ag_news": 83.93995666503906,
        "amazon_polarity": 76.64067077636719,
        "cnn_dailymail/3.0.0": 127.94174194335938,
        "common_gen": 6.291223526000977,
        "cos_e/v1.11": 29.38383674621582,
        "glue/mrpc": 41.008331298828125,
        "kilt_tasks/hotpotqa": 0.8477466106414795
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2279,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10400868207216263,
        "ag_news": 0.13476718962192535,
        "amazon_polarity": 0.13309048116207123,
        "cnn_dailymail/3.0.0": 0.14533798396587372,
        "common_gen": 0.11797559261322021,
        "cos_e/v1.11": 0.1227349042892456,
        "glue/mrpc": 0.1252039223909378,
        "kilt_tasks/hotpotqa": 0.11688125878572464
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8216,
        "ag_news": 9024,
        "amazon_polarity": 8712,
        "cnn_dailymail/3.0.0": 8664,
        "common_gen": 8736,
        "cos_e/v1.11": 8544,
        "glue/mrpc": 8424,
        "kilt_tasks/hotpotqa": 8792
      },
      "step": 540
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -74.49412536621094,
        "ag_news": 83.73097229003906,
        "amazon_polarity": 76.52660369873047,
        "cnn_dailymail/3.0.0": 130.32337951660156,
        "common_gen": 10.187902450561523,
        "cos_e/v1.11": 32.57294845581055,
        "glue/mrpc": 36.81421661376953,
        "kilt_tasks/hotpotqa": -1.6317938566207886
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2589,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10300537198781967,
        "ag_news": 0.13472265005111694,
        "amazon_polarity": 0.1330830305814743,
        "cnn_dailymail/3.0.0": 0.14583194255828857,
        "common_gen": 0.11890392750501633,
        "cos_e/v1.11": 0.12350860238075256,
        "glue/mrpc": 0.12440120428800583,
        "kilt_tasks/hotpotqa": 0.11654326319694519
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8480,
        "ag_news": 9200,
        "amazon_polarity": 8832,
        "cnn_dailymail/3.0.0": 8856,
        "common_gen": 8920,
        "cos_e/v1.11": 8656,
        "glue/mrpc": 8520,
        "kilt_tasks/hotpotqa": 8928
      },
      "step": 550
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -78.11548614501953,
        "ag_news": 83.53082275390625,
        "amazon_polarity": 76.3440933227539,
        "cnn_dailymail/3.0.0": 134.5119171142578,
        "common_gen": 9.400542259216309,
        "cos_e/v1.11": 33.2943229675293,
        "glue/mrpc": 37.78919219970703,
        "kilt_tasks/hotpotqa": 8.411104202270508
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3063,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10230589658021927,
        "ag_news": 0.13425694406032562,
        "amazon_polarity": 0.13264146447181702,
        "cnn_dailymail/3.0.0": 0.14630372822284698,
        "common_gen": 0.11850788444280624,
        "cos_e/v1.11": 0.1233682855963707,
        "glue/mrpc": 0.12430497258901596,
        "kilt_tasks/hotpotqa": 0.1183108538389206
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8600,
        "ag_news": 9352,
        "amazon_polarity": 8968,
        "cnn_dailymail/3.0.0": 9024,
        "common_gen": 9096,
        "cos_e/v1.11": 8872,
        "glue/mrpc": 8688,
        "kilt_tasks/hotpotqa": 9072
      },
      "step": 560
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -79.36589050292969,
        "ag_news": 83.39189910888672,
        "amazon_polarity": 75.98331451416016,
        "cnn_dailymail/3.0.0": 136.78646850585938,
        "common_gen": 10.542176246643066,
        "cos_e/v1.11": 31.54034423828125,
        "glue/mrpc": 37.340248107910156,
        "kilt_tasks/hotpotqa": 5.052794933319092
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1622,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1023426204919815,
        "ag_news": 0.13423602283000946,
        "amazon_polarity": 0.13258567452430725,
        "cnn_dailymail/3.0.0": 0.14676202833652496,
        "common_gen": 0.11887185275554657,
        "cos_e/v1.11": 0.12310798466205597,
        "glue/mrpc": 0.12430480867624283,
        "kilt_tasks/hotpotqa": 0.11778902262449265
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8784,
        "ag_news": 9568,
        "amazon_polarity": 9096,
        "cnn_dailymail/3.0.0": 9216,
        "common_gen": 9256,
        "cos_e/v1.11": 9024,
        "glue/mrpc": 8816,
        "kilt_tasks/hotpotqa": 9192
      },
      "step": 570
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -82.61500549316406,
        "ag_news": 83.2796859741211,
        "amazon_polarity": 75.83846282958984,
        "cnn_dailymail/3.0.0": 137.99473571777344,
        "common_gen": 9.649357795715332,
        "cos_e/v1.11": 31.015493392944336,
        "glue/mrpc": 37.12271499633789,
        "kilt_tasks/hotpotqa": 1.3454915285110474
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2135,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10211241245269775,
        "ag_news": 0.1343173086643219,
        "amazon_polarity": 0.13267286121845245,
        "cnn_dailymail/3.0.0": 0.14706003665924072,
        "common_gen": 0.11891409754753113,
        "cos_e/v1.11": 0.12318973988294601,
        "glue/mrpc": 0.12444030493497849,
        "kilt_tasks/hotpotqa": 0.11729327589273453
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8944,
        "ag_news": 9688,
        "amazon_polarity": 9296,
        "cnn_dailymail/3.0.0": 9400,
        "common_gen": 9424,
        "cos_e/v1.11": 9192,
        "glue/mrpc": 8992,
        "kilt_tasks/hotpotqa": 9296
      },
      "step": 580
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -87.62175750732422,
        "ag_news": 83.24446868896484,
        "amazon_polarity": 75.65281677246094,
        "cnn_dailymail/3.0.0": 139.16458129882812,
        "common_gen": 5.147421360015869,
        "cos_e/v1.11": 32.52109146118164,
        "glue/mrpc": 36.499427795410156,
        "kilt_tasks/hotpotqa": 5.020500183105469
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4132,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10151594132184982,
        "ag_news": 0.13431300222873688,
        "amazon_polarity": 0.13264960050582886,
        "cnn_dailymail/3.0.0": 0.14723409712314606,
        "common_gen": 0.1181640699505806,
        "cos_e/v1.11": 0.12358740717172623,
        "glue/mrpc": 0.12439633905887604,
        "kilt_tasks/hotpotqa": 0.11813950538635254
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9112,
        "ag_news": 9840,
        "amazon_polarity": 9384,
        "cnn_dailymail/3.0.0": 9592,
        "common_gen": 9568,
        "cos_e/v1.11": 9392,
        "glue/mrpc": 9128,
        "kilt_tasks/hotpotqa": 9496
      },
      "step": 590
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -87.984130859375,
        "ag_news": 83.0849609375,
        "amazon_polarity": 75.50178527832031,
        "cnn_dailymail/3.0.0": 143.69915771484375,
        "common_gen": 0.8776051998138428,
        "cos_e/v1.11": 29.28626251220703,
        "glue/mrpc": 35.38833999633789,
        "kilt_tasks/hotpotqa": 6.405576705932617
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2326,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10168195515871048,
        "ag_news": 0.13426591455936432,
        "amazon_polarity": 0.13261865079402924,
        "cnn_dailymail/3.0.0": 0.14819975197315216,
        "common_gen": 0.11746079474687576,
        "cos_e/v1.11": 0.12301259487867355,
        "glue/mrpc": 0.12423941493034363,
        "kilt_tasks/hotpotqa": 0.1185208261013031
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9272,
        "ag_news": 10008,
        "amazon_polarity": 9536,
        "cnn_dailymail/3.0.0": 9744,
        "common_gen": 9752,
        "cos_e/v1.11": 9552,
        "glue/mrpc": 9280,
        "kilt_tasks/hotpotqa": 9648
      },
      "step": 600
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1845,
      "eval_samples_per_second": 86.73,
      "eval_steps_per_second": 5.421,
      "step": 600
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -93.2696304321289,
        "ag_news": 82.82574462890625,
        "amazon_polarity": 75.16912078857422,
        "cnn_dailymail/3.0.0": 148.21249389648438,
        "common_gen": 0.11817678064107895,
        "cos_e/v1.11": 26.712383270263672,
        "glue/mrpc": 33.67256546020508,
        "kilt_tasks/hotpotqa": 3.9620509147644043
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3492,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10113298147916794,
        "ag_news": 0.13432148098945618,
        "amazon_polarity": 0.13267114758491516,
        "cnn_dailymail/3.0.0": 0.149289071559906,
        "common_gen": 0.11754249036312103,
        "cos_e/v1.11": 0.12269233912229538,
        "glue/mrpc": 0.12407750636339188,
        "kilt_tasks/hotpotqa": 0.11827307194471359
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9416,
        "ag_news": 10160,
        "amazon_polarity": 9664,
        "cnn_dailymail/3.0.0": 9968,
        "common_gen": 9944,
        "cos_e/v1.11": 9672,
        "glue/mrpc": 9456,
        "kilt_tasks/hotpotqa": 9792
      },
      "step": 610
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -93.80867004394531,
        "ag_news": 82.61175537109375,
        "amazon_polarity": 75.16096496582031,
        "cnn_dailymail/3.0.0": 146.38600158691406,
        "common_gen": 2.494575262069702,
        "cos_e/v1.11": 25.086105346679688,
        "glue/mrpc": 30.62885856628418,
        "kilt_tasks/hotpotqa": 5.201359272003174
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.206,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10130375623703003,
        "ag_news": 0.13431307673454285,
        "amazon_polarity": 0.13271977007389069,
        "cnn_dailymail/3.0.0": 0.1487678736448288,
        "common_gen": 0.11814924329519272,
        "cos_e/v1.11": 0.12249665707349777,
        "glue/mrpc": 0.12358781695365906,
        "kilt_tasks/hotpotqa": 0.1186617761850357
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9584,
        "ag_news": 10336,
        "amazon_polarity": 9816,
        "cnn_dailymail/3.0.0": 10096,
        "common_gen": 10072,
        "cos_e/v1.11": 9829,
        "glue/mrpc": 9600,
        "kilt_tasks/hotpotqa": 10016
      },
      "step": 620
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -96.3668212890625,
        "ag_news": 82.91900634765625,
        "amazon_polarity": 75.17768859863281,
        "cnn_dailymail/3.0.0": 146.5559539794922,
        "common_gen": 5.245527267456055,
        "cos_e/v1.11": 22.15475082397461,
        "glue/mrpc": 30.317089080810547,
        "kilt_tasks/hotpotqa": 6.127367973327637
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1095,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10108987987041473,
        "ag_news": 0.13434052467346191,
        "amazon_polarity": 0.13269810378551483,
        "cnn_dailymail/3.0.0": 0.14864563941955566,
        "common_gen": 0.1187523901462555,
        "cos_e/v1.11": 0.12198202311992645,
        "glue/mrpc": 0.12357273697853088,
        "kilt_tasks/hotpotqa": 0.11891867220401764
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9704,
        "ag_news": 10520,
        "amazon_polarity": 9984,
        "cnn_dailymail/3.0.0": 10272,
        "common_gen": 10192,
        "cos_e/v1.11": 10013,
        "glue/mrpc": 9760,
        "kilt_tasks/hotpotqa": 10184
      },
      "step": 630
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -104.50921630859375,
        "ag_news": 82.80339813232422,
        "amazon_polarity": 75.13554382324219,
        "cnn_dailymail/3.0.0": 150.69876098632812,
        "common_gen": -0.9620959758758545,
        "cos_e/v1.11": 22.644254684448242,
        "glue/mrpc": 27.615039825439453,
        "kilt_tasks/hotpotqa": 6.451970100402832
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1329,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10016079992055893,
        "ag_news": 0.13449853658676147,
        "amazon_polarity": 0.1328822821378708,
        "cnn_dailymail/3.0.0": 0.14970657229423523,
        "common_gen": 0.11786988377571106,
        "cos_e/v1.11": 0.12233339995145798,
        "glue/mrpc": 0.12329491972923279,
        "kilt_tasks/hotpotqa": 0.11925367265939713
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9920,
        "ag_news": 10696,
        "amazon_polarity": 10120,
        "cnn_dailymail/3.0.0": 10416,
        "common_gen": 10296,
        "cos_e/v1.11": 10197,
        "glue/mrpc": 9904,
        "kilt_tasks/hotpotqa": 10360
      },
      "step": 640
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -102.0792465209961,
        "ag_news": 82.58474731445312,
        "amazon_polarity": 75.0683822631836,
        "cnn_dailymail/3.0.0": 149.50112915039062,
        "common_gen": 0.6864126920700073,
        "cos_e/v1.11": 17.94586181640625,
        "glue/mrpc": 26.97331428527832,
        "kilt_tasks/hotpotqa": 4.730479717254639
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1985,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10081534087657928,
        "ag_news": 0.13451731204986572,
        "amazon_polarity": 0.13294461369514465,
        "cnn_dailymail/3.0.0": 0.14937534928321838,
        "common_gen": 0.11834993213415146,
        "cos_e/v1.11": 0.121584951877594,
        "glue/mrpc": 0.1233125552535057,
        "kilt_tasks/hotpotqa": 0.11910001933574677
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10048,
        "ag_news": 10832,
        "amazon_polarity": 10256,
        "cnn_dailymail/3.0.0": 10568,
        "common_gen": 10464,
        "cos_e/v1.11": 10429,
        "glue/mrpc": 10056,
        "kilt_tasks/hotpotqa": 10536
      },
      "step": 650
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -99.78169250488281,
        "ag_news": 82.3593521118164,
        "amazon_polarity": 74.94740295410156,
        "cnn_dailymail/3.0.0": 149.55284118652344,
        "common_gen": 0.07816193997859955,
        "cos_e/v1.11": 15.171204566955566,
        "glue/mrpc": 27.052433013916016,
        "kilt_tasks/hotpotqa": 0.3317814767360687
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1345,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10145636647939682,
        "ag_news": 0.13455383479595184,
        "amazon_polarity": 0.13301405310630798,
        "cnn_dailymail/3.0.0": 0.14936219155788422,
        "common_gen": 0.11842581629753113,
        "cos_e/v1.11": 0.12123022228479385,
        "glue/mrpc": 0.12348510324954987,
        "kilt_tasks/hotpotqa": 0.11847240477800369
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10176,
        "ag_news": 11016,
        "amazon_polarity": 10416,
        "cnn_dailymail/3.0.0": 10760,
        "common_gen": 10648,
        "cos_e/v1.11": 10549,
        "glue/mrpc": 10208,
        "kilt_tasks/hotpotqa": 10696
      },
      "step": 660
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -98.45733642578125,
        "ag_news": 82.13624572753906,
        "amazon_polarity": 75.01847076416016,
        "cnn_dailymail/3.0.0": 151.03623962402344,
        "common_gen": -1.0634336471557617,
        "cos_e/v1.11": 19.91808319091797,
        "glue/mrpc": 27.118633270263672,
        "kilt_tasks/hotpotqa": 0.5248835682868958
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1096,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1016978919506073,
        "ag_news": 0.1342722624540329,
        "amazon_polarity": 0.13280726969242096,
        "cnn_dailymail/3.0.0": 0.14932633936405182,
        "common_gen": 0.11812321841716766,
        "cos_e/v1.11": 0.1220003291964531,
        "glue/mrpc": 0.12336039543151855,
        "kilt_tasks/hotpotqa": 0.1184123158454895
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10296,
        "ag_news": 11160,
        "amazon_polarity": 10584,
        "cnn_dailymail/3.0.0": 10936,
        "common_gen": 10800,
        "cos_e/v1.11": 10741,
        "glue/mrpc": 10424,
        "kilt_tasks/hotpotqa": 10808
      },
      "step": 670
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -99.24946594238281,
        "ag_news": 82.09393310546875,
        "amazon_polarity": 74.9726791381836,
        "cnn_dailymail/3.0.0": 153.1548309326172,
        "common_gen": -0.8191826343536377,
        "cos_e/v1.11": 20.955297470092773,
        "glue/mrpc": 26.845600128173828,
        "kilt_tasks/hotpotqa": -2.2053022384643555
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0592,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1017284244298935,
        "ag_news": 0.13419383764266968,
        "amazon_polarity": 0.13273966312408447,
        "cnn_dailymail/3.0.0": 0.14961738884449005,
        "common_gen": 0.11821664124727249,
        "cos_e/v1.11": 0.12221606820821762,
        "glue/mrpc": 0.12332132458686829,
        "kilt_tasks/hotpotqa": 0.11796656996011734
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10424,
        "ag_news": 11320,
        "amazon_polarity": 10776,
        "cnn_dailymail/3.0.0": 11072,
        "common_gen": 11016,
        "cos_e/v1.11": 10869,
        "glue/mrpc": 10632,
        "kilt_tasks/hotpotqa": 10920
      },
      "step": 680
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -104.95258331298828,
        "ag_news": 82.37167358398438,
        "amazon_polarity": 74.98629760742188,
        "cnn_dailymail/3.0.0": 155.1413116455078,
        "common_gen": 0.46133434772491455,
        "cos_e/v1.11": 17.112903594970703,
        "glue/mrpc": 25.23399543762207,
        "kilt_tasks/hotpotqa": -4.235994338989258
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1545,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10115986317396164,
        "ag_news": 0.13439026474952698,
        "amazon_polarity": 0.13289107382297516,
        "cnn_dailymail/3.0.0": 0.15010863542556763,
        "common_gen": 0.11867786198854446,
        "cos_e/v1.11": 0.12171391397714615,
        "glue/mrpc": 0.12322302907705307,
        "kilt_tasks/hotpotqa": 0.11783535778522491
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10536,
        "ag_news": 11480,
        "amazon_polarity": 10936,
        "cnn_dailymail/3.0.0": 11224,
        "common_gen": 11168,
        "cos_e/v1.11": 11061,
        "glue/mrpc": 10792,
        "kilt_tasks/hotpotqa": 11112
      },
      "step": 690
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -104.38204956054688,
        "ag_news": 82.21351623535156,
        "amazon_polarity": 74.90087890625,
        "cnn_dailymail/3.0.0": 157.3209228515625,
        "common_gen": 2.7237370014190674,
        "cos_e/v1.11": 14.018754005432129,
        "glue/mrpc": 24.956674575805664,
        "kilt_tasks/hotpotqa": -1.955765962600708
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0973,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10132940858602524,
        "ag_news": 0.13419735431671143,
        "amazon_polarity": 0.13272546231746674,
        "cnn_dailymail/3.0.0": 0.1503046452999115,
        "common_gen": 0.11904552578926086,
        "cos_e/v1.11": 0.12108814716339111,
        "glue/mrpc": 0.12310002744197845,
        "kilt_tasks/hotpotqa": 0.11820952594280243
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10704,
        "ag_news": 11680,
        "amazon_polarity": 11072,
        "cnn_dailymail/3.0.0": 11368,
        "common_gen": 11384,
        "cos_e/v1.11": 11205,
        "glue/mrpc": 10968,
        "kilt_tasks/hotpotqa": 11208
      },
      "step": 700
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.1888,
      "eval_samples_per_second": 84.768,
      "eval_steps_per_second": 5.298,
      "step": 700
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -108.38882446289062,
        "ag_news": 82.15880584716797,
        "amazon_polarity": 74.78356170654297,
        "cnn_dailymail/3.0.0": 157.94264221191406,
        "common_gen": 4.529688358306885,
        "cos_e/v1.11": 15.6432523727417,
        "glue/mrpc": 23.48235511779785,
        "kilt_tasks/hotpotqa": 0.7661727666854858
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0993,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10084420442581177,
        "ag_news": 0.13408102095127106,
        "amazon_polarity": 0.13260823488235474,
        "cnn_dailymail/3.0.0": 0.15020710229873657,
        "common_gen": 0.11937393993139267,
        "cos_e/v1.11": 0.12137485295534134,
        "glue/mrpc": 0.12280663102865219,
        "kilt_tasks/hotpotqa": 0.1187039315700531
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10888,
        "ag_news": 11880,
        "amazon_polarity": 11176,
        "cnn_dailymail/3.0.0": 11552,
        "common_gen": 11536,
        "cos_e/v1.11": 11341,
        "glue/mrpc": 11164,
        "kilt_tasks/hotpotqa": 11328
      },
      "step": 710
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -105.02637481689453,
        "ag_news": 81.97150421142578,
        "amazon_polarity": 74.65802764892578,
        "cnn_dailymail/3.0.0": 159.28036499023438,
        "common_gen": 6.445247650146484,
        "cos_e/v1.11": 14.486677169799805,
        "glue/mrpc": 23.40995216369629,
        "kilt_tasks/hotpotqa": 2.0498080253601074
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.105,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10139207541942596,
        "ag_news": 0.13383863866329193,
        "amazon_polarity": 0.1323907971382141,
        "cnn_dailymail/3.0.0": 0.1501581221818924,
        "common_gen": 0.11962703615427017,
        "cos_e/v1.11": 0.12106453627347946,
        "glue/mrpc": 0.12268013507127762,
        "kilt_tasks/hotpotqa": 0.11884863674640656
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11032,
        "ag_news": 12056,
        "amazon_polarity": 11352,
        "cnn_dailymail/3.0.0": 11704,
        "common_gen": 11672,
        "cos_e/v1.11": 11493,
        "glue/mrpc": 11284,
        "kilt_tasks/hotpotqa": 11552
      },
      "step": 720
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -108.20975494384766,
        "ag_news": 81.95578002929688,
        "amazon_polarity": 74.57673645019531,
        "cnn_dailymail/3.0.0": 159.42735290527344,
        "common_gen": 6.920658111572266,
        "cos_e/v1.11": 16.174182891845703,
        "glue/mrpc": 24.020463943481445,
        "kilt_tasks/hotpotqa": -1.3270769119262695
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0962,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10112158954143524,
        "ag_news": 0.13385283946990967,
        "amazon_polarity": 0.13240183889865875,
        "cnn_dailymail/3.0.0": 0.15009234845638275,
        "common_gen": 0.11981793493032455,
        "cos_e/v1.11": 0.12146492302417755,
        "glue/mrpc": 0.12287938594818115,
        "kilt_tasks/hotpotqa": 0.11836904287338257
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11224,
        "ag_news": 12224,
        "amazon_polarity": 11512,
        "cnn_dailymail/3.0.0": 11864,
        "common_gen": 11832,
        "cos_e/v1.11": 11669,
        "glue/mrpc": 11380,
        "kilt_tasks/hotpotqa": 11720
      },
      "step": 730
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -109.27629852294922,
        "ag_news": 81.91950988769531,
        "amazon_polarity": 74.5561752319336,
        "cnn_dailymail/3.0.0": 158.5446014404297,
        "common_gen": 7.367814540863037,
        "cos_e/v1.11": 12.759133338928223,
        "glue/mrpc": 24.166521072387695,
        "kilt_tasks/hotpotqa": -2.892568588256836
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1135,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1012260913848877,
        "ag_news": 0.1339416801929474,
        "amazon_polarity": 0.1325024515390396,
        "cnn_dailymail/3.0.0": 0.14988987147808075,
        "common_gen": 0.12007156014442444,
        "cos_e/v1.11": 0.12102396041154861,
        "glue/mrpc": 0.12306439876556396,
        "kilt_tasks/hotpotqa": 0.11827995628118515
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11368,
        "ag_news": 12384,
        "amazon_polarity": 11688,
        "cnn_dailymail/3.0.0": 12040,
        "common_gen": 11992,
        "cos_e/v1.11": 11797,
        "glue/mrpc": 11564,
        "kilt_tasks/hotpotqa": 11872
      },
      "step": 740
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -108.92130279541016,
        "ag_news": 81.8243179321289,
        "amazon_polarity": 74.49906921386719,
        "cnn_dailymail/3.0.0": 159.3009490966797,
        "common_gen": 8.773274421691895,
        "cos_e/v1.11": 14.026920318603516,
        "glue/mrpc": 23.8649845123291,
        "kilt_tasks/hotpotqa": -3.77939510345459
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1001,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10137782990932465,
        "ag_news": 0.13380643725395203,
        "amazon_polarity": 0.13238553702831268,
        "cnn_dailymail/3.0.0": 0.14981257915496826,
        "common_gen": 0.12029986828565598,
        "cos_e/v1.11": 0.12122347205877304,
        "glue/mrpc": 0.12297230958938599,
        "kilt_tasks/hotpotqa": 0.11812188476324081
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11512,
        "ag_news": 12592,
        "amazon_polarity": 11816,
        "cnn_dailymail/3.0.0": 12232,
        "common_gen": 12120,
        "cos_e/v1.11": 11949,
        "glue/mrpc": 11700,
        "kilt_tasks/hotpotqa": 12064
      },
      "step": 750
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -109.50838470458984,
        "ag_news": 81.68814086914062,
        "amazon_polarity": 74.41651916503906,
        "cnn_dailymail/3.0.0": 157.55963134765625,
        "common_gen": 8.339186668395996,
        "cos_e/v1.11": 15.12378978729248,
        "glue/mrpc": 22.615652084350586,
        "kilt_tasks/hotpotqa": -3.6684951782226562
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0944,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10149408131837845,
        "ag_news": 0.13380466401576996,
        "amazon_polarity": 0.13240329921245575,
        "cnn_dailymail/3.0.0": 0.14935177564620972,
        "common_gen": 0.12033011019229889,
        "cos_e/v1.11": 0.121516652405262,
        "glue/mrpc": 0.12284062057733536,
        "kilt_tasks/hotpotqa": 0.11825882643461227
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11672,
        "ag_news": 12752,
        "amazon_polarity": 11992,
        "cnn_dailymail/3.0.0": 12416,
        "common_gen": 12280,
        "cos_e/v1.11": 12149,
        "glue/mrpc": 11828,
        "kilt_tasks/hotpotqa": 12176
      },
      "step": 760
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -114.66703033447266,
        "ag_news": 81.68570709228516,
        "amazon_polarity": 74.341552734375,
        "cnn_dailymail/3.0.0": 157.8766632080078,
        "common_gen": 6.300222396850586,
        "cos_e/v1.11": 17.442420959472656,
        "glue/mrpc": 21.87200927734375,
        "kilt_tasks/hotpotqa": -5.933539867401123
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1818,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10100166499614716,
        "ag_news": 0.13390526175498962,
        "amazon_polarity": 0.13249802589416504,
        "cnn_dailymail/3.0.0": 0.1494266837835312,
        "common_gen": 0.12015087902545929,
        "cos_e/v1.11": 0.12209007889032364,
        "glue/mrpc": 0.12286977469921112,
        "kilt_tasks/hotpotqa": 0.11805758625268936
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11840,
        "ag_news": 12888,
        "amazon_polarity": 12144,
        "cnn_dailymail/3.0.0": 12600,
        "common_gen": 12392,
        "cos_e/v1.11": 12349,
        "glue/mrpc": 11964,
        "kilt_tasks/hotpotqa": 12368
      },
      "step": 770
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -112.9726333618164,
        "ag_news": 81.79391479492188,
        "amazon_polarity": 74.29395294189453,
        "cnn_dailymail/3.0.0": 158.1788787841797,
        "common_gen": 7.819531440734863,
        "cos_e/v1.11": 17.646181106567383,
        "glue/mrpc": 23.447668075561523,
        "kilt_tasks/hotpotqa": -9.085775375366211
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0942,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10134987533092499,
        "ag_news": 0.13382335007190704,
        "amazon_polarity": 0.1323964148759842,
        "cnn_dailymail/3.0.0": 0.1492720991373062,
        "common_gen": 0.12040271610021591,
        "cos_e/v1.11": 0.12210395932197571,
        "glue/mrpc": 0.12311973422765732,
        "kilt_tasks/hotpotqa": 0.1175319254398346
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12040,
        "ag_news": 13072,
        "amazon_polarity": 12280,
        "cnn_dailymail/3.0.0": 12776,
        "common_gen": 12544,
        "cos_e/v1.11": 12509,
        "glue/mrpc": 12108,
        "kilt_tasks/hotpotqa": 12496
      },
      "step": 780
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -116.6050033569336,
        "ag_news": 81.76058197021484,
        "amazon_polarity": 74.9581298828125,
        "cnn_dailymail/3.0.0": 159.34632873535156,
        "common_gen": 6.612405300140381,
        "cos_e/v1.11": 18.290170669555664,
        "glue/mrpc": 21.491050720214844,
        "kilt_tasks/hotpotqa": -10.5222749710083
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1322,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10104997456073761,
        "ag_news": 0.13387535512447357,
        "amazon_polarity": 0.13258807361125946,
        "cnn_dailymail/3.0.0": 0.1494823843240738,
        "common_gen": 0.12032897025346756,
        "cos_e/v1.11": 0.12233931571245193,
        "glue/mrpc": 0.12289626151323318,
        "kilt_tasks/hotpotqa": 0.11743956804275513
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12224,
        "ag_news": 13184,
        "amazon_polarity": 12504,
        "cnn_dailymail/3.0.0": 12952,
        "common_gen": 12720,
        "cos_e/v1.11": 12669,
        "glue/mrpc": 12212,
        "kilt_tasks/hotpotqa": 12640
      },
      "step": 790
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -114.16754150390625,
        "ag_news": 81.62325286865234,
        "amazon_polarity": 74.89323425292969,
        "cnn_dailymail/3.0.0": 159.017578125,
        "common_gen": 7.554520130157471,
        "cos_e/v1.11": 15.626054763793945,
        "glue/mrpc": 19.587141036987305,
        "kilt_tasks/hotpotqa": -11.282279968261719
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0913,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1015864685177803,
        "ag_news": 0.13386596739292145,
        "amazon_polarity": 0.13260029256343842,
        "cnn_dailymail/3.0.0": 0.14932894706726074,
        "common_gen": 0.1205836609005928,
        "cos_e/v1.11": 0.12196388840675354,
        "glue/mrpc": 0.12264706194400787,
        "kilt_tasks/hotpotqa": 0.11742378771305084
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12376,
        "ag_news": 13424,
        "amazon_polarity": 12648,
        "cnn_dailymail/3.0.0": 13120,
        "common_gen": 12856,
        "cos_e/v1.11": 12821,
        "glue/mrpc": 12316,
        "kilt_tasks/hotpotqa": 12824
      },
      "step": 800
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1889,
      "eval_samples_per_second": 84.701,
      "eval_steps_per_second": 5.294,
      "step": 800
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -114.49285888671875,
        "ag_news": 81.85530090332031,
        "amazon_polarity": 74.82007598876953,
        "cnn_dailymail/3.0.0": 159.03701782226562,
        "common_gen": 6.52849006652832,
        "cos_e/v1.11": 18.516632080078125,
        "glue/mrpc": 21.476882934570312,
        "kilt_tasks/hotpotqa": -17.29731559753418
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9691,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10170825570821762,
        "ag_news": 0.13390477001667023,
        "amazon_polarity": 0.1325896829366684,
        "cnn_dailymail/3.0.0": 0.14922736585140228,
        "common_gen": 0.12048331648111343,
        "cos_e/v1.11": 0.12252457439899445,
        "glue/mrpc": 0.12303399294614792,
        "kilt_tasks/hotpotqa": 0.11652800440788269
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12560,
        "ag_news": 13656,
        "amazon_polarity": 12832,
        "cnn_dailymail/3.0.0": 13216,
        "common_gen": 12976,
        "cos_e/v1.11": 12965,
        "glue/mrpc": 12492,
        "kilt_tasks/hotpotqa": 12968
      },
      "step": 810
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -110.85868835449219,
        "ag_news": 81.17613983154297,
        "amazon_polarity": 74.69149780273438,
        "cnn_dailymail/3.0.0": 160.66421508789062,
        "common_gen": 10.839864730834961,
        "cos_e/v1.11": 16.20787811279297,
        "glue/mrpc": 28.24928092956543,
        "kilt_tasks/hotpotqa": -16.883901596069336
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1507,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10212299227714539,
        "ag_news": 0.1334235817193985,
        "amazon_polarity": 0.13222265243530273,
        "cnn_dailymail/3.0.0": 0.14907190203666687,
        "common_gen": 0.1209656149148941,
        "cos_e/v1.11": 0.12187349796295166,
        "glue/mrpc": 0.12393515557050705,
        "kilt_tasks/hotpotqa": 0.1163846105337143
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12728,
        "ag_news": 13800,
        "amazon_polarity": 12992,
        "cnn_dailymail/3.0.0": 13456,
        "common_gen": 13128,
        "cos_e/v1.11": 13117,
        "glue/mrpc": 12620,
        "kilt_tasks/hotpotqa": 13104
      },
      "step": 820
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -113.17720031738281,
        "ag_news": 81.21550750732422,
        "amazon_polarity": 74.5663070678711,
        "cnn_dailymail/3.0.0": 161.54222106933594,
        "common_gen": 9.639738082885742,
        "cos_e/v1.11": 18.308313369750977,
        "glue/mrpc": 29.07216453552246,
        "kilt_tasks/hotpotqa": -17.922922134399414
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0193,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10192602127790451,
        "ag_news": 0.13338744640350342,
        "amazon_polarity": 0.132163867354393,
        "cnn_dailymail/3.0.0": 0.14910577237606049,
        "common_gen": 0.12079638242721558,
        "cos_e/v1.11": 0.12225498259067535,
        "glue/mrpc": 0.12409093230962753,
        "kilt_tasks/hotpotqa": 0.1162746399641037
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12864,
        "ag_news": 13960,
        "amazon_polarity": 13176,
        "cnn_dailymail/3.0.0": 13600,
        "common_gen": 13320,
        "cos_e/v1.11": 13205,
        "glue/mrpc": 12844,
        "kilt_tasks/hotpotqa": 13256
      },
      "step": 830
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -116.1732406616211,
        "ag_news": 81.01209259033203,
        "amazon_polarity": 74.40594482421875,
        "cnn_dailymail/3.0.0": 162.53211975097656,
        "common_gen": 14.804036140441895,
        "cos_e/v1.11": 18.9602108001709,
        "glue/mrpc": 30.810361862182617,
        "kilt_tasks/hotpotqa": -18.12106704711914
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1632,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1015363559126854,
        "ag_news": 0.1331757754087448,
        "amazon_polarity": 0.13196918368339539,
        "cnn_dailymail/3.0.0": 0.14901569485664368,
        "common_gen": 0.12157049775123596,
        "cos_e/v1.11": 0.12226796895265579,
        "glue/mrpc": 0.12427889555692673,
        "kilt_tasks/hotpotqa": 0.11618552356958389
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13040,
        "ag_news": 14080,
        "amazon_polarity": 13320,
        "cnn_dailymail/3.0.0": 13784,
        "common_gen": 13448,
        "cos_e/v1.11": 13365,
        "glue/mrpc": 13036,
        "kilt_tasks/hotpotqa": 13432
      },
      "step": 840
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -117.3089370727539,
        "ag_news": 80.99695587158203,
        "amazon_polarity": 74.35755920410156,
        "cnn_dailymail/3.0.0": 163.73277282714844,
        "common_gen": 12.522981643676758,
        "cos_e/v1.11": 20.43286895751953,
        "glue/mrpc": 28.541824340820312,
        "kilt_tasks/hotpotqa": -20.416793823242188
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1625,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10158691555261612,
        "ag_news": 0.13323532044887543,
        "amazon_polarity": 0.1320292055606842,
        "cnn_dailymail/3.0.0": 0.149232879281044,
        "common_gen": 0.1213129311800003,
        "cos_e/v1.11": 0.12263315916061401,
        "glue/mrpc": 0.12400167435407639,
        "kilt_tasks/hotpotqa": 0.11596786230802536
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13168,
        "ag_news": 14224,
        "amazon_polarity": 13480,
        "cnn_dailymail/3.0.0": 13976,
        "common_gen": 13624,
        "cos_e/v1.11": 13501,
        "glue/mrpc": 13220,
        "kilt_tasks/hotpotqa": 13592
      },
      "step": 850
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -117.9644775390625,
        "ag_news": 81.03924560546875,
        "amazon_polarity": 74.20063781738281,
        "cnn_dailymail/3.0.0": 164.8865509033203,
        "common_gen": 11.261021614074707,
        "cos_e/v1.11": 16.45921516418457,
        "glue/mrpc": 31.02092742919922,
        "kilt_tasks/hotpotqa": -20.317792892456055
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0563,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10165274888277054,
        "ag_news": 0.13323956727981567,
        "amazon_polarity": 0.1320045441389084,
        "cnn_dailymail/3.0.0": 0.1493658423423767,
        "common_gen": 0.12116732448339462,
        "cos_e/v1.11": 0.12202725559473038,
        "glue/mrpc": 0.12446915358304977,
        "kilt_tasks/hotpotqa": 0.11607348173856735
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13336,
        "ag_news": 14416,
        "amazon_polarity": 13664,
        "cnn_dailymail/3.0.0": 14120,
        "common_gen": 13784,
        "cos_e/v1.11": 13605,
        "glue/mrpc": 13388,
        "kilt_tasks/hotpotqa": 13752
      },
      "step": 860
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -118.67964935302734,
        "ag_news": 81.02278900146484,
        "amazon_polarity": 74.12890625,
        "cnn_dailymail/3.0.0": 165.78179931640625,
        "common_gen": 12.737105369567871,
        "cos_e/v1.11": 16.4948787689209,
        "glue/mrpc": 33.64766311645508,
        "kilt_tasks/hotpotqa": -21.23798370361328
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2632,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10161536931991577,
        "ag_news": 0.1331104040145874,
        "amazon_polarity": 0.1318737417459488,
        "cnn_dailymail/3.0.0": 0.1493077427148819,
        "common_gen": 0.12136043608188629,
        "cos_e/v1.11": 0.12197890132665634,
        "glue/mrpc": 0.12484265863895416,
        "kilt_tasks/hotpotqa": 0.11591076850891113
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13464,
        "ag_news": 14552,
        "amazon_polarity": 13800,
        "cnn_dailymail/3.0.0": 14328,
        "common_gen": 13984,
        "cos_e/v1.11": 13773,
        "glue/mrpc": 13492,
        "kilt_tasks/hotpotqa": 13952
      },
      "step": 870
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -121.06157684326172,
        "ag_news": 80.8749008178711,
        "amazon_polarity": 74.01020812988281,
        "cnn_dailymail/3.0.0": 165.88150024414062,
        "common_gen": 14.764421463012695,
        "cos_e/v1.11": 17.042556762695312,
        "glue/mrpc": 35.96784591674805,
        "kilt_tasks/hotpotqa": -19.653226852416992
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1525,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10134103894233704,
        "ag_news": 0.13294674456119537,
        "amazon_polarity": 0.13172374665737152,
        "cnn_dailymail/3.0.0": 0.14907684922218323,
        "common_gen": 0.12162996828556061,
        "cos_e/v1.11": 0.12200325727462769,
        "glue/mrpc": 0.12514932453632355,
        "kilt_tasks/hotpotqa": 0.1161290779709816
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13544,
        "ag_news": 14720,
        "amazon_polarity": 13968,
        "cnn_dailymail/3.0.0": 14552,
        "common_gen": 14192,
        "cos_e/v1.11": 13949,
        "glue/mrpc": 13612,
        "kilt_tasks/hotpotqa": 14088
      },
      "step": 880
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -121.75471496582031,
        "ag_news": 80.76470947265625,
        "amazon_polarity": 73.98885345458984,
        "cnn_dailymail/3.0.0": 165.7259063720703,
        "common_gen": 13.520380973815918,
        "cos_e/v1.11": 17.014070510864258,
        "glue/mrpc": 37.79249954223633,
        "kilt_tasks/hotpotqa": -23.125831604003906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1955,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10142826288938522,
        "ag_news": 0.13296356797218323,
        "amazon_polarity": 0.13176289200782776,
        "cnn_dailymail/3.0.0": 0.1489911675453186,
        "common_gen": 0.12152136117219925,
        "cos_e/v1.11": 0.12209057062864304,
        "glue/mrpc": 0.12553197145462036,
        "kilt_tasks/hotpotqa": 0.11571017652750015
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13672,
        "ag_news": 14840,
        "amazon_polarity": 14128,
        "cnn_dailymail/3.0.0": 14712,
        "common_gen": 14376,
        "cos_e/v1.11": 14093,
        "glue/mrpc": 13772,
        "kilt_tasks/hotpotqa": 14312
      },
      "step": 890
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -124.87357330322266,
        "ag_news": 80.74564361572266,
        "amazon_polarity": 73.86824035644531,
        "cnn_dailymail/3.0.0": 165.04441833496094,
        "common_gen": 19.50910758972168,
        "cos_e/v1.11": 10.061114311218262,
        "glue/mrpc": 37.247955322265625,
        "kilt_tasks/hotpotqa": -26.1381778717041
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2202,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10125844925642014,
        "ag_news": 0.13308995962142944,
        "amazon_polarity": 0.13187691569328308,
        "cnn_dailymail/3.0.0": 0.14890755712985992,
        "common_gen": 0.12267367541790009,
        "cos_e/v1.11": 0.12114159762859344,
        "glue/mrpc": 0.1256033033132553,
        "kilt_tasks/hotpotqa": 0.11544854193925858
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13856,
        "ag_news": 14928,
        "amazon_polarity": 14248,
        "cnn_dailymail/3.0.0": 14816,
        "common_gen": 14624,
        "cos_e/v1.11": 14325,
        "glue/mrpc": 13932,
        "kilt_tasks/hotpotqa": 14456
      },
      "step": 900
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1946,
      "eval_samples_per_second": 82.233,
      "eval_steps_per_second": 5.14,
      "step": 900
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -126.05146789550781,
        "ag_news": 80.68577575683594,
        "amazon_polarity": 73.29029083251953,
        "cnn_dailymail/3.0.0": 162.29930114746094,
        "common_gen": 17.921905517578125,
        "cos_e/v1.11": 10.089446067810059,
        "glue/mrpc": 33.45163345336914,
        "kilt_tasks/hotpotqa": -21.683135986328125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1424,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10132228583097458,
        "ag_news": 0.13317233324050903,
        "amazon_polarity": 0.13187463581562042,
        "cnn_dailymail/3.0.0": 0.14837917685508728,
        "common_gen": 0.12255626916885376,
        "cos_e/v1.11": 0.12129291892051697,
        "glue/mrpc": 0.12510062754154205,
        "kilt_tasks/hotpotqa": 0.11630174517631531
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14064,
        "ag_news": 15048,
        "amazon_polarity": 14400,
        "cnn_dailymail/3.0.0": 14968,
        "common_gen": 14752,
        "cos_e/v1.11": 14517,
        "glue/mrpc": 14124,
        "kilt_tasks/hotpotqa": 14592
      },
      "step": 910
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -131.87428283691406,
        "ag_news": 80.48780822753906,
        "amazon_polarity": 73.08673095703125,
        "cnn_dailymail/3.0.0": 163.4448699951172,
        "common_gen": 17.607446670532227,
        "cos_e/v1.11": 21.86455535888672,
        "glue/mrpc": 35.33318328857422,
        "kilt_tasks/hotpotqa": -19.633609771728516
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1387,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10048216581344604,
        "ag_news": 0.13285009562969208,
        "amazon_polarity": 0.1315615475177765,
        "cnn_dailymail/3.0.0": 0.14819541573524475,
        "common_gen": 0.12229608744382858,
        "cos_e/v1.11": 0.12298308312892914,
        "glue/mrpc": 0.12518243491649628,
        "kilt_tasks/hotpotqa": 0.116449274122715
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14200,
        "ag_news": 15168,
        "amazon_polarity": 14576,
        "cnn_dailymail/3.0.0": 15144,
        "common_gen": 14880,
        "cos_e/v1.11": 14645,
        "glue/mrpc": 14340,
        "kilt_tasks/hotpotqa": 14792
      },
      "step": 920
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -134.9806671142578,
        "ag_news": 80.38953399658203,
        "amazon_polarity": 73.11555480957031,
        "cnn_dailymail/3.0.0": 163.14117431640625,
        "common_gen": 22.225481033325195,
        "cos_e/v1.11": 17.380525588989258,
        "glue/mrpc": 36.643436431884766,
        "kilt_tasks/hotpotqa": -18.933307647705078
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1207,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10020837932825089,
        "ag_news": 0.1328115016222,
        "amazon_polarity": 0.1315520852804184,
        "cnn_dailymail/3.0.0": 0.148025780916214,
        "common_gen": 0.1230720654129982,
        "cos_e/v1.11": 0.1222940981388092,
        "glue/mrpc": 0.12541690468788147,
        "kilt_tasks/hotpotqa": 0.11661920696496964
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14304,
        "ag_news": 15328,
        "amazon_polarity": 14768,
        "cnn_dailymail/3.0.0": 15320,
        "common_gen": 15080,
        "cos_e/v1.11": 14821,
        "glue/mrpc": 14500,
        "kilt_tasks/hotpotqa": 14904
      },
      "step": 930
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -137.98052978515625,
        "ag_news": 80.30052947998047,
        "amazon_polarity": 72.65884399414062,
        "cnn_dailymail/3.0.0": 166.43563842773438,
        "common_gen": 21.628618240356445,
        "cos_e/v1.11": 19.57461166381836,
        "glue/mrpc": 35.87628173828125,
        "kilt_tasks/hotpotqa": -22.9666690826416
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0135,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09997078031301498,
        "ag_news": 0.13280099630355835,
        "amazon_polarity": 0.13148531317710876,
        "cnn_dailymail/3.0.0": 0.1485833376646042,
        "common_gen": 0.12303052097558975,
        "cos_e/v1.11": 0.12270195037126541,
        "glue/mrpc": 0.1253342628479004,
        "kilt_tasks/hotpotqa": 0.11609278619289398
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14496,
        "ag_news": 15480,
        "amazon_polarity": 14944,
        "cnn_dailymail/3.0.0": 15472,
        "common_gen": 15232,
        "cos_e/v1.11": 14965,
        "glue/mrpc": 14668,
        "kilt_tasks/hotpotqa": 15048
      },
      "step": 940
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -136.4739227294922,
        "ag_news": 80.2862777709961,
        "amazon_polarity": 72.62973022460938,
        "cnn_dailymail/3.0.0": 164.94000244140625,
        "common_gen": 20.417394638061523,
        "cos_e/v1.11": 18.82387924194336,
        "glue/mrpc": 35.45528030395508,
        "kilt_tasks/hotpotqa": -27.07081413269043
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0709,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10039513558149338,
        "ag_news": 0.13290615379810333,
        "amazon_polarity": 0.1315937340259552,
        "cnn_dailymail/3.0.0": 0.1483282446861267,
        "common_gen": 0.12298628687858582,
        "cos_e/v1.11": 0.1227327361702919,
        "glue/mrpc": 0.12540532648563385,
        "kilt_tasks/hotpotqa": 0.11565246433019638
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14672,
        "ag_news": 15616,
        "amazon_polarity": 15080,
        "cnn_dailymail/3.0.0": 15616,
        "common_gen": 15360,
        "cos_e/v1.11": 15117,
        "glue/mrpc": 14872,
        "kilt_tasks/hotpotqa": 15248
      },
      "step": 950
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -134.68809509277344,
        "ag_news": 80.25403594970703,
        "amazon_polarity": 72.37344360351562,
        "cnn_dailymail/3.0.0": 163.73558044433594,
        "common_gen": 18.71353530883789,
        "cos_e/v1.11": 18.00912094116211,
        "glue/mrpc": 36.05790328979492,
        "kilt_tasks/hotpotqa": -30.233362197875977
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0567,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10082513093948364,
        "ag_news": 0.13297124207019806,
        "amazon_polarity": 0.1316269189119339,
        "cnn_dailymail/3.0.0": 0.14809225499629974,
        "common_gen": 0.1228310689330101,
        "cos_e/v1.11": 0.1227196455001831,
        "glue/mrpc": 0.1256071925163269,
        "kilt_tasks/hotpotqa": 0.11532653868198395
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14864,
        "ag_news": 15824,
        "amazon_polarity": 15272,
        "cnn_dailymail/3.0.0": 15776,
        "common_gen": 15512,
        "cos_e/v1.11": 15253,
        "glue/mrpc": 15008,
        "kilt_tasks/hotpotqa": 15352
      },
      "step": 960
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -137.55397033691406,
        "ag_news": 79.98460388183594,
        "amazon_polarity": 72.19737243652344,
        "cnn_dailymail/3.0.0": 165.09463500976562,
        "common_gen": 16.885801315307617,
        "cos_e/v1.11": 18.88599967956543,
        "glue/mrpc": 35.8052978515625,
        "kilt_tasks/hotpotqa": -32.766849517822266
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1694,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10064483433961868,
        "ag_news": 0.13298672437667847,
        "amazon_polarity": 0.13166487216949463,
        "cnn_dailymail/3.0.0": 0.14833754301071167,
        "common_gen": 0.12265007197856903,
        "cos_e/v1.11": 0.12296493351459503,
        "glue/mrpc": 0.1256612092256546,
        "kilt_tasks/hotpotqa": 0.1150897890329361
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14976,
        "ag_news": 16016,
        "amazon_polarity": 15384,
        "cnn_dailymail/3.0.0": 15960,
        "common_gen": 15688,
        "cos_e/v1.11": 15421,
        "glue/mrpc": 15168,
        "kilt_tasks/hotpotqa": 15528
      },
      "step": 970
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -138.01412963867188,
        "ag_news": 79.88069152832031,
        "amazon_polarity": 72.08749389648438,
        "cnn_dailymail/3.0.0": 162.62484741210938,
        "common_gen": 17.165210723876953,
        "cos_e/v1.11": 22.946041107177734,
        "glue/mrpc": 33.86235046386719,
        "kilt_tasks/hotpotqa": -32.98531723022461
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1819,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10072150826454163,
        "ag_news": 0.132960706949234,
        "amazon_polarity": 0.13164478540420532,
        "cnn_dailymail/3.0.0": 0.14777882397174835,
        "common_gen": 0.12273639440536499,
        "cos_e/v1.11": 0.1236446350812912,
        "glue/mrpc": 0.12537828087806702,
        "kilt_tasks/hotpotqa": 0.1151348128914833
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15136,
        "ag_news": 16168,
        "amazon_polarity": 15568,
        "cnn_dailymail/3.0.0": 16184,
        "common_gen": 15808,
        "cos_e/v1.11": 15621,
        "glue/mrpc": 15280,
        "kilt_tasks/hotpotqa": 15656
      },
      "step": 980
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -139.54483032226562,
        "ag_news": 79.87752532958984,
        "amazon_polarity": 71.77490997314453,
        "cnn_dailymail/3.0.0": 164.20086669921875,
        "common_gen": 17.297271728515625,
        "cos_e/v1.11": 22.38729476928711,
        "glue/mrpc": 30.311691284179688,
        "kilt_tasks/hotpotqa": -32.61543273925781
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0896,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10069114714860916,
        "ag_news": 0.1329929083585739,
        "amazon_polarity": 0.1316315233707428,
        "cnn_dailymail/3.0.0": 0.148033007979393,
        "common_gen": 0.12283651530742645,
        "cos_e/v1.11": 0.12363249063491821,
        "glue/mrpc": 0.12488208711147308,
        "kilt_tasks/hotpotqa": 0.11530038714408875
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15336,
        "ag_news": 16352,
        "amazon_polarity": 15688,
        "cnn_dailymail/3.0.0": 16352,
        "common_gen": 15928,
        "cos_e/v1.11": 15813,
        "glue/mrpc": 15456,
        "kilt_tasks/hotpotqa": 15776
      },
      "step": 990
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -137.0578155517578,
        "ag_news": 79.81083679199219,
        "amazon_polarity": 71.75708770751953,
        "cnn_dailymail/3.0.0": 165.7052764892578,
        "common_gen": 20.050212860107422,
        "cos_e/v1.11": 23.776588439941406,
        "glue/mrpc": 31.061885833740234,
        "kilt_tasks/hotpotqa": -33.18054962158203
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1043,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10099075734615326,
        "ag_news": 0.13277626037597656,
        "amazon_polarity": 0.1314319372177124,
        "cnn_dailymail/3.0.0": 0.1480066180229187,
        "common_gen": 0.12312254309654236,
        "cos_e/v1.11": 0.12370322644710541,
        "glue/mrpc": 0.12484649568796158,
        "kilt_tasks/hotpotqa": 0.11512205749750137
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15440,
        "ag_news": 16512,
        "amazon_polarity": 15856,
        "cnn_dailymail/3.0.0": 16528,
        "common_gen": 16064,
        "cos_e/v1.11": 16013,
        "glue/mrpc": 15640,
        "kilt_tasks/hotpotqa": 15928
      },
      "step": 1000
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1876,
      "eval_samples_per_second": 85.3,
      "eval_steps_per_second": 5.331,
      "step": 1000
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -141.6566162109375,
        "ag_news": 79.5455322265625,
        "amazon_polarity": 71.78195190429688,
        "cnn_dailymail/3.0.0": 168.36648559570312,
        "common_gen": 19.615398406982422,
        "cos_e/v1.11": 24.046890258789062,
        "glue/mrpc": 30.670578002929688,
        "kilt_tasks/hotpotqa": -36.32524108886719
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1643,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10058488696813583,
        "ag_news": 0.13278447091579437,
        "amazon_polarity": 0.13149462640285492,
        "cnn_dailymail/3.0.0": 0.14848250150680542,
        "common_gen": 0.12314966320991516,
        "cos_e/v1.11": 0.12383729219436646,
        "glue/mrpc": 0.12487229704856873,
        "kilt_tasks/hotpotqa": 0.11479423195123672
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15608,
        "ag_news": 16624,
        "amazon_polarity": 16008,
        "cnn_dailymail/3.0.0": 16672,
        "common_gen": 16224,
        "cos_e/v1.11": 16269,
        "glue/mrpc": 15808,
        "kilt_tasks/hotpotqa": 16048
      },
      "step": 1010
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -141.7422637939453,
        "ag_news": 79.51535034179688,
        "amazon_polarity": 71.37480163574219,
        "cnn_dailymail/3.0.0": 170.71536254882812,
        "common_gen": 18.547130584716797,
        "cos_e/v1.11": 23.426101684570312,
        "glue/mrpc": 31.759279251098633,
        "kilt_tasks/hotpotqa": -33.872676849365234
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.064,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1006213054060936,
        "ag_news": 0.13266213238239288,
        "amazon_polarity": 0.13131779432296753,
        "cnn_dailymail/3.0.0": 0.14870712161064148,
        "common_gen": 0.12292182445526123,
        "cos_e/v1.11": 0.12367396801710129,
        "glue/mrpc": 0.12496940046548843,
        "kilt_tasks/hotpotqa": 0.11512650549411774
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15768,
        "ag_news": 16800,
        "amazon_polarity": 16208,
        "cnn_dailymail/3.0.0": 16776,
        "common_gen": 16368,
        "cos_e/v1.11": 16421,
        "glue/mrpc": 15944,
        "kilt_tasks/hotpotqa": 16256
      },
      "step": 1020
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -142.22024536132812,
        "ag_news": 79.51197052001953,
        "amazon_polarity": 71.34373474121094,
        "cnn_dailymail/3.0.0": 169.48794555664062,
        "common_gen": 21.28652572631836,
        "cos_e/v1.11": 21.448701858520508,
        "glue/mrpc": 34.240970611572266,
        "kilt_tasks/hotpotqa": -34.28195571899414
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0897,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1006542220711708,
        "ag_news": 0.13260698318481445,
        "amazon_polarity": 0.13126514852046967,
        "cnn_dailymail/3.0.0": 0.148336723446846,
        "common_gen": 0.12333616614341736,
        "cos_e/v1.11": 0.12336106598377228,
        "glue/mrpc": 0.1253405213356018,
        "kilt_tasks/hotpotqa": 0.11509930342435837
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15928,
        "ag_news": 16992,
        "amazon_polarity": 16384,
        "cnn_dailymail/3.0.0": 16976,
        "common_gen": 16512,
        "cos_e/v1.11": 16549,
        "glue/mrpc": 16064,
        "kilt_tasks/hotpotqa": 16416
      },
      "step": 1030
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -141.78781127929688,
        "ag_news": 79.46320343017578,
        "amazon_polarity": 71.28024291992188,
        "cnn_dailymail/3.0.0": 173.33377075195312,
        "common_gen": 14.853737831115723,
        "cos_e/v1.11": 15.604304313659668,
        "glue/mrpc": 32.81269073486328,
        "kilt_tasks/hotpotqa": -35.70473861694336
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0706,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10097064077854156,
        "ag_news": 0.13277064263820648,
        "amazon_polarity": 0.13143111765384674,
        "cnn_dailymail/3.0.0": 0.14915919303894043,
        "common_gen": 0.1225583404302597,
        "cos_e/v1.11": 0.12267229706048965,
        "glue/mrpc": 0.1253146380186081,
        "kilt_tasks/hotpotqa": 0.1151231974363327
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16080,
        "ag_news": 17192,
        "amazon_polarity": 16552,
        "cnn_dailymail/3.0.0": 17152,
        "common_gen": 16680,
        "cos_e/v1.11": 16685,
        "glue/mrpc": 16192,
        "kilt_tasks/hotpotqa": 16568
      },
      "step": 1040
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -143.56219482421875,
        "ag_news": 79.43785095214844,
        "amazon_polarity": 71.17273712158203,
        "cnn_dailymail/3.0.0": 174.94772338867188,
        "common_gen": 11.021902084350586,
        "cos_e/v1.11": 17.126081466674805,
        "glue/mrpc": 32.532875061035156,
        "kilt_tasks/hotpotqa": -35.19558334350586
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0169,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10088130086660385,
        "ag_news": 0.1327669620513916,
        "amazon_polarity": 0.13142049312591553,
        "cnn_dailymail/3.0.0": 0.14937478303909302,
        "common_gen": 0.12202761322259903,
        "cos_e/v1.11": 0.12294905632734299,
        "glue/mrpc": 0.1253061443567276,
        "kilt_tasks/hotpotqa": 0.11527355760335922
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16216,
        "ag_news": 17400,
        "amazon_polarity": 16744,
        "cnn_dailymail/3.0.0": 17272,
        "common_gen": 16832,
        "cos_e/v1.11": 16837,
        "glue/mrpc": 16352,
        "kilt_tasks/hotpotqa": 16728
      },
      "step": 1050
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -142.64405822753906,
        "ag_news": 79.31822967529297,
        "amazon_polarity": 71.00584411621094,
        "cnn_dailymail/3.0.0": 172.760009765625,
        "common_gen": 10.940378189086914,
        "cos_e/v1.11": 17.343238830566406,
        "glue/mrpc": 30.01153564453125,
        "kilt_tasks/hotpotqa": -36.316490173339844
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9535,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10118541121482849,
        "ag_news": 0.13282756507396698,
        "amazon_polarity": 0.13147911429405212,
        "cnn_dailymail/3.0.0": 0.14898119866847992,
        "common_gen": 0.12213723361492157,
        "cos_e/v1.11": 0.12310028076171875,
        "glue/mrpc": 0.1250283569097519,
        "kilt_tasks/hotpotqa": 0.11526091396808624
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16432,
        "ag_news": 17600,
        "amazon_polarity": 16936,
        "cnn_dailymail/3.0.0": 17384,
        "common_gen": 16928,
        "cos_e/v1.11": 16981,
        "glue/mrpc": 16504,
        "kilt_tasks/hotpotqa": 16896
      },
      "step": 1060
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -144.93936157226562,
        "ag_news": 79.17436981201172,
        "amazon_polarity": 70.91846466064453,
        "cnn_dailymail/3.0.0": 173.0439910888672,
        "common_gen": 11.774223327636719,
        "cos_e/v1.11": 18.157121658325195,
        "glue/mrpc": 30.654258728027344,
        "kilt_tasks/hotpotqa": -34.846900939941406
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1337,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10097578167915344,
        "ag_news": 0.13273248076438904,
        "amazon_polarity": 0.13140030205249786,
        "cnn_dailymail/3.0.0": 0.14887285232543945,
        "common_gen": 0.12224331498146057,
        "cos_e/v1.11": 0.12319968640804291,
        "glue/mrpc": 0.12509416043758392,
        "kilt_tasks/hotpotqa": 0.11548151820898056
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16608,
        "ag_news": 17752,
        "amazon_polarity": 17016,
        "cnn_dailymail/3.0.0": 17512,
        "common_gen": 17128,
        "cos_e/v1.11": 17157,
        "glue/mrpc": 16712,
        "kilt_tasks/hotpotqa": 17056
      },
      "step": 1070
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -144.29830932617188,
        "ag_news": 79.11036682128906,
        "amazon_polarity": 70.74176025390625,
        "cnn_dailymail/3.0.0": 173.96627807617188,
        "common_gen": 16.39756965637207,
        "cos_e/v1.11": 20.100439071655273,
        "glue/mrpc": 29.654735565185547,
        "kilt_tasks/hotpotqa": -37.00044250488281
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.03,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1010819673538208,
        "ag_news": 0.13259148597717285,
        "amazon_polarity": 0.1312488317489624,
        "cnn_dailymail/3.0.0": 0.14881446957588196,
        "common_gen": 0.12285768985748291,
        "cos_e/v1.11": 0.12341184914112091,
        "glue/mrpc": 0.12485336512327194,
        "kilt_tasks/hotpotqa": 0.11514033377170563
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16736,
        "ag_news": 17928,
        "amazon_polarity": 17200,
        "cnn_dailymail/3.0.0": 17664,
        "common_gen": 17304,
        "cos_e/v1.11": 17317,
        "glue/mrpc": 16888,
        "kilt_tasks/hotpotqa": 17184
      },
      "step": 1080
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -146.87619018554688,
        "ag_news": 79.09772491455078,
        "amazon_polarity": 70.59471893310547,
        "cnn_dailymail/3.0.0": 172.71180725097656,
        "common_gen": 15.755932807922363,
        "cos_e/v1.11": 18.766983032226562,
        "glue/mrpc": 28.880168914794922,
        "kilt_tasks/hotpotqa": -36.63069152832031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1069,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10096105188131332,
        "ag_news": 0.13267995417118073,
        "amazon_polarity": 0.13132114708423615,
        "cnn_dailymail/3.0.0": 0.14861156046390533,
        "common_gen": 0.12288882583379745,
        "cos_e/v1.11": 0.12333731353282928,
        "glue/mrpc": 0.12485574930906296,
        "kilt_tasks/hotpotqa": 0.11534448713064194
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16912,
        "ag_news": 18048,
        "amazon_polarity": 17400,
        "cnn_dailymail/3.0.0": 17880,
        "common_gen": 17424,
        "cos_e/v1.11": 17453,
        "glue/mrpc": 17040,
        "kilt_tasks/hotpotqa": 17344
      },
      "step": 1090
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -148.7019500732422,
        "ag_news": 79.03901672363281,
        "amazon_polarity": 70.37784576416016,
        "cnn_dailymail/3.0.0": 174.7991180419922,
        "common_gen": 11.268964767456055,
        "cos_e/v1.11": 19.20374870300293,
        "glue/mrpc": 27.614171981811523,
        "kilt_tasks/hotpotqa": -36.340118408203125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.016,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10090354084968567,
        "ag_news": 0.13272280991077423,
        "amazon_polarity": 0.13134461641311646,
        "cnn_dailymail/3.0.0": 0.14896848797798157,
        "common_gen": 0.12231700867414474,
        "cos_e/v1.11": 0.12349149584770203,
        "glue/mrpc": 0.12474881857633591,
        "kilt_tasks/hotpotqa": 0.11550319939851761
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17032,
        "ag_news": 18272,
        "amazon_polarity": 17568,
        "cnn_dailymail/3.0.0": 18040,
        "common_gen": 17504,
        "cos_e/v1.11": 17637,
        "glue/mrpc": 17224,
        "kilt_tasks/hotpotqa": 17504
      },
      "step": 1100
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1795,
      "eval_samples_per_second": 89.151,
      "eval_steps_per_second": 5.572,
      "step": 1100
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -149.0585479736328,
        "ag_news": 79.12190246582031,
        "amazon_polarity": 69.9608383178711,
        "cnn_dailymail/3.0.0": 172.70852661132812,
        "common_gen": 15.63458251953125,
        "cos_e/v1.11": 13.26171875,
        "glue/mrpc": 26.857276916503906,
        "kilt_tasks/hotpotqa": -41.12892532348633
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2006,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10110864788293839,
        "ag_news": 0.1329001784324646,
        "amazon_polarity": 0.131447434425354,
        "cnn_dailymail/3.0.0": 0.14870184659957886,
        "common_gen": 0.12315588444471359,
        "cos_e/v1.11": 0.12280600517988205,
        "glue/mrpc": 0.12482433766126633,
        "kilt_tasks/hotpotqa": 0.11505573987960815
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17248,
        "ag_news": 18352,
        "amazon_polarity": 17696,
        "cnn_dailymail/3.0.0": 18184,
        "common_gen": 17672,
        "cos_e/v1.11": 17821,
        "glue/mrpc": 17392,
        "kilt_tasks/hotpotqa": 17696
      },
      "step": 1110
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -147.56094360351562,
        "ag_news": 79.07744598388672,
        "amazon_polarity": 69.94051361083984,
        "cnn_dailymail/3.0.0": 172.47225952148438,
        "common_gen": 15.51374340057373,
        "cos_e/v1.11": 14.553584098815918,
        "glue/mrpc": 25.740182876586914,
        "kilt_tasks/hotpotqa": -37.19394302368164
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0316,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10131853073835373,
        "ag_news": 0.13277044892311096,
        "amazon_polarity": 0.13132932782173157,
        "cnn_dailymail/3.0.0": 0.14844833314418793,
        "common_gen": 0.12306611984968185,
        "cos_e/v1.11": 0.12292515486478806,
        "glue/mrpc": 0.12457764148712158,
        "kilt_tasks/hotpotqa": 0.11556437611579895
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17464,
        "ag_news": 18480,
        "amazon_polarity": 17824,
        "cnn_dailymail/3.0.0": 18336,
        "common_gen": 17768,
        "cos_e/v1.11": 17973,
        "glue/mrpc": 17672,
        "kilt_tasks/hotpotqa": 17824
      },
      "step": 1120
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -146.02154541015625,
        "ag_news": 79.34947204589844,
        "amazon_polarity": 69.89122009277344,
        "cnn_dailymail/3.0.0": 173.68016052246094,
        "common_gen": 10.125337600708008,
        "cos_e/v1.11": 15.266796112060547,
        "glue/mrpc": 20.33705711364746,
        "kilt_tasks/hotpotqa": -37.9308967590332
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0166,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10171598196029663,
        "ag_news": 0.13293370604515076,
        "amazon_polarity": 0.13144689798355103,
        "cnn_dailymail/3.0.0": 0.1487235724925995,
        "common_gen": 0.1224321499466896,
        "cos_e/v1.11": 0.12318249046802521,
        "glue/mrpc": 0.12392698973417282,
        "kilt_tasks/hotpotqa": 0.11563825607299805
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17552,
        "ag_news": 18712,
        "amazon_polarity": 18008,
        "cnn_dailymail/3.0.0": 18480,
        "common_gen": 17920,
        "cos_e/v1.11": 18197,
        "glue/mrpc": 17808,
        "kilt_tasks/hotpotqa": 17944
      },
      "step": 1130
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -148.4556427001953,
        "ag_news": 79.21670532226562,
        "amazon_polarity": 69.72537994384766,
        "cnn_dailymail/3.0.0": 171.57493591308594,
        "common_gen": 15.11073112487793,
        "cos_e/v1.11": 8.741922378540039,
        "glue/mrpc": 22.827558517456055,
        "kilt_tasks/hotpotqa": -38.78704071044922
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9989,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10158671438694,
        "ag_news": 0.13297118246555328,
        "amazon_polarity": 0.1314852386713028,
        "cnn_dailymail/3.0.0": 0.14834542572498322,
        "common_gen": 0.12325471639633179,
        "cos_e/v1.11": 0.12232942879199982,
        "glue/mrpc": 0.12438532710075378,
        "kilt_tasks/hotpotqa": 0.11564211547374725
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17776,
        "ag_news": 18888,
        "amazon_polarity": 18216,
        "cnn_dailymail/3.0.0": 18608,
        "common_gen": 18040,
        "cos_e/v1.11": 18341,
        "glue/mrpc": 17976,
        "kilt_tasks/hotpotqa": 18056
      },
      "step": 1140
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -144.9193572998047,
        "ag_news": 79.13522338867188,
        "amazon_polarity": 69.57096099853516,
        "cnn_dailymail/3.0.0": 172.10252380371094,
        "common_gen": 14.526556015014648,
        "cos_e/v1.11": 5.11944580078125,
        "glue/mrpc": 21.557756423950195,
        "kilt_tasks/hotpotqa": -39.69834899902344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1343,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10214806348085403,
        "ag_news": 0.1329839527606964,
        "amazon_polarity": 0.13149294257164001,
        "cnn_dailymail/3.0.0": 0.14839603006839752,
        "common_gen": 0.12323399633169174,
        "cos_e/v1.11": 0.12187585979700089,
        "glue/mrpc": 0.12425907701253891,
        "kilt_tasks/hotpotqa": 0.11561000347137451
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17912,
        "ag_news": 19024,
        "amazon_polarity": 18376,
        "cnn_dailymail/3.0.0": 18760,
        "common_gen": 18208,
        "cos_e/v1.11": 18509,
        "glue/mrpc": 18128,
        "kilt_tasks/hotpotqa": 18264
      },
      "step": 1150
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -149.0066375732422,
        "ag_news": 79.13565826416016,
        "amazon_polarity": 69.77149963378906,
        "cnn_dailymail/3.0.0": 166.70848083496094,
        "common_gen": 17.17382049560547,
        "cos_e/v1.11": 3.173959970474243,
        "glue/mrpc": 13.126591682434082,
        "kilt_tasks/hotpotqa": -36.465538024902344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1941,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10196136683225632,
        "ag_news": 0.13322792947292328,
        "amazon_polarity": 0.1317714899778366,
        "cnn_dailymail/3.0.0": 0.14765968918800354,
        "common_gen": 0.12388427555561066,
        "cos_e/v1.11": 0.12186643481254578,
        "glue/mrpc": 0.12329749017953873,
        "kilt_tasks/hotpotqa": 0.11633127927780151
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18072,
        "ag_news": 19128,
        "amazon_polarity": 18512,
        "cnn_dailymail/3.0.0": 18920,
        "common_gen": 18344,
        "cos_e/v1.11": 18757,
        "glue/mrpc": 18280,
        "kilt_tasks/hotpotqa": 18448
      },
      "step": 1160
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -150.0045166015625,
        "ag_news": 79.1058578491211,
        "amazon_polarity": 69.72721099853516,
        "cnn_dailymail/3.0.0": 168.73175048828125,
        "common_gen": 21.402559280395508,
        "cos_e/v1.11": -1.2417072057724,
        "glue/mrpc": 10.662895202636719,
        "kilt_tasks/hotpotqa": -32.692447662353516
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1335,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10189586877822876,
        "ag_news": 0.1331413835287094,
        "amazon_polarity": 0.13168981671333313,
        "cnn_dailymail/3.0.0": 0.147853821516037,
        "common_gen": 0.12445970624685287,
        "cos_e/v1.11": 0.121210977435112,
        "glue/mrpc": 0.1229080781340599,
        "kilt_tasks/hotpotqa": 0.11684034764766693
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18232,
        "ag_news": 19288,
        "amazon_polarity": 18648,
        "cnn_dailymail/3.0.0": 19088,
        "common_gen": 18504,
        "cos_e/v1.11": 18925,
        "glue/mrpc": 18468,
        "kilt_tasks/hotpotqa": 18584
      },
      "step": 1170
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -150.6976318359375,
        "ag_news": 78.77510070800781,
        "amazon_polarity": 69.38674926757812,
        "cnn_dailymail/3.0.0": 170.19781494140625,
        "common_gen": 18.604759216308594,
        "cos_e/v1.11": -2.1335673332214355,
        "glue/mrpc": 11.202391624450684,
        "kilt_tasks/hotpotqa": -31.61719512939453
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1162,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1019279882311821,
        "ag_news": 0.13308949768543243,
        "amazon_polarity": 0.1316431164741516,
        "cnn_dailymail/3.0.0": 0.14804038405418396,
        "common_gen": 0.12408997863531113,
        "cos_e/v1.11": 0.12113264948129654,
        "glue/mrpc": 0.12302609533071518,
        "kilt_tasks/hotpotqa": 0.11705029755830765
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18360,
        "ag_news": 19440,
        "amazon_polarity": 18824,
        "cnn_dailymail/3.0.0": 19280,
        "common_gen": 18640,
        "cos_e/v1.11": 19085,
        "glue/mrpc": 18612,
        "kilt_tasks/hotpotqa": 18776
      },
      "step": 1180
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -153.28395080566406,
        "ag_news": 78.744384765625,
        "amazon_polarity": 69.86843872070312,
        "cnn_dailymail/3.0.0": 173.03573608398438,
        "common_gen": 22.559635162353516,
        "cos_e/v1.11": -2.2635536193847656,
        "glue/mrpc": 9.3701171875,
        "kilt_tasks/hotpotqa": -31.081192016601562
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1712,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10164991766214371,
        "ag_news": 0.13297082483768463,
        "amazon_polarity": 0.13160987198352814,
        "cnn_dailymail/3.0.0": 0.14833523333072662,
        "common_gen": 0.12458954751491547,
        "cos_e/v1.11": 0.1210583969950676,
        "glue/mrpc": 0.12270054966211319,
        "kilt_tasks/hotpotqa": 0.11708555370569229
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18544,
        "ag_news": 19560,
        "amazon_polarity": 18928,
        "cnn_dailymail/3.0.0": 19408,
        "common_gen": 18848,
        "cos_e/v1.11": 19285,
        "glue/mrpc": 18788,
        "kilt_tasks/hotpotqa": 18936
      },
      "step": 1190
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -154.08360290527344,
        "ag_news": 78.71743774414062,
        "amazon_polarity": 69.82470703125,
        "cnn_dailymail/3.0.0": 174.12144470214844,
        "common_gen": 22.818836212158203,
        "cos_e/v1.11": -2.5495314598083496,
        "glue/mrpc": 9.248062133789062,
        "kilt_tasks/hotpotqa": -30.59075355529785
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0618,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10163244605064392,
        "ag_news": 0.13291847705841064,
        "amazon_polarity": 0.13156113028526306,
        "cnn_dailymail/3.0.0": 0.1484001874923706,
        "common_gen": 0.12461524456739426,
        "cos_e/v1.11": 0.12102165818214417,
        "glue/mrpc": 0.12267966568470001,
        "kilt_tasks/hotpotqa": 0.11717104911804199
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18672,
        "ag_news": 19728,
        "amazon_polarity": 19096,
        "cnn_dailymail/3.0.0": 19560,
        "common_gen": 19048,
        "cos_e/v1.11": 19429,
        "glue/mrpc": 18948,
        "kilt_tasks/hotpotqa": 19096
      },
      "step": 1200
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1807,
      "eval_samples_per_second": 88.547,
      "eval_steps_per_second": 5.534,
      "step": 1200
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -153.9619598388672,
        "ag_news": 78.69991302490234,
        "amazon_polarity": 69.94120788574219,
        "cnn_dailymail/3.0.0": 174.93980407714844,
        "common_gen": 25.89027214050293,
        "cos_e/v1.11": -0.8167833089828491,
        "glue/mrpc": 12.756035804748535,
        "kilt_tasks/hotpotqa": -27.23275375366211
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0845,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10155282914638519,
        "ag_news": 0.132646381855011,
        "amazon_polarity": 0.131317600607872,
        "cnn_dailymail/3.0.0": 0.14817142486572266,
        "common_gen": 0.12483550608158112,
        "cos_e/v1.11": 0.12106379866600037,
        "glue/mrpc": 0.12296601384878159,
        "kilt_tasks/hotpotqa": 0.11744635552167892
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18816,
        "ag_news": 19888,
        "amazon_polarity": 19232,
        "cnn_dailymail/3.0.0": 19720,
        "common_gen": 19216,
        "cos_e/v1.11": 19610,
        "glue/mrpc": 19116,
        "kilt_tasks/hotpotqa": 19256
      },
      "step": 1210
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -153.2144012451172,
        "ag_news": 78.54325103759766,
        "amazon_polarity": 70.03355407714844,
        "cnn_dailymail/3.0.0": 171.2353515625,
        "common_gen": 24.092151641845703,
        "cos_e/v1.11": -6.653757572174072,
        "glue/mrpc": 12.90368938446045,
        "kilt_tasks/hotpotqa": -26.65053939819336
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0518,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10188145935535431,
        "ag_news": 0.13279439508914948,
        "amazon_polarity": 0.1315069943666458,
        "cnn_dailymail/3.0.0": 0.14766837656497955,
        "common_gen": 0.12477107346057892,
        "cos_e/v1.11": 0.12045864760875702,
        "glue/mrpc": 0.12318403273820877,
        "kilt_tasks/hotpotqa": 0.11773498356342316
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18952,
        "ag_news": 20072,
        "amazon_polarity": 19352,
        "cnn_dailymail/3.0.0": 19848,
        "common_gen": 19376,
        "cos_e/v1.11": 19778,
        "glue/mrpc": 19324,
        "kilt_tasks/hotpotqa": 19432
      },
      "step": 1220
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -151.70675659179688,
        "ag_news": 78.4889907836914,
        "amazon_polarity": 69.93679809570312,
        "cnn_dailymail/3.0.0": 171.95091247558594,
        "common_gen": 28.384408950805664,
        "cos_e/v1.11": -7.475212097167969,
        "glue/mrpc": 16.81765365600586,
        "kilt_tasks/hotpotqa": -30.871063232421875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.979,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10206537693738937,
        "ag_news": 0.1326557844877243,
        "amazon_polarity": 0.13136856257915497,
        "cnn_dailymail/3.0.0": 0.1475803107023239,
        "common_gen": 0.1252913922071457,
        "cos_e/v1.11": 0.12027529627084732,
        "glue/mrpc": 0.12365076690912247,
        "kilt_tasks/hotpotqa": 0.1171124279499054
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19128,
        "ag_news": 20280,
        "amazon_polarity": 19488,
        "cnn_dailymail/3.0.0": 20000,
        "common_gen": 19464,
        "cos_e/v1.11": 19970,
        "glue/mrpc": 19516,
        "kilt_tasks/hotpotqa": 19568
      },
      "step": 1230
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -153.06747436523438,
        "ag_news": 78.47293853759766,
        "amazon_polarity": 69.86964416503906,
        "cnn_dailymail/3.0.0": 175.32411193847656,
        "common_gen": 26.22386932373047,
        "cos_e/v1.11": -5.301782131195068,
        "glue/mrpc": 18.670059204101562,
        "kilt_tasks/hotpotqa": -32.405216217041016
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0821,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10194779187440872,
        "ag_news": 0.13256555795669556,
        "amazon_polarity": 0.13127674162387848,
        "cnn_dailymail/3.0.0": 0.14798574149608612,
        "common_gen": 0.12493043392896652,
        "cos_e/v1.11": 0.12053985893726349,
        "glue/mrpc": 0.12386393547058105,
        "kilt_tasks/hotpotqa": 0.11688987165689468
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19296,
        "ag_news": 20432,
        "amazon_polarity": 19616,
        "cnn_dailymail/3.0.0": 20160,
        "common_gen": 19648,
        "cos_e/v1.11": 20082,
        "glue/mrpc": 19724,
        "kilt_tasks/hotpotqa": 19736
      },
      "step": 1240
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -150.62554931640625,
        "ag_news": 78.452392578125,
        "amazon_polarity": 69.84889221191406,
        "cnn_dailymail/3.0.0": 174.63584899902344,
        "common_gen": 25.01823616027832,
        "cos_e/v1.11": -5.139857292175293,
        "glue/mrpc": 17.783428192138672,
        "kilt_tasks/hotpotqa": -31.21582794189453
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0142,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10230924934148788,
        "ag_news": 0.1325281858444214,
        "amazon_polarity": 0.13124479353427887,
        "cnn_dailymail/3.0.0": 0.14776739478111267,
        "common_gen": 0.12475743889808655,
        "cos_e/v1.11": 0.12057633697986603,
        "glue/mrpc": 0.12374124675989151,
        "kilt_tasks/hotpotqa": 0.1170753538608551
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19488,
        "ag_news": 20640,
        "amazon_polarity": 19712,
        "cnn_dailymail/3.0.0": 20352,
        "common_gen": 19712,
        "cos_e/v1.11": 20210,
        "glue/mrpc": 19932,
        "kilt_tasks/hotpotqa": 19928
      },
      "step": 1250
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -148.45433044433594,
        "ag_news": 78.43045043945312,
        "amazon_polarity": 69.77857971191406,
        "cnn_dailymail/3.0.0": 177.74032592773438,
        "common_gen": 23.291872024536133,
        "cos_e/v1.11": -5.878546237945557,
        "glue/mrpc": 13.313935279846191,
        "kilt_tasks/hotpotqa": -30.518230438232422
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0102,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10265414416790009,
        "ag_news": 0.13251246511936188,
        "amazon_polarity": 0.13122710585594177,
        "cnn_dailymail/3.0.0": 0.1482079029083252,
        "common_gen": 0.12453314661979675,
        "cos_e/v1.11": 0.12050972133874893,
        "glue/mrpc": 0.12314187735319138,
        "kilt_tasks/hotpotqa": 0.11721358448266983
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19616,
        "ag_news": 20840,
        "amazon_polarity": 19872,
        "cnn_dailymail/3.0.0": 20528,
        "common_gen": 19840,
        "cos_e/v1.11": 20370,
        "glue/mrpc": 20100,
        "kilt_tasks/hotpotqa": 20088
      },
      "step": 1260
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -151.4056854248047,
        "ag_news": 78.47674560546875,
        "amazon_polarity": 69.54052734375,
        "cnn_dailymail/3.0.0": 177.5217742919922,
        "common_gen": 25.61743927001953,
        "cos_e/v1.11": -6.958650588989258,
        "glue/mrpc": 13.554264068603516,
        "kilt_tasks/hotpotqa": -30.063079833984375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9384,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10240967571735382,
        "ag_news": 0.1325089931488037,
        "amazon_polarity": 0.1311868131160736,
        "cnn_dailymail/3.0.0": 0.14809493720531464,
        "common_gen": 0.12487902492284775,
        "cos_e/v1.11": 0.12039919197559357,
        "glue/mrpc": 0.12320080399513245,
        "kilt_tasks/hotpotqa": 0.11732055991888046
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19816,
        "ag_news": 20992,
        "amazon_polarity": 20056,
        "cnn_dailymail/3.0.0": 20656,
        "common_gen": 19992,
        "cos_e/v1.11": 20522,
        "glue/mrpc": 20284,
        "kilt_tasks/hotpotqa": 20216
      },
      "step": 1270
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -152.16497802734375,
        "ag_news": 78.47158813476562,
        "amazon_polarity": 69.46006774902344,
        "cnn_dailymail/3.0.0": 178.87155151367188,
        "common_gen": 24.667993545532227,
        "cos_e/v1.11": -8.93766975402832,
        "glue/mrpc": 15.12244987487793,
        "kilt_tasks/hotpotqa": -29.071523666381836
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0278,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10239670425653458,
        "ag_news": 0.13247117400169373,
        "amazon_polarity": 0.1311434507369995,
        "cnn_dailymail/3.0.0": 0.14821313321590424,
        "common_gen": 0.12474049627780914,
        "cos_e/v1.11": 0.12014450877904892,
        "glue/mrpc": 0.12341726571321487,
        "kilt_tasks/hotpotqa": 0.11747321486473083
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19960,
        "ag_news": 21112,
        "amazon_polarity": 20232,
        "cnn_dailymail/3.0.0": 20776,
        "common_gen": 20160,
        "cos_e/v1.11": 20634,
        "glue/mrpc": 20500,
        "kilt_tasks/hotpotqa": 20440
      },
      "step": 1280
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -151.78387451171875,
        "ag_news": 78.41764068603516,
        "amazon_polarity": 69.26129913330078,
        "cnn_dailymail/3.0.0": 181.2783660888672,
        "common_gen": 20.264577865600586,
        "cos_e/v1.11": -6.225926876068115,
        "glue/mrpc": 15.423566818237305,
        "kilt_tasks/hotpotqa": -31.527544021606445
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9462,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10253309458494186,
        "ag_news": 0.13245223462581635,
        "amazon_polarity": 0.13110865652561188,
        "cnn_dailymail/3.0.0": 0.14853453636169434,
        "common_gen": 0.1241491511464119,
        "cos_e/v1.11": 0.12054291367530823,
        "glue/mrpc": 0.12348208576440811,
        "kilt_tasks/hotpotqa": 0.11719726026058197
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20128,
        "ag_news": 21256,
        "amazon_polarity": 20464,
        "cnn_dailymail/3.0.0": 20976,
        "common_gen": 20328,
        "cos_e/v1.11": 20762,
        "glue/mrpc": 20652,
        "kilt_tasks/hotpotqa": 20528
      },
      "step": 1290
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -155.90296936035156,
        "ag_news": 78.39893341064453,
        "amazon_polarity": 69.22171783447266,
        "cnn_dailymail/3.0.0": 180.7484893798828,
        "common_gen": 19.2871036529541,
        "cos_e/v1.11": -4.9706339836120605,
        "glue/mrpc": 14.343823432922363,
        "kilt_tasks/hotpotqa": -32.423465728759766
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8996,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10222693532705307,
        "ag_news": 0.13252787292003632,
        "amazon_polarity": 0.1311855912208557,
        "cnn_dailymail/3.0.0": 0.14846991002559662,
        "common_gen": 0.12411873787641525,
        "cos_e/v1.11": 0.1208256185054779,
        "glue/mrpc": 0.12344039231538773,
        "kilt_tasks/hotpotqa": 0.11720498651266098
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20336,
        "ag_news": 21424,
        "amazon_polarity": 20656,
        "cnn_dailymail/3.0.0": 21136,
        "common_gen": 20464,
        "cos_e/v1.11": 20866,
        "glue/mrpc": 20812,
        "kilt_tasks/hotpotqa": 20680
      },
      "step": 1300
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1773,
      "eval_samples_per_second": 90.224,
      "eval_steps_per_second": 5.639,
      "step": 1300
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -160.85189819335938,
        "ag_news": 78.38345336914062,
        "amazon_polarity": 69.20015716552734,
        "cnn_dailymail/3.0.0": 182.6263427734375,
        "common_gen": 20.22862434387207,
        "cos_e/v1.11": -3.635234832763672,
        "glue/mrpc": 17.606067657470703,
        "kilt_tasks/hotpotqa": -34.978973388671875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9656,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10173302888870239,
        "ag_news": 0.13247625529766083,
        "amazon_polarity": 0.13113871216773987,
        "cnn_dailymail/3.0.0": 0.14865897595882416,
        "common_gen": 0.12423256784677505,
        "cos_e/v1.11": 0.12100135535001755,
        "glue/mrpc": 0.12387324869632721,
        "kilt_tasks/hotpotqa": 0.11688584089279175
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20480,
        "ag_news": 21576,
        "amazon_polarity": 20800,
        "cnn_dailymail/3.0.0": 21248,
        "common_gen": 20616,
        "cos_e/v1.11": 21098,
        "glue/mrpc": 21028,
        "kilt_tasks/hotpotqa": 20808
      },
      "step": 1310
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -164.91195678710938,
        "ag_news": 78.3384780883789,
        "amazon_polarity": 67.86280059814453,
        "cnn_dailymail/3.0.0": 182.59027099609375,
        "common_gen": 20.500608444213867,
        "cos_e/v1.11": -6.802265644073486,
        "glue/mrpc": 16.85148811340332,
        "kilt_tasks/hotpotqa": -34.46266555786133
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0067,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10147009789943695,
        "ag_news": 0.13258634507656097,
        "amazon_polarity": 0.13106608390808105,
        "cnn_dailymail/3.0.0": 0.1487194150686264,
        "common_gen": 0.12440921366214752,
        "cos_e/v1.11": 0.12072781473398209,
        "glue/mrpc": 0.12391070276498795,
        "kilt_tasks/hotpotqa": 0.11711027473211288
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20664,
        "ag_news": 21712,
        "amazon_polarity": 20968,
        "cnn_dailymail/3.0.0": 21368,
        "common_gen": 20800,
        "cos_e/v1.11": 21282,
        "glue/mrpc": 21180,
        "kilt_tasks/hotpotqa": 20960
      },
      "step": 1320
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -164.62234497070312,
        "ag_news": 78.28795623779297,
        "amazon_polarity": 67.90226745605469,
        "cnn_dailymail/3.0.0": 181.8693389892578,
        "common_gen": 18.708784103393555,
        "cos_e/v1.11": -6.197591781616211,
        "glue/mrpc": 18.390857696533203,
        "kilt_tasks/hotpotqa": -36.8260383605957
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8641,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1016182154417038,
        "ag_news": 0.1325981467962265,
        "amazon_polarity": 0.13109634816646576,
        "cnn_dailymail/3.0.0": 0.1485593616962433,
        "common_gen": 0.12421257048845291,
        "cos_e/v1.11": 0.12086758017539978,
        "glue/mrpc": 0.12416928261518478,
        "kilt_tasks/hotpotqa": 0.11687847226858139
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20784,
        "ag_news": 21872,
        "amazon_polarity": 21192,
        "cnn_dailymail/3.0.0": 21488,
        "common_gen": 20928,
        "cos_e/v1.11": 21482,
        "glue/mrpc": 21364,
        "kilt_tasks/hotpotqa": 21104
      },
      "step": 1330
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.4855194091797,
        "ag_news": 78.28237915039062,
        "amazon_polarity": 67.40655517578125,
        "cnn_dailymail/3.0.0": 181.07041931152344,
        "common_gen": 23.30242156982422,
        "cos_e/v1.11": -7.555249214172363,
        "glue/mrpc": 17.277584075927734,
        "kilt_tasks/hotpotqa": -36.29722213745117
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0325,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10179506987333298,
        "ag_news": 0.13253279030323029,
        "amazon_polarity": 0.1309671252965927,
        "cnn_dailymail/3.0.0": 0.14829465746879578,
        "common_gen": 0.12480680644512177,
        "cos_e/v1.11": 0.12067130953073502,
        "glue/mrpc": 0.12398829311132431,
        "kilt_tasks/hotpotqa": 0.11694380640983582
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20936,
        "ag_news": 21992,
        "amazon_polarity": 21344,
        "cnn_dailymail/3.0.0": 21688,
        "common_gen": 21080,
        "cos_e/v1.11": 21658,
        "glue/mrpc": 21548,
        "kilt_tasks/hotpotqa": 21248
      },
      "step": 1340
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.50228881835938,
        "ag_news": 78.27397155761719,
        "amazon_polarity": 67.35566711425781,
        "cnn_dailymail/3.0.0": 179.58497619628906,
        "common_gen": 25.33309555053711,
        "cos_e/v1.11": -8.776137351989746,
        "glue/mrpc": 16.70941162109375,
        "kilt_tasks/hotpotqa": -36.93073654174805
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0069,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10190162062644958,
        "ag_news": 0.1325441598892212,
        "amazon_polarity": 0.1309780329465866,
        "cnn_dailymail/3.0.0": 0.14800751209259033,
        "common_gen": 0.12512242794036865,
        "cos_e/v1.11": 0.12056417763233185,
        "glue/mrpc": 0.12395381927490234,
        "kilt_tasks/hotpotqa": 0.11692817509174347
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21120,
        "ag_news": 22160,
        "amazon_polarity": 21448,
        "cnn_dailymail/3.0.0": 21880,
        "common_gen": 21224,
        "cos_e/v1.11": 21770,
        "glue/mrpc": 21756,
        "kilt_tasks/hotpotqa": 21416
      },
      "step": 1350
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -166.3613739013672,
        "ag_news": 78.32649230957031,
        "amazon_polarity": 66.79823303222656,
        "cnn_dailymail/3.0.0": 179.92764282226562,
        "common_gen": 25.60432243347168,
        "cos_e/v1.11": -7.611660480499268,
        "glue/mrpc": 17.272010803222656,
        "kilt_tasks/hotpotqa": -33.70301818847656
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9237,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10162974894046783,
        "ag_news": 0.13248030841350555,
        "amazon_polarity": 0.13083404302597046,
        "cnn_dailymail/3.0.0": 0.14792299270629883,
        "common_gen": 0.125118225812912,
        "cos_e/v1.11": 0.12069325894117355,
        "glue/mrpc": 0.12399304658174515,
        "kilt_tasks/hotpotqa": 0.11732844263315201
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21256,
        "ag_news": 22368,
        "amazon_polarity": 21592,
        "cnn_dailymail/3.0.0": 22000,
        "common_gen": 21424,
        "cos_e/v1.11": 21946,
        "glue/mrpc": 21908,
        "kilt_tasks/hotpotqa": 21560
      },
      "step": 1360
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -165.69976806640625,
        "ag_news": 78.047119140625,
        "amazon_polarity": 66.6443099975586,
        "cnn_dailymail/3.0.0": 179.63560485839844,
        "common_gen": 28.21109962463379,
        "cos_e/v1.11": -9.500265121459961,
        "glue/mrpc": 17.577533721923828,
        "kilt_tasks/hotpotqa": -33.682579040527344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9898,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10176876932382584,
        "ag_news": 0.13239961862564087,
        "amazon_polarity": 0.13077805936336517,
        "cnn_dailymail/3.0.0": 0.14777158200740814,
        "common_gen": 0.12545855343341827,
        "cos_e/v1.11": 0.12045110017061234,
        "glue/mrpc": 0.12402569502592087,
        "kilt_tasks/hotpotqa": 0.11734670400619507
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21464,
        "ag_news": 22504,
        "amazon_polarity": 21784,
        "cnn_dailymail/3.0.0": 22176,
        "common_gen": 21576,
        "cos_e/v1.11": 22058,
        "glue/mrpc": 22048,
        "kilt_tasks/hotpotqa": 21720
      },
      "step": 1370
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -166.1435089111328,
        "ag_news": 78.02381896972656,
        "amazon_polarity": 66.48738098144531,
        "cnn_dailymail/3.0.0": 178.29522705078125,
        "common_gen": 29.734033584594727,
        "cos_e/v1.11": -10.492615699768066,
        "glue/mrpc": 15.574249267578125,
        "kilt_tasks/hotpotqa": -32.841827392578125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9544,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10183502733707428,
        "ag_news": 0.1324203610420227,
        "amazon_polarity": 0.1307855248451233,
        "cnn_dailymail/3.0.0": 0.1475266069173813,
        "common_gen": 0.1257116198539734,
        "cos_e/v1.11": 0.12038542330265045,
        "glue/mrpc": 0.12381020933389664,
        "kilt_tasks/hotpotqa": 0.11752528697252274
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21640,
        "ag_news": 22672,
        "amazon_polarity": 21912,
        "cnn_dailymail/3.0.0": 22320,
        "common_gen": 21720,
        "cos_e/v1.11": 22210,
        "glue/mrpc": 22288,
        "kilt_tasks/hotpotqa": 21848
      },
      "step": 1380
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -169.17318725585938,
        "ag_news": 77.9705810546875,
        "amazon_polarity": 66.36042785644531,
        "cnn_dailymail/3.0.0": 179.3022918701172,
        "common_gen": 33.3803825378418,
        "cos_e/v1.11": -14.410873413085938,
        "glue/mrpc": 17.740022659301758,
        "kilt_tasks/hotpotqa": -28.96381950378418
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9677,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10152369737625122,
        "ag_news": 0.13231241703033447,
        "amazon_polarity": 0.13067439198493958,
        "cnn_dailymail/3.0.0": 0.14751707017421722,
        "common_gen": 0.1261320412158966,
        "cos_e/v1.11": 0.11983074992895126,
        "glue/mrpc": 0.12403388321399689,
        "kilt_tasks/hotpotqa": 0.11797576397657394
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21784,
        "ag_news": 22832,
        "amazon_polarity": 22080,
        "cnn_dailymail/3.0.0": 22472,
        "common_gen": 21904,
        "cos_e/v1.11": 22354,
        "glue/mrpc": 22416,
        "kilt_tasks/hotpotqa": 22048
      },
      "step": 1390
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -160.89907836914062,
        "ag_news": 77.8847427368164,
        "amazon_polarity": 66.2681655883789,
        "cnn_dailymail/3.0.0": 182.05502319335938,
        "common_gen": 32.8076057434082,
        "cos_e/v1.11": -19.617990493774414,
        "glue/mrpc": 14.103843688964844,
        "kilt_tasks/hotpotqa": -32.31160354614258
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9419,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10253513604402542,
        "ag_news": 0.1323200762271881,
        "amazon_polarity": 0.13068681955337524,
        "cnn_dailymail/3.0.0": 0.14791718125343323,
        "common_gen": 0.12609511613845825,
        "cos_e/v1.11": 0.11922579258680344,
        "glue/mrpc": 0.12359970062971115,
        "kilt_tasks/hotpotqa": 0.11762011796236038
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21912,
        "ag_news": 23088,
        "amazon_polarity": 22216,
        "cnn_dailymail/3.0.0": 22600,
        "common_gen": 22096,
        "cos_e/v1.11": 22498,
        "glue/mrpc": 22504,
        "kilt_tasks/hotpotqa": 22256
      },
      "step": 1400
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 1.0,
      "eval_runtime": 0.1847,
      "eval_samples_per_second": 86.625,
      "eval_steps_per_second": 5.414,
      "step": 1400
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.9867401123047,
        "ag_news": 77.9066390991211,
        "amazon_polarity": 66.0771713256836,
        "cnn_dailymail/3.0.0": 181.5865478515625,
        "common_gen": 31.800395965576172,
        "cos_e/v1.11": -18.74628257751465,
        "glue/mrpc": 13.607840538024902,
        "kilt_tasks/hotpotqa": -34.70945358276367
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9941,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10235633701086044,
        "ag_news": 0.13240793347358704,
        "amazon_polarity": 0.1307496726512909,
        "cnn_dailymail/3.0.0": 0.14787989854812622,
        "common_gen": 0.12606200575828552,
        "cos_e/v1.11": 0.11945673078298569,
        "glue/mrpc": 0.12364325672388077,
        "kilt_tasks/hotpotqa": 0.11744414269924164
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22016,
        "ag_news": 23240,
        "amazon_polarity": 22424,
        "cnn_dailymail/3.0.0": 22800,
        "common_gen": 22240,
        "cos_e/v1.11": 22666,
        "glue/mrpc": 22672,
        "kilt_tasks/hotpotqa": 22392
      },
      "step": 1410
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.17361450195312,
        "ag_news": 77.80829620361328,
        "amazon_polarity": 66.06947326660156,
        "cnn_dailymail/3.0.0": 184.0557403564453,
        "common_gen": 30.668914794921875,
        "cos_e/v1.11": -20.327180862426758,
        "glue/mrpc": 13.13394546508789,
        "kilt_tasks/hotpotqa": -35.02141189575195
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9843,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10251695662736893,
        "ag_news": 0.13236849009990692,
        "amazon_polarity": 0.1307290643453598,
        "cnn_dailymail/3.0.0": 0.14818227291107178,
        "common_gen": 0.1259080320596695,
        "cos_e/v1.11": 0.1192765012383461,
        "glue/mrpc": 0.12358683347702026,
        "kilt_tasks/hotpotqa": 0.1174318790435791
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22184,
        "ag_news": 23400,
        "amazon_polarity": 22552,
        "cnn_dailymail/3.0.0": 22936,
        "common_gen": 22424,
        "cos_e/v1.11": 22818,
        "glue/mrpc": 22848,
        "kilt_tasks/hotpotqa": 22568
      },
      "step": 1420
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -167.34423828125,
        "ag_news": 77.8009262084961,
        "amazon_polarity": 66.2539291381836,
        "cnn_dailymail/3.0.0": 185.32269287109375,
        "common_gen": 33.66796875,
        "cos_e/v1.11": -20.41093635559082,
        "glue/mrpc": 10.289664268493652,
        "kilt_tasks/hotpotqa": -33.81455612182617
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9657,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10214471817016602,
        "ag_news": 0.13235118985176086,
        "amazon_polarity": 0.13074418902397156,
        "cnn_dailymail/3.0.0": 0.14830467104911804,
        "common_gen": 0.12631447613239288,
        "cos_e/v1.11": 0.11929446458816528,
        "glue/mrpc": 0.12322998046875,
        "kilt_tasks/hotpotqa": 0.11761626601219177
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22376,
        "ag_news": 23568,
        "amazon_polarity": 22712,
        "cnn_dailymail/3.0.0": 23112,
        "common_gen": 22568,
        "cos_e/v1.11": 22962,
        "glue/mrpc": 22992,
        "kilt_tasks/hotpotqa": 22720
      },
      "step": 1430
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -167.31629943847656,
        "ag_news": 77.75787353515625,
        "amazon_polarity": 66.3216781616211,
        "cnn_dailymail/3.0.0": 185.30081176757812,
        "common_gen": 32.10145568847656,
        "cos_e/v1.11": -21.639480590820312,
        "glue/mrpc": 6.420210838317871,
        "kilt_tasks/hotpotqa": -35.84797668457031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8261,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10233429819345474,
        "ag_news": 0.13246887922286987,
        "amazon_polarity": 0.13088122010231018,
        "cnn_dailymail/3.0.0": 0.14838159084320068,
        "common_gen": 0.12624427676200867,
        "cos_e/v1.11": 0.11929420381784439,
        "glue/mrpc": 0.12287349998950958,
        "kilt_tasks/hotpotqa": 0.11752206832170486
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22576,
        "ag_news": 23728,
        "amazon_polarity": 22944,
        "cnn_dailymail/3.0.0": 23248,
        "common_gen": 22664,
        "cos_e/v1.11": 23098,
        "glue/mrpc": 23176,
        "kilt_tasks/hotpotqa": 22856
      },
      "step": 1440
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -169.03594970703125,
        "ag_news": 77.75957489013672,
        "amazon_polarity": 66.29198455810547,
        "cnn_dailymail/3.0.0": 184.70584106445312,
        "common_gen": 35.001800537109375,
        "cos_e/v1.11": -21.335559844970703,
        "glue/mrpc": 5.060647010803223,
        "kilt_tasks/hotpotqa": -34.71881866455078
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9137,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10221090167760849,
        "ag_news": 0.13243094086647034,
        "amazon_polarity": 0.1308448761701584,
        "cnn_dailymail/3.0.0": 0.1481882631778717,
        "common_gen": 0.12661388516426086,
        "cos_e/v1.11": 0.11934076994657516,
        "glue/mrpc": 0.12269450724124908,
        "kilt_tasks/hotpotqa": 0.11767587810754776
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22720,
        "ag_news": 23856,
        "amazon_polarity": 23144,
        "cnn_dailymail/3.0.0": 23424,
        "common_gen": 22856,
        "cos_e/v1.11": 23210,
        "glue/mrpc": 23360,
        "kilt_tasks/hotpotqa": 23000
      },
      "step": 1450
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -167.0525665283203,
        "ag_news": 77.7064208984375,
        "amazon_polarity": 66.32701873779297,
        "cnn_dailymail/3.0.0": 186.05258178710938,
        "common_gen": 35.26279830932617,
        "cos_e/v1.11": -22.99586296081543,
        "glue/mrpc": 3.3805794715881348,
        "kilt_tasks/hotpotqa": -32.02533721923828
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8994,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10245765745639801,
        "ag_news": 0.13235175609588623,
        "amazon_polarity": 0.1307840794324875,
        "cnn_dailymail/3.0.0": 0.14826016128063202,
        "common_gen": 0.12659917771816254,
        "cos_e/v1.11": 0.11911129206418991,
        "glue/mrpc": 0.12244442850351334,
        "kilt_tasks/hotpotqa": 0.11799140274524689
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22856,
        "ag_news": 24016,
        "amazon_polarity": 23312,
        "cnn_dailymail/3.0.0": 23568,
        "common_gen": 23040,
        "cos_e/v1.11": 23386,
        "glue/mrpc": 23544,
        "kilt_tasks/hotpotqa": 23128
      },
      "step": 1460
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -165.86524963378906,
        "ag_news": 77.703369140625,
        "amazon_polarity": 66.32972717285156,
        "cnn_dailymail/3.0.0": 185.87380981445312,
        "common_gen": 35.02719497680664,
        "cos_e/v1.11": -24.668590545654297,
        "glue/mrpc": 2.344449758529663,
        "kilt_tasks/hotpotqa": -32.12162399291992
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9418,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10268410295248032,
        "ag_news": 0.13236555457115173,
        "amazon_polarity": 0.13080376386642456,
        "cnn_dailymail/3.0.0": 0.148191437125206,
        "common_gen": 0.1266006976366043,
        "cos_e/v1.11": 0.11895886808633804,
        "glue/mrpc": 0.12235749512910843,
        "kilt_tasks/hotpotqa": 0.11803804337978363
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23040,
        "ag_news": 24128,
        "amazon_polarity": 23504,
        "cnn_dailymail/3.0.0": 23720,
        "common_gen": 23200,
        "cos_e/v1.11": 23554,
        "glue/mrpc": 23712,
        "kilt_tasks/hotpotqa": 23272
      },
      "step": 1470
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -168.193603515625,
        "ag_news": 77.55175018310547,
        "amazon_polarity": 66.31299591064453,
        "cnn_dailymail/3.0.0": 185.83343505859375,
        "common_gen": 32.44235610961914,
        "cos_e/v1.11": -28.448833465576172,
        "glue/mrpc": -0.20420396327972412,
        "kilt_tasks/hotpotqa": -30.156728744506836
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0148,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1026250571012497,
        "ag_news": 0.13247597217559814,
        "amazon_polarity": 0.13093647360801697,
        "cnn_dailymail/3.0.0": 0.1482759714126587,
        "common_gen": 0.1264050304889679,
        "cos_e/v1.11": 0.11865247786045074,
        "glue/mrpc": 0.122187040746212,
        "kilt_tasks/hotpotqa": 0.11844208836555481
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23152,
        "ag_news": 24328,
        "amazon_polarity": 23616,
        "cnn_dailymail/3.0.0": 23928,
        "common_gen": 23312,
        "cos_e/v1.11": 23738,
        "glue/mrpc": 23888,
        "kilt_tasks/hotpotqa": 23448
      },
      "step": 1480
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -166.65545654296875,
        "ag_news": 77.321044921875,
        "amazon_polarity": 66.17182159423828,
        "cnn_dailymail/3.0.0": 185.5193328857422,
        "common_gen": 33.44805145263672,
        "cos_e/v1.11": -29.91126251220703,
        "glue/mrpc": -1.5381687879562378,
        "kilt_tasks/hotpotqa": -28.20263671875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.915,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10284867882728577,
        "ag_news": 0.13240915536880493,
        "amazon_polarity": 0.1308876872062683,
        "cnn_dailymail/3.0.0": 0.14813251793384552,
        "common_gen": 0.12652307748794556,
        "cos_e/v1.11": 0.11848505586385727,
        "glue/mrpc": 0.12201887369155884,
        "kilt_tasks/hotpotqa": 0.11869490891695023
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23256,
        "ag_news": 24504,
        "amazon_polarity": 23784,
        "cnn_dailymail/3.0.0": 24096,
        "common_gen": 23464,
        "cos_e/v1.11": 23882,
        "glue/mrpc": 24088,
        "kilt_tasks/hotpotqa": 23616
      },
      "step": 1490
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -164.0761260986328,
        "ag_news": 77.29165649414062,
        "amazon_polarity": 66.064697265625,
        "cnn_dailymail/3.0.0": 188.5446319580078,
        "common_gen": 33.02488327026367,
        "cos_e/v1.11": -33.282569885253906,
        "glue/mrpc": -2.0843324661254883,
        "kilt_tasks/hotpotqa": -26.48710060119629
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0333,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10315021872520447,
        "ag_news": 0.13232985138893127,
        "amazon_polarity": 0.13080380856990814,
        "cnn_dailymail/3.0.0": 0.14845678210258484,
        "common_gen": 0.1264149695634842,
        "cos_e/v1.11": 0.11804984509944916,
        "glue/mrpc": 0.12191381305456161,
        "kilt_tasks/hotpotqa": 0.11888080835342407
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23392,
        "ag_news": 24632,
        "amazon_polarity": 23896,
        "cnn_dailymail/3.0.0": 24264,
        "common_gen": 23656,
        "cos_e/v1.11": 24066,
        "glue/mrpc": 24288,
        "kilt_tasks/hotpotqa": 23776
      },
      "step": 1500
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.189,
      "eval_samples_per_second": 84.678,
      "eval_steps_per_second": 5.292,
      "step": 1500
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -165.37753295898438,
        "ag_news": 77.15010070800781,
        "amazon_polarity": 66.02597045898438,
        "cnn_dailymail/3.0.0": 189.58120727539062,
        "common_gen": 34.09454345703125,
        "cos_e/v1.11": -33.464622497558594,
        "glue/mrpc": -1.6196898221969604,
        "kilt_tasks/hotpotqa": -33.53437805175781
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8969,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1031498834490776,
        "ag_news": 0.13237887620925903,
        "amazon_polarity": 0.13087111711502075,
        "cnn_dailymail/3.0.0": 0.1486358940601349,
        "common_gen": 0.12663863599300385,
        "cos_e/v1.11": 0.11813300848007202,
        "glue/mrpc": 0.12206799536943436,
        "kilt_tasks/hotpotqa": 0.11812452971935272
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23528,
        "ag_news": 24872,
        "amazon_polarity": 24048,
        "cnn_dailymail/3.0.0": 24368,
        "common_gen": 23800,
        "cos_e/v1.11": 24274,
        "glue/mrpc": 24456,
        "kilt_tasks/hotpotqa": 23904
      },
      "step": 1510
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -165.04673767089844,
        "ag_news": 77.07947540283203,
        "amazon_polarity": 66.01750946044922,
        "cnn_dailymail/3.0.0": 188.3055419921875,
        "common_gen": 36.13604736328125,
        "cos_e/v1.11": -38.93928909301758,
        "glue/mrpc": -1.1520720720291138,
        "kilt_tasks/hotpotqa": -36.90752410888672
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9184,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10334574431180954,
        "ag_news": 0.13246794044971466,
        "amazon_polarity": 0.13097243010997772,
        "cnn_dailymail/3.0.0": 0.1484955996274948,
        "common_gen": 0.12701715528964996,
        "cos_e/v1.11": 0.11760292947292328,
        "glue/mrpc": 0.12224996089935303,
        "kilt_tasks/hotpotqa": 0.11784820258617401
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23664,
        "ag_news": 25104,
        "amazon_polarity": 24208,
        "cnn_dailymail/3.0.0": 24520,
        "common_gen": 23928,
        "cos_e/v1.11": 24474,
        "glue/mrpc": 24608,
        "kilt_tasks/hotpotqa": 24024
      },
      "step": 1520
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.58338928222656,
        "ag_news": 77.05245208740234,
        "amazon_polarity": 65.98787689208984,
        "cnn_dailymail/3.0.0": 189.34078979492188,
        "common_gen": 33.99674606323242,
        "cos_e/v1.11": -41.86664962768555,
        "glue/mrpc": -1.6550847291946411,
        "kilt_tasks/hotpotqa": -35.2978630065918
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9989,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10358582437038422,
        "ag_news": 0.13246706128120422,
        "amazon_polarity": 0.13097605109214783,
        "cnn_dailymail/3.0.0": 0.1486009806394577,
        "common_gen": 0.12675954401493073,
        "cos_e/v1.11": 0.1172994002699852,
        "glue/mrpc": 0.12222153693437576,
        "kilt_tasks/hotpotqa": 0.11808957904577255
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23848,
        "ag_news": 25256,
        "amazon_polarity": 24344,
        "cnn_dailymail/3.0.0": 24632,
        "common_gen": 24136,
        "cos_e/v1.11": 24634,
        "glue/mrpc": 24768,
        "kilt_tasks/hotpotqa": 24192
      },
      "step": 1530
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -160.2982940673828,
        "ag_news": 77.01406860351562,
        "amazon_polarity": 65.85819244384766,
        "cnn_dailymail/3.0.0": 189.6643829345703,
        "common_gen": 33.492156982421875,
        "cos_e/v1.11": -40.18431854248047,
        "glue/mrpc": -2.3450894355773926,
        "kilt_tasks/hotpotqa": -35.23019790649414
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9403,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10395248979330063,
        "ag_news": 0.13238196074962616,
        "amazon_polarity": 0.13088449835777283,
        "cnn_dailymail/3.0.0": 0.1485051065683365,
        "common_gen": 0.12663595378398895,
        "cos_e/v1.11": 0.11747588962316513,
        "glue/mrpc": 0.12209371477365494,
        "kilt_tasks/hotpotqa": 0.1180703192949295
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23992,
        "ag_news": 25408,
        "amazon_polarity": 24552,
        "cnn_dailymail/3.0.0": 24808,
        "common_gen": 24208,
        "cos_e/v1.11": 24882,
        "glue/mrpc": 24904,
        "kilt_tasks/hotpotqa": 24336
      },
      "step": 1540
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.15023803710938,
        "ag_news": 76.9378433227539,
        "amazon_polarity": 65.8532943725586,
        "cnn_dailymail/3.0.0": 189.8354034423828,
        "common_gen": 31.043203353881836,
        "cos_e/v1.11": -41.167293548583984,
        "glue/mrpc": -3.1375579833984375,
        "kilt_tasks/hotpotqa": -34.300498962402344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9921,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10378802567720413,
        "ag_news": 0.13244269788265228,
        "amazon_polarity": 0.13095884025096893,
        "cnn_dailymail/3.0.0": 0.14855583012104034,
        "common_gen": 0.1264069527387619,
        "cos_e/v1.11": 0.11746656894683838,
        "glue/mrpc": 0.12209255248308182,
        "kilt_tasks/hotpotqa": 0.11828857660293579
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24144,
        "ag_news": 25616,
        "amazon_polarity": 24688,
        "cnn_dailymail/3.0.0": 24928,
        "common_gen": 24400,
        "cos_e/v1.11": 25066,
        "glue/mrpc": 25016,
        "kilt_tasks/hotpotqa": 24512
      },
      "step": 1550
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -162.11026000976562,
        "ag_news": 76.92086791992188,
        "amazon_polarity": 65.53179931640625,
        "cnn_dailymail/3.0.0": 189.7688751220703,
        "common_gen": 31.573434829711914,
        "cos_e/v1.11": -44.9040641784668,
        "glue/mrpc": -7.478123188018799,
        "kilt_tasks/hotpotqa": -40.1048698425293
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9602,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10412146151065826,
        "ag_news": 0.13262371718883514,
        "amazon_polarity": 0.131102055311203,
        "cnn_dailymail/3.0.0": 0.14869704842567444,
        "common_gen": 0.12666864693164825,
        "cos_e/v1.11": 0.11722968518733978,
        "glue/mrpc": 0.12175679951906204,
        "kilt_tasks/hotpotqa": 0.11780058592557907
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24312,
        "ag_news": 25784,
        "amazon_polarity": 24832,
        "cnn_dailymail/3.0.0": 25056,
        "common_gen": 24528,
        "cos_e/v1.11": 25234,
        "glue/mrpc": 25168,
        "kilt_tasks/hotpotqa": 24736
      },
      "step": 1560
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -166.64425659179688,
        "ag_news": 76.86734008789062,
        "amazon_polarity": 65.46088409423828,
        "cnn_dailymail/3.0.0": 191.65380859375,
        "common_gen": 34.151180267333984,
        "cos_e/v1.11": -42.43107604980469,
        "glue/mrpc": -9.105981826782227,
        "kilt_tasks/hotpotqa": -38.9564208984375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8709,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10367186367511749,
        "ag_news": 0.13254711031913757,
        "amazon_polarity": 0.13102883100509644,
        "cnn_dailymail/3.0.0": 0.14884857833385468,
        "common_gen": 0.12695078551769257,
        "cos_e/v1.11": 0.11750699579715729,
        "glue/mrpc": 0.12152618914842606,
        "kilt_tasks/hotpotqa": 0.11791972070932388
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24480,
        "ag_news": 25944,
        "amazon_polarity": 25048,
        "cnn_dailymail/3.0.0": 25152,
        "common_gen": 24696,
        "cos_e/v1.11": 25386,
        "glue/mrpc": 25328,
        "kilt_tasks/hotpotqa": 24896
      },
      "step": 1570
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -168.6895751953125,
        "ag_news": 76.59374237060547,
        "amazon_polarity": 65.29988861083984,
        "cnn_dailymail/3.0.0": 192.27955627441406,
        "common_gen": 35.83372116088867,
        "cos_e/v1.11": -47.59006118774414,
        "glue/mrpc": -11.211417198181152,
        "kilt_tasks/hotpotqa": -42.14035415649414
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.821,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10364612191915512,
        "ag_news": 0.1326480507850647,
        "amazon_polarity": 0.13114823400974274,
        "cnn_dailymail/3.0.0": 0.14904257655143738,
        "common_gen": 0.12731510400772095,
        "cos_e/v1.11": 0.11706428229808807,
        "glue/mrpc": 0.12142789363861084,
        "kilt_tasks/hotpotqa": 0.117707759141922
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24648,
        "ag_news": 26088,
        "amazon_polarity": 25272,
        "cnn_dailymail/3.0.0": 25232,
        "common_gen": 24848,
        "cos_e/v1.11": 25530,
        "glue/mrpc": 25496,
        "kilt_tasks/hotpotqa": 25096
      },
      "step": 1580
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -166.52833557128906,
        "ag_news": 76.43463897705078,
        "amazon_polarity": 65.3065414428711,
        "cnn_dailymail/3.0.0": 191.20606994628906,
        "common_gen": 34.448814392089844,
        "cos_e/v1.11": -47.02408218383789,
        "glue/mrpc": -11.737643241882324,
        "kilt_tasks/hotpotqa": -43.762847900390625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8838,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10396656394004822,
        "ag_news": 0.1326470673084259,
        "amazon_polarity": 0.1311737447977066,
        "cnn_dailymail/3.0.0": 0.14885029196739197,
        "common_gen": 0.1271740049123764,
        "cos_e/v1.11": 0.11719432473182678,
        "glue/mrpc": 0.12141582369804382,
        "kilt_tasks/hotpotqa": 0.11757820099592209
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24792,
        "ag_news": 26304,
        "amazon_polarity": 25472,
        "cnn_dailymail/3.0.0": 25352,
        "common_gen": 24936,
        "cos_e/v1.11": 25706,
        "glue/mrpc": 25640,
        "kilt_tasks/hotpotqa": 25288
      },
      "step": 1590
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -174.2808380126953,
        "ag_news": 76.41117858886719,
        "amazon_polarity": 65.06562805175781,
        "cnn_dailymail/3.0.0": 191.10763549804688,
        "common_gen": 38.329952239990234,
        "cos_e/v1.11": -49.7119255065918,
        "glue/mrpc": -4.964430332183838,
        "kilt_tasks/hotpotqa": -41.42376708984375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8859,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10318131744861603,
        "ag_news": 0.13256460428237915,
        "amazon_polarity": 0.13106824457645416,
        "cnn_dailymail/3.0.0": 0.14869315922260284,
        "common_gen": 0.12760905921459198,
        "cos_e/v1.11": 0.11685498803853989,
        "glue/mrpc": 0.12220145761966705,
        "kilt_tasks/hotpotqa": 0.1178271546959877
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24952,
        "ag_news": 26512,
        "amazon_polarity": 25632,
        "cnn_dailymail/3.0.0": 25480,
        "common_gen": 25064,
        "cos_e/v1.11": 25898,
        "glue/mrpc": 25804,
        "kilt_tasks/hotpotqa": 25424
      },
      "step": 1600
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1868,
      "eval_samples_per_second": 85.655,
      "eval_steps_per_second": 5.353,
      "step": 1600
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -170.56068420410156,
        "ag_news": 76.29064178466797,
        "amazon_polarity": 64.92080688476562,
        "cnn_dailymail/3.0.0": 191.05520629882812,
        "common_gen": 41.43311309814453,
        "cos_e/v1.11": -51.45180130004883,
        "glue/mrpc": -2.6898200511932373,
        "kilt_tasks/hotpotqa": -40.392330169677734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0247,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10353066772222519,
        "ag_news": 0.13240323960781097,
        "amazon_polarity": 0.13091011345386505,
        "cnn_dailymail/3.0.0": 0.14846937358379364,
        "common_gen": 0.12787918746471405,
        "cos_e/v1.11": 0.11657009273767471,
        "glue/mrpc": 0.12237532436847687,
        "kilt_tasks/hotpotqa": 0.11786191165447235
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25128,
        "ag_news": 26632,
        "amazon_polarity": 25800,
        "cnn_dailymail/3.0.0": 25648,
        "common_gen": 25240,
        "cos_e/v1.11": 26090,
        "glue/mrpc": 25932,
        "kilt_tasks/hotpotqa": 25576
      },
      "step": 1610
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -170.9581298828125,
        "ag_news": 76.23560333251953,
        "amazon_polarity": 64.86699676513672,
        "cnn_dailymail/3.0.0": 193.08131408691406,
        "common_gen": 38.99633026123047,
        "cos_e/v1.11": -53.270755767822266,
        "glue/mrpc": -4.189918518066406,
        "kilt_tasks/hotpotqa": -44.52769088745117
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8499,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1036486104130745,
        "ag_news": 0.13249938189983368,
        "amazon_polarity": 0.13100990653038025,
        "cnn_dailymail/3.0.0": 0.14883294701576233,
        "common_gen": 0.12768299877643585,
        "cos_e/v1.11": 0.11649594455957413,
        "glue/mrpc": 0.12231796234846115,
        "kilt_tasks/hotpotqa": 0.11751221865415573
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25296,
        "ag_news": 26816,
        "amazon_polarity": 25992,
        "cnn_dailymail/3.0.0": 25744,
        "common_gen": 25400,
        "cos_e/v1.11": 26266,
        "glue/mrpc": 26100,
        "kilt_tasks/hotpotqa": 25712
      },
      "step": 1620
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -170.15858459472656,
        "ag_news": 76.2221450805664,
        "amazon_polarity": 64.59455108642578,
        "cnn_dailymail/3.0.0": 196.10415649414062,
        "common_gen": 38.13064956665039,
        "cos_e/v1.11": -54.06685256958008,
        "glue/mrpc": -2.3263559341430664,
        "kilt_tasks/hotpotqa": -42.79915237426758
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.997,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10371711105108261,
        "ag_news": 0.13238102197647095,
        "amazon_polarity": 0.13086381554603577,
        "cnn_dailymail/3.0.0": 0.14909560978412628,
        "common_gen": 0.12747567892074585,
        "cos_e/v1.11": 0.11634748429059982,
        "glue/mrpc": 0.12246613949537277,
        "kilt_tasks/hotpotqa": 0.11765316128730774
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25480,
        "ag_news": 27016,
        "amazon_polarity": 26136,
        "cnn_dailymail/3.0.0": 25920,
        "common_gen": 25560,
        "cos_e/v1.11": 26418,
        "glue/mrpc": 26212,
        "kilt_tasks/hotpotqa": 25864
      },
      "step": 1630
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -166.87118530273438,
        "ag_news": 76.30449676513672,
        "amazon_polarity": 64.59219360351562,
        "cnn_dailymail/3.0.0": 197.7850799560547,
        "common_gen": 41.18156051635742,
        "cos_e/v1.11": -54.17066955566406,
        "glue/mrpc": -2.2000112533569336,
        "kilt_tasks/hotpotqa": -43.36160659790039
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9008,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10401901602745056,
        "ag_news": 0.13224929571151733,
        "amazon_polarity": 0.13072724640369415,
        "cnn_dailymail/3.0.0": 0.1491290032863617,
        "common_gen": 0.1277376115322113,
        "cos_e/v1.11": 0.11625593900680542,
        "glue/mrpc": 0.12237853556871414,
        "kilt_tasks/hotpotqa": 0.11750336736440659
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25640,
        "ag_news": 27216,
        "amazon_polarity": 26304,
        "cnn_dailymail/3.0.0": 26064,
        "common_gen": 25744,
        "cos_e/v1.11": 26586,
        "glue/mrpc": 26356,
        "kilt_tasks/hotpotqa": 25976
      },
      "step": 1640
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -165.3548126220703,
        "ag_news": 76.23455047607422,
        "amazon_polarity": 64.57345581054688,
        "cnn_dailymail/3.0.0": 201.2814178466797,
        "common_gen": 36.09067916870117,
        "cos_e/v1.11": -52.621543884277344,
        "glue/mrpc": -3.5333092212677,
        "kilt_tasks/hotpotqa": -40.48073196411133
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0432,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10419491678476334,
        "ag_news": 0.13217075169086456,
        "amazon_polarity": 0.1306607574224472,
        "cnn_dailymail/3.0.0": 0.14951127767562866,
        "common_gen": 0.1270451694726944,
        "cos_e/v1.11": 0.11641748249530792,
        "glue/mrpc": 0.12218239158391953,
        "kilt_tasks/hotpotqa": 0.11781726032495499
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25784,
        "ag_news": 27360,
        "amazon_polarity": 26472,
        "cnn_dailymail/3.0.0": 26272,
        "common_gen": 25888,
        "cos_e/v1.11": 26802,
        "glue/mrpc": 26476,
        "kilt_tasks/hotpotqa": 26112
      },
      "step": 1650
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -169.70423889160156,
        "ag_news": 76.27565002441406,
        "amazon_polarity": 64.67056274414062,
        "cnn_dailymail/3.0.0": 201.55174255371094,
        "common_gen": 37.710872650146484,
        "cos_e/v1.11": -54.69590759277344,
        "glue/mrpc": -7.319572925567627,
        "kilt_tasks/hotpotqa": -40.61109924316406
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0984,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10390184074640274,
        "ag_news": 0.13227364420890808,
        "amazon_polarity": 0.13077415525913239,
        "cnn_dailymail/3.0.0": 0.1496061384677887,
        "common_gen": 0.12735646963119507,
        "cos_e/v1.11": 0.11631056666374207,
        "glue/mrpc": 0.1218474805355072,
        "kilt_tasks/hotpotqa": 0.11792963743209839
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25904,
        "ag_news": 27544,
        "amazon_polarity": 26600,
        "cnn_dailymail/3.0.0": 26488,
        "common_gen": 26048,
        "cos_e/v1.11": 26954,
        "glue/mrpc": 26620,
        "kilt_tasks/hotpotqa": 26288
      },
      "step": 1660
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -168.7112579345703,
        "ag_news": 76.22383880615234,
        "amazon_polarity": 64.49966430664062,
        "cnn_dailymail/3.0.0": 202.48846435546875,
        "common_gen": 41.17607116699219,
        "cos_e/v1.11": -57.22998809814453,
        "glue/mrpc": -11.176844596862793,
        "kilt_tasks/hotpotqa": -38.61695098876953
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8766,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10404849797487259,
        "ag_news": 0.13223005831241608,
        "amazon_polarity": 0.13072025775909424,
        "cnn_dailymail/3.0.0": 0.14964687824249268,
        "common_gen": 0.12776818871498108,
        "cos_e/v1.11": 0.1160346269607544,
        "glue/mrpc": 0.1213841363787651,
        "kilt_tasks/hotpotqa": 0.11816748231649399
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26064,
        "ag_news": 27720,
        "amazon_polarity": 26784,
        "cnn_dailymail/3.0.0": 26600,
        "common_gen": 26176,
        "cos_e/v1.11": 27170,
        "glue/mrpc": 26796,
        "kilt_tasks/hotpotqa": 26416
      },
      "step": 1670
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.6080322265625,
        "ag_news": 76.12488555908203,
        "amazon_polarity": 64.31278991699219,
        "cnn_dailymail/3.0.0": 205.2752685546875,
        "common_gen": 39.71281051635742,
        "cos_e/v1.11": -57.81832504272461,
        "glue/mrpc": -11.61581802368164,
        "kilt_tasks/hotpotqa": -39.5086784362793
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0847,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10457479953765869,
        "ag_news": 0.13213293254375458,
        "amazon_polarity": 0.13061748445034027,
        "cnn_dailymail/3.0.0": 0.1499042809009552,
        "common_gen": 0.12751735746860504,
        "cos_e/v1.11": 0.1159389466047287,
        "glue/mrpc": 0.12128550559282303,
        "kilt_tasks/hotpotqa": 0.11802870780229568
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26200,
        "ag_news": 27840,
        "amazon_polarity": 26920,
        "cnn_dailymail/3.0.0": 26784,
        "common_gen": 26352,
        "cos_e/v1.11": 27330,
        "glue/mrpc": 26932,
        "kilt_tasks/hotpotqa": 26648
      },
      "step": 1680
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -163.37074279785156,
        "ag_news": 76.11913299560547,
        "amazon_polarity": 64.40290069580078,
        "cnn_dailymail/3.0.0": 206.35293579101562,
        "common_gen": 42.17333984375,
        "cos_e/v1.11": -56.161766052246094,
        "glue/mrpc": -9.430429458618164,
        "kilt_tasks/hotpotqa": -39.44762420654297
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9999,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1045561134815216,
        "ag_news": 0.1319870948791504,
        "amazon_polarity": 0.13048993051052094,
        "cnn_dailymail/3.0.0": 0.14984112977981567,
        "common_gen": 0.1276962161064148,
        "cos_e/v1.11": 0.11604315042495728,
        "glue/mrpc": 0.12144093215465546,
        "kilt_tasks/hotpotqa": 0.11794538795948029
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26368,
        "ag_news": 27960,
        "amazon_polarity": 27104,
        "cnn_dailymail/3.0.0": 26928,
        "common_gen": 26512,
        "cos_e/v1.11": 27466,
        "glue/mrpc": 27108,
        "kilt_tasks/hotpotqa": 26840
      },
      "step": 1690
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -164.26402282714844,
        "ag_news": 75.85325622558594,
        "amazon_polarity": 64.36703491210938,
        "cnn_dailymail/3.0.0": 207.3358917236328,
        "common_gen": 44.147220611572266,
        "cos_e/v1.11": -59.521018981933594,
        "glue/mrpc": -11.014747619628906,
        "kilt_tasks/hotpotqa": -42.17155456542969
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.965,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10458610206842422,
        "ag_news": 0.1320154070854187,
        "amazon_polarity": 0.13055144250392914,
        "cnn_dailymail/3.0.0": 0.14999952912330627,
        "common_gen": 0.12801393866539001,
        "cos_e/v1.11": 0.11576388031244278,
        "glue/mrpc": 0.12134125083684921,
        "kilt_tasks/hotpotqa": 0.11772842705249786
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26528,
        "ag_news": 28128,
        "amazon_polarity": 27256,
        "cnn_dailymail/3.0.0": 27112,
        "common_gen": 26672,
        "cos_e/v1.11": 27602,
        "glue/mrpc": 27292,
        "kilt_tasks/hotpotqa": 26976
      },
      "step": 1700
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1807,
      "eval_samples_per_second": 88.542,
      "eval_steps_per_second": 5.534,
      "step": 1700
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -168.19468688964844,
        "ag_news": 75.87623596191406,
        "amazon_polarity": 64.216796875,
        "cnn_dailymail/3.0.0": 206.50086975097656,
        "common_gen": 43.33850860595703,
        "cos_e/v1.11": -57.12700653076172,
        "glue/mrpc": -7.136127471923828,
        "kilt_tasks/hotpotqa": -43.635440826416016
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8738,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1042531207203865,
        "ag_news": 0.13200940191745758,
        "amazon_polarity": 0.13052783906459808,
        "cnn_dailymail/3.0.0": 0.14981231093406677,
        "common_gen": 0.12791657447814941,
        "cos_e/v1.11": 0.11606864631175995,
        "glue/mrpc": 0.12181901931762695,
        "kilt_tasks/hotpotqa": 0.11759305000305176
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26664,
        "ag_news": 28400,
        "amazon_polarity": 27424,
        "cnn_dailymail/3.0.0": 27256,
        "common_gen": 26792,
        "cos_e/v1.11": 27746,
        "glue/mrpc": 27412,
        "kilt_tasks/hotpotqa": 27152
      },
      "step": 1710
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -167.10105895996094,
        "ag_news": 75.82632446289062,
        "amazon_polarity": 64.27723693847656,
        "cnn_dailymail/3.0.0": 206.23696899414062,
        "common_gen": 46.940696716308594,
        "cos_e/v1.11": -60.85634994506836,
        "glue/mrpc": -10.473445892333984,
        "kilt_tasks/hotpotqa": -43.03446960449219
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9686,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10444238781929016,
        "ag_news": 0.1320134401321411,
        "amazon_polarity": 0.13055001199245453,
        "cnn_dailymail/3.0.0": 0.1497310996055603,
        "common_gen": 0.1283838301897049,
        "cos_e/v1.11": 0.11570415645837784,
        "glue/mrpc": 0.12146525830030441,
        "kilt_tasks/hotpotqa": 0.11770983785390854
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26792,
        "ag_news": 28600,
        "amazon_polarity": 27584,
        "cnn_dailymail/3.0.0": 27464,
        "common_gen": 26968,
        "cos_e/v1.11": 27866,
        "glue/mrpc": 27572,
        "kilt_tasks/hotpotqa": 27280
      },
      "step": 1720
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -170.27188110351562,
        "ag_news": 75.81742095947266,
        "amazon_polarity": 64.19882202148438,
        "cnn_dailymail/3.0.0": 205.76596069335938,
        "common_gen": 48.692752838134766,
        "cos_e/v1.11": -61.171852111816406,
        "glue/mrpc": -9.349531173706055,
        "kilt_tasks/hotpotqa": -40.67791748046875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0039,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10416093468666077,
        "ag_news": 0.13196933269500732,
        "amazon_polarity": 0.13050183653831482,
        "cnn_dailymail/3.0.0": 0.14956015348434448,
        "common_gen": 0.12856890261173248,
        "cos_e/v1.11": 0.11567524820566177,
        "glue/mrpc": 0.12158617377281189,
        "kilt_tasks/hotpotqa": 0.11797737330198288
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 26968,
        "ag_news": 28704,
        "amazon_polarity": 27720,
        "cnn_dailymail/3.0.0": 27632,
        "common_gen": 27184,
        "cos_e/v1.11": 28034,
        "glue/mrpc": 27756,
        "kilt_tasks/hotpotqa": 27408
      },
      "step": 1730
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -178.35350036621094,
        "ag_news": 75.71759796142578,
        "amazon_polarity": 64.06507873535156,
        "cnn_dailymail/3.0.0": 205.18243408203125,
        "common_gen": 48.4939079284668,
        "cos_e/v1.11": -58.30257034301758,
        "glue/mrpc": -8.530953407287598,
        "kilt_tasks/hotpotqa": -38.52646255493164
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9629,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10344237834215164,
        "ag_news": 0.13197557628154755,
        "amazon_polarity": 0.1305079460144043,
        "cnn_dailymail/3.0.0": 0.14944422245025635,
        "common_gen": 0.12857237458229065,
        "cos_e/v1.11": 0.11605416983366013,
        "glue/mrpc": 0.1217275857925415,
        "kilt_tasks/hotpotqa": 0.11827579140663147
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27160,
        "ag_news": 28888,
        "amazon_polarity": 27904,
        "cnn_dailymail/3.0.0": 27800,
        "common_gen": 27264,
        "cos_e/v1.11": 28218,
        "glue/mrpc": 27852,
        "kilt_tasks/hotpotqa": 27600
      },
      "step": 1740
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -179.7399139404297,
        "ag_news": 75.70346069335938,
        "amazon_polarity": 63.49069595336914,
        "cnn_dailymail/3.0.0": 203.54281616210938,
        "common_gen": 46.547420501708984,
        "cos_e/v1.11": -59.347049713134766,
        "glue/mrpc": -7.468438625335693,
        "kilt_tasks/hotpotqa": -38.144718170166016
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1438,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10342789441347122,
        "ag_news": 0.13203898072242737,
        "amazon_polarity": 0.1305048018693924,
        "cnn_dailymail/3.0.0": 0.14923067390918732,
        "common_gen": 0.12840604782104492,
        "cos_e/v1.11": 0.11603792011737823,
        "glue/mrpc": 0.12193949520587921,
        "kilt_tasks/hotpotqa": 0.11841423064470291
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27288,
        "ag_news": 29008,
        "amazon_polarity": 28032,
        "cnn_dailymail/3.0.0": 28032,
        "common_gen": 27480,
        "cos_e/v1.11": 28426,
        "glue/mrpc": 27964,
        "kilt_tasks/hotpotqa": 27736
      },
      "step": 1750
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -179.6706085205078,
        "ag_news": 75.62191009521484,
        "amazon_polarity": 63.41341018676758,
        "cnn_dailymail/3.0.0": 203.6207733154297,
        "common_gen": 48.82172393798828,
        "cos_e/v1.11": -58.60218811035156,
        "glue/mrpc": -7.8084259033203125,
        "kilt_tasks/hotpotqa": -37.26859664916992
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8644,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10344826430082321,
        "ag_news": 0.13195489346981049,
        "amazon_polarity": 0.1304265409708023,
        "cnn_dailymail/3.0.0": 0.14910662174224854,
        "common_gen": 0.12862320244312286,
        "cos_e/v1.11": 0.1160978451371193,
        "glue/mrpc": 0.12185925990343094,
        "kilt_tasks/hotpotqa": 0.11848344653844833
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27432,
        "ag_news": 29288,
        "amazon_polarity": 28184,
        "cnn_dailymail/3.0.0": 28216,
        "common_gen": 27560,
        "cos_e/v1.11": 28570,
        "glue/mrpc": 28132,
        "kilt_tasks/hotpotqa": 27864
      },
      "step": 1760
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -178.55239868164062,
        "ag_news": 75.4607162475586,
        "amazon_polarity": 63.32137680053711,
        "cnn_dailymail/3.0.0": 203.04910278320312,
        "common_gen": 51.451377868652344,
        "cos_e/v1.11": -54.61486053466797,
        "glue/mrpc": -7.543110370635986,
        "kilt_tasks/hotpotqa": -38.36042785644531
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0143,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10354557633399963,
        "ag_news": 0.13182833790779114,
        "amazon_polarity": 0.13031429052352905,
        "cnn_dailymail/3.0.0": 0.1488540917634964,
        "common_gen": 0.1288507878780365,
        "cos_e/v1.11": 0.1164868175983429,
        "glue/mrpc": 0.12181906402111053,
        "kilt_tasks/hotpotqa": 0.11830098927021027
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27584,
        "ag_news": 29448,
        "amazon_polarity": 28328,
        "cnn_dailymail/3.0.0": 28384,
        "common_gen": 27704,
        "cos_e/v1.11": 28746,
        "glue/mrpc": 28276,
        "kilt_tasks/hotpotqa": 28056
      },
      "step": 1770
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -181.8922882080078,
        "ag_news": 75.35322570800781,
        "amazon_polarity": 62.90461349487305,
        "cnn_dailymail/3.0.0": 202.2928009033203,
        "common_gen": 49.7733154296875,
        "cos_e/v1.11": -54.2896842956543,
        "glue/mrpc": -8.393635749816895,
        "kilt_tasks/hotpotqa": -38.7081184387207
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0411,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10335737466812134,
        "ag_news": 0.13190342485904694,
        "amazon_polarity": 0.13035446405410767,
        "cnn_dailymail/3.0.0": 0.14879661798477173,
        "common_gen": 0.12874041497707367,
        "cos_e/v1.11": 0.11664120852947235,
        "glue/mrpc": 0.12182942032814026,
        "kilt_tasks/hotpotqa": 0.11837713420391083
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27792,
        "ag_news": 29624,
        "amazon_polarity": 28440,
        "cnn_dailymail/3.0.0": 28576,
        "common_gen": 27904,
        "cos_e/v1.11": 28914,
        "glue/mrpc": 28396,
        "kilt_tasks/hotpotqa": 28160
      },
      "step": 1780
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -178.38861083984375,
        "ag_news": 75.3309326171875,
        "amazon_polarity": 62.86790084838867,
        "cnn_dailymail/3.0.0": 201.85914611816406,
        "common_gen": 47.113746643066406,
        "cos_e/v1.11": -53.1479377746582,
        "glue/mrpc": -6.832789421081543,
        "kilt_tasks/hotpotqa": -39.66184997558594
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0223,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10374055802822113,
        "ag_news": 0.13186295330524445,
        "amazon_polarity": 0.13031698763370514,
        "cnn_dailymail/3.0.0": 0.1486431360244751,
        "common_gen": 0.12838885188102722,
        "cos_e/v1.11": 0.11677374690771103,
        "glue/mrpc": 0.12200150638818741,
        "kilt_tasks/hotpotqa": 0.11827223002910614
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 27928,
        "ag_news": 29736,
        "amazon_polarity": 28608,
        "cnn_dailymail/3.0.0": 28784,
        "common_gen": 28048,
        "cos_e/v1.11": 29098,
        "glue/mrpc": 28540,
        "kilt_tasks/hotpotqa": 28344
      },
      "step": 1790
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -179.54446411132812,
        "ag_news": 75.32658386230469,
        "amazon_polarity": 62.7962532043457,
        "cnn_dailymail/3.0.0": 201.95242309570312,
        "common_gen": 46.194480895996094,
        "cos_e/v1.11": -51.89552307128906,
        "glue/mrpc": -5.799508094787598,
        "kilt_tasks/hotpotqa": -36.69185256958008
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0289,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10364429652690887,
        "ag_news": 0.13179616630077362,
        "amazon_polarity": 0.13024695217609406,
        "cnn_dailymail/3.0.0": 0.14853224158287048,
        "common_gen": 0.12822258472442627,
        "cos_e/v1.11": 0.1168922558426857,
        "glue/mrpc": 0.12208535522222519,
        "kilt_tasks/hotpotqa": 0.11857999116182327
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28072,
        "ag_news": 29904,
        "amazon_polarity": 28736,
        "cnn_dailymail/3.0.0": 28984,
        "common_gen": 28192,
        "cos_e/v1.11": 29287,
        "glue/mrpc": 28716,
        "kilt_tasks/hotpotqa": 28472
      },
      "step": 1800
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.1805,
      "eval_samples_per_second": 88.64,
      "eval_steps_per_second": 5.54,
      "step": 1800
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -179.36175537109375,
        "ag_news": 75.24114990234375,
        "amazon_polarity": 62.57923889160156,
        "cnn_dailymail/3.0.0": 202.84756469726562,
        "common_gen": 46.49003601074219,
        "cos_e/v1.11": -51.99595642089844,
        "glue/mrpc": -1.4836827516555786,
        "kilt_tasks/hotpotqa": -39.23051071166992
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0854,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10368114709854126,
        "ag_news": 0.1317228227853775,
        "amazon_polarity": 0.1301625818014145,
        "cnn_dailymail/3.0.0": 0.14853782951831818,
        "common_gen": 0.12820686399936676,
        "cos_e/v1.11": 0.11686412245035172,
        "glue/mrpc": 0.12254936993122101,
        "kilt_tasks/hotpotqa": 0.11827529966831207
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28232,
        "ag_news": 30024,
        "amazon_polarity": 28864,
        "cnn_dailymail/3.0.0": 29240,
        "common_gen": 28336,
        "cos_e/v1.11": 29463,
        "glue/mrpc": 28884,
        "kilt_tasks/hotpotqa": 28600
      },
      "step": 1810
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -175.46983337402344,
        "ag_news": 75.06620025634766,
        "amazon_polarity": 62.570133209228516,
        "cnn_dailymail/3.0.0": 200.36122131347656,
        "common_gen": 41.01656723022461,
        "cos_e/v1.11": -52.05658721923828,
        "glue/mrpc": 3.667125701904297,
        "kilt_tasks/hotpotqa": -41.74955749511719
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9258,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10414958000183105,
        "ag_news": 0.13172878324985504,
        "amazon_polarity": 0.13019298017024994,
        "cnn_dailymail/3.0.0": 0.14817368984222412,
        "common_gen": 0.1275862455368042,
        "cos_e/v1.11": 0.11692015081644058,
        "glue/mrpc": 0.12319298833608627,
        "kilt_tasks/hotpotqa": 0.11805564910173416
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28400,
        "ag_news": 30160,
        "amazon_polarity": 29040,
        "cnn_dailymail/3.0.0": 29416,
        "common_gen": 28480,
        "cos_e/v1.11": 29591,
        "glue/mrpc": 29076,
        "kilt_tasks/hotpotqa": 28760
      },
      "step": 1820
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -176.81515502929688,
        "ag_news": 75.02933502197266,
        "amazon_polarity": 62.58256912231445,
        "cnn_dailymail/3.0.0": 197.554931640625,
        "common_gen": 39.54460144042969,
        "cos_e/v1.11": -50.416587829589844,
        "glue/mrpc": 3.9383511543273926,
        "kilt_tasks/hotpotqa": -41.79592514038086
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9191,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10412285476922989,
        "ag_news": 0.13177208602428436,
        "amazon_polarity": 0.13024593889713287,
        "cnn_dailymail/3.0.0": 0.1477910876274109,
        "common_gen": 0.12746797502040863,
        "cos_e/v1.11": 0.11718005686998367,
        "glue/mrpc": 0.12329144775867462,
        "kilt_tasks/hotpotqa": 0.11812855303287506
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28576,
        "ag_news": 30328,
        "amazon_polarity": 29224,
        "cnn_dailymail/3.0.0": 29584,
        "common_gen": 28608,
        "cos_e/v1.11": 29751,
        "glue/mrpc": 29220,
        "kilt_tasks/hotpotqa": 28912
      },
      "step": 1830
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -175.62147521972656,
        "ag_news": 75.01695251464844,
        "amazon_polarity": 62.56988525390625,
        "cnn_dailymail/3.0.0": 199.1825408935547,
        "common_gen": 39.438514709472656,
        "cos_e/v1.11": -54.4837760925293,
        "glue/mrpc": 1.4676885604858398,
        "kilt_tasks/hotpotqa": -42.25479507446289
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.916,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10433866083621979,
        "ag_news": 0.1318131536245346,
        "amazon_polarity": 0.13029061257839203,
        "cnn_dailymail/3.0.0": 0.14801789820194244,
        "common_gen": 0.1275079995393753,
        "cos_e/v1.11": 0.11681118607521057,
        "glue/mrpc": 0.12306946516036987,
        "kilt_tasks/hotpotqa": 0.11815104633569717
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28712,
        "ag_news": 30472,
        "amazon_polarity": 29360,
        "cnn_dailymail/3.0.0": 29728,
        "common_gen": 28736,
        "cos_e/v1.11": 29935,
        "glue/mrpc": 29440,
        "kilt_tasks/hotpotqa": 29096
      },
      "step": 1840
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -177.62155151367188,
        "ag_news": 74.87165069580078,
        "amazon_polarity": 62.418766021728516,
        "cnn_dailymail/3.0.0": 196.4877166748047,
        "common_gen": 39.99494934082031,
        "cos_e/v1.11": -58.83863830566406,
        "glue/mrpc": 2.2938480377197266,
        "kilt_tasks/hotpotqa": -40.323734283447266
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9651,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10426966100931168,
        "ag_news": 0.1318705528974533,
        "amazon_polarity": 0.13035067915916443,
        "cnn_dailymail/3.0.0": 0.1476849764585495,
        "common_gen": 0.12765823304653168,
        "cos_e/v1.11": 0.11644314974546432,
        "glue/mrpc": 0.1232570931315422,
        "kilt_tasks/hotpotqa": 0.11846577376127243
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 28896,
        "ag_news": 30608,
        "amazon_polarity": 29520,
        "cnn_dailymail/3.0.0": 29888,
        "common_gen": 28888,
        "cos_e/v1.11": 30071,
        "glue/mrpc": 29616,
        "kilt_tasks/hotpotqa": 29272
      },
      "step": 1850
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -178.68313598632812,
        "ag_news": 74.82496643066406,
        "amazon_polarity": 62.42795181274414,
        "cnn_dailymail/3.0.0": 197.9161834716797,
        "common_gen": 38.41884231567383,
        "cos_e/v1.11": -60.859989166259766,
        "glue/mrpc": 1.640055537223816,
        "kilt_tasks/hotpotqa": -40.808475494384766
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0179,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10426507890224457,
        "ag_news": 0.1319061517715454,
        "amazon_polarity": 0.13039669394493103,
        "cnn_dailymail/3.0.0": 0.1478826403617859,
        "common_gen": 0.12752260267734528,
        "cos_e/v1.11": 0.1163000836968422,
        "glue/mrpc": 0.12324316054582596,
        "kilt_tasks/hotpotqa": 0.1184835433959961
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29080,
        "ag_news": 30720,
        "amazon_polarity": 29688,
        "cnn_dailymail/3.0.0": 30024,
        "common_gen": 29096,
        "cos_e/v1.11": 30215,
        "glue/mrpc": 29752,
        "kilt_tasks/hotpotqa": 29464
      },
      "step": 1860
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -178.4263458251953,
        "ag_news": 74.63997650146484,
        "amazon_polarity": 62.3111686706543,
        "cnn_dailymail/3.0.0": 194.8173370361328,
        "common_gen": 39.489200592041016,
        "cos_e/v1.11": -57.14140319824219,
        "glue/mrpc": 1.4821330308914185,
        "kilt_tasks/hotpotqa": -43.42740249633789
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9341,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10436361283063889,
        "ag_news": 0.13189448416233063,
        "amazon_polarity": 0.13039739429950714,
        "cnn_dailymail/3.0.0": 0.14742591977119446,
        "common_gen": 0.12767109274864197,
        "cos_e/v1.11": 0.1167495995759964,
        "glue/mrpc": 0.12325763702392578,
        "kilt_tasks/hotpotqa": 0.11824031174182892
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29264,
        "ag_news": 30928,
        "amazon_polarity": 29792,
        "cnn_dailymail/3.0.0": 30216,
        "common_gen": 29208,
        "cos_e/v1.11": 30399,
        "glue/mrpc": 29912,
        "kilt_tasks/hotpotqa": 29600
      },
      "step": 1870
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -179.6571044921875,
        "ag_news": 74.5525894165039,
        "amazon_polarity": 62.33930206298828,
        "cnn_dailymail/3.0.0": 194.13304138183594,
        "common_gen": 37.84041976928711,
        "cos_e/v1.11": -55.72664260864258,
        "glue/mrpc": 2.1740469932556152,
        "kilt_tasks/hotpotqa": -44.29377365112305
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9102,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10432501137256622,
        "ag_news": 0.13190314173698425,
        "amazon_polarity": 0.13042378425598145,
        "cnn_dailymail/3.0.0": 0.14731082320213318,
        "common_gen": 0.12750650942325592,
        "cos_e/v1.11": 0.11695690453052521,
        "glue/mrpc": 0.12337653338909149,
        "kilt_tasks/hotpotqa": 0.11819726228713989
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29448,
        "ag_news": 31144,
        "amazon_polarity": 29936,
        "cnn_dailymail/3.0.0": 30384,
        "common_gen": 29376,
        "cos_e/v1.11": 30543,
        "glue/mrpc": 30032,
        "kilt_tasks/hotpotqa": 29736
      },
      "step": 1880
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -180.06272888183594,
        "ag_news": 74.46636962890625,
        "amazon_polarity": 62.31940460205078,
        "cnn_dailymail/3.0.0": 195.21652221679688,
        "common_gen": 38.055641174316406,
        "cos_e/v1.11": -55.10934066772461,
        "glue/mrpc": 0.5229848623275757,
        "kilt_tasks/hotpotqa": -46.292720794677734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9265,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10435961186885834,
        "ag_news": 0.13190430402755737,
        "amazon_polarity": 0.13043679296970367,
        "cnn_dailymail/3.0.0": 0.14742812514305115,
        "common_gen": 0.12755441665649414,
        "cos_e/v1.11": 0.11707071214914322,
        "glue/mrpc": 0.12322166562080383,
        "kilt_tasks/hotpotqa": 0.11802446842193604
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29552,
        "ag_news": 31320,
        "amazon_polarity": 30112,
        "cnn_dailymail/3.0.0": 30536,
        "common_gen": 29584,
        "cos_e/v1.11": 30695,
        "glue/mrpc": 30200,
        "kilt_tasks/hotpotqa": 29880
      },
      "step": 1890
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -182.69041442871094,
        "ag_news": 74.18327331542969,
        "amazon_polarity": 62.122013092041016,
        "cnn_dailymail/3.0.0": 194.2566680908203,
        "common_gen": 37.03452682495117,
        "cos_e/v1.11": -56.74790954589844,
        "glue/mrpc": 1.6453155279159546,
        "kilt_tasks/hotpotqa": -44.03303527832031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8664,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10419655591249466,
        "ag_news": 0.1319008469581604,
        "amazon_polarity": 0.13044743239879608,
        "cnn_dailymail/3.0.0": 0.14728960394859314,
        "common_gen": 0.1274758279323578,
        "cos_e/v1.11": 0.11695859581232071,
        "glue/mrpc": 0.12339955568313599,
        "kilt_tasks/hotpotqa": 0.11833161115646362
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29704,
        "ag_news": 31496,
        "amazon_polarity": 30280,
        "cnn_dailymail/3.0.0": 30680,
        "common_gen": 29744,
        "cos_e/v1.11": 30759,
        "glue/mrpc": 30424,
        "kilt_tasks/hotpotqa": 30072
      },
      "step": 1900
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.1824,
      "eval_samples_per_second": 87.706,
      "eval_steps_per_second": 5.482,
      "step": 1900
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -183.12559509277344,
        "ag_news": 74.16921997070312,
        "amazon_polarity": 62.06795120239258,
        "cnn_dailymail/3.0.0": 193.29666137695312,
        "common_gen": 37.009159088134766,
        "cos_e/v1.11": -59.48535919189453,
        "glue/mrpc": -0.4374295175075531,
        "kilt_tasks/hotpotqa": -45.45575714111328
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9904,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10429564118385315,
        "ag_news": 0.13199636340141296,
        "amazon_polarity": 0.1305409073829651,
        "cnn_dailymail/3.0.0": 0.14722616970539093,
        "common_gen": 0.12757815420627594,
        "cos_e/v1.11": 0.11678832024335861,
        "glue/mrpc": 0.12327651679515839,
        "kilt_tasks/hotpotqa": 0.11829803138971329
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 29872,
        "ag_news": 31576,
        "amazon_polarity": 30416,
        "cnn_dailymail/3.0.0": 30872,
        "common_gen": 29944,
        "cos_e/v1.11": 30911,
        "glue/mrpc": 30640,
        "kilt_tasks/hotpotqa": 30208
      },
      "step": 1910
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -185.73562622070312,
        "ag_news": 74.03244018554688,
        "amazon_polarity": 61.946876525878906,
        "cnn_dailymail/3.0.0": 191.37107849121094,
        "common_gen": 34.96733856201172,
        "cos_e/v1.11": -60.143131256103516,
        "glue/mrpc": -4.943769931793213,
        "kilt_tasks/hotpotqa": -44.82059860229492
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8877,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10423120856285095,
        "ag_news": 0.13213245570659637,
        "amazon_polarity": 0.130681112408638,
        "cnn_dailymail/3.0.0": 0.14709551632404327,
        "common_gen": 0.1274988055229187,
        "cos_e/v1.11": 0.116890087723732,
        "glue/mrpc": 0.1229337602853775,
        "kilt_tasks/hotpotqa": 0.1185370460152626
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30048,
        "ag_news": 31736,
        "amazon_polarity": 30552,
        "cnn_dailymail/3.0.0": 31032,
        "common_gen": 30080,
        "cos_e/v1.11": 31023,
        "glue/mrpc": 30824,
        "kilt_tasks/hotpotqa": 30424
      },
      "step": 1920
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -184.93177795410156,
        "ag_news": 73.97655487060547,
        "amazon_polarity": 61.90705490112305,
        "cnn_dailymail/3.0.0": 189.78399658203125,
        "common_gen": 28.990131378173828,
        "cos_e/v1.11": -60.6960334777832,
        "glue/mrpc": -4.2947163581848145,
        "kilt_tasks/hotpotqa": -43.235721588134766
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.7755,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1044258177280426,
        "ag_news": 0.13219505548477173,
        "amazon_polarity": 0.13074864447116852,
        "cnn_dailymail/3.0.0": 0.1469191461801529,
        "common_gen": 0.12688438594341278,
        "cos_e/v1.11": 0.11692939698696136,
        "glue/mrpc": 0.1230938583612442,
        "kilt_tasks/hotpotqa": 0.11880375444889069
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30232,
        "ag_news": 31936,
        "amazon_polarity": 30688,
        "cnn_dailymail/3.0.0": 31176,
        "common_gen": 30216,
        "cos_e/v1.11": 31111,
        "glue/mrpc": 31040,
        "kilt_tasks/hotpotqa": 30600
      },
      "step": 1930
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -182.34654235839844,
        "ag_news": 73.96932220458984,
        "amazon_polarity": 61.895999908447266,
        "cnn_dailymail/3.0.0": 190.1404571533203,
        "common_gen": 32.84284210205078,
        "cos_e/v1.11": -62.933223724365234,
        "glue/mrpc": -5.5379486083984375,
        "kilt_tasks/hotpotqa": -40.392967224121094
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8599,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1046508178114891,
        "ag_news": 0.1320885866880417,
        "amazon_polarity": 0.13064658641815186,
        "cnn_dailymail/3.0.0": 0.14680951833724976,
        "common_gen": 0.12724120914936066,
        "cos_e/v1.11": 0.11663555353879929,
        "glue/mrpc": 0.12287916988134384,
        "kilt_tasks/hotpotqa": 0.11904849857091904
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30376,
        "ag_news": 32080,
        "amazon_polarity": 30944,
        "cnn_dailymail/3.0.0": 31360,
        "common_gen": 30408,
        "cos_e/v1.11": 31223,
        "glue/mrpc": 31176,
        "kilt_tasks/hotpotqa": 30712
      },
      "step": 1940
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -183.41067504882812,
        "ag_news": 73.90827178955078,
        "amazon_polarity": 61.954708099365234,
        "cnn_dailymail/3.0.0": 190.30361938476562,
        "common_gen": 29.905792236328125,
        "cos_e/v1.11": -66.8704833984375,
        "glue/mrpc": -3.5638558864593506,
        "kilt_tasks/hotpotqa": -39.14863586425781
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8412,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10464861243963242,
        "ag_news": 0.13212746381759644,
        "amazon_polarity": 0.1307028979063034,
        "cnn_dailymail/3.0.0": 0.14684303104877472,
        "common_gen": 0.12695932388305664,
        "cos_e/v1.11": 0.11629771441221237,
        "glue/mrpc": 0.12316498905420303,
        "kilt_tasks/hotpotqa": 0.11925607919692993
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30472,
        "ag_news": 32296,
        "amazon_polarity": 31112,
        "cnn_dailymail/3.0.0": 31504,
        "common_gen": 30648,
        "cos_e/v1.11": 31343,
        "glue/mrpc": 31280,
        "kilt_tasks/hotpotqa": 30904
      },
      "step": 1950
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -185.15896606445312,
        "ag_news": 73.93852233886719,
        "amazon_polarity": 61.89796829223633,
        "cnn_dailymail/3.0.0": 189.24375915527344,
        "common_gen": 31.464632034301758,
        "cos_e/v1.11": -69.56136322021484,
        "glue/mrpc": -2.554482936859131,
        "kilt_tasks/hotpotqa": -38.000343322753906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9287,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10455015301704407,
        "ag_news": 0.1321372240781784,
        "amazon_polarity": 0.13070586323738098,
        "cnn_dailymail/3.0.0": 0.1466696709394455,
        "common_gen": 0.12715719640254974,
        "cos_e/v1.11": 0.11605817824602127,
        "glue/mrpc": 0.12330514937639236,
        "kilt_tasks/hotpotqa": 0.11941651999950409
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30672,
        "ag_news": 32448,
        "amazon_polarity": 31256,
        "cnn_dailymail/3.0.0": 31688,
        "common_gen": 30792,
        "cos_e/v1.11": 31511,
        "glue/mrpc": 31368,
        "kilt_tasks/hotpotqa": 31104
      },
      "step": 1960
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -186.74058532714844,
        "ag_news": 73.92739868164062,
        "amazon_polarity": 61.8892936706543,
        "cnn_dailymail/3.0.0": 190.4796905517578,
        "common_gen": 31.556907653808594,
        "cos_e/v1.11": -71.62464141845703,
        "glue/mrpc": -3.7075605392456055,
        "kilt_tasks/hotpotqa": -37.56761169433594
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8443,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1044781506061554,
        "ag_news": 0.13215509057044983,
        "amazon_polarity": 0.13072742521762848,
        "cnn_dailymail/3.0.0": 0.14681604504585266,
        "common_gen": 0.12719860672950745,
        "cos_e/v1.11": 0.1158972829580307,
        "glue/mrpc": 0.1232164055109024,
        "kilt_tasks/hotpotqa": 0.11951100081205368
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30824,
        "ag_news": 32600,
        "amazon_polarity": 31392,
        "cnn_dailymail/3.0.0": 31832,
        "common_gen": 30944,
        "cos_e/v1.11": 31687,
        "glue/mrpc": 31552,
        "kilt_tasks/hotpotqa": 31288
      },
      "step": 1970
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -186.53466796875,
        "ag_news": 73.93364715576172,
        "amazon_polarity": 61.85616683959961,
        "cnn_dailymail/3.0.0": 189.91151428222656,
        "common_gen": 33.4310302734375,
        "cos_e/v1.11": -72.69447326660156,
        "glue/mrpc": -0.5287483930587769,
        "kilt_tasks/hotpotqa": -37.32402420043945
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9404,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10450148582458496,
        "ag_news": 0.13208287954330444,
        "amazon_polarity": 0.1306549310684204,
        "cnn_dailymail/3.0.0": 0.14662107825279236,
        "common_gen": 0.1273552030324936,
        "cos_e/v1.11": 0.11576013267040253,
        "glue/mrpc": 0.1235228106379509,
        "kilt_tasks/hotpotqa": 0.11950142681598663
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 30960,
        "ag_news": 32776,
        "amazon_polarity": 31552,
        "cnn_dailymail/3.0.0": 32056,
        "common_gen": 31088,
        "cos_e/v1.11": 31847,
        "glue/mrpc": 31704,
        "kilt_tasks/hotpotqa": 31416
      },
      "step": 1980
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -186.774658203125,
        "ag_news": 73.850830078125,
        "amazon_polarity": 61.80772018432617,
        "cnn_dailymail/3.0.0": 191.5663299560547,
        "common_gen": 33.272098541259766,
        "cos_e/v1.11": -70.83305358886719,
        "glue/mrpc": -0.31176814436912537,
        "kilt_tasks/hotpotqa": -37.25106430053711
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8658,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10448649525642395,
        "ag_news": 0.13200518488883972,
        "amazon_polarity": 0.1305856555700302,
        "cnn_dailymail/3.0.0": 0.1467253565788269,
        "common_gen": 0.1272832155227661,
        "cos_e/v1.11": 0.11593223363161087,
        "glue/mrpc": 0.12350408732891083,
        "kilt_tasks/hotpotqa": 0.1194777637720108
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31104,
        "ag_news": 32904,
        "amazon_polarity": 31776,
        "cnn_dailymail/3.0.0": 32208,
        "common_gen": 31240,
        "cos_e/v1.11": 31999,
        "glue/mrpc": 31832,
        "kilt_tasks/hotpotqa": 31616
      },
      "step": 1990
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -186.86892700195312,
        "ag_news": 73.73605346679688,
        "amazon_polarity": 61.809852600097656,
        "cnn_dailymail/3.0.0": 189.0820770263672,
        "common_gen": 32.936492919921875,
        "cos_e/v1.11": -75.99604034423828,
        "glue/mrpc": 2.3540194034576416,
        "kilt_tasks/hotpotqa": -38.25727462768555
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8851,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10460197925567627,
        "ag_news": 0.1320720613002777,
        "amazon_polarity": 0.1306690126657486,
        "cnn_dailymail/3.0.0": 0.14644980430603027,
        "common_gen": 0.12733404338359833,
        "cos_e/v1.11": 0.11550549417734146,
        "glue/mrpc": 0.1238950788974762,
        "kilt_tasks/hotpotqa": 0.11947254836559296
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31312,
        "ag_news": 33112,
        "amazon_polarity": 31896,
        "cnn_dailymail/3.0.0": 32344,
        "common_gen": 31368,
        "cos_e/v1.11": 32183,
        "glue/mrpc": 31936,
        "kilt_tasks/hotpotqa": 31808
      },
      "step": 2000
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 1.0,
      "eval_runtime": 0.1857,
      "eval_samples_per_second": 86.146,
      "eval_steps_per_second": 5.384,
      "step": 2000
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -190.2353057861328,
        "ag_news": 73.69617462158203,
        "amazon_polarity": 61.8718376159668,
        "cnn_dailymail/3.0.0": 189.4890899658203,
        "common_gen": 32.832279205322266,
        "cos_e/v1.11": -77.12460327148438,
        "glue/mrpc": 4.636351585388184,
        "kilt_tasks/hotpotqa": -39.25196838378906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9015,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10436044633388519,
        "ag_news": 0.13208243250846863,
        "amazon_polarity": 0.13069459795951843,
        "cnn_dailymail/3.0.0": 0.14648228883743286,
        "common_gen": 0.12734821438789368,
        "cos_e/v1.11": 0.11544062942266464,
        "glue/mrpc": 0.12418164312839508,
        "kilt_tasks/hotpotqa": 0.11940973997116089
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31440,
        "ag_news": 33304,
        "amazon_polarity": 32024,
        "cnn_dailymail/3.0.0": 32536,
        "common_gen": 31504,
        "cos_e/v1.11": 32383,
        "glue/mrpc": 32088,
        "kilt_tasks/hotpotqa": 31960
      },
      "step": 2010
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -187.4585723876953,
        "ag_news": 73.66873168945312,
        "amazon_polarity": 61.78912353515625,
        "cnn_dailymail/3.0.0": 189.079345703125,
        "common_gen": 35.32339859008789,
        "cos_e/v1.11": -79.42214965820312,
        "glue/mrpc": 5.506965160369873,
        "kilt_tasks/hotpotqa": -38.431488037109375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8087,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10462198406457901,
        "ag_news": 0.1320069283246994,
        "amazon_polarity": 0.13061687350273132,
        "cnn_dailymail/3.0.0": 0.14631128311157227,
        "common_gen": 0.12757283449172974,
        "cos_e/v1.11": 0.11517993360757828,
        "glue/mrpc": 0.12422886490821838,
        "kilt_tasks/hotpotqa": 0.11946132779121399
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31584,
        "ag_news": 33488,
        "amazon_polarity": 32192,
        "cnn_dailymail/3.0.0": 32656,
        "common_gen": 31672,
        "cos_e/v1.11": 32591,
        "glue/mrpc": 32232,
        "kilt_tasks/hotpotqa": 32104
      },
      "step": 2020
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -186.4238739013672,
        "ag_news": 73.48938751220703,
        "amazon_polarity": 61.9515380859375,
        "cnn_dailymail/3.0.0": 192.36228942871094,
        "common_gen": 33.692142486572266,
        "cos_e/v1.11": -81.00350952148438,
        "glue/mrpc": 7.52967643737793,
        "kilt_tasks/hotpotqa": -37.33225631713867
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.7704,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10471095144748688,
        "ag_news": 0.13190163671970367,
        "amazon_polarity": 0.13055574893951416,
        "cnn_dailymail/3.0.0": 0.14660847187042236,
        "common_gen": 0.1273173987865448,
        "cos_e/v1.11": 0.11498337239027023,
        "glue/mrpc": 0.12439148128032684,
        "kilt_tasks/hotpotqa": 0.11953101307153702
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31704,
        "ag_news": 33688,
        "amazon_polarity": 32400,
        "cnn_dailymail/3.0.0": 32776,
        "common_gen": 31888,
        "cos_e/v1.11": 32711,
        "glue/mrpc": 32424,
        "kilt_tasks/hotpotqa": 32208
      },
      "step": 2030
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -188.38131713867188,
        "ag_news": 73.35651397705078,
        "amazon_polarity": 61.85658645629883,
        "cnn_dailymail/3.0.0": 191.3467254638672,
        "common_gen": 31.695131301879883,
        "cos_e/v1.11": -81.97836303710938,
        "glue/mrpc": 10.314493179321289,
        "kilt_tasks/hotpotqa": -36.620765686035156
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.7668,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1046052873134613,
        "ag_news": 0.1319073736667633,
        "amazon_polarity": 0.13056908547878265,
        "cnn_dailymail/3.0.0": 0.14646224677562714,
        "common_gen": 0.1271236538887024,
        "cos_e/v1.11": 0.1149410679936409,
        "glue/mrpc": 0.12473685294389725,
        "kilt_tasks/hotpotqa": 0.11965440213680267
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31808,
        "ag_news": 33856,
        "amazon_polarity": 32584,
        "cnn_dailymail/3.0.0": 32928,
        "common_gen": 32080,
        "cos_e/v1.11": 32823,
        "glue/mrpc": 32688,
        "kilt_tasks/hotpotqa": 32312
      },
      "step": 2040
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -185.02415466308594,
        "ag_news": 73.3383560180664,
        "amazon_polarity": 61.80891799926758,
        "cnn_dailymail/3.0.0": 193.13587951660156,
        "common_gen": 30.81852149963379,
        "cos_e/v1.11": -81.92864990234375,
        "glue/mrpc": 8.931212425231934,
        "kilt_tasks/hotpotqa": -36.517845153808594
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8612,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10493086278438568,
        "ag_news": 0.13184988498687744,
        "amazon_polarity": 0.13051201403141022,
        "cnn_dailymail/3.0.0": 0.14659549295902252,
        "common_gen": 0.12698321044445038,
        "cos_e/v1.11": 0.11493629217147827,
        "glue/mrpc": 0.124549001455307,
        "kilt_tasks/hotpotqa": 0.11964339762926102
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 31952,
        "ag_news": 34024,
        "amazon_polarity": 32784,
        "cnn_dailymail/3.0.0": 33136,
        "common_gen": 32184,
        "cos_e/v1.11": 32919,
        "glue/mrpc": 32848,
        "kilt_tasks/hotpotqa": 32512
      },
      "step": 2050
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -188.62860107421875,
        "ag_news": 73.1206283569336,
        "amazon_polarity": 61.407142639160156,
        "cnn_dailymail/3.0.0": 192.3956298828125,
        "common_gen": 26.679763793945312,
        "cos_e/v1.11": -83.3506088256836,
        "glue/mrpc": 8.35942268371582,
        "kilt_tasks/hotpotqa": -37.02190399169922
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8654,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10477139800786972,
        "ag_news": 0.1319703906774521,
        "amazon_polarity": 0.1306132823228836,
        "cnn_dailymail/3.0.0": 0.14662428200244904,
        "common_gen": 0.12667182087898254,
        "cos_e/v1.11": 0.11495723575353622,
        "glue/mrpc": 0.12464097887277603,
        "kilt_tasks/hotpotqa": 0.1197505071759224
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32080,
        "ag_news": 34208,
        "amazon_polarity": 32968,
        "cnn_dailymail/3.0.0": 33304,
        "common_gen": 32336,
        "cos_e/v1.11": 33103,
        "glue/mrpc": 33012,
        "kilt_tasks/hotpotqa": 32624
      },
      "step": 2060
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -188.95079040527344,
        "ag_news": 73.10282135009766,
        "amazon_polarity": 61.2766227722168,
        "cnn_dailymail/3.0.0": 190.55345153808594,
        "common_gen": 23.017391204833984,
        "cos_e/v1.11": -83.28199768066406,
        "glue/mrpc": 5.120558738708496,
        "kilt_tasks/hotpotqa": -35.64874267578125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8244,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10488099604845047,
        "ag_news": 0.13207077980041504,
        "amazon_polarity": 0.1307028979063034,
        "cnn_dailymail/3.0.0": 0.14646314084529877,
        "common_gen": 0.12637461721897125,
        "cos_e/v1.11": 0.11509149521589279,
        "glue/mrpc": 0.12439976632595062,
        "kilt_tasks/hotpotqa": 0.12001629918813705
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32224,
        "ag_news": 34400,
        "amazon_polarity": 33136,
        "cnn_dailymail/3.0.0": 33440,
        "common_gen": 32464,
        "cos_e/v1.11": 33335,
        "glue/mrpc": 33132,
        "kilt_tasks/hotpotqa": 32784
      },
      "step": 2070
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -189.17953491210938,
        "ag_news": 73.04646301269531,
        "amazon_polarity": 61.14280700683594,
        "cnn_dailymail/3.0.0": 191.68309020996094,
        "common_gen": 21.258901596069336,
        "cos_e/v1.11": -81.73673248291016,
        "glue/mrpc": 6.402421474456787,
        "kilt_tasks/hotpotqa": -35.36322784423828
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8012,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10488051921129227,
        "ag_news": 0.1320173591375351,
        "amazon_polarity": 0.13064441084861755,
        "cnn_dailymail/3.0.0": 0.1465202420949936,
        "common_gen": 0.12614816427230835,
        "cos_e/v1.11": 0.11524466425180435,
        "glue/mrpc": 0.12451345473527908,
        "kilt_tasks/hotpotqa": 0.12003125250339508
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32400,
        "ag_news": 34592,
        "amazon_polarity": 33264,
        "cnn_dailymail/3.0.0": 33592,
        "common_gen": 32616,
        "cos_e/v1.11": 33487,
        "glue/mrpc": 33324,
        "kilt_tasks/hotpotqa": 32920
      },
      "step": 2080
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -190.09878540039062,
        "ag_news": 73.02039337158203,
        "amazon_polarity": 61.06147003173828,
        "cnn_dailymail/3.0.0": 190.8918914794922,
        "common_gen": 21.62190818786621,
        "cos_e/v1.11": -81.04423522949219,
        "glue/mrpc": 5.773238658905029,
        "kilt_tasks/hotpotqa": -34.768558502197266
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8574,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10485091060400009,
        "ag_news": 0.13201098144054413,
        "amazon_polarity": 0.13063502311706543,
        "cnn_dailymail/3.0.0": 0.1463785320520401,
        "common_gen": 0.12619872391223907,
        "cos_e/v1.11": 0.11534889042377472,
        "glue/mrpc": 0.12445903569459915,
        "kilt_tasks/hotpotqa": 0.1201179102063179
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32544,
        "ag_news": 34752,
        "amazon_polarity": 33448,
        "cnn_dailymail/3.0.0": 33752,
        "common_gen": 32800,
        "cos_e/v1.11": 33647,
        "glue/mrpc": 33492,
        "kilt_tasks/hotpotqa": 33040
      },
      "step": 2090
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -189.7186737060547,
        "ag_news": 73.03022003173828,
        "amazon_polarity": 60.99382400512695,
        "cnn_dailymail/3.0.0": 190.83140563964844,
        "common_gen": 20.18146514892578,
        "cos_e/v1.11": -86.67755126953125,
        "glue/mrpc": 4.315145015716553,
        "kilt_tasks/hotpotqa": -33.824092864990234
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8629,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1050104945898056,
        "ag_news": 0.13209731876850128,
        "amazon_polarity": 0.13071486353874207,
        "cnn_dailymail/3.0.0": 0.14642944931983948,
        "common_gen": 0.1261347532272339,
        "cos_e/v1.11": 0.1148935854434967,
        "glue/mrpc": 0.1243981420993805,
        "kilt_tasks/hotpotqa": 0.12032150477170944
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32688,
        "ag_news": 34960,
        "amazon_polarity": 33576,
        "cnn_dailymail/3.0.0": 33960,
        "common_gen": 32936,
        "cos_e/v1.11": 33775,
        "glue/mrpc": 33612,
        "kilt_tasks/hotpotqa": 33248
      },
      "step": 2100
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1787,
      "eval_samples_per_second": 89.511,
      "eval_steps_per_second": 5.594,
      "step": 2100
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -190.31283569335938,
        "ag_news": 72.9870376586914,
        "amazon_polarity": 60.878849029541016,
        "cnn_dailymail/3.0.0": 193.5078887939453,
        "common_gen": 20.745500564575195,
        "cos_e/v1.11": -90.01065063476562,
        "glue/mrpc": 4.785187721252441,
        "kilt_tasks/hotpotqa": -34.73287582397461
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9057,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10500509291887283,
        "ag_news": 0.1320825070142746,
        "amazon_polarity": 0.13069525361061096,
        "cnn_dailymail/3.0.0": 0.14672520756721497,
        "common_gen": 0.12620112299919128,
        "cos_e/v1.11": 0.11458957195281982,
        "glue/mrpc": 0.1244574561715126,
        "kilt_tasks/hotpotqa": 0.12024374306201935
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32792,
        "ag_news": 35096,
        "amazon_polarity": 33752,
        "cnn_dailymail/3.0.0": 34136,
        "common_gen": 33128,
        "cos_e/v1.11": 33935,
        "glue/mrpc": 33780,
        "kilt_tasks/hotpotqa": 33416
      },
      "step": 2110
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -190.97799682617188,
        "ag_news": 73.00186157226562,
        "amazon_polarity": 60.80513000488281,
        "cnn_dailymail/3.0.0": 193.59629821777344,
        "common_gen": 18.276498794555664,
        "cos_e/v1.11": -90.51482391357422,
        "glue/mrpc": 4.851366996765137,
        "kilt_tasks/hotpotqa": -38.04208755493164
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9321,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10506348311901093,
        "ag_news": 0.13216306269168854,
        "amazon_polarity": 0.13076813519001007,
        "cnn_dailymail/3.0.0": 0.14678791165351868,
        "common_gen": 0.12601907551288605,
        "cos_e/v1.11": 0.11464589834213257,
        "glue/mrpc": 0.1245562881231308,
        "kilt_tasks/hotpotqa": 0.11999627947807312
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 32936,
        "ag_news": 35240,
        "amazon_polarity": 33928,
        "cnn_dailymail/3.0.0": 34320,
        "common_gen": 33344,
        "cos_e/v1.11": 34103,
        "glue/mrpc": 33884,
        "kilt_tasks/hotpotqa": 33560
      },
      "step": 2120
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -194.55714416503906,
        "ag_news": 72.8648910522461,
        "amazon_polarity": 60.379554748535156,
        "cnn_dailymail/3.0.0": 193.96847534179688,
        "common_gen": 18.21050453186035,
        "cos_e/v1.11": -87.16551971435547,
        "glue/mrpc": 7.372175693511963,
        "kilt_tasks/hotpotqa": -41.27587890625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9816,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10478996485471725,
        "ag_news": 0.13214196264743805,
        "amazon_polarity": 0.13071773946285248,
        "cnn_dailymail/3.0.0": 0.14679335057735443,
        "common_gen": 0.12602072954177856,
        "cos_e/v1.11": 0.11501280963420868,
        "glue/mrpc": 0.12484119832515717,
        "kilt_tasks/hotpotqa": 0.11968227475881577
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33032,
        "ag_news": 35400,
        "amazon_polarity": 34096,
        "cnn_dailymail/3.0.0": 34560,
        "common_gen": 33488,
        "cos_e/v1.11": 34311,
        "glue/mrpc": 34004,
        "kilt_tasks/hotpotqa": 33704
      },
      "step": 2130
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -197.02207946777344,
        "ag_news": 72.77839660644531,
        "amazon_polarity": 60.26458740234375,
        "cnn_dailymail/3.0.0": 194.96292114257812,
        "common_gen": 16.260038375854492,
        "cos_e/v1.11": -78.5529556274414,
        "glue/mrpc": 4.009554862976074,
        "kilt_tasks/hotpotqa": -42.34828567504883
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8205,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10460514575242996,
        "ag_news": 0.13210918009281158,
        "amazon_polarity": 0.13068538904190063,
        "cnn_dailymail/3.0.0": 0.14685848355293274,
        "common_gen": 0.1258002072572708,
        "cos_e/v1.11": 0.115890271961689,
        "glue/mrpc": 0.12447324395179749,
        "kilt_tasks/hotpotqa": 0.11957807838916779
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33152,
        "ag_news": 35568,
        "amazon_polarity": 34288,
        "cnn_dailymail/3.0.0": 34688,
        "common_gen": 33704,
        "cos_e/v1.11": 34447,
        "glue/mrpc": 34156,
        "kilt_tasks/hotpotqa": 33872
      },
      "step": 2140
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -195.4776153564453,
        "ag_news": 72.65604400634766,
        "amazon_polarity": 60.05951690673828,
        "cnn_dailymail/3.0.0": 194.276123046875,
        "common_gen": 20.07428550720215,
        "cos_e/v1.11": -82.0877685546875,
        "glue/mrpc": 6.106949329376221,
        "kilt_tasks/hotpotqa": -51.85658264160156
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8505,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10485943406820297,
        "ag_news": 0.13216885924339294,
        "amazon_polarity": 0.13073836266994476,
        "cnn_dailymail/3.0.0": 0.1468171775341034,
        "common_gen": 0.12629996240139008,
        "cos_e/v1.11": 0.11563661694526672,
        "glue/mrpc": 0.12478558719158173,
        "kilt_tasks/hotpotqa": 0.11869397014379501
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33320,
        "ag_news": 35728,
        "amazon_polarity": 34440,
        "cnn_dailymail/3.0.0": 34880,
        "common_gen": 33856,
        "cos_e/v1.11": 34599,
        "glue/mrpc": 34324,
        "kilt_tasks/hotpotqa": 34008
      },
      "step": 2150
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -195.76060485839844,
        "ag_news": 71.74666595458984,
        "amazon_polarity": 59.91904830932617,
        "cnn_dailymail/3.0.0": 194.5091552734375,
        "common_gen": 16.7515869140625,
        "cos_e/v1.11": -81.8491439819336,
        "glue/mrpc": 7.784125804901123,
        "kilt_tasks/hotpotqa": -51.59162902832031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8021,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10490302741527557,
        "ag_news": 0.13208205997943878,
        "amazon_polarity": 0.1307424008846283,
        "cnn_dailymail/3.0.0": 0.1468297690153122,
        "common_gen": 0.12596803903579712,
        "cos_e/v1.11": 0.11571064591407776,
        "glue/mrpc": 0.12499845772981644,
        "kilt_tasks/hotpotqa": 0.11876551806926727
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33456,
        "ag_news": 35856,
        "amazon_polarity": 34616,
        "cnn_dailymail/3.0.0": 35000,
        "common_gen": 34024,
        "cos_e/v1.11": 34783,
        "glue/mrpc": 34516,
        "kilt_tasks/hotpotqa": 34184
      },
      "step": 2160
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -194.7440185546875,
        "ag_news": 71.7242660522461,
        "amazon_polarity": 59.852813720703125,
        "cnn_dailymail/3.0.0": 190.14251708984375,
        "common_gen": 19.12238311767578,
        "cos_e/v1.11": -79.00025177001953,
        "glue/mrpc": 6.497589588165283,
        "kilt_tasks/hotpotqa": -51.18690490722656
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9052,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10504047572612762,
        "ag_news": 0.1320674866437912,
        "amazon_polarity": 0.13072611391544342,
        "cnn_dailymail/3.0.0": 0.14623022079467773,
        "common_gen": 0.1262272596359253,
        "cos_e/v1.11": 0.11601884663105011,
        "glue/mrpc": 0.12486469745635986,
        "kilt_tasks/hotpotqa": 0.11882495880126953
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33640,
        "ag_news": 36000,
        "amazon_polarity": 34760,
        "cnn_dailymail/3.0.0": 35240,
        "common_gen": 34184,
        "cos_e/v1.11": 34911,
        "glue/mrpc": 34668,
        "kilt_tasks/hotpotqa": 34312
      },
      "step": 2170
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -197.17710876464844,
        "ag_news": 71.73700714111328,
        "amazon_polarity": 59.59093475341797,
        "cnn_dailymail/3.0.0": 194.16531372070312,
        "common_gen": 17.19358253479004,
        "cos_e/v1.11": -79.12379455566406,
        "glue/mrpc": 7.170464992523193,
        "kilt_tasks/hotpotqa": -49.93067932128906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8876,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10483943670988083,
        "ag_news": 0.1320221722126007,
        "amazon_polarity": 0.1306535005569458,
        "cnn_dailymail/3.0.0": 0.14665000140666962,
        "common_gen": 0.1259869933128357,
        "cos_e/v1.11": 0.11599979549646378,
        "glue/mrpc": 0.12490854412317276,
        "kilt_tasks/hotpotqa": 0.1189396008849144
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33816,
        "ag_news": 36184,
        "amazon_polarity": 34872,
        "cnn_dailymail/3.0.0": 35384,
        "common_gen": 34360,
        "cos_e/v1.11": 35079,
        "glue/mrpc": 34788,
        "kilt_tasks/hotpotqa": 34512
      },
      "step": 2180
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -200.88230895996094,
        "ag_news": 71.6837387084961,
        "amazon_polarity": 59.22603988647461,
        "cnn_dailymail/3.0.0": 194.28726196289062,
        "common_gen": 15.690264701843262,
        "cos_e/v1.11": -76.33737182617188,
        "glue/mrpc": 7.978508472442627,
        "kilt_tasks/hotpotqa": -50.1458625793457
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.7938,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1045699194073677,
        "ag_news": 0.13202530145645142,
        "amazon_polarity": 0.13062486052513123,
        "cnn_dailymail/3.0.0": 0.14664046466350555,
        "common_gen": 0.12584711611270905,
        "cos_e/v1.11": 0.11631879210472107,
        "glue/mrpc": 0.1250193566083908,
        "kilt_tasks/hotpotqa": 0.118954136967659
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 33920,
        "ag_news": 36424,
        "amazon_polarity": 35032,
        "cnn_dailymail/3.0.0": 35520,
        "common_gen": 34544,
        "cos_e/v1.11": 35255,
        "glue/mrpc": 34908,
        "kilt_tasks/hotpotqa": 34672
      },
      "step": 2190
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -198.67491149902344,
        "ag_news": 71.62956237792969,
        "amazon_polarity": 58.92781066894531,
        "cnn_dailymail/3.0.0": 194.4073028564453,
        "common_gen": 14.827682495117188,
        "cos_e/v1.11": -80.97650909423828,
        "glue/mrpc": 6.978824138641357,
        "kilt_tasks/hotpotqa": -49.749412536621094
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.879,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10485687851905823,
        "ag_news": 0.132063090801239,
        "amazon_polarity": 0.13063815236091614,
        "cnn_dailymail/3.0.0": 0.1466694176197052,
        "common_gen": 0.12580987811088562,
        "cos_e/v1.11": 0.11593088507652283,
        "glue/mrpc": 0.12496960163116455,
        "kilt_tasks/hotpotqa": 0.11906197667121887
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 34104,
        "ag_news": 36584,
        "amazon_polarity": 35184,
        "cnn_dailymail/3.0.0": 35704,
        "common_gen": 34704,
        "cos_e/v1.11": 35391,
        "glue/mrpc": 35036,
        "kilt_tasks/hotpotqa": 34848
      },
      "step": 2200
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1771,
      "eval_samples_per_second": 90.363,
      "eval_steps_per_second": 5.648,
      "step": 2200
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -199.5106658935547,
        "ag_news": 71.59993743896484,
        "amazon_polarity": 58.7676887512207,
        "cnn_dailymail/3.0.0": 194.6093292236328,
        "common_gen": 18.922048568725586,
        "cos_e/v1.11": -79.5134506225586,
        "glue/mrpc": 9.61435317993164,
        "kilt_tasks/hotpotqa": -48.01293182373047
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9578,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.104723259806633,
        "ag_news": 0.1319166123867035,
        "amazon_polarity": 0.13048194348812103,
        "cnn_dailymail/3.0.0": 0.14650094509124756,
        "common_gen": 0.1261264532804489,
        "cos_e/v1.11": 0.11598366498947144,
        "glue/mrpc": 0.1251303255558014,
        "kilt_tasks/hotpotqa": 0.11913678050041199
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 34232,
        "ag_news": 36680,
        "amazon_polarity": 35336,
        "cnn_dailymail/3.0.0": 35944,
        "common_gen": 34872,
        "cos_e/v1.11": 35519,
        "glue/mrpc": 35236,
        "kilt_tasks/hotpotqa": 35016
      },
      "step": 2210
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -197.46109008789062,
        "ag_news": 71.39710998535156,
        "amazon_polarity": 58.69441223144531,
        "cnn_dailymail/3.0.0": 193.7079620361328,
        "common_gen": 17.145353317260742,
        "cos_e/v1.11": -86.70597076416016,
        "glue/mrpc": 8.960413932800293,
        "kilt_tasks/hotpotqa": -51.142574310302734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8317,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10507871210575104,
        "ag_news": 0.1320434808731079,
        "amazon_polarity": 0.13062502443790436,
        "cnn_dailymail/3.0.0": 0.14652034640312195,
        "common_gen": 0.12609164416790009,
        "cos_e/v1.11": 0.11544111371040344,
        "glue/mrpc": 0.12521743774414062,
        "kilt_tasks/hotpotqa": 0.11898227781057358
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 34408,
        "ag_news": 36912,
        "amazon_polarity": 35472,
        "cnn_dailymail/3.0.0": 36088,
        "common_gen": 35064,
        "cos_e/v1.11": 35655,
        "glue/mrpc": 35356,
        "kilt_tasks/hotpotqa": 35160
      },
      "step": 2220
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -198.27072143554688,
        "ag_news": 71.01019287109375,
        "amazon_polarity": 58.61627197265625,
        "cnn_dailymail/3.0.0": 197.2846221923828,
        "common_gen": 16.553380966186523,
        "cos_e/v1.11": -83.31029510498047,
        "glue/mrpc": 6.721299648284912,
        "kilt_tasks/hotpotqa": -54.79633331298828
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.969,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10504986345767975,
        "ag_news": 0.13198721408843994,
        "amazon_polarity": 0.13060671091079712,
        "cnn_dailymail/3.0.0": 0.14691734313964844,
        "common_gen": 0.12602896988391876,
        "cos_e/v1.11": 0.11579719930887222,
        "glue/mrpc": 0.12498244643211365,
        "kilt_tasks/hotpotqa": 0.11863022297620773
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 34504,
        "ag_news": 37112,
        "amazon_polarity": 35568,
        "cnn_dailymail/3.0.0": 36320,
        "common_gen": 35184,
        "cos_e/v1.11": 35815,
        "glue/mrpc": 35540,
        "kilt_tasks/hotpotqa": 35352
      },
      "step": 2230
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -198.7149200439453,
        "ag_news": 70.97807312011719,
        "amazon_polarity": 58.512908935546875,
        "cnn_dailymail/3.0.0": 200.40650939941406,
        "common_gen": 18.048738479614258,
        "cos_e/v1.11": -82.8841323852539,
        "glue/mrpc": 8.291753768920898,
        "kilt_tasks/hotpotqa": -50.386409759521484
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8147,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10493195801973343,
        "ag_news": 0.13181795179843903,
        "amazon_polarity": 0.13043439388275146,
        "cnn_dailymail/3.0.0": 0.14708629250526428,
        "common_gen": 0.12604312598705292,
        "cos_e/v1.11": 0.11572727560997009,
        "glue/mrpc": 0.12500673532485962,
        "kilt_tasks/hotpotqa": 0.11895237863063812
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 34640,
        "ag_news": 37344,
        "amazon_polarity": 35744,
        "cnn_dailymail/3.0.0": 36456,
        "common_gen": 35368,
        "cos_e/v1.11": 35943,
        "glue/mrpc": 35676,
        "kilt_tasks/hotpotqa": 35504
      },
      "step": 2240
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -202.61915588378906,
        "ag_news": 70.9383773803711,
        "amazon_polarity": 58.37981414794922,
        "cnn_dailymail/3.0.0": 201.00994873046875,
        "common_gen": 16.677440643310547,
        "cos_e/v1.11": -85.33568572998047,
        "glue/mrpc": 8.828495025634766,
        "kilt_tasks/hotpotqa": -46.108280181884766
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8253,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10464807599782944,
        "ag_news": 0.13182398676872253,
        "amazon_polarity": 0.13043314218521118,
        "cnn_dailymail/3.0.0": 0.14713731408119202,
        "common_gen": 0.12591972947120667,
        "cos_e/v1.11": 0.11553050577640533,
        "glue/mrpc": 0.12508800625801086,
        "kilt_tasks/hotpotqa": 0.11941926181316376
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 34840,
        "ag_news": 37528,
        "amazon_polarity": 35888,
        "cnn_dailymail/3.0.0": 36560,
        "common_gen": 35520,
        "cos_e/v1.11": 36095,
        "glue/mrpc": 35828,
        "kilt_tasks/hotpotqa": 35696
      },
      "step": 2250
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -200.35037231445312,
        "ag_news": 70.92686462402344,
        "amazon_polarity": 58.292755126953125,
        "cnn_dailymail/3.0.0": 202.3244171142578,
        "common_gen": 14.09886646270752,
        "cos_e/v1.11": -89.59558868408203,
        "glue/mrpc": 7.771940231323242,
        "kilt_tasks/hotpotqa": -48.92288589477539
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9188,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1049664318561554,
        "ag_news": 0.131904736161232,
        "amazon_polarity": 0.13050776720046997,
        "cnn_dailymail/3.0.0": 0.1473565250635147,
        "common_gen": 0.12573732435703278,
        "cos_e/v1.11": 0.11522188782691956,
        "glue/mrpc": 0.12506890296936035,
        "kilt_tasks/hotpotqa": 0.1192365437746048
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 34944,
        "ag_news": 37624,
        "amazon_polarity": 36112,
        "cnn_dailymail/3.0.0": 36736,
        "common_gen": 35704,
        "cos_e/v1.11": 36255,
        "glue/mrpc": 35988,
        "kilt_tasks/hotpotqa": 35872
      },
      "step": 2260
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -199.8363494873047,
        "ag_news": 70.91231536865234,
        "amazon_polarity": 61.65541458129883,
        "cnn_dailymail/3.0.0": 204.4143829345703,
        "common_gen": 15.481273651123047,
        "cos_e/v1.11": -88.52114868164062,
        "glue/mrpc": 5.103461742401123,
        "kilt_tasks/hotpotqa": -50.6041374206543
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8369,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10500318557024002,
        "ag_news": 0.13182632625102997,
        "amazon_polarity": 0.1308041661977768,
        "cnn_dailymail/3.0.0": 0.14749404788017273,
        "common_gen": 0.12582345306873322,
        "cos_e/v1.11": 0.1152930036187172,
        "glue/mrpc": 0.12473057210445404,
        "kilt_tasks/hotpotqa": 0.11902526021003723
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 35104,
        "ag_news": 37808,
        "amazon_polarity": 36248,
        "cnn_dailymail/3.0.0": 36904,
        "common_gen": 35864,
        "cos_e/v1.11": 36399,
        "glue/mrpc": 36172,
        "kilt_tasks/hotpotqa": 36016
      },
      "step": 2270
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -198.72390747070312,
        "ag_news": 70.9007568359375,
        "amazon_polarity": 61.19633483886719,
        "cnn_dailymail/3.0.0": 204.5917510986328,
        "common_gen": 14.332145690917969,
        "cos_e/v1.11": -90.52765655517578,
        "glue/mrpc": 6.750134468078613,
        "kilt_tasks/hotpotqa": -48.194515228271484
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.7181,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1051245853304863,
        "ag_news": 0.13178908824920654,
        "amazon_polarity": 0.1307203322649002,
        "cnn_dailymail/3.0.0": 0.14743956923484802,
        "common_gen": 0.12568074464797974,
        "cos_e/v1.11": 0.11510151624679565,
        "glue/mrpc": 0.1248839944601059,
        "kilt_tasks/hotpotqa": 0.11926006525754929
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 35336,
        "ag_news": 37960,
        "amazon_polarity": 36464,
        "cnn_dailymail/3.0.0": 37008,
        "common_gen": 35976,
        "cos_e/v1.11": 36527,
        "glue/mrpc": 36380,
        "kilt_tasks/hotpotqa": 36144
      },
      "step": 2280
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -200.22500610351562,
        "ag_news": 70.90165710449219,
        "amazon_polarity": 61.10216522216797,
        "cnn_dailymail/3.0.0": 205.0391082763672,
        "common_gen": 15.449217796325684,
        "cos_e/v1.11": -90.91311645507812,
        "glue/mrpc": 5.519379138946533,
        "kilt_tasks/hotpotqa": -46.68035125732422
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8253,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10503154993057251,
        "ag_news": 0.1317731887102127,
        "amazon_polarity": 0.13069649040699005,
        "cnn_dailymail/3.0.0": 0.14744092524051666,
        "common_gen": 0.12579602003097534,
        "cos_e/v1.11": 0.11508429050445557,
        "glue/mrpc": 0.1247548758983612,
        "kilt_tasks/hotpotqa": 0.11942266672849655
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 35448,
        "ag_news": 38080,
        "amazon_polarity": 36656,
        "cnn_dailymail/3.0.0": 37144,
        "common_gen": 36120,
        "cos_e/v1.11": 36703,
        "glue/mrpc": 36556,
        "kilt_tasks/hotpotqa": 36368
      },
      "step": 2290
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -193.99517822265625,
        "ag_news": 70.86588287353516,
        "amazon_polarity": 60.96985626220703,
        "cnn_dailymail/3.0.0": 206.98580932617188,
        "common_gen": 17.382793426513672,
        "cos_e/v1.11": -89.18782806396484,
        "glue/mrpc": 4.866320610046387,
        "kilt_tasks/hotpotqa": -46.61368179321289
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9077,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10550598800182343,
        "ag_news": 0.13161370158195496,
        "amazon_polarity": 0.13053008913993835,
        "cnn_dailymail/3.0.0": 0.14747072756290436,
        "common_gen": 0.12586328387260437,
        "cos_e/v1.11": 0.1151479110121727,
        "glue/mrpc": 0.12455444782972336,
        "kilt_tasks/hotpotqa": 0.11931382119655609
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 35576,
        "ag_news": 38208,
        "amazon_polarity": 36800,
        "cnn_dailymail/3.0.0": 37352,
        "common_gen": 36280,
        "cos_e/v1.11": 36895,
        "glue/mrpc": 36744,
        "kilt_tasks/hotpotqa": 36496
      },
      "step": 2300
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1878,
      "eval_samples_per_second": 85.204,
      "eval_steps_per_second": 5.325,
      "step": 2300
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -194.12596130371094,
        "ag_news": 70.83985137939453,
        "amazon_polarity": 60.8129768371582,
        "cnn_dailymail/3.0.0": 206.9725799560547,
        "common_gen": 17.631404876708984,
        "cos_e/v1.11": -90.03851318359375,
        "glue/mrpc": 4.328246593475342,
        "kilt_tasks/hotpotqa": -46.359657287597656
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9423,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10554655641317368,
        "ag_news": 0.13161316514015198,
        "amazon_polarity": 0.13051766157150269,
        "cnn_dailymail/3.0.0": 0.1474355310201645,
        "common_gen": 0.1259036809206009,
        "cos_e/v1.11": 0.11510148644447327,
        "glue/mrpc": 0.1245155856013298,
        "kilt_tasks/hotpotqa": 0.11936637759208679
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 35736,
        "ag_news": 38352,
        "amazon_polarity": 36936,
        "cnn_dailymail/3.0.0": 37560,
        "common_gen": 36416,
        "cos_e/v1.11": 37103,
        "glue/mrpc": 36864,
        "kilt_tasks/hotpotqa": 36664
      },
      "step": 2310
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -195.82008361816406,
        "ag_news": 70.82647705078125,
        "amazon_polarity": 60.85940933227539,
        "cnn_dailymail/3.0.0": 206.1756134033203,
        "common_gen": 19.537452697753906,
        "cos_e/v1.11": -88.65934753417969,
        "glue/mrpc": 4.717940807342529,
        "kilt_tasks/hotpotqa": -49.775184631347656
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.7803,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10545936226844788,
        "ag_news": 0.13162589073181152,
        "amazon_polarity": 0.13053910434246063,
        "cnn_dailymail/3.0.0": 0.14731773734092712,
        "common_gen": 0.12612900137901306,
        "cos_e/v1.11": 0.11527903378009796,
        "glue/mrpc": 0.12458418309688568,
        "kilt_tasks/hotpotqa": 0.11906570196151733
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 35840,
        "ag_news": 38536,
        "amazon_polarity": 37136,
        "cnn_dailymail/3.0.0": 37704,
        "common_gen": 36560,
        "cos_e/v1.11": 37231,
        "glue/mrpc": 37088,
        "kilt_tasks/hotpotqa": 36816
      },
      "step": 2320
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -197.0558319091797,
        "ag_news": 70.81130981445312,
        "amazon_polarity": 60.38786315917969,
        "cnn_dailymail/3.0.0": 205.88162231445312,
        "common_gen": 22.14337921142578,
        "cos_e/v1.11": -91.80928802490234,
        "glue/mrpc": 5.244585037231445,
        "kilt_tasks/hotpotqa": -52.55473709106445
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8735,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10543736815452576,
        "ag_news": 0.13166943192481995,
        "amazon_polarity": 0.13053514063358307,
        "cnn_dailymail/3.0.0": 0.1472969353199005,
        "common_gen": 0.12645697593688965,
        "cos_e/v1.11": 0.115050308406353,
        "glue/mrpc": 0.12469609081745148,
        "kilt_tasks/hotpotqa": 0.1188577264547348
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 35928,
        "ag_news": 38728,
        "amazon_polarity": 37288,
        "cnn_dailymail/3.0.0": 37880,
        "common_gen": 36696,
        "cos_e/v1.11": 37391,
        "glue/mrpc": 37320,
        "kilt_tasks/hotpotqa": 36960
      },
      "step": 2330
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -195.70281982421875,
        "ag_news": 70.7889404296875,
        "amazon_polarity": 60.40822219848633,
        "cnn_dailymail/3.0.0": 207.53244018554688,
        "common_gen": 23.613327026367188,
        "cos_e/v1.11": -88.59576416015625,
        "glue/mrpc": 5.3615498542785645,
        "kilt_tasks/hotpotqa": -53.704139709472656
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9667,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1055230125784874,
        "ag_news": 0.13156431913375854,
        "amazon_polarity": 0.13043798506259918,
        "cnn_dailymail/3.0.0": 0.1473483294248581,
        "common_gen": 0.12652316689491272,
        "cos_e/v1.11": 0.11529985815286636,
        "glue/mrpc": 0.12462536990642548,
        "kilt_tasks/hotpotqa": 0.11867798119783401
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 36032,
        "ag_news": 38856,
        "amazon_polarity": 37448,
        "cnn_dailymail/3.0.0": 38088,
        "common_gen": 36928,
        "cos_e/v1.11": 37519,
        "glue/mrpc": 37520,
        "kilt_tasks/hotpotqa": 37080
      },
      "step": 2340
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -194.56227111816406,
        "ag_news": 70.77360534667969,
        "amazon_polarity": 60.38908386230469,
        "cnn_dailymail/3.0.0": 211.46783447265625,
        "common_gen": 22.580141067504883,
        "cos_e/v1.11": -86.037841796875,
        "glue/mrpc": 3.8252298831939697,
        "kilt_tasks/hotpotqa": -53.426204681396484
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.977,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10559993982315063,
        "ag_news": 0.13147322833538055,
        "amazon_polarity": 0.13034960627555847,
        "cnn_dailymail/3.0.0": 0.1476926952600479,
        "common_gen": 0.12633971869945526,
        "cos_e/v1.11": 0.11549742519855499,
        "glue/mrpc": 0.12439695000648499,
        "kilt_tasks/hotpotqa": 0.11865046620368958
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 36184,
        "ag_news": 39000,
        "amazon_polarity": 37536,
        "cnn_dailymail/3.0.0": 38296,
        "common_gen": 37128,
        "cos_e/v1.11": 37663,
        "glue/mrpc": 37720,
        "kilt_tasks/hotpotqa": 37224
      },
      "step": 2350
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -195.75852966308594,
        "ag_news": 70.71256256103516,
        "amazon_polarity": 59.57126235961914,
        "cnn_dailymail/3.0.0": 209.67388916015625,
        "common_gen": 18.37572479248047,
        "cos_e/v1.11": -87.09222412109375,
        "glue/mrpc": 5.951826095581055,
        "kilt_tasks/hotpotqa": -52.319580078125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9224,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10560064017772675,
        "ag_news": 0.13153643906116486,
        "amazon_polarity": 0.13033327460289001,
        "cnn_dailymail/3.0.0": 0.14751635491847992,
        "common_gen": 0.12597991526126862,
        "cos_e/v1.11": 0.1154899001121521,
        "glue/mrpc": 0.12469598650932312,
        "kilt_tasks/hotpotqa": 0.11884749680757523
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 36328,
        "ag_news": 39120,
        "amazon_polarity": 37704,
        "cnn_dailymail/3.0.0": 38472,
        "common_gen": 37288,
        "cos_e/v1.11": 37823,
        "glue/mrpc": 37912,
        "kilt_tasks/hotpotqa": 37384
      },
      "step": 2360
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -197.2581787109375,
        "ag_news": 70.67803192138672,
        "amazon_polarity": 59.525413513183594,
        "cnn_dailymail/3.0.0": 208.7303009033203,
        "common_gen": 13.408244132995605,
        "cos_e/v1.11": -90.52110290527344,
        "glue/mrpc": 3.863626718521118,
        "kilt_tasks/hotpotqa": -52.47296142578125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8412,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10564828664064407,
        "ag_news": 0.13169392943382263,
        "amazon_polarity": 0.13049061596393585,
        "cnn_dailymail/3.0.0": 0.14754699170589447,
        "common_gen": 0.125631183385849,
        "cos_e/v1.11": 0.11533723771572113,
        "glue/mrpc": 0.12464842200279236,
        "kilt_tasks/hotpotqa": 0.11900338530540466
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 36448,
        "ag_news": 39280,
        "amazon_polarity": 37880,
        "cnn_dailymail/3.0.0": 38592,
        "common_gen": 37496,
        "cos_e/v1.11": 37999,
        "glue/mrpc": 38040,
        "kilt_tasks/hotpotqa": 37576
      },
      "step": 2370
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -196.32676696777344,
        "ag_news": 70.60211944580078,
        "amazon_polarity": 59.27002716064453,
        "cnn_dailymail/3.0.0": 209.7149200439453,
        "common_gen": 15.438064575195312,
        "cos_e/v1.11": -88.0086898803711,
        "glue/mrpc": 2.183502197265625,
        "kilt_tasks/hotpotqa": -57.916969299316406
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8231,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10577666014432907,
        "ag_news": 0.13168442249298096,
        "amazon_polarity": 0.13046447932720184,
        "cnn_dailymail/3.0.0": 0.14762987196445465,
        "common_gen": 0.12585191428661346,
        "cos_e/v1.11": 0.11560618877410889,
        "glue/mrpc": 0.1244896948337555,
        "kilt_tasks/hotpotqa": 0.11849677562713623
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 36552,
        "ag_news": 39472,
        "amazon_polarity": 38120,
        "cnn_dailymail/3.0.0": 38752,
        "common_gen": 37632,
        "cos_e/v1.11": 38175,
        "glue/mrpc": 38176,
        "kilt_tasks/hotpotqa": 37712
      },
      "step": 2380
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -196.62001037597656,
        "ag_news": 70.57608032226562,
        "amazon_polarity": 59.09158706665039,
        "cnn_dailymail/3.0.0": 210.4435577392578,
        "common_gen": 14.568329811096191,
        "cos_e/v1.11": -84.80030059814453,
        "glue/mrpc": -0.21218803524971008,
        "kilt_tasks/hotpotqa": -55.87204360961914
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9367,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10576678067445755,
        "ag_news": 0.13164088129997253,
        "amazon_polarity": 0.13040755689144135,
        "cnn_dailymail/3.0.0": 0.14763720333576202,
        "common_gen": 0.12573522329330444,
        "cos_e/v1.11": 0.11590589582920074,
        "glue/mrpc": 0.12422167509794235,
        "kilt_tasks/hotpotqa": 0.11868476867675781
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 36696,
        "ag_news": 39608,
        "amazon_polarity": 38312,
        "cnn_dailymail/3.0.0": 38936,
        "common_gen": 37784,
        "cos_e/v1.11": 38359,
        "glue/mrpc": 38344,
        "kilt_tasks/hotpotqa": 37832
      },
      "step": 2390
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -198.3015899658203,
        "ag_news": 70.55390930175781,
        "amazon_polarity": 57.424034118652344,
        "cnn_dailymail/3.0.0": 211.65296936035156,
        "common_gen": 13.044669151306152,
        "cos_e/v1.11": -82.40884399414062,
        "glue/mrpc": -4.838440895080566,
        "kilt_tasks/hotpotqa": -48.0315055847168
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9206,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10563959181308746,
        "ag_news": 0.13160116970539093,
        "amazon_polarity": 0.1301954686641693,
        "cnn_dailymail/3.0.0": 0.14770634472370148,
        "common_gen": 0.12555502355098724,
        "cos_e/v1.11": 0.11613037437200546,
        "glue/mrpc": 0.12373249232769012,
        "kilt_tasks/hotpotqa": 0.11943964660167694
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 36760,
        "ag_news": 39720,
        "amazon_polarity": 38464,
        "cnn_dailymail/3.0.0": 39120,
        "common_gen": 37960,
        "cos_e/v1.11": 38503,
        "glue/mrpc": 38568,
        "kilt_tasks/hotpotqa": 38056
      },
      "step": 2400
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1863,
      "eval_samples_per_second": 85.874,
      "eval_steps_per_second": 5.367,
      "step": 2400
    },
    {
      "epoch": 0.0,
      "step": 2400,
      "total_flos": 9.291118544100311e+17,
      "train_loss": 1.1127207094430924,
      "train_runtime": 26770.3261,
      "train_samples_per_second": 47.814,
      "train_steps_per_second": 0.374
    }
  ],
  "max_steps": 10000,
  "num_train_epochs": 18,
  "total_flos": 9.291118544100311e+17,
  "trial_name": null,
  "trial_params": null
}
