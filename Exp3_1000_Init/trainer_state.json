{
  "best_metric": 0.9375,
  "best_model_checkpoint": "src/../outputs/T5_LM_3B/T0Mixture/weighted_batch_exp3/42/copa/cosine/1.0/16/0.0001/1000/1000/checkpoint-600",
  "epoch": 0.00021793614470960008,
  "global_step": 1600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 31.689990997314453,
        "ag_news": 38.13383102416992,
        "amazon_polarity": 34.15214157104492,
        "cnn_dailymail/3.0.0": -52.82991027832031,
        "common_gen": 22.215974807739258,
        "cos_e/v1.11": 31.119102478027344,
        "glue/mrpc": 25.738615036010742,
        "kilt_tasks/hotpotqa": 32.37123107910156
      },
      "epoch": 0.0,
      "learning_rate": 1e-05,
      "loss": 5.2333,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1369512379169464,
        "ag_news": 0.14882592856884003,
        "amazon_polarity": 0.1413602977991104,
        "cnn_dailymail/3.0.0": 0.0504872165620327,
        "common_gen": 0.12135744094848633,
        "cos_e/v1.11": 0.13595083355903625,
        "glue/mrpc": 0.12691128253936768,
        "kilt_tasks/hotpotqa": 0.1381557285785675
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 160,
        "ag_news": 160,
        "amazon_polarity": 176,
        "cnn_dailymail/3.0.0": 88,
        "common_gen": 192,
        "cos_e/v1.11": 176,
        "glue/mrpc": 176,
        "kilt_tasks/hotpotqa": 152
      },
      "step": 10
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 64.20833587646484,
        "ag_news": 76.55016326904297,
        "amazon_polarity": 69.23016357421875,
        "cnn_dailymail/3.0.0": -295.677001953125,
        "common_gen": 52.33624267578125,
        "cos_e/v1.11": 70.1746826171875,
        "glue/mrpc": 63.6438102722168,
        "kilt_tasks/hotpotqa": 72.69600677490234
      },
      "epoch": 0.0,
      "learning_rate": 2e-05,
      "loss": 4.5815,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13721683621406555,
        "ag_news": 0.1531336009502411,
        "amazon_polarity": 0.14346902072429657,
        "cnn_dailymail/3.0.0": 0.013438312336802483,
        "common_gen": 0.12356974929571152,
        "cos_e/v1.11": 0.14467863738536835,
        "glue/mrpc": 0.1365324705839157,
        "kilt_tasks/hotpotqa": 0.14796125888824463
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 320,
        "ag_news": 272,
        "amazon_polarity": 312,
        "cnn_dailymail/3.0.0": 256,
        "common_gen": 416,
        "cos_e/v1.11": 328,
        "glue/mrpc": 360,
        "kilt_tasks/hotpotqa": 296
      },
      "step": 20
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 82.32721710205078,
        "ag_news": 99.49148559570312,
        "amazon_polarity": 93.969482421875,
        "cnn_dailymail/3.0.0": -610.1751098632812,
        "common_gen": 55.380985260009766,
        "cos_e/v1.11": 86.2037124633789,
        "glue/mrpc": 82.09464263916016,
        "kilt_tasks/hotpotqa": 93.85417938232422
      },
      "epoch": 0.0,
      "learning_rate": 3e-05,
      "loss": 3.1339,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1385686695575714,
        "ag_news": 0.1568755805492401,
        "amazon_polarity": 0.15072289109230042,
        "cnn_dailymail/3.0.0": 0.008155185729265213,
        "common_gen": 0.11424727737903595,
        "cos_e/v1.11": 0.14249657094478607,
        "glue/mrpc": 0.1383366733789444,
        "kilt_tasks/hotpotqa": 0.15059718489646912
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 464,
        "ag_news": 480,
        "amazon_polarity": 504,
        "cnn_dailymail/3.0.0": 336,
        "common_gen": 576,
        "cos_e/v1.11": 456,
        "glue/mrpc": 576,
        "kilt_tasks/hotpotqa": 448
      },
      "step": 30
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 67.88338470458984,
        "ag_news": 94.27764892578125,
        "amazon_polarity": 89.86632537841797,
        "cnn_dailymail/3.0.0": -442.82244873046875,
        "common_gen": 32.91050338745117,
        "cos_e/v1.11": 76.8543701171875,
        "glue/mrpc": 76.7599868774414,
        "kilt_tasks/hotpotqa": 83.09677124023438
      },
      "epoch": 0.0,
      "learning_rate": 4e-05,
      "loss": 2.1351,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1346338838338852,
        "ag_news": 0.1587763875722885,
        "amazon_polarity": 0.15444600582122803,
        "cnn_dailymail/3.0.0": 0.0110006183385849,
        "common_gen": 0.10843467712402344,
        "cos_e/v1.11": 0.14237673580646515,
        "glue/mrpc": 0.14229288697242737,
        "kilt_tasks/hotpotqa": 0.148038849234581
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 656,
        "ag_news": 680,
        "amazon_polarity": 680,
        "cnn_dailymail/3.0.0": 464,
        "common_gen": 720,
        "cos_e/v1.11": 608,
        "glue/mrpc": 728,
        "kilt_tasks/hotpotqa": 584
      },
      "step": 40
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 60.50016403198242,
        "ag_news": 91.51139831542969,
        "amazon_polarity": 86.7690200805664,
        "cnn_dailymail/3.0.0": -300.8755187988281,
        "common_gen": 23.582523345947266,
        "cos_e/v1.11": 76.93604278564453,
        "glue/mrpc": 74.3239974975586,
        "kilt_tasks/hotpotqa": 68.11455535888672
      },
      "epoch": 0.0,
      "learning_rate": 5e-05,
      "loss": 1.7269,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.13259293138980865,
        "ag_news": 0.15766790509223938,
        "amazon_polarity": 0.15353433787822723,
        "cnn_dailymail/3.0.0": 0.021254951134324074,
        "common_gen": 0.10808008909225464,
        "cos_e/v1.11": 0.14531856775283813,
        "glue/mrpc": 0.14321397244930267,
        "kilt_tasks/hotpotqa": 0.1383373737335205
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 776,
        "ag_news": 864,
        "amazon_polarity": 920,
        "cnn_dailymail/3.0.0": 584,
        "common_gen": 824,
        "cos_e/v1.11": 792,
        "glue/mrpc": 856,
        "kilt_tasks/hotpotqa": 784
      },
      "step": 50
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 49.87179183959961,
        "ag_news": 90.87557983398438,
        "amazon_polarity": 85.89771270751953,
        "cnn_dailymail/3.0.0": -212.42098999023438,
        "common_gen": 17.280475616455078,
        "cos_e/v1.11": 75.48617553710938,
        "glue/mrpc": 73.3916015625,
        "kilt_tasks/hotpotqa": 64.57408142089844
      },
      "epoch": 0.0,
      "learning_rate": 6e-05,
      "loss": 1.7028,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12648293375968933,
        "ag_news": 0.15586337447166443,
        "amazon_polarity": 0.15194742381572723,
        "cnn_dailymail/3.0.0": 0.035501714795827866,
        "common_gen": 0.10727640986442566,
        "cos_e/v1.11": 0.14408297836780548,
        "glue/mrpc": 0.14255252480506897,
        "kilt_tasks/hotpotqa": 0.13629256188869476
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 968,
        "ag_news": 1016,
        "amazon_polarity": 1104,
        "cnn_dailymail/3.0.0": 752,
        "common_gen": 928,
        "cos_e/v1.11": 936,
        "glue/mrpc": 1000,
        "kilt_tasks/hotpotqa": 976
      },
      "step": 60
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 47.252593994140625,
        "ag_news": 90.74540710449219,
        "amazon_polarity": 86.42417907714844,
        "cnn_dailymail/3.0.0": -200.0384063720703,
        "common_gen": 10.45254135131836,
        "cos_e/v1.11": 74.0159912109375,
        "glue/mrpc": 73.08574676513672,
        "kilt_tasks/hotpotqa": 62.5938835144043
      },
      "epoch": 0.0,
      "learning_rate": 7e-05,
      "loss": 1.5709,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12599879503250122,
        "ag_news": 0.15469343960285187,
        "amazon_polarity": 0.15156190097332,
        "cnn_dailymail/3.0.0": 0.04102630168199539,
        "common_gen": 0.10605614632368088,
        "cos_e/v1.11": 0.14292897284030914,
        "glue/mrpc": 0.14230260252952576,
        "kilt_tasks/hotpotqa": 0.13543182611465454
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1144,
        "ag_news": 1224,
        "amazon_polarity": 1264,
        "cnn_dailymail/3.0.0": 872,
        "common_gen": 1080,
        "cos_e/v1.11": 1104,
        "glue/mrpc": 1104,
        "kilt_tasks/hotpotqa": 1168
      },
      "step": 70
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 36.180328369140625,
        "ag_news": 90.42654418945312,
        "amazon_polarity": 84.72022247314453,
        "cnn_dailymail/3.0.0": -168.01235961914062,
        "common_gen": 10.145482063293457,
        "cos_e/v1.11": 73.49353790283203,
        "glue/mrpc": 69.28794860839844,
        "kilt_tasks/hotpotqa": 60.90425491333008
      },
      "epoch": 0.0,
      "learning_rate": 8e-05,
      "loss": 1.544,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.12094265222549438,
        "ag_news": 0.15364061295986176,
        "amazon_polarity": 0.1498078554868698,
        "cnn_dailymail/3.0.0": 0.05037914589047432,
        "common_gen": 0.10790206491947174,
        "cos_e/v1.11": 0.1425524204969406,
        "glue/mrpc": 0.13992878794670105,
        "kilt_tasks/hotpotqa": 0.1348465234041214
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1320,
        "ag_news": 1424,
        "amazon_polarity": 1376,
        "cnn_dailymail/3.0.0": 1008,
        "common_gen": 1240,
        "cos_e/v1.11": 1288,
        "glue/mrpc": 1256,
        "kilt_tasks/hotpotqa": 1328
      },
      "step": 80
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 28.3994083404541,
        "ag_news": 90.1995849609375,
        "amazon_polarity": 84.2943115234375,
        "cnn_dailymail/3.0.0": -146.75099182128906,
        "common_gen": 11.62893295288086,
        "cos_e/v1.11": 74.31415557861328,
        "glue/mrpc": 67.73143005371094,
        "kilt_tasks/hotpotqa": 55.18619918823242
      },
      "epoch": 0.0,
      "learning_rate": 9e-05,
      "loss": 1.4617,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11788017302751541,
        "ag_news": 0.1524297147989273,
        "amazon_polarity": 0.1487179845571518,
        "cnn_dailymail/3.0.0": 0.057801343500614166,
        "common_gen": 0.10998224467039108,
        "cos_e/v1.11": 0.142655149102211,
        "glue/mrpc": 0.13879616558551788,
        "kilt_tasks/hotpotqa": 0.13173724710941315
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1496,
        "ag_news": 1608,
        "amazon_polarity": 1496,
        "cnn_dailymail/3.0.0": 1152,
        "common_gen": 1384,
        "cos_e/v1.11": 1464,
        "glue/mrpc": 1440,
        "kilt_tasks/hotpotqa": 1480
      },
      "step": 90
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 25.981630325317383,
        "ag_news": 90.6142807006836,
        "amazon_polarity": 83.7959976196289,
        "cnn_dailymail/3.0.0": -125.21833038330078,
        "common_gen": 9.963540077209473,
        "cos_e/v1.11": 73.11341857910156,
        "glue/mrpc": 65.14643859863281,
        "kilt_tasks/hotpotqa": 54.56433868408203
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2603,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11720088124275208,
        "ag_news": 0.151260644197464,
        "amazon_polarity": 0.147230327129364,
        "cnn_dailymail/3.0.0": 0.06518812477588654,
        "common_gen": 0.11005719006061554,
        "cos_e/v1.11": 0.1411365270614624,
        "glue/mrpc": 0.13676126301288605,
        "kilt_tasks/hotpotqa": 0.1311650276184082
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1648,
        "ag_news": 1760,
        "amazon_polarity": 1760,
        "cnn_dailymail/3.0.0": 1352,
        "common_gen": 1480,
        "cos_e/v1.11": 1600,
        "glue/mrpc": 1608,
        "kilt_tasks/hotpotqa": 1592
      },
      "step": 100
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.6875,
      "eval_runtime": 0.7807,
      "eval_samples_per_second": 20.495,
      "eval_steps_per_second": 1.281,
      "step": 100
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 23.927757263183594,
        "ag_news": 90.46487426757812,
        "amazon_polarity": 83.37869262695312,
        "cnn_dailymail/3.0.0": -88.26201629638672,
        "common_gen": 8.812122344970703,
        "cos_e/v1.11": 69.80702209472656,
        "glue/mrpc": 65.63720703125,
        "kilt_tasks/hotpotqa": 54.440826416015625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3776,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11602754890918732,
        "ag_news": 0.1490502655506134,
        "amazon_polarity": 0.14511442184448242,
        "cnn_dailymail/3.0.0": 0.07645441591739655,
        "common_gen": 0.10964097082614899,
        "cos_e/v1.11": 0.13787174224853516,
        "glue/mrpc": 0.13572198152542114,
        "kilt_tasks/hotpotqa": 0.13011866807937622
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1816,
        "ag_news": 1912,
        "amazon_polarity": 1952,
        "cnn_dailymail/3.0.0": 1576,
        "common_gen": 1568,
        "cos_e/v1.11": 1752,
        "glue/mrpc": 1784,
        "kilt_tasks/hotpotqa": 1720
      },
      "step": 110
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 16.704181671142578,
        "ag_news": 90.06138610839844,
        "amazon_polarity": 83.20158386230469,
        "cnn_dailymail/3.0.0": -63.78608703613281,
        "common_gen": 8.610381126403809,
        "cos_e/v1.11": 67.30555725097656,
        "glue/mrpc": 65.6476821899414,
        "kilt_tasks/hotpotqa": 46.165592193603516
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4233,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11364655196666718,
        "ag_news": 0.1480422466993332,
        "amazon_polarity": 0.14441463351249695,
        "cnn_dailymail/3.0.0": 0.08525926619768143,
        "common_gen": 0.11039368063211441,
        "cos_e/v1.11": 0.13635499775409698,
        "glue/mrpc": 0.13554146885871887,
        "kilt_tasks/hotpotqa": 0.12634716928005219
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 1968,
        "ag_news": 2008,
        "amazon_polarity": 2168,
        "cnn_dailymail/3.0.0": 1768,
        "common_gen": 1744,
        "cos_e/v1.11": 1864,
        "glue/mrpc": 1952,
        "kilt_tasks/hotpotqa": 1888
      },
      "step": 120
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": 6.3907856941223145,
        "ag_news": 89.89976501464844,
        "amazon_polarity": 83.15682220458984,
        "cnn_dailymail/3.0.0": -45.142940521240234,
        "common_gen": 2.9167213439941406,
        "cos_e/v1.11": 65.33946228027344,
        "glue/mrpc": 63.23808670043945,
        "kilt_tasks/hotpotqa": 42.405548095703125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3413,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11060075461864471,
        "ag_news": 0.1476929485797882,
        "amazon_polarity": 0.1442716270685196,
        "cnn_dailymail/3.0.0": 0.09264581650495529,
        "common_gen": 0.10928401350975037,
        "cos_e/v1.11": 0.1356169581413269,
        "glue/mrpc": 0.1346319615840912,
        "kilt_tasks/hotpotqa": 0.1252557784318924
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2112,
        "ag_news": 2224,
        "amazon_polarity": 2328,
        "cnn_dailymail/3.0.0": 1904,
        "common_gen": 1928,
        "cos_e/v1.11": 2008,
        "glue/mrpc": 2080,
        "kilt_tasks/hotpotqa": 2056
      },
      "step": 130
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -8.485957145690918,
        "ag_news": 89.0377426147461,
        "amazon_polarity": 82.95055389404297,
        "cnn_dailymail/3.0.0": -24.2288818359375,
        "common_gen": 0.014346867799758911,
        "cos_e/v1.11": 64.06359100341797,
        "glue/mrpc": 62.18790054321289,
        "kilt_tasks/hotpotqa": 39.17230987548828
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3592,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10604508221149445,
        "ag_news": 0.14682726562023163,
        "amazon_polarity": 0.1438632309436798,
        "cnn_dailymail/3.0.0": 0.10064888000488281,
        "common_gen": 0.1090821921825409,
        "cos_e/v1.11": 0.1350509077310562,
        "glue/mrpc": 0.13420650362968445,
        "kilt_tasks/hotpotqa": 0.12427593022584915
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2320,
        "ag_news": 2336,
        "amazon_polarity": 2464,
        "cnn_dailymail/3.0.0": 2064,
        "common_gen": 2128,
        "cos_e/v1.11": 2152,
        "glue/mrpc": 2264,
        "kilt_tasks/hotpotqa": 2192
      },
      "step": 140
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -9.696290969848633,
        "ag_news": 88.74693298339844,
        "amazon_polarity": 82.89239501953125,
        "cnn_dailymail/3.0.0": -1.318960189819336,
        "common_gen": -7.308968544006348,
        "cos_e/v1.11": 63.35103225708008,
        "glue/mrpc": 58.93768310546875,
        "kilt_tasks/hotpotqa": 32.70577621459961
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4127,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10621071606874466,
        "ag_news": 0.1458943784236908,
        "amazon_polarity": 0.1431552618741989,
        "cnn_dailymail/3.0.0": 0.10910690575838089,
        "common_gen": 0.10702787339687347,
        "cos_e/v1.11": 0.1343877911567688,
        "glue/mrpc": 0.1324850618839264,
        "kilt_tasks/hotpotqa": 0.12173205614089966
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2448,
        "ag_news": 2488,
        "amazon_polarity": 2624,
        "cnn_dailymail/3.0.0": 2248,
        "common_gen": 2296,
        "cos_e/v1.11": 2336,
        "glue/mrpc": 2384,
        "kilt_tasks/hotpotqa": 2376
      },
      "step": 150
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -12.785517692565918,
        "ag_news": 88.5031967163086,
        "amazon_polarity": 83.1619644165039,
        "cnn_dailymail/3.0.0": 5.668410778045654,
        "common_gen": -5.2917704582214355,
        "cos_e/v1.11": 61.086570739746094,
        "glue/mrpc": 57.251434326171875,
        "kilt_tasks/hotpotqa": 21.45335578918457
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3475,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10615425556898117,
        "ag_news": 0.14566220343112946,
        "amazon_polarity": 0.14324301481246948,
        "cnn_dailymail/3.0.0": 0.1124303862452507,
        "common_gen": 0.10865816473960876,
        "cos_e/v1.11": 0.1336725801229477,
        "glue/mrpc": 0.1320778876543045,
        "kilt_tasks/hotpotqa": 0.11810151487588882
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2624,
        "ag_news": 2664,
        "amazon_polarity": 2784,
        "cnn_dailymail/3.0.0": 2400,
        "common_gen": 2432,
        "cos_e/v1.11": 2504,
        "glue/mrpc": 2496,
        "kilt_tasks/hotpotqa": 2576
      },
      "step": 160
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -18.883432388305664,
        "ag_news": 88.78936004638672,
        "amazon_polarity": 83.27854919433594,
        "cnn_dailymail/3.0.0": 14.367984771728516,
        "common_gen": -4.993443489074707,
        "cos_e/v1.11": 60.99687576293945,
        "glue/mrpc": 58.783416748046875,
        "kilt_tasks/hotpotqa": 20.056371688842773
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2627,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10459278523921967,
        "ag_news": 0.14495520293712616,
        "amazon_polarity": 0.14254501461982727,
        "cnn_dailymail/3.0.0": 0.11564872413873672,
        "common_gen": 0.10907253623008728,
        "cos_e/v1.11": 0.13321040570735931,
        "glue/mrpc": 0.1323179304599762,
        "kilt_tasks/hotpotqa": 0.11765725910663605
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2784,
        "ag_news": 2880,
        "amazon_polarity": 2904,
        "cnn_dailymail/3.0.0": 2544,
        "common_gen": 2632,
        "cos_e/v1.11": 2624,
        "glue/mrpc": 2656,
        "kilt_tasks/hotpotqa": 2736
      },
      "step": 170
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -26.511354446411133,
        "ag_news": 88.43814849853516,
        "amazon_polarity": 83.19403839111328,
        "cnn_dailymail/3.0.0": 20.30373764038086,
        "common_gen": -12.525867462158203,
        "cos_e/v1.11": 61.145713806152344,
        "glue/mrpc": 57.95661163330078,
        "kilt_tasks/hotpotqa": 17.234066009521484
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3944,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10322438180446625,
        "ag_news": 0.144831120967865,
        "amazon_polarity": 0.1426020860671997,
        "cnn_dailymail/3.0.0": 0.11844836920499802,
        "common_gen": 0.10754906386137009,
        "cos_e/v1.11": 0.1336071938276291,
        "glue/mrpc": 0.13235504925251007,
        "kilt_tasks/hotpotqa": 0.11738281697034836
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 2896,
        "ag_news": 3040,
        "amazon_polarity": 3072,
        "cnn_dailymail/3.0.0": 2680,
        "common_gen": 2848,
        "cos_e/v1.11": 2760,
        "glue/mrpc": 2824,
        "kilt_tasks/hotpotqa": 2920
      },
      "step": 180
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -29.059080123901367,
        "ag_news": 88.31166076660156,
        "amazon_polarity": 83.13488006591797,
        "cnn_dailymail/3.0.0": 23.243696212768555,
        "common_gen": -11.893170356750488,
        "cos_e/v1.11": 56.57502746582031,
        "glue/mrpc": 57.12507629394531,
        "kilt_tasks/hotpotqa": 14.634064674377441
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2609,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1032726913690567,
        "ag_news": 0.14461472630500793,
        "amazon_polarity": 0.14247499406337738,
        "cnn_dailymail/3.0.0": 0.11994893103837967,
        "common_gen": 0.10846584290266037,
        "cos_e/v1.11": 0.13199469447135925,
        "glue/mrpc": 0.13220354914665222,
        "kilt_tasks/hotpotqa": 0.11702457815408707
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3008,
        "ag_news": 3240,
        "amazon_polarity": 3264,
        "cnn_dailymail/3.0.0": 2792,
        "common_gen": 3024,
        "cos_e/v1.11": 2936,
        "glue/mrpc": 2936,
        "kilt_tasks/hotpotqa": 3120
      },
      "step": 190
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -34.71194839477539,
        "ag_news": 87.98545837402344,
        "amazon_polarity": 83.2712631225586,
        "cnn_dailymail/3.0.0": 32.91432571411133,
        "common_gen": -13.153003692626953,
        "cos_e/v1.11": 53.13190460205078,
        "glue/mrpc": 57.89028549194336,
        "kilt_tasks/hotpotqa": 12.1209077835083
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.5214,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10222034901380539,
        "ag_news": 0.14406493306159973,
        "amazon_polarity": 0.1421709805727005,
        "cnn_dailymail/3.0.0": 0.12345825135707855,
        "common_gen": 0.10854972898960114,
        "cos_e/v1.11": 0.13064852356910706,
        "glue/mrpc": 0.1324022114276886,
        "kilt_tasks/hotpotqa": 0.11648497730493546
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3168,
        "ag_news": 3368,
        "amazon_polarity": 3368,
        "cnn_dailymail/3.0.0": 3032,
        "common_gen": 3192,
        "cos_e/v1.11": 3104,
        "glue/mrpc": 3048,
        "kilt_tasks/hotpotqa": 3320
      },
      "step": 200
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.2986,
      "eval_samples_per_second": 53.579,
      "eval_steps_per_second": 3.349,
      "step": 200
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -38.607913970947266,
        "ag_news": 87.93804931640625,
        "amazon_polarity": 83.33997344970703,
        "cnn_dailymail/3.0.0": 36.2009162902832,
        "common_gen": -12.827394485473633,
        "cos_e/v1.11": 53.12599563598633,
        "glue/mrpc": 54.612483978271484,
        "kilt_tasks/hotpotqa": 10.210370063781738
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.444,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10180944204330444,
        "ag_news": 0.14382050931453705,
        "amazon_polarity": 0.1420198231935501,
        "cnn_dailymail/3.0.0": 0.12483453005552292,
        "common_gen": 0.10920703411102295,
        "cos_e/v1.11": 0.1307460218667984,
        "glue/mrpc": 0.13127869367599487,
        "kilt_tasks/hotpotqa": 0.11628396809101105
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3312,
        "ag_news": 3512,
        "amazon_polarity": 3544,
        "cnn_dailymail/3.0.0": 3208,
        "common_gen": 3376,
        "cos_e/v1.11": 3240,
        "glue/mrpc": 3168,
        "kilt_tasks/hotpotqa": 3520
      },
      "step": 210
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -40.136505126953125,
        "ag_news": 87.9702377319336,
        "amazon_polarity": 83.36495971679688,
        "cnn_dailymail/3.0.0": 36.88001251220703,
        "common_gen": -13.484247207641602,
        "cos_e/v1.11": 51.99599838256836,
        "glue/mrpc": 53.35519027709961,
        "kilt_tasks/hotpotqa": 6.458065986633301
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3641,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1021215170621872,
        "ag_news": 0.14373481273651123,
        "amazon_polarity": 0.14197318255901337,
        "cnn_dailymail/3.0.0": 0.12537819147109985,
        "common_gen": 0.10962287336587906,
        "cos_e/v1.11": 0.13054527342319489,
        "glue/mrpc": 0.1310204416513443,
        "kilt_tasks/hotpotqa": 0.11560367047786713
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3456,
        "ag_news": 3664,
        "amazon_polarity": 3640,
        "cnn_dailymail/3.0.0": 3408,
        "common_gen": 3496,
        "cos_e/v1.11": 3416,
        "glue/mrpc": 3376,
        "kilt_tasks/hotpotqa": 3704
      },
      "step": 220
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -44.32291030883789,
        "ag_news": 88.11621856689453,
        "amazon_polarity": 83.36187744140625,
        "cnn_dailymail/3.0.0": 45.09432601928711,
        "common_gen": -14.048394203186035,
        "cos_e/v1.11": 48.29582595825195,
        "glue/mrpc": 53.181602478027344,
        "kilt_tasks/hotpotqa": 5.103023529052734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2575,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10149437934160233,
        "ag_news": 0.14340545237064362,
        "amazon_polarity": 0.141630619764328,
        "cnn_dailymail/3.0.0": 0.12813647091388702,
        "common_gen": 0.10981260985136032,
        "cos_e/v1.11": 0.12921330332756042,
        "glue/mrpc": 0.13087451457977295,
        "kilt_tasks/hotpotqa": 0.11543256044387817
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3632,
        "ag_news": 3768,
        "amazon_polarity": 3808,
        "cnn_dailymail/3.0.0": 3552,
        "common_gen": 3664,
        "cos_e/v1.11": 3560,
        "glue/mrpc": 3632,
        "kilt_tasks/hotpotqa": 3824
      },
      "step": 230
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -47.45256805419922,
        "ag_news": 87.88558959960938,
        "amazon_polarity": 83.25458526611328,
        "cnn_dailymail/3.0.0": 50.28416061401367,
        "common_gen": -9.7538423538208,
        "cos_e/v1.11": 49.9671745300293,
        "glue/mrpc": 54.1926155090332,
        "kilt_tasks/hotpotqa": 5.4408183097839355
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4003,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1008375957608223,
        "ag_news": 0.1425034999847412,
        "amazon_polarity": 0.14082108438014984,
        "cnn_dailymail/3.0.0": 0.12941387295722961,
        "common_gen": 0.11100499331951141,
        "cos_e/v1.11": 0.12930889427661896,
        "glue/mrpc": 0.13071535527706146,
        "kilt_tasks/hotpotqa": 0.11539468914270401
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3776,
        "ag_news": 3912,
        "amazon_polarity": 3960,
        "cnn_dailymail/3.0.0": 3752,
        "common_gen": 3824,
        "cos_e/v1.11": 3696,
        "glue/mrpc": 3724,
        "kilt_tasks/hotpotqa": 4072
      },
      "step": 240
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -49.56407928466797,
        "ag_news": 87.86103057861328,
        "amazon_polarity": 83.21869659423828,
        "cnn_dailymail/3.0.0": 51.36402130126953,
        "common_gen": -9.947880744934082,
        "cos_e/v1.11": 47.84513473510742,
        "glue/mrpc": 56.338714599609375,
        "kilt_tasks/hotpotqa": 5.5145955085754395
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.354,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1007704883813858,
        "ag_news": 0.14217033982276917,
        "amazon_polarity": 0.14052128791809082,
        "cnn_dailymail/3.0.0": 0.1297193467617035,
        "common_gen": 0.11125132441520691,
        "cos_e/v1.11": 0.12857921421527863,
        "glue/mrpc": 0.13134880363941193,
        "kilt_tasks/hotpotqa": 0.11563920974731445
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 3904,
        "ag_news": 4064,
        "amazon_polarity": 4112,
        "cnn_dailymail/3.0.0": 3936,
        "common_gen": 4008,
        "cos_e/v1.11": 3840,
        "glue/mrpc": 3884,
        "kilt_tasks/hotpotqa": 4248
      },
      "step": 250
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -48.66023254394531,
        "ag_news": 86.87098693847656,
        "amazon_polarity": 83.1011734008789,
        "cnn_dailymail/3.0.0": 52.66273498535156,
        "common_gen": -12.171863555908203,
        "cos_e/v1.11": 46.88959503173828,
        "glue/mrpc": 55.81640625,
        "kilt_tasks/hotpotqa": 4.235552787780762
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3057,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10154152661561966,
        "ag_news": 0.1416587233543396,
        "amazon_polarity": 0.14034859836101532,
        "cnn_dailymail/3.0.0": 0.1302121877670288,
        "common_gen": 0.1110374853014946,
        "cos_e/v1.11": 0.12837548553943634,
        "glue/mrpc": 0.1312268078327179,
        "kilt_tasks/hotpotqa": 0.11559918522834778
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4008,
        "ag_news": 4248,
        "amazon_polarity": 4240,
        "cnn_dailymail/3.0.0": 4088,
        "common_gen": 4152,
        "cos_e/v1.11": 4048,
        "glue/mrpc": 4020,
        "kilt_tasks/hotpotqa": 4472
      },
      "step": 260
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -52.536460876464844,
        "ag_news": 87.22769165039062,
        "amazon_polarity": 82.94502258300781,
        "cnn_dailymail/3.0.0": 60.318382263183594,
        "common_gen": -9.721263885498047,
        "cos_e/v1.11": 45.517181396484375,
        "glue/mrpc": 56.41586685180664,
        "kilt_tasks/hotpotqa": -2.7192156314849854
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.4161,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10099080204963684,
        "ag_news": 0.14146116375923157,
        "amazon_polarity": 0.14000318944454193,
        "cnn_dailymail/3.0.0": 0.13255034387111664,
        "common_gen": 0.11194468289613724,
        "cos_e/v1.11": 0.12789493799209595,
        "glue/mrpc": 0.13130636513233185,
        "kilt_tasks/hotpotqa": 0.11384854465723038
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4144,
        "ag_news": 4376,
        "amazon_polarity": 4376,
        "cnn_dailymail/3.0.0": 4248,
        "common_gen": 4328,
        "cos_e/v1.11": 4248,
        "glue/mrpc": 4180,
        "kilt_tasks/hotpotqa": 4656
      },
      "step": 270
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.531105041503906,
        "ag_news": 87.02462768554688,
        "amazon_polarity": 82.59972381591797,
        "cnn_dailymail/3.0.0": 62.58213806152344,
        "common_gen": -11.475166320800781,
        "cos_e/v1.11": 43.938072204589844,
        "glue/mrpc": 56.83037567138672,
        "kilt_tasks/hotpotqa": -0.09188875555992126
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2169,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09963496029376984,
        "ag_news": 0.14130431413650513,
        "amazon_polarity": 0.13982656598091125,
        "cnn_dailymail/3.0.0": 0.13333548605442047,
        "common_gen": 0.11187554150819778,
        "cos_e/v1.11": 0.1275658905506134,
        "glue/mrpc": 0.13152773678302765,
        "kilt_tasks/hotpotqa": 0.11492950469255447
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4264,
        "ag_news": 4592,
        "amazon_polarity": 4552,
        "cnn_dailymail/3.0.0": 4392,
        "common_gen": 4440,
        "cos_e/v1.11": 4440,
        "glue/mrpc": 4340,
        "kilt_tasks/hotpotqa": 4816
      },
      "step": 280
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -62.954193115234375,
        "ag_news": 85.97896575927734,
        "amazon_polarity": 82.52792358398438,
        "cnn_dailymail/3.0.0": 61.90608596801758,
        "common_gen": -12.395234107971191,
        "cos_e/v1.11": 41.83287811279297,
        "glue/mrpc": 58.74550247192383,
        "kilt_tasks/hotpotqa": -1.2057008743286133
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1915,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09964204579591751,
        "ag_news": 0.14091958105564117,
        "amazon_polarity": 0.13978862762451172,
        "cnn_dailymail/3.0.0": 0.13322044909000397,
        "common_gen": 0.11205242574214935,
        "cos_e/v1.11": 0.12712864577770233,
        "glue/mrpc": 0.13224190473556519,
        "kilt_tasks/hotpotqa": 0.11500632762908936
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4448,
        "ag_news": 4792,
        "amazon_polarity": 4736,
        "cnn_dailymail/3.0.0": 4520,
        "common_gen": 4552,
        "cos_e/v1.11": 4608,
        "glue/mrpc": 4508,
        "kilt_tasks/hotpotqa": 4952
      },
      "step": 290
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -63.429847717285156,
        "ag_news": 85.93596649169922,
        "amazon_polarity": 82.38774871826172,
        "cnn_dailymail/3.0.0": 58.522666931152344,
        "common_gen": -10.315718650817871,
        "cos_e/v1.11": 41.98141860961914,
        "glue/mrpc": 57.5485954284668,
        "kilt_tasks/hotpotqa": 0.29124873876571655
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3293,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09997615963220596,
        "ag_news": 0.14072220027446747,
        "amazon_polarity": 0.13958042860031128,
        "cnn_dailymail/3.0.0": 0.13214191794395447,
        "common_gen": 0.11286826431751251,
        "cos_e/v1.11": 0.12722405791282654,
        "glue/mrpc": 0.13184702396392822,
        "kilt_tasks/hotpotqa": 0.11563995480537415
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4600,
        "ag_news": 4880,
        "amazon_polarity": 4944,
        "cnn_dailymail/3.0.0": 4752,
        "common_gen": 4704,
        "cos_e/v1.11": 4792,
        "glue/mrpc": 4660,
        "kilt_tasks/hotpotqa": 5064
      },
      "step": 300
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.75,
      "eval_runtime": 0.1949,
      "eval_samples_per_second": 82.093,
      "eval_steps_per_second": 5.131,
      "step": 300
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -65.4156265258789,
        "ag_news": 85.88591766357422,
        "amazon_polarity": 82.31855773925781,
        "cnn_dailymail/3.0.0": 62.717140197753906,
        "common_gen": -13.758562088012695,
        "cos_e/v1.11": 43.46879959106445,
        "glue/mrpc": 58.2948112487793,
        "kilt_tasks/hotpotqa": 0.8676812648773193
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3196,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.09982774406671524,
        "ag_news": 0.14035333693027496,
        "amazon_polarity": 0.13922683894634247,
        "cnn_dailymail/3.0.0": 0.13319918513298035,
        "common_gen": 0.11211330443620682,
        "cos_e/v1.11": 0.12753838300704956,
        "glue/mrpc": 0.1318763792514801,
        "kilt_tasks/hotpotqa": 0.11586491763591766
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4752,
        "ag_news": 5040,
        "amazon_polarity": 5056,
        "cnn_dailymail/3.0.0": 4952,
        "common_gen": 4888,
        "cos_e/v1.11": 4960,
        "glue/mrpc": 4804,
        "kilt_tasks/hotpotqa": 5224
      },
      "step": 310
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -65.23419952392578,
        "ag_news": 85.69953918457031,
        "amazon_polarity": 82.09252166748047,
        "cnn_dailymail/3.0.0": 67.07083129882812,
        "common_gen": -14.846284866333008,
        "cos_e/v1.11": 43.060272216796875,
        "glue/mrpc": 56.9158821105957,
        "kilt_tasks/hotpotqa": -4.946669578552246
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1844,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10033220797777176,
        "ag_news": 0.1402052789926529,
        "amazon_polarity": 0.13908520340919495,
        "cnn_dailymail/3.0.0": 0.13451753556728363,
        "common_gen": 0.11216269433498383,
        "cos_e/v1.11": 0.12753114104270935,
        "glue/mrpc": 0.13151641190052032,
        "kilt_tasks/hotpotqa": 0.11464958637952805
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 4928,
        "ag_news": 5216,
        "amazon_polarity": 5216,
        "cnn_dailymail/3.0.0": 5112,
        "common_gen": 5072,
        "cos_e/v1.11": 5104,
        "glue/mrpc": 4980,
        "kilt_tasks/hotpotqa": 5328
      },
      "step": 320
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -67.49642944335938,
        "ag_news": 85.686767578125,
        "amazon_polarity": 82.1233901977539,
        "cnn_dailymail/3.0.0": 67.66956329345703,
        "common_gen": -21.719148635864258,
        "cos_e/v1.11": 41.64169692993164,
        "glue/mrpc": 56.00020217895508,
        "kilt_tasks/hotpotqa": -4.4329071044921875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3698,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10043002665042877,
        "ag_news": 0.14032456278800964,
        "amazon_polarity": 0.13923370838165283,
        "cnn_dailymail/3.0.0": 0.13489659130573273,
        "common_gen": 0.11096258461475372,
        "cos_e/v1.11": 0.1274297684431076,
        "glue/mrpc": 0.1314953714609146,
        "kilt_tasks/hotpotqa": 0.11522739380598068
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5080,
        "ag_news": 5376,
        "amazon_polarity": 5360,
        "cnn_dailymail/3.0.0": 5280,
        "common_gen": 5264,
        "cos_e/v1.11": 5272,
        "glue/mrpc": 5124,
        "kilt_tasks/hotpotqa": 5480
      },
      "step": 330
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -68.44749450683594,
        "ag_news": 85.58062744140625,
        "amazon_polarity": 82.02860260009766,
        "cnn_dailymail/3.0.0": 70.53677368164062,
        "common_gen": -20.887142181396484,
        "cos_e/v1.11": 44.433773040771484,
        "glue/mrpc": 55.52118682861328,
        "kilt_tasks/hotpotqa": -1.6338410377502441
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1671,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1003449559211731,
        "ag_news": 0.1397734433412552,
        "amazon_polarity": 0.13870620727539062,
        "cnn_dailymail/3.0.0": 0.13530977070331573,
        "common_gen": 0.11113208532333374,
        "cos_e/v1.11": 0.12790565192699432,
        "glue/mrpc": 0.130998894572258,
        "kilt_tasks/hotpotqa": 0.11582894623279572
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5200,
        "ag_news": 5576,
        "amazon_polarity": 5544,
        "cnn_dailymail/3.0.0": 5488,
        "common_gen": 5392,
        "cos_e/v1.11": 5368,
        "glue/mrpc": 5308,
        "kilt_tasks/hotpotqa": 5640
      },
      "step": 340
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -63.51757049560547,
        "ag_news": 84.85311889648438,
        "amazon_polarity": 81.91990661621094,
        "cnn_dailymail/3.0.0": 69.31172180175781,
        "common_gen": -22.219694137573242,
        "cos_e/v1.11": 41.142581939697266,
        "glue/mrpc": 58.03499221801758,
        "kilt_tasks/hotpotqa": -4.7013258934021
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3359,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10180211812257767,
        "ag_news": 0.13945911824703217,
        "amazon_polarity": 0.1385917067527771,
        "cnn_dailymail/3.0.0": 0.1349252462387085,
        "common_gen": 0.11110197007656097,
        "cos_e/v1.11": 0.12708567082881927,
        "glue/mrpc": 0.13172951340675354,
        "kilt_tasks/hotpotqa": 0.11530456691980362
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5344,
        "ag_news": 5744,
        "amazon_polarity": 5712,
        "cnn_dailymail/3.0.0": 5656,
        "common_gen": 5544,
        "cos_e/v1.11": 5520,
        "glue/mrpc": 5412,
        "kilt_tasks/hotpotqa": 5864
      },
      "step": 350
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -67.60189056396484,
        "ag_news": 84.51878356933594,
        "amazon_polarity": 81.45504760742188,
        "cnn_dailymail/3.0.0": 73.41690826416016,
        "common_gen": -22.132652282714844,
        "cos_e/v1.11": 42.71342468261719,
        "glue/mrpc": 59.769290924072266,
        "kilt_tasks/hotpotqa": 0.4917807877063751
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1924,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10100637376308441,
        "ag_news": 0.13884896039962769,
        "amazon_polarity": 0.1379595547914505,
        "cnn_dailymail/3.0.0": 0.1356535106897354,
        "common_gen": 0.11106288433074951,
        "cos_e/v1.11": 0.1271996945142746,
        "glue/mrpc": 0.1318274736404419,
        "kilt_tasks/hotpotqa": 0.11644160747528076
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5512,
        "ag_news": 5960,
        "amazon_polarity": 5848,
        "cnn_dailymail/3.0.0": 5800,
        "common_gen": 5656,
        "cos_e/v1.11": 5688,
        "glue/mrpc": 5580,
        "kilt_tasks/hotpotqa": 6032
      },
      "step": 360
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -66.51922607421875,
        "ag_news": 84.32962799072266,
        "amazon_polarity": 81.40496063232422,
        "cnn_dailymail/3.0.0": 73.89266204833984,
        "common_gen": -22.49493408203125,
        "cos_e/v1.11": 43.2891960144043,
        "glue/mrpc": 59.0453987121582,
        "kilt_tasks/hotpotqa": -2.90610671043396
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2368,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10159476101398468,
        "ag_news": 0.13869959115982056,
        "amazon_polarity": 0.13786275684833527,
        "cnn_dailymail/3.0.0": 0.13573668897151947,
        "common_gen": 0.11123708635568619,
        "cos_e/v1.11": 0.12741416692733765,
        "glue/mrpc": 0.13163217902183533,
        "kilt_tasks/hotpotqa": 0.1158226802945137
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5624,
        "ag_news": 6096,
        "amazon_polarity": 6040,
        "cnn_dailymail/3.0.0": 5928,
        "common_gen": 5816,
        "cos_e/v1.11": 5888,
        "glue/mrpc": 5772,
        "kilt_tasks/hotpotqa": 6192
      },
      "step": 370
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -72.42193603515625,
        "ag_news": 84.28162384033203,
        "amazon_polarity": 80.93597412109375,
        "cnn_dailymail/3.0.0": 73.53638458251953,
        "common_gen": -21.33993911743164,
        "cos_e/v1.11": 42.48262405395508,
        "glue/mrpc": 57.8141975402832,
        "kilt_tasks/hotpotqa": -5.591890335083008
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1576,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1009012907743454,
        "ag_news": 0.13883639872074127,
        "amazon_polarity": 0.13789108395576477,
        "cnn_dailymail/3.0.0": 0.13582350313663483,
        "common_gen": 0.11194152384996414,
        "cos_e/v1.11": 0.12748414278030396,
        "glue/mrpc": 0.13153429329395294,
        "kilt_tasks/hotpotqa": 0.11558769643306732
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5792,
        "ag_news": 6320,
        "amazon_polarity": 6216,
        "cnn_dailymail/3.0.0": 6032,
        "common_gen": 5984,
        "cos_e/v1.11": 6024,
        "glue/mrpc": 5948,
        "kilt_tasks/hotpotqa": 6320
      },
      "step": 380
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.71107482910156,
        "ag_news": 84.23702239990234,
        "amazon_polarity": 80.90735626220703,
        "cnn_dailymail/3.0.0": 75.48677062988281,
        "common_gen": -22.666845321655273,
        "cos_e/v1.11": 39.59661865234375,
        "glue/mrpc": 58.01445007324219,
        "kilt_tasks/hotpotqa": -4.880745887756348
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2402,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10170996189117432,
        "ag_news": 0.13861364126205444,
        "amazon_polarity": 0.13768631219863892,
        "cnn_dailymail/3.0.0": 0.13619013130664825,
        "common_gen": 0.11178100109100342,
        "cos_e/v1.11": 0.12669163942337036,
        "glue/mrpc": 0.13147884607315063,
        "kilt_tasks/hotpotqa": 0.1158483549952507
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 5944,
        "ag_news": 6504,
        "amazon_polarity": 6384,
        "cnn_dailymail/3.0.0": 6208,
        "common_gen": 6168,
        "cos_e/v1.11": 6192,
        "glue/mrpc": 6060,
        "kilt_tasks/hotpotqa": 6456
      },
      "step": 390
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -71.77934265136719,
        "ag_news": 84.11104583740234,
        "amazon_polarity": 80.7755126953125,
        "cnn_dailymail/3.0.0": 75.68811798095703,
        "common_gen": -18.6102237701416,
        "cos_e/v1.11": 39.00062561035156,
        "glue/mrpc": 56.874916076660156,
        "kilt_tasks/hotpotqa": -8.975111961364746
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3971,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10165287554264069,
        "ag_news": 0.1385369747877121,
        "amazon_polarity": 0.13762007653713226,
        "cnn_dailymail/3.0.0": 0.13623344898223877,
        "common_gen": 0.1129516065120697,
        "cos_e/v1.11": 0.12664499878883362,
        "glue/mrpc": 0.1312277913093567,
        "kilt_tasks/hotpotqa": 0.11513222008943558
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6088,
        "ag_news": 6600,
        "amazon_polarity": 6568,
        "cnn_dailymail/3.0.0": 6400,
        "common_gen": 6384,
        "cos_e/v1.11": 6352,
        "glue/mrpc": 6164,
        "kilt_tasks/hotpotqa": 6640
      },
      "step": 400
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.75,
      "eval_runtime": 0.1983,
      "eval_samples_per_second": 80.682,
      "eval_steps_per_second": 5.043,
      "step": 400
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -72.35930633544922,
        "ag_news": 83.97802734375,
        "amazon_polarity": 80.57447052001953,
        "cnn_dailymail/3.0.0": 75.67485046386719,
        "common_gen": -18.629253387451172,
        "cos_e/v1.11": 35.37784957885742,
        "glue/mrpc": 57.09077072143555,
        "kilt_tasks/hotpotqa": -7.989673137664795
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2892,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10188286006450653,
        "ag_news": 0.1384524255990982,
        "amazon_polarity": 0.13752880692481995,
        "cnn_dailymail/3.0.0": 0.13621015846729279,
        "common_gen": 0.11318767070770264,
        "cos_e/v1.11": 0.12584030628204346,
        "glue/mrpc": 0.13132411241531372,
        "kilt_tasks/hotpotqa": 0.11557361483573914
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6280,
        "ag_news": 6800,
        "amazon_polarity": 6664,
        "cnn_dailymail/3.0.0": 6536,
        "common_gen": 6568,
        "cos_e/v1.11": 6544,
        "glue/mrpc": 6300,
        "kilt_tasks/hotpotqa": 6784
      },
      "step": 410
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.3604965209961,
        "ag_news": 82.97570037841797,
        "amazon_polarity": 80.46257019042969,
        "cnn_dailymail/3.0.0": 79.81411743164062,
        "common_gen": -22.46686363220215,
        "cos_e/v1.11": 35.11711502075195,
        "glue/mrpc": 55.31591033935547,
        "kilt_tasks/hotpotqa": -9.464325904846191
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2105,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10275906324386597,
        "ag_news": 0.13806447386741638,
        "amazon_polarity": 0.1373918652534485,
        "cnn_dailymail/3.0.0": 0.13721886277198792,
        "common_gen": 0.11252103000879288,
        "cos_e/v1.11": 0.12581117451190948,
        "glue/mrpc": 0.13084207475185394,
        "kilt_tasks/hotpotqa": 0.11539147794246674
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6424,
        "ag_news": 7040,
        "amazon_polarity": 6840,
        "cnn_dailymail/3.0.0": 6704,
        "common_gen": 6704,
        "cos_e/v1.11": 6704,
        "glue/mrpc": 6388,
        "kilt_tasks/hotpotqa": 6952
      },
      "step": 420
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.36767578125,
        "ag_news": 82.92254638671875,
        "amazon_polarity": 80.30883026123047,
        "cnn_dailymail/3.0.0": 82.71590423583984,
        "common_gen": -22.419111251831055,
        "cos_e/v1.11": 36.455543518066406,
        "glue/mrpc": 54.03854751586914,
        "kilt_tasks/hotpotqa": -12.207406044006348
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2602,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10298401117324829,
        "ag_news": 0.1378835141658783,
        "amazon_polarity": 0.13719305396080017,
        "cnn_dailymail/3.0.0": 0.1378287822008133,
        "common_gen": 0.11266151815652847,
        "cos_e/v1.11": 0.12611781060695648,
        "glue/mrpc": 0.13044513761997223,
        "kilt_tasks/hotpotqa": 0.11488624662160873
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6568,
        "ag_news": 7208,
        "amazon_polarity": 6960,
        "cnn_dailymail/3.0.0": 6840,
        "common_gen": 6888,
        "cos_e/v1.11": 6896,
        "glue/mrpc": 6580,
        "kilt_tasks/hotpotqa": 7096
      },
      "step": 430
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.5878677368164,
        "ag_news": 82.69695281982422,
        "amazon_polarity": 80.22003936767578,
        "cnn_dailymail/3.0.0": 82.18279266357422,
        "common_gen": -25.0911865234375,
        "cos_e/v1.11": 36.83235549926758,
        "glue/mrpc": 55.21608352661133,
        "kilt_tasks/hotpotqa": -11.94146728515625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3876,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10321258753538132,
        "ag_news": 0.13773389160633087,
        "amazon_polarity": 0.1370875984430313,
        "cnn_dailymail/3.0.0": 0.13759949803352356,
        "common_gen": 0.11227531731128693,
        "cos_e/v1.11": 0.1262524127960205,
        "glue/mrpc": 0.13073307275772095,
        "kilt_tasks/hotpotqa": 0.11510562896728516
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6752,
        "ag_news": 7376,
        "amazon_polarity": 7072,
        "cnn_dailymail/3.0.0": 7112,
        "common_gen": 7088,
        "cos_e/v1.11": 7032,
        "glue/mrpc": 6660,
        "kilt_tasks/hotpotqa": 7224
      },
      "step": 440
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -70.77659606933594,
        "ag_news": 82.53530883789062,
        "amazon_polarity": 79.8025894165039,
        "cnn_dailymail/3.0.0": 84.17945861816406,
        "common_gen": -23.13041114807129,
        "cos_e/v1.11": 37.085506439208984,
        "glue/mrpc": 55.796302795410156,
        "kilt_tasks/hotpotqa": -15.638029098510742
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1753,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10321108251810074,
        "ag_news": 0.13755787909030914,
        "amazon_polarity": 0.13685379922389984,
        "cnn_dailymail/3.0.0": 0.1379832625389099,
        "common_gen": 0.11283280700445175,
        "cos_e/v1.11": 0.12631085515022278,
        "glue/mrpc": 0.13082346320152283,
        "kilt_tasks/hotpotqa": 0.11442685127258301
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 6864,
        "ag_news": 7560,
        "amazon_polarity": 7248,
        "cnn_dailymail/3.0.0": 7272,
        "common_gen": 7232,
        "cos_e/v1.11": 7168,
        "glue/mrpc": 6868,
        "kilt_tasks/hotpotqa": 7384
      },
      "step": 450
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -72.43718719482422,
        "ag_news": 82.33212280273438,
        "amazon_polarity": 79.70137023925781,
        "cnn_dailymail/3.0.0": 86.91846466064453,
        "common_gen": -25.71070671081543,
        "cos_e/v1.11": 35.82319641113281,
        "glue/mrpc": 53.92188262939453,
        "kilt_tasks/hotpotqa": -17.087112426757812
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2389,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10324534773826599,
        "ag_news": 0.13754841685295105,
        "amazon_polarity": 0.1368778944015503,
        "cnn_dailymail/3.0.0": 0.13872535526752472,
        "common_gen": 0.11256992816925049,
        "cos_e/v1.11": 0.12617053091526031,
        "glue/mrpc": 0.13048012554645538,
        "kilt_tasks/hotpotqa": 0.11438232660293579
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7024,
        "ag_news": 7752,
        "amazon_polarity": 7352,
        "cnn_dailymail/3.0.0": 7360,
        "common_gen": 7360,
        "cos_e/v1.11": 7384,
        "glue/mrpc": 7052,
        "kilt_tasks/hotpotqa": 7592
      },
      "step": 460
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -75.55995178222656,
        "ag_news": 82.10897827148438,
        "amazon_polarity": 79.65889739990234,
        "cnn_dailymail/3.0.0": 87.53863525390625,
        "common_gen": -26.46663475036621,
        "cos_e/v1.11": 32.10603713989258,
        "glue/mrpc": 54.01775360107422,
        "kilt_tasks/hotpotqa": -16.952905654907227
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1766,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1030200943350792,
        "ag_news": 0.1375616490840912,
        "amazon_polarity": 0.13694362342357635,
        "cnn_dailymail/3.0.0": 0.13894139230251312,
        "common_gen": 0.1127091720700264,
        "cos_e/v1.11": 0.12549056112766266,
        "glue/mrpc": 0.1306420862674713,
        "kilt_tasks/hotpotqa": 0.11469150334596634
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7192,
        "ag_news": 7904,
        "amazon_polarity": 7560,
        "cnn_dailymail/3.0.0": 7472,
        "common_gen": 7536,
        "cos_e/v1.11": 7536,
        "glue/mrpc": 7236,
        "kilt_tasks/hotpotqa": 7720
      },
      "step": 470
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -74.96665954589844,
        "ag_news": 82.00065612792969,
        "amazon_polarity": 79.67676544189453,
        "cnn_dailymail/3.0.0": 89.61123657226562,
        "common_gen": -25.47058868408203,
        "cos_e/v1.11": 30.148738861083984,
        "glue/mrpc": 52.17359924316406,
        "kilt_tasks/hotpotqa": -17.28217124938965
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3538,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10335639119148254,
        "ag_news": 0.13742394745349884,
        "amazon_polarity": 0.13684436678886414,
        "cnn_dailymail/3.0.0": 0.1393396556377411,
        "common_gen": 0.11305515468120575,
        "cos_e/v1.11": 0.1250637024641037,
        "glue/mrpc": 0.13016994297504425,
        "kilt_tasks/hotpotqa": 0.11474673449993134
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7320,
        "ag_news": 8064,
        "amazon_polarity": 7672,
        "cnn_dailymail/3.0.0": 7680,
        "common_gen": 7704,
        "cos_e/v1.11": 7672,
        "glue/mrpc": 7400,
        "kilt_tasks/hotpotqa": 7920
      },
      "step": 480
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -76.80265808105469,
        "ag_news": 81.95755004882812,
        "amazon_polarity": 79.69393157958984,
        "cnn_dailymail/3.0.0": 91.06853485107422,
        "common_gen": -24.287572860717773,
        "cos_e/v1.11": 28.296663284301758,
        "glue/mrpc": 52.05269241333008,
        "kilt_tasks/hotpotqa": -22.18389892578125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1926,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10334321111440659,
        "ag_news": 0.1374521702528,
        "amazon_polarity": 0.13689318299293518,
        "cnn_dailymail/3.0.0": 0.13972564041614532,
        "common_gen": 0.1135518029332161,
        "cos_e/v1.11": 0.12480246275663376,
        "glue/mrpc": 0.13025011122226715,
        "kilt_tasks/hotpotqa": 0.11398147791624069
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7440,
        "ag_news": 8264,
        "amazon_polarity": 7824,
        "cnn_dailymail/3.0.0": 7832,
        "common_gen": 7904,
        "cos_e/v1.11": 7808,
        "glue/mrpc": 7576,
        "kilt_tasks/hotpotqa": 8064
      },
      "step": 490
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -72.90514373779297,
        "ag_news": 81.7740249633789,
        "amazon_polarity": 79.68682861328125,
        "cnn_dailymail/3.0.0": 89.01853942871094,
        "common_gen": -31.15364646911621,
        "cos_e/v1.11": 26.367599487304688,
        "glue/mrpc": 53.30278015136719,
        "kilt_tasks/hotpotqa": -25.821176528930664
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2354,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10447996109724045,
        "ag_news": 0.13757221400737762,
        "amazon_polarity": 0.13706135749816895,
        "cnn_dailymail/3.0.0": 0.13936035335063934,
        "common_gen": 0.11252203583717346,
        "cos_e/v1.11": 0.12464337795972824,
        "glue/mrpc": 0.1307670921087265,
        "kilt_tasks/hotpotqa": 0.11359351873397827
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7600,
        "ag_news": 8400,
        "amazon_polarity": 7984,
        "cnn_dailymail/3.0.0": 8056,
        "common_gen": 8048,
        "cos_e/v1.11": 7952,
        "glue/mrpc": 7736,
        "kilt_tasks/hotpotqa": 8216
      },
      "step": 500
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1938,
      "eval_samples_per_second": 82.564,
      "eval_steps_per_second": 5.16,
      "step": 500
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.4652099609375,
        "ag_news": 81.66777801513672,
        "amazon_polarity": 79.6121826171875,
        "cnn_dailymail/3.0.0": 86.35511779785156,
        "common_gen": -29.60708999633789,
        "cos_e/v1.11": 29.65958023071289,
        "glue/mrpc": 55.47671890258789,
        "kilt_tasks/hotpotqa": -25.03574562072754
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0965,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10513143241405487,
        "ag_news": 0.13720083236694336,
        "amazon_polarity": 0.1367039829492569,
        "cnn_dailymail/3.0.0": 0.13834068179130554,
        "common_gen": 0.11276643723249435,
        "cos_e/v1.11": 0.12517456710338593,
        "glue/mrpc": 0.1310046911239624,
        "kilt_tasks/hotpotqa": 0.11367739737033844
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7792,
        "ag_news": 8576,
        "amazon_polarity": 8168,
        "cnn_dailymail/3.0.0": 8216,
        "common_gen": 8176,
        "cos_e/v1.11": 8064,
        "glue/mrpc": 7944,
        "kilt_tasks/hotpotqa": 8336
      },
      "step": 510
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -65.60778045654297,
        "ag_news": 81.5481185913086,
        "amazon_polarity": 79.60059356689453,
        "cnn_dailymail/3.0.0": 82.0690689086914,
        "common_gen": -28.60964012145996,
        "cos_e/v1.11": 27.902406692504883,
        "glue/mrpc": 53.64735794067383,
        "kilt_tasks/hotpotqa": -27.769020080566406
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2096,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10617844760417938,
        "ag_news": 0.1372622847557068,
        "amazon_polarity": 0.1367958039045334,
        "cnn_dailymail/3.0.0": 0.13738735020160675,
        "common_gen": 0.11324853450059891,
        "cos_e/v1.11": 0.12498263269662857,
        "glue/mrpc": 0.1307302564382553,
        "kilt_tasks/hotpotqa": 0.11341463029384613
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 7952,
        "ag_news": 8712,
        "amazon_polarity": 8328,
        "cnn_dailymail/3.0.0": 8288,
        "common_gen": 8400,
        "cos_e/v1.11": 8216,
        "glue/mrpc": 8176,
        "kilt_tasks/hotpotqa": 8480
      },
      "step": 520
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -67.16310119628906,
        "ag_news": 81.13194274902344,
        "amazon_polarity": 79.41687774658203,
        "cnn_dailymail/3.0.0": 85.16328430175781,
        "common_gen": -26.49701499938965,
        "cos_e/v1.11": 31.535619735717773,
        "glue/mrpc": 53.92274856567383,
        "kilt_tasks/hotpotqa": -33.72255325317383
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2562,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10601654648780823,
        "ag_news": 0.13699205219745636,
        "amazon_polarity": 0.13658583164215088,
        "cnn_dailymail/3.0.0": 0.1379517763853073,
        "common_gen": 0.11372553557157516,
        "cos_e/v1.11": 0.12572400271892548,
        "glue/mrpc": 0.1306890845298767,
        "kilt_tasks/hotpotqa": 0.11231531947851181
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8096,
        "ag_news": 8904,
        "amazon_polarity": 8472,
        "cnn_dailymail/3.0.0": 8440,
        "common_gen": 8576,
        "cos_e/v1.11": 8352,
        "glue/mrpc": 8328,
        "kilt_tasks/hotpotqa": 8664
      },
      "step": 530
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -65.87936401367188,
        "ag_news": 80.8464126586914,
        "amazon_polarity": 79.28128051757812,
        "cnn_dailymail/3.0.0": 83.09441375732422,
        "common_gen": -30.717214584350586,
        "cos_e/v1.11": 28.164894104003906,
        "glue/mrpc": 47.92905807495117,
        "kilt_tasks/hotpotqa": -28.16802215576172
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1815,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10664448887109756,
        "ag_news": 0.13711164891719818,
        "amazon_polarity": 0.13674396276474,
        "cnn_dailymail/3.0.0": 0.1376415193080902,
        "common_gen": 0.11325439810752869,
        "cos_e/v1.11": 0.1252690702676773,
        "glue/mrpc": 0.129585400223732,
        "kilt_tasks/hotpotqa": 0.11374948918819427
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8200,
        "ag_news": 9040,
        "amazon_polarity": 8712,
        "cnn_dailymail/3.0.0": 8632,
        "common_gen": 8736,
        "cos_e/v1.11": 8544,
        "glue/mrpc": 8472,
        "kilt_tasks/hotpotqa": 8776
      },
      "step": 540
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -66.14942932128906,
        "ag_news": 80.5476303100586,
        "amazon_polarity": 79.24006652832031,
        "cnn_dailymail/3.0.0": 81.66276550292969,
        "common_gen": -29.55594825744629,
        "cos_e/v1.11": 30.902938842773438,
        "glue/mrpc": 48.844966888427734,
        "kilt_tasks/hotpotqa": -30.63775634765625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2317,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1067451611161232,
        "ag_news": 0.13692311942577362,
        "amazon_polarity": 0.13661909103393555,
        "cnn_dailymail/3.0.0": 0.13718298077583313,
        "common_gen": 0.11357522010803223,
        "cos_e/v1.11": 0.12584653496742249,
        "glue/mrpc": 0.129740908741951,
        "kilt_tasks/hotpotqa": 0.11336707323789597
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8464,
        "ag_news": 9216,
        "amazon_polarity": 8832,
        "cnn_dailymail/3.0.0": 8824,
        "common_gen": 8920,
        "cos_e/v1.11": 8656,
        "glue/mrpc": 8568,
        "kilt_tasks/hotpotqa": 8912
      },
      "step": 550
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -64.26384735107422,
        "ag_news": 80.16883087158203,
        "amazon_polarity": 79.12069702148438,
        "cnn_dailymail/3.0.0": 85.32688903808594,
        "common_gen": -34.26905822753906,
        "cos_e/v1.11": 28.661130905151367,
        "glue/mrpc": 47.96702194213867,
        "kilt_tasks/hotpotqa": -30.971721649169922
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.3141,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10729674994945526,
        "ag_news": 0.13680599629878998,
        "amazon_polarity": 0.13656459748744965,
        "cnn_dailymail/3.0.0": 0.1380002647638321,
        "common_gen": 0.11284156143665314,
        "cos_e/v1.11": 0.12543924152851105,
        "glue/mrpc": 0.12958307564258575,
        "kilt_tasks/hotpotqa": 0.11346859484910965
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8568,
        "ag_news": 9368,
        "amazon_polarity": 8960,
        "cnn_dailymail/3.0.0": 8992,
        "common_gen": 9096,
        "cos_e/v1.11": 8880,
        "glue/mrpc": 8736,
        "kilt_tasks/hotpotqa": 9072
      },
      "step": 560
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -72.08300018310547,
        "ag_news": 79.77161407470703,
        "amazon_polarity": 78.9328842163086,
        "cnn_dailymail/3.0.0": 87.280029296875,
        "common_gen": -34.20131301879883,
        "cos_e/v1.11": 29.723779678344727,
        "glue/mrpc": 49.42906188964844,
        "kilt_tasks/hotpotqa": -33.201927185058594
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.13,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1061539351940155,
        "ag_news": 0.13674163818359375,
        "amazon_polarity": 0.1365502029657364,
        "cnn_dailymail/3.0.0": 0.138467475771904,
        "common_gen": 0.11306546628475189,
        "cos_e/v1.11": 0.12578117847442627,
        "glue/mrpc": 0.12998627126216888,
        "kilt_tasks/hotpotqa": 0.1132538765668869
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8752,
        "ag_news": 9584,
        "amazon_polarity": 9096,
        "cnn_dailymail/3.0.0": 9184,
        "common_gen": 9248,
        "cos_e/v1.11": 9032,
        "glue/mrpc": 8864,
        "kilt_tasks/hotpotqa": 9192
      },
      "step": 570
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -68.091064453125,
        "ag_news": 79.70864868164062,
        "amazon_polarity": 78.75070190429688,
        "cnn_dailymail/3.0.0": 90.56130981445312,
        "common_gen": -36.30705642700195,
        "cos_e/v1.11": 26.257122039794922,
        "glue/mrpc": 46.29130554199219,
        "kilt_tasks/hotpotqa": -35.13137435913086
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2053,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10708867758512497,
        "ag_news": 0.1367293894290924,
        "amazon_polarity": 0.1365126669406891,
        "cnn_dailymail/3.0.0": 0.13920913636684418,
        "common_gen": 0.11285806447267532,
        "cos_e/v1.11": 0.12515343725681305,
        "glue/mrpc": 0.12937115132808685,
        "kilt_tasks/hotpotqa": 0.11307742446660995
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 8912,
        "ag_news": 9704,
        "amazon_polarity": 9288,
        "cnn_dailymail/3.0.0": 9368,
        "common_gen": 9416,
        "cos_e/v1.11": 9208,
        "glue/mrpc": 9040,
        "kilt_tasks/hotpotqa": 9296
      },
      "step": 580
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -70.76851654052734,
        "ag_news": 79.68003845214844,
        "amazon_polarity": 78.62870025634766,
        "cnn_dailymail/3.0.0": 93.60576629638672,
        "common_gen": -41.05536651611328,
        "cos_e/v1.11": 29.45806121826172,
        "glue/mrpc": 46.78396987915039,
        "kilt_tasks/hotpotqa": -38.823150634765625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.381,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10682715475559235,
        "ag_news": 0.13670682907104492,
        "amazon_polarity": 0.13647103309631348,
        "cnn_dailymail/3.0.0": 0.13986918330192566,
        "common_gen": 0.11215155571699142,
        "cos_e/v1.11": 0.12589117884635925,
        "glue/mrpc": 0.12952086329460144,
        "kilt_tasks/hotpotqa": 0.11256227642297745
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9088,
        "ag_news": 9856,
        "amazon_polarity": 9376,
        "cnn_dailymail/3.0.0": 9560,
        "common_gen": 9560,
        "cos_e/v1.11": 9400,
        "glue/mrpc": 9176,
        "kilt_tasks/hotpotqa": 9496
      },
      "step": 590
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.17840576171875,
        "ag_news": 79.5330581665039,
        "amazon_polarity": 78.55232238769531,
        "cnn_dailymail/3.0.0": 94.71443939208984,
        "common_gen": -41.94540023803711,
        "cos_e/v1.11": 29.46219825744629,
        "glue/mrpc": 47.089263916015625,
        "kilt_tasks/hotpotqa": -37.333866119384766
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1639,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10717650502920151,
        "ag_news": 0.13648852705955505,
        "amazon_polarity": 0.13627073168754578,
        "cnn_dailymail/3.0.0": 0.1399051547050476,
        "common_gen": 0.11202121526002884,
        "cos_e/v1.11": 0.12580715119838715,
        "glue/mrpc": 0.12946733832359314,
        "kilt_tasks/hotpotqa": 0.11286336183547974
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9256,
        "ag_news": 10024,
        "amazon_polarity": 9528,
        "cnn_dailymail/3.0.0": 9712,
        "common_gen": 9744,
        "cos_e/v1.11": 9552,
        "glue/mrpc": 9328,
        "kilt_tasks/hotpotqa": 9648
      },
      "step": 600
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.9375,
      "eval_runtime": 0.1878,
      "eval_samples_per_second": 85.197,
      "eval_steps_per_second": 5.325,
      "step": 600
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -67.16686248779297,
        "ag_news": 79.40369415283203,
        "amazon_polarity": 78.3239974975586,
        "cnn_dailymail/3.0.0": 95.02714538574219,
        "common_gen": -40.29984664916992,
        "cos_e/v1.11": 29.318864822387695,
        "glue/mrpc": 48.11622619628906,
        "kilt_tasks/hotpotqa": -36.84878921508789
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2697,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10756494849920273,
        "ag_news": 0.1362430453300476,
        "amazon_polarity": 0.1360056847333908,
        "cnn_dailymail/3.0.0": 0.13972501456737518,
        "common_gen": 0.11232081800699234,
        "cos_e/v1.11": 0.1256617158651352,
        "glue/mrpc": 0.12953180074691772,
        "kilt_tasks/hotpotqa": 0.1129469946026802
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9400,
        "ag_news": 10176,
        "amazon_polarity": 9664,
        "cnn_dailymail/3.0.0": 9936,
        "common_gen": 9928,
        "cos_e/v1.11": 9672,
        "glue/mrpc": 9504,
        "kilt_tasks/hotpotqa": 9792
      },
      "step": 610
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -65.91802978515625,
        "ag_news": 79.21833038330078,
        "amazon_polarity": 78.12873077392578,
        "cnn_dailymail/3.0.0": 99.91853332519531,
        "common_gen": -34.636390686035156,
        "cos_e/v1.11": 23.96347999572754,
        "glue/mrpc": 44.69131851196289,
        "kilt_tasks/hotpotqa": -35.78555679321289
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1451,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10784164816141129,
        "ag_news": 0.1360229104757309,
        "amazon_polarity": 0.13578566908836365,
        "cnn_dailymail/3.0.0": 0.14061026275157928,
        "common_gen": 0.11336793750524521,
        "cos_e/v1.11": 0.12450580298900604,
        "glue/mrpc": 0.12870578467845917,
        "kilt_tasks/hotpotqa": 0.11315993219614029
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9568,
        "ag_news": 10352,
        "amazon_polarity": 9816,
        "cnn_dailymail/3.0.0": 10064,
        "common_gen": 10056,
        "cos_e/v1.11": 9829,
        "glue/mrpc": 9648,
        "kilt_tasks/hotpotqa": 10016
      },
      "step": 620
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.03117370605469,
        "ag_news": 78.94896697998047,
        "amazon_polarity": 78.09346008300781,
        "cnn_dailymail/3.0.0": 99.53775787353516,
        "common_gen": -34.99148178100586,
        "cos_e/v1.11": 26.529850006103516,
        "glue/mrpc": 42.28917694091797,
        "kilt_tasks/hotpotqa": -34.26593780517578
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1124,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10748828947544098,
        "ag_news": 0.13594047725200653,
        "amazon_polarity": 0.1357557624578476,
        "cnn_dailymail/3.0.0": 0.14046332240104675,
        "common_gen": 0.11344673484563828,
        "cos_e/v1.11": 0.1250791996717453,
        "glue/mrpc": 0.12824882566928864,
        "kilt_tasks/hotpotqa": 0.11357732862234116
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9688,
        "ag_news": 10536,
        "amazon_polarity": 9984,
        "cnn_dailymail/3.0.0": 10232,
        "common_gen": 10184,
        "cos_e/v1.11": 10013,
        "glue/mrpc": 9808,
        "kilt_tasks/hotpotqa": 10184
      },
      "step": 630
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -62.0859375,
        "ag_news": 78.66756439208984,
        "amazon_polarity": 77.96670532226562,
        "cnn_dailymail/3.0.0": 98.0772705078125,
        "common_gen": -35.88761901855469,
        "cos_e/v1.11": 29.271020889282227,
        "glue/mrpc": 37.6218376159668,
        "kilt_tasks/hotpotqa": -36.72301483154297
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0743,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.108823761343956,
        "ag_news": 0.13582681119441986,
        "amazon_polarity": 0.1356767863035202,
        "cnn_dailymail/3.0.0": 0.14004938304424286,
        "common_gen": 0.11340151727199554,
        "cos_e/v1.11": 0.1256524920463562,
        "glue/mrpc": 0.1273166984319687,
        "kilt_tasks/hotpotqa": 0.11325257271528244
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 9904,
        "ag_news": 10712,
        "amazon_polarity": 10120,
        "cnn_dailymail/3.0.0": 10376,
        "common_gen": 10288,
        "cos_e/v1.11": 10197,
        "glue/mrpc": 9952,
        "kilt_tasks/hotpotqa": 10360
      },
      "step": 640
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.38600540161133,
        "ag_news": 78.55064392089844,
        "amazon_polarity": 77.9295883178711,
        "cnn_dailymail/3.0.0": 98.07588195800781,
        "common_gen": -36.44051742553711,
        "cos_e/v1.11": 30.099084854125977,
        "glue/mrpc": 35.30042266845703,
        "kilt_tasks/hotpotqa": -41.053428649902344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2047,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10933031141757965,
        "ag_news": 0.13584277033805847,
        "amazon_polarity": 0.13571080565452576,
        "cnn_dailymail/3.0.0": 0.14005832374095917,
        "common_gen": 0.11349393427371979,
        "cos_e/v1.11": 0.12592799961566925,
        "glue/mrpc": 0.1269562989473343,
        "kilt_tasks/hotpotqa": 0.11267951875925064
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10032,
        "ag_news": 10848,
        "amazon_polarity": 10264,
        "cnn_dailymail/3.0.0": 10520,
        "common_gen": 10456,
        "cos_e/v1.11": 10429,
        "glue/mrpc": 10104,
        "kilt_tasks/hotpotqa": 10536
      },
      "step": 650
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.543399810791016,
        "ag_news": 78.54170989990234,
        "amazon_polarity": 77.87091827392578,
        "cnn_dailymail/3.0.0": 98.40487670898438,
        "common_gen": -36.41776657104492,
        "cos_e/v1.11": 24.24617576599121,
        "glue/mrpc": 33.272335052490234,
        "kilt_tasks/hotpotqa": -40.22688293457031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1269,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10956563800573349,
        "ag_news": 0.13594470918178558,
        "amazon_polarity": 0.13580314815044403,
        "cnn_dailymail/3.0.0": 0.1402047574520111,
        "common_gen": 0.11373813450336456,
        "cos_e/v1.11": 0.1249561458826065,
        "glue/mrpc": 0.12671855092048645,
        "kilt_tasks/hotpotqa": 0.11306878924369812
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10160,
        "ag_news": 11032,
        "amazon_polarity": 10424,
        "cnn_dailymail/3.0.0": 10712,
        "common_gen": 10640,
        "cos_e/v1.11": 10549,
        "glue/mrpc": 10256,
        "kilt_tasks/hotpotqa": 10696
      },
      "step": 660
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -59.67261505126953,
        "ag_news": 78.460693359375,
        "amazon_polarity": 77.88993072509766,
        "cnn_dailymail/3.0.0": 101.60314178466797,
        "common_gen": -37.302330017089844,
        "cos_e/v1.11": 23.365604400634766,
        "glue/mrpc": 35.72353744506836,
        "kilt_tasks/hotpotqa": -40.83234786987305
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.118,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10972678661346436,
        "ag_news": 0.13572798669338226,
        "amazon_polarity": 0.13560861349105835,
        "cnn_dailymail/3.0.0": 0.14065861701965332,
        "common_gen": 0.11356693506240845,
        "cos_e/v1.11": 0.12468156218528748,
        "glue/mrpc": 0.1270773857831955,
        "kilt_tasks/hotpotqa": 0.11295203119516373
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10288,
        "ag_news": 11176,
        "amazon_polarity": 10592,
        "cnn_dailymail/3.0.0": 10888,
        "common_gen": 10792,
        "cos_e/v1.11": 10733,
        "glue/mrpc": 10472,
        "kilt_tasks/hotpotqa": 10808
      },
      "step": 670
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -55.64894104003906,
        "ag_news": 78.35301971435547,
        "amazon_polarity": 77.80572509765625,
        "cnn_dailymail/3.0.0": 100.02287292480469,
        "common_gen": -35.919429779052734,
        "cos_e/v1.11": 20.253177642822266,
        "glue/mrpc": 37.77604675292969,
        "kilt_tasks/hotpotqa": -43.80731964111328
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9811,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11052943021059036,
        "ag_news": 0.1356506198644638,
        "amazon_polarity": 0.1355370432138443,
        "cnn_dailymail/3.0.0": 0.14022521674633026,
        "common_gen": 0.11390910297632217,
        "cos_e/v1.11": 0.12411649525165558,
        "glue/mrpc": 0.12748658657073975,
        "kilt_tasks/hotpotqa": 0.11254550516605377
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10416,
        "ag_news": 11336,
        "amazon_polarity": 10784,
        "cnn_dailymail/3.0.0": 11024,
        "common_gen": 11008,
        "cos_e/v1.11": 10861,
        "glue/mrpc": 10688,
        "kilt_tasks/hotpotqa": 10912
      },
      "step": 680
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -55.133033752441406,
        "ag_news": 78.24478149414062,
        "amazon_polarity": 77.43917083740234,
        "cnn_dailymail/3.0.0": 99.79991912841797,
        "common_gen": -33.88574981689453,
        "cos_e/v1.11": 18.9498291015625,
        "glue/mrpc": 32.168426513671875,
        "kilt_tasks/hotpotqa": -44.09065246582031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1077,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11083649843931198,
        "ag_news": 0.13569897413253784,
        "amazon_polarity": 0.13553299009799957,
        "cnn_dailymail/3.0.0": 0.14021722972393036,
        "common_gen": 0.11446399986743927,
        "cos_e/v1.11": 0.12401504814624786,
        "glue/mrpc": 0.1265283226966858,
        "kilt_tasks/hotpotqa": 0.11270695179700851
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10536,
        "ag_news": 11496,
        "amazon_polarity": 10944,
        "cnn_dailymail/3.0.0": 11176,
        "common_gen": 11152,
        "cos_e/v1.11": 11053,
        "glue/mrpc": 10848,
        "kilt_tasks/hotpotqa": 11104
      },
      "step": 690
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -55.4362907409668,
        "ag_news": 78.20556640625,
        "amazon_polarity": 77.39543914794922,
        "cnn_dailymail/3.0.0": 99.94828033447266,
        "common_gen": -33.701663970947266,
        "cos_e/v1.11": 22.476457595825195,
        "glue/mrpc": 33.131103515625,
        "kilt_tasks/hotpotqa": -48.1489143371582
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.06,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11086638271808624,
        "ag_news": 0.13559459149837494,
        "amazon_polarity": 0.1354289948940277,
        "cnn_dailymail/3.0.0": 0.140116348862648,
        "common_gen": 0.11455275118350983,
        "cos_e/v1.11": 0.12466706335544586,
        "glue/mrpc": 0.12668506801128387,
        "kilt_tasks/hotpotqa": 0.11208879947662354
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10704,
        "ag_news": 11696,
        "amazon_polarity": 11080,
        "cnn_dailymail/3.0.0": 11320,
        "common_gen": 11368,
        "cos_e/v1.11": 11197,
        "glue/mrpc": 11028,
        "kilt_tasks/hotpotqa": 11192
      },
      "step": 700
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.189,
      "eval_samples_per_second": 84.643,
      "eval_steps_per_second": 5.29,
      "step": 700
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -53.16312789916992,
        "ag_news": 78.0611572265625,
        "amazon_polarity": 77.2863540649414,
        "cnn_dailymail/3.0.0": 102.20930480957031,
        "common_gen": -40.003448486328125,
        "cos_e/v1.11": 21.54824447631836,
        "glue/mrpc": 33.987483978271484,
        "kilt_tasks/hotpotqa": -50.07785415649414
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0367,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11140736192464828,
        "ag_news": 0.13557395339012146,
        "amazon_polarity": 0.1354166865348816,
        "cnn_dailymail/3.0.0": 0.1405685395002365,
        "common_gen": 0.11361996829509735,
        "cos_e/v1.11": 0.12457523494958878,
        "glue/mrpc": 0.1269160360097885,
        "kilt_tasks/hotpotqa": 0.11192215979099274
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 10888,
        "ag_news": 11896,
        "amazon_polarity": 11184,
        "cnn_dailymail/3.0.0": 11504,
        "common_gen": 11520,
        "cos_e/v1.11": 11333,
        "glue/mrpc": 11228,
        "kilt_tasks/hotpotqa": 11312
      },
      "step": 710
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -56.05967712402344,
        "ag_news": 78.02452087402344,
        "amazon_polarity": 77.24205780029297,
        "cnn_dailymail/3.0.0": 104.03067779541016,
        "common_gen": -41.77202224731445,
        "cos_e/v1.11": 24.86832618713379,
        "glue/mrpc": 31.838613510131836,
        "kilt_tasks/hotpotqa": -52.933074951171875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1068,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11109529435634613,
        "ag_news": 0.13558556139469147,
        "amazon_polarity": 0.1354278326034546,
        "cnn_dailymail/3.0.0": 0.14093457162380219,
        "common_gen": 0.11347608268260956,
        "cos_e/v1.11": 0.12528209388256073,
        "glue/mrpc": 0.1265866905450821,
        "kilt_tasks/hotpotqa": 0.11161192506551743
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11032,
        "ag_news": 12072,
        "amazon_polarity": 11360,
        "cnn_dailymail/3.0.0": 11656,
        "common_gen": 11656,
        "cos_e/v1.11": 11485,
        "glue/mrpc": 11348,
        "kilt_tasks/hotpotqa": 11536
      },
      "step": 720
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.48203659057617,
        "ag_news": 77.9979019165039,
        "amazon_polarity": 77.13196563720703,
        "cnn_dailymail/3.0.0": 105.22176361083984,
        "common_gen": -43.90505599975586,
        "cos_e/v1.11": 20.665185928344727,
        "glue/mrpc": 32.724632263183594,
        "kilt_tasks/hotpotqa": -56.41209411621094
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1317,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11069042235612869,
        "ag_news": 0.13578587770462036,
        "amazon_polarity": 0.13561227917671204,
        "cnn_dailymail/3.0.0": 0.1413598507642746,
        "common_gen": 0.1134282574057579,
        "cos_e/v1.11": 0.12476307898759842,
        "glue/mrpc": 0.12700387835502625,
        "kilt_tasks/hotpotqa": 0.11135634034872055
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11224,
        "ag_news": 12240,
        "amazon_polarity": 11512,
        "cnn_dailymail/3.0.0": 11808,
        "common_gen": 11824,
        "cos_e/v1.11": 11669,
        "glue/mrpc": 11444,
        "kilt_tasks/hotpotqa": 11704
      },
      "step": 730
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.30363082885742,
        "ag_news": 77.9522933959961,
        "amazon_polarity": 77.1130599975586,
        "cnn_dailymail/3.0.0": 105.77708435058594,
        "common_gen": -43.71704864501953,
        "cos_e/v1.11": 22.417842864990234,
        "glue/mrpc": 30.350536346435547,
        "kilt_tasks/hotpotqa": -55.193485260009766
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0787,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.110786072909832,
        "ag_news": 0.13567231595516205,
        "amazon_polarity": 0.1355053335428238,
        "cnn_dailymail/3.0.0": 0.14132799208164215,
        "common_gen": 0.11350929737091064,
        "cos_e/v1.11": 0.12505900859832764,
        "glue/mrpc": 0.126522034406662,
        "kilt_tasks/hotpotqa": 0.11161793023347855
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11376,
        "ag_news": 12400,
        "amazon_polarity": 11680,
        "cnn_dailymail/3.0.0": 11984,
        "common_gen": 11984,
        "cos_e/v1.11": 11805,
        "glue/mrpc": 11628,
        "kilt_tasks/hotpotqa": 11848
      },
      "step": 740
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -59.82500076293945,
        "ag_news": 77.83634185791016,
        "amazon_polarity": 77.06853485107422,
        "cnn_dailymail/3.0.0": 106.30935668945312,
        "common_gen": -45.237823486328125,
        "cos_e/v1.11": 19.683425903320312,
        "glue/mrpc": 29.471141815185547,
        "kilt_tasks/hotpotqa": -53.29123306274414
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0875,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11100417375564575,
        "ag_news": 0.13563984632492065,
        "amazon_polarity": 0.1354881227016449,
        "cnn_dailymail/3.0.0": 0.14138945937156677,
        "common_gen": 0.11338430643081665,
        "cos_e/v1.11": 0.12462049722671509,
        "glue/mrpc": 0.12640969455242157,
        "kilt_tasks/hotpotqa": 0.112063929438591
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11520,
        "ag_news": 12608,
        "amazon_polarity": 11808,
        "cnn_dailymail/3.0.0": 12176,
        "common_gen": 12104,
        "cos_e/v1.11": 11965,
        "glue/mrpc": 11764,
        "kilt_tasks/hotpotqa": 12040
      },
      "step": 750
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -60.30992126464844,
        "ag_news": 77.75628662109375,
        "amazon_polarity": 77.25405883789062,
        "cnn_dailymail/3.0.0": 107.47570037841797,
        "common_gen": -52.90412139892578,
        "cos_e/v1.11": 14.092180252075195,
        "glue/mrpc": 28.58827018737793,
        "kilt_tasks/hotpotqa": -56.42194747924805
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0826,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11131994426250458,
        "ag_news": 0.1359279751777649,
        "amazon_polarity": 0.1358291208744049,
        "cnn_dailymail/3.0.0": 0.1419074386358261,
        "common_gen": 0.11251746863126755,
        "cos_e/v1.11": 0.12396181374788284,
        "glue/mrpc": 0.12658923864364624,
        "kilt_tasks/hotpotqa": 0.11194701492786407
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11688,
        "ag_news": 12768,
        "amazon_polarity": 11984,
        "cnn_dailymail/3.0.0": 12360,
        "common_gen": 12264,
        "cos_e/v1.11": 12165,
        "glue/mrpc": 11892,
        "kilt_tasks/hotpotqa": 12144
      },
      "step": 760
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -64.2728042602539,
        "ag_news": 77.617919921875,
        "amazon_polarity": 77.27161407470703,
        "cnn_dailymail/3.0.0": 109.13368225097656,
        "common_gen": -56.555179595947266,
        "cos_e/v1.11": 10.319880485534668,
        "glue/mrpc": 29.425472259521484,
        "kilt_tasks/hotpotqa": -53.398651123046875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2027,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1108778864145279,
        "ag_news": 0.13595841825008392,
        "amazon_polarity": 0.1358906775712967,
        "cnn_dailymail/3.0.0": 0.1422671675682068,
        "common_gen": 0.11211305111646652,
        "cos_e/v1.11": 0.12341700494289398,
        "glue/mrpc": 0.1268535852432251,
        "kilt_tasks/hotpotqa": 0.11262224614620209
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 11864,
        "ag_news": 12904,
        "amazon_polarity": 12128,
        "cnn_dailymail/3.0.0": 12544,
        "common_gen": 12376,
        "cos_e/v1.11": 12365,
        "glue/mrpc": 12028,
        "kilt_tasks/hotpotqa": 12336
      },
      "step": 770
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -66.97647857666016,
        "ag_news": 77.42787170410156,
        "amazon_polarity": 77.27978515625,
        "cnn_dailymail/3.0.0": 112.70503234863281,
        "common_gen": -54.22837448120117,
        "cos_e/v1.11": 9.687784194946289,
        "glue/mrpc": 28.721359252929688,
        "kilt_tasks/hotpotqa": -57.52076721191406
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0774,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11056730151176453,
        "ag_news": 0.13588787615299225,
        "amazon_polarity": 0.13585910201072693,
        "cnn_dailymail/3.0.0": 0.14291903376579285,
        "common_gen": 0.11259612441062927,
        "cos_e/v1.11": 0.12335123866796494,
        "glue/mrpc": 0.12675072252750397,
        "kilt_tasks/hotpotqa": 0.11206856369972229
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12072,
        "ag_news": 13088,
        "amazon_polarity": 12264,
        "cnn_dailymail/3.0.0": 12720,
        "common_gen": 12528,
        "cos_e/v1.11": 12517,
        "glue/mrpc": 12172,
        "kilt_tasks/hotpotqa": 12464
      },
      "step": 780
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -67.86011505126953,
        "ag_news": 77.04820251464844,
        "amazon_polarity": 77.22843933105469,
        "cnn_dailymail/3.0.0": 112.53623962402344,
        "common_gen": -55.00294876098633,
        "cos_e/v1.11": 11.950204849243164,
        "glue/mrpc": 29.63515281677246,
        "kilt_tasks/hotpotqa": -58.76554489135742
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0834,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1105189099907875,
        "ag_news": 0.13574914634227753,
        "amazon_polarity": 0.13578391075134277,
        "cnn_dailymail/3.0.0": 0.14277046918869019,
        "common_gen": 0.11255137622356415,
        "cos_e/v1.11": 0.12376369535923004,
        "glue/mrpc": 0.12690970301628113,
        "kilt_tasks/hotpotqa": 0.11195269972085953
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12256,
        "ag_news": 13208,
        "amazon_polarity": 12496,
        "cnn_dailymail/3.0.0": 12888,
        "common_gen": 12696,
        "cos_e/v1.11": 12677,
        "glue/mrpc": 12276,
        "kilt_tasks/hotpotqa": 12608
      },
      "step": 790
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -63.18974685668945,
        "ag_news": 77.01667785644531,
        "amazon_polarity": 77.21006774902344,
        "cnn_dailymail/3.0.0": 113.29544067382812,
        "common_gen": -57.759220123291016,
        "cos_e/v1.11": 11.084549903869629,
        "glue/mrpc": 28.423477172851562,
        "kilt_tasks/hotpotqa": -58.372867584228516
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.12,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11132179200649261,
        "ag_news": 0.13565941154956818,
        "amazon_polarity": 0.1356964409351349,
        "cnn_dailymail/3.0.0": 0.14279069006443024,
        "common_gen": 0.11217660456895828,
        "cos_e/v1.11": 0.12360751628875732,
        "glue/mrpc": 0.12666788697242737,
        "kilt_tasks/hotpotqa": 0.1120796799659729
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12408,
        "ag_news": 13448,
        "amazon_polarity": 12640,
        "cnn_dailymail/3.0.0": 13056,
        "common_gen": 12832,
        "cos_e/v1.11": 12829,
        "glue/mrpc": 12380,
        "kilt_tasks/hotpotqa": 12792
      },
      "step": 800
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1822,
      "eval_samples_per_second": 87.816,
      "eval_steps_per_second": 5.489,
      "step": 800
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -66.1279296875,
        "ag_news": 76.81127166748047,
        "amazon_polarity": 77.15814971923828,
        "cnn_dailymail/3.0.0": 114.50750732421875,
        "common_gen": -57.83034896850586,
        "cos_e/v1.11": 10.483786582946777,
        "glue/mrpc": 27.852581024169922,
        "kilt_tasks/hotpotqa": -57.77646255493164
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9483,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11098934710025787,
        "ag_news": 0.13560819625854492,
        "amazon_polarity": 0.13567420840263367,
        "cnn_dailymail/3.0.0": 0.1429760605096817,
        "common_gen": 0.11228613555431366,
        "cos_e/v1.11": 0.12356293946504593,
        "glue/mrpc": 0.12660850584506989,
        "kilt_tasks/hotpotqa": 0.11229461431503296
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12592,
        "ag_news": 13680,
        "amazon_polarity": 12824,
        "cnn_dailymail/3.0.0": 13152,
        "common_gen": 12952,
        "cos_e/v1.11": 12973,
        "glue/mrpc": 12556,
        "kilt_tasks/hotpotqa": 12936
      },
      "step": 810
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -63.805416107177734,
        "ag_news": 76.65361785888672,
        "amazon_polarity": 77.02659606933594,
        "cnn_dailymail/3.0.0": 116.2870101928711,
        "common_gen": -59.0306396484375,
        "cos_e/v1.11": 6.811267375946045,
        "glue/mrpc": 28.33054542541504,
        "kilt_tasks/hotpotqa": -57.91054916381836
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1718,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11144223064184189,
        "ag_news": 0.1355278342962265,
        "amazon_polarity": 0.1355983316898346,
        "cnn_dailymail/3.0.0": 0.1432320475578308,
        "common_gen": 0.11218512803316116,
        "cos_e/v1.11": 0.12295585870742798,
        "glue/mrpc": 0.12669840455055237,
        "kilt_tasks/hotpotqa": 0.11236012727022171
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12760,
        "ag_news": 13824,
        "amazon_polarity": 12992,
        "cnn_dailymail/3.0.0": 13392,
        "common_gen": 13096,
        "cos_e/v1.11": 13125,
        "glue/mrpc": 12684,
        "kilt_tasks/hotpotqa": 13072
      },
      "step": 820
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -66.54058074951172,
        "ag_news": 76.55442810058594,
        "amazon_polarity": 76.94306182861328,
        "cnn_dailymail/3.0.0": 119.52366638183594,
        "common_gen": -56.736576080322266,
        "cos_e/v1.11": 12.116406440734863,
        "glue/mrpc": 29.12395668029785,
        "kilt_tasks/hotpotqa": -57.05754470825195
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.989,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11090961843729019,
        "ag_news": 0.1352137178182602,
        "amazon_polarity": 0.1352865993976593,
        "cnn_dailymail/3.0.0": 0.14351502060890198,
        "common_gen": 0.1124238446354866,
        "cos_e/v1.11": 0.12366475909948349,
        "glue/mrpc": 0.12661243975162506,
        "kilt_tasks/hotpotqa": 0.11237394064664841
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 12896,
        "ag_news": 13984,
        "amazon_polarity": 13184,
        "cnn_dailymail/3.0.0": 13536,
        "common_gen": 13280,
        "cos_e/v1.11": 13213,
        "glue/mrpc": 12908,
        "kilt_tasks/hotpotqa": 13224
      },
      "step": 830
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -66.96598052978516,
        "ag_news": 76.52645111083984,
        "amazon_polarity": 76.8968734741211,
        "cnn_dailymail/3.0.0": 122.27352142333984,
        "common_gen": -60.5460090637207,
        "cos_e/v1.11": 9.678288459777832,
        "glue/mrpc": 28.77750587463379,
        "kilt_tasks/hotpotqa": -53.017066955566406
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1654,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1109226644039154,
        "ag_news": 0.13514508306980133,
        "amazon_polarity": 0.13521409034729004,
        "cnn_dailymail/3.0.0": 0.1439417451620102,
        "common_gen": 0.11190612614154816,
        "cos_e/v1.11": 0.12325771152973175,
        "glue/mrpc": 0.12654194235801697,
        "kilt_tasks/hotpotqa": 0.11307071894407272
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13072,
        "ag_news": 14104,
        "amazon_polarity": 13328,
        "cnn_dailymail/3.0.0": 13720,
        "common_gen": 13408,
        "cos_e/v1.11": 13373,
        "glue/mrpc": 13100,
        "kilt_tasks/hotpotqa": 13400
      },
      "step": 840
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -68.5693588256836,
        "ag_news": 76.49372863769531,
        "amazon_polarity": 76.75375366210938,
        "cnn_dailymail/3.0.0": 122.36474609375,
        "common_gen": -56.50406265258789,
        "cos_e/v1.11": 9.769012451171875,
        "glue/mrpc": 23.89714241027832,
        "kilt_tasks/hotpotqa": -53.3576545715332
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.128,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11081713438034058,
        "ag_news": 0.1351507157087326,
        "amazon_polarity": 0.13519887626171112,
        "cnn_dailymail/3.0.0": 0.14391906559467316,
        "common_gen": 0.11265997588634491,
        "cos_e/v1.11": 0.12335006147623062,
        "glue/mrpc": 0.1257585734128952,
        "kilt_tasks/hotpotqa": 0.11314564943313599
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13200,
        "ag_news": 14248,
        "amazon_polarity": 13488,
        "cnn_dailymail/3.0.0": 13912,
        "common_gen": 13584,
        "cos_e/v1.11": 13509,
        "glue/mrpc": 13284,
        "kilt_tasks/hotpotqa": 13560
      },
      "step": 850
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.6988525390625,
        "ag_news": 76.3735580444336,
        "amazon_polarity": 76.8437271118164,
        "cnn_dailymail/3.0.0": 121.89901733398438,
        "common_gen": -55.413604736328125,
        "cos_e/v1.11": 11.766834259033203,
        "glue/mrpc": 24.421676635742188,
        "kilt_tasks/hotpotqa": -54.815147399902344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0323,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1107155829668045,
        "ag_news": 0.13505715131759644,
        "amazon_polarity": 0.1351436823606491,
        "cnn_dailymail/3.0.0": 0.14369936287403107,
        "common_gen": 0.11288610845804214,
        "cos_e/v1.11": 0.1236857995390892,
        "glue/mrpc": 0.12583427131175995,
        "kilt_tasks/hotpotqa": 0.11297797411680222
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13368,
        "ag_news": 14440,
        "amazon_polarity": 13672,
        "cnn_dailymail/3.0.0": 14056,
        "common_gen": 13744,
        "cos_e/v1.11": 13613,
        "glue/mrpc": 13452,
        "kilt_tasks/hotpotqa": 13720
      },
      "step": 860
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -68.42301177978516,
        "ag_news": 76.2826919555664,
        "amazon_polarity": 76.71337127685547,
        "cnn_dailymail/3.0.0": 122.56854248046875,
        "common_gen": -56.708187103271484,
        "cos_e/v1.11": 13.130495071411133,
        "glue/mrpc": 22.149343490600586,
        "kilt_tasks/hotpotqa": -54.81787872314453
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2434,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11099439859390259,
        "ag_news": 0.13499417901039124,
        "amazon_polarity": 0.13507293164730072,
        "cnn_dailymail/3.0.0": 0.14372935891151428,
        "common_gen": 0.11276549100875854,
        "cos_e/v1.11": 0.12393396347761154,
        "glue/mrpc": 0.1254556030035019,
        "kilt_tasks/hotpotqa": 0.11305396258831024
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13496,
        "ag_news": 14576,
        "amazon_polarity": 13808,
        "cnn_dailymail/3.0.0": 14264,
        "common_gen": 13944,
        "cos_e/v1.11": 13781,
        "glue/mrpc": 13556,
        "kilt_tasks/hotpotqa": 13920
      },
      "step": 870
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.72856140136719,
        "ag_news": 76.23076629638672,
        "amazon_polarity": 76.69197845458984,
        "cnn_dailymail/3.0.0": 122.43567657470703,
        "common_gen": -58.16658401489258,
        "cos_e/v1.11": 11.196025848388672,
        "glue/mrpc": 22.718547821044922,
        "kilt_tasks/hotpotqa": -53.520938873291016
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1657,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11093035340309143,
        "ag_news": 0.13499461114406586,
        "amazon_polarity": 0.13507847487926483,
        "cnn_dailymail/3.0.0": 0.1436631679534912,
        "common_gen": 0.11266721785068512,
        "cos_e/v1.11": 0.12368056178092957,
        "glue/mrpc": 0.12561288475990295,
        "kilt_tasks/hotpotqa": 0.11337282508611679
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13576,
        "ag_news": 14744,
        "amazon_polarity": 13976,
        "cnn_dailymail/3.0.0": 14488,
        "common_gen": 14152,
        "cos_e/v1.11": 13957,
        "glue/mrpc": 13676,
        "kilt_tasks/hotpotqa": 14056
      },
      "step": 880
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.690185546875,
        "ag_news": 76.03286743164062,
        "amazon_polarity": 76.53594207763672,
        "cnn_dailymail/3.0.0": 121.83631134033203,
        "common_gen": -56.82244110107422,
        "cos_e/v1.11": 12.949536323547363,
        "glue/mrpc": 21.92776107788086,
        "kilt_tasks/hotpotqa": -52.69669723510742
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.174,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11097797751426697,
        "ag_news": 0.13486188650131226,
        "amazon_polarity": 0.13495278358459473,
        "cnn_dailymail/3.0.0": 0.14339473843574524,
        "common_gen": 0.1129026785492897,
        "cos_e/v1.11": 0.12394264340400696,
        "glue/mrpc": 0.12544041872024536,
        "kilt_tasks/hotpotqa": 0.11352690309286118
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13704,
        "ag_news": 14864,
        "amazon_polarity": 14136,
        "cnn_dailymail/3.0.0": 14648,
        "common_gen": 14328,
        "cos_e/v1.11": 14109,
        "glue/mrpc": 13836,
        "kilt_tasks/hotpotqa": 14280
      },
      "step": 890
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -67.43241882324219,
        "ag_news": 76.07569885253906,
        "amazon_polarity": 76.56564331054688,
        "cnn_dailymail/3.0.0": 123.12262725830078,
        "common_gen": -61.61100387573242,
        "cos_e/v1.11": 12.347220420837402,
        "glue/mrpc": 20.164752960205078,
        "kilt_tasks/hotpotqa": -45.8929443359375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1914,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11132978647947311,
        "ag_news": 0.13474665582180023,
        "amazon_polarity": 0.13483458757400513,
        "cnn_dailymail/3.0.0": 0.14346103370189667,
        "common_gen": 0.11219433695077896,
        "cos_e/v1.11": 0.1237882748246193,
        "glue/mrpc": 0.12508253753185272,
        "kilt_tasks/hotpotqa": 0.11456277966499329
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 13904,
        "ag_news": 14952,
        "amazon_polarity": 14256,
        "cnn_dailymail/3.0.0": 14752,
        "common_gen": 14576,
        "cos_e/v1.11": 14325,
        "glue/mrpc": 13996,
        "kilt_tasks/hotpotqa": 14424
      },
      "step": 900
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.178,
      "eval_samples_per_second": 89.884,
      "eval_steps_per_second": 5.618,
      "step": 900
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -69.95433807373047,
        "ag_news": 76.06377410888672,
        "amazon_polarity": 76.36841583251953,
        "cnn_dailymail/3.0.0": 123.44542694091797,
        "common_gen": -65.25146484375,
        "cos_e/v1.11": 9.557759284973145,
        "glue/mrpc": 22.497787475585938,
        "kilt_tasks/hotpotqa": -47.693450927734375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1286,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11116816848516464,
        "ag_news": 0.13485781848430634,
        "amazon_polarity": 0.13491223752498627,
        "cnn_dailymail/3.0.0": 0.1435939371585846,
        "common_gen": 0.11186125129461288,
        "cos_e/v1.11": 0.12349305301904678,
        "glue/mrpc": 0.12562578916549683,
        "kilt_tasks/hotpotqa": 0.11448769271373749
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14112,
        "ag_news": 15072,
        "amazon_polarity": 14400,
        "cnn_dailymail/3.0.0": 14904,
        "common_gen": 14704,
        "cos_e/v1.11": 14525,
        "glue/mrpc": 14188,
        "kilt_tasks/hotpotqa": 14560
      },
      "step": 910
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -71.1786880493164,
        "ag_news": 76.00614929199219,
        "amazon_polarity": 76.36915588378906,
        "cnn_dailymail/3.0.0": 124.00086212158203,
        "common_gen": -65.71370697021484,
        "cos_e/v1.11": 8.208881378173828,
        "glue/mrpc": 21.850099563598633,
        "kilt_tasks/hotpotqa": -45.2580451965332
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0513,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11107442528009415,
        "ag_news": 0.1348101943731308,
        "amazon_polarity": 0.13487467169761658,
        "cnn_dailymail/3.0.0": 0.14361046254634857,
        "common_gen": 0.11187517642974854,
        "cos_e/v1.11": 0.1232985109090805,
        "glue/mrpc": 0.12553206086158752,
        "kilt_tasks/hotpotqa": 0.11492463946342468
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14256,
        "ag_news": 15200,
        "amazon_polarity": 14576,
        "cnn_dailymail/3.0.0": 15072,
        "common_gen": 14832,
        "cos_e/v1.11": 14653,
        "glue/mrpc": 14404,
        "kilt_tasks/hotpotqa": 14752
      },
      "step": 920
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -65.76529693603516,
        "ag_news": 75.97467041015625,
        "amazon_polarity": 76.3667221069336,
        "cnn_dailymail/3.0.0": 124.1673583984375,
        "common_gen": -63.82778549194336,
        "cos_e/v1.11": 6.540441989898682,
        "glue/mrpc": 24.449769973754883,
        "kilt_tasks/hotpotqa": -44.52083969116211
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0441,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11178436130285263,
        "ag_news": 0.13456980884075165,
        "amazon_polarity": 0.1346389502286911,
        "cnn_dailymail/3.0.0": 0.14334288239479065,
        "common_gen": 0.11206790059804916,
        "cos_e/v1.11": 0.12287403643131256,
        "glue/mrpc": 0.12578868865966797,
        "kilt_tasks/hotpotqa": 0.11493334919214249
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14360,
        "ag_news": 15360,
        "amazon_polarity": 14784,
        "cnn_dailymail/3.0.0": 15248,
        "common_gen": 15016,
        "cos_e/v1.11": 14829,
        "glue/mrpc": 14564,
        "kilt_tasks/hotpotqa": 14864
      },
      "step": 930
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -68.12442016601562,
        "ag_news": 75.9507064819336,
        "amazon_polarity": 76.39227294921875,
        "cnn_dailymail/3.0.0": 122.51190185546875,
        "common_gen": -60.123619079589844,
        "cos_e/v1.11": 4.5126495361328125,
        "glue/mrpc": 25.330547332763672,
        "kilt_tasks/hotpotqa": -45.811912536621094
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0372,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11156376451253891,
        "ag_news": 0.1345808357000351,
        "amazon_polarity": 0.13465829193592072,
        "cnn_dailymail/3.0.0": 0.14300215244293213,
        "common_gen": 0.11273074150085449,
        "cos_e/v1.11": 0.12262286245822906,
        "glue/mrpc": 0.12599225342273712,
        "kilt_tasks/hotpotqa": 0.11484909057617188
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14552,
        "ag_news": 15512,
        "amazon_polarity": 14960,
        "cnn_dailymail/3.0.0": 15400,
        "common_gen": 15168,
        "cos_e/v1.11": 14973,
        "glue/mrpc": 14728,
        "kilt_tasks/hotpotqa": 15008
      },
      "step": 940
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -67.0059814453125,
        "ag_news": 75.94378662109375,
        "amazon_polarity": 76.25127410888672,
        "cnn_dailymail/3.0.0": 120.83961486816406,
        "common_gen": -62.32810974121094,
        "cos_e/v1.11": 7.109988212585449,
        "glue/mrpc": 26.317773818969727,
        "kilt_tasks/hotpotqa": -45.282047271728516
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0669,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11177632212638855,
        "ag_news": 0.13450902700424194,
        "amazon_polarity": 0.1345626264810562,
        "cnn_dailymail/3.0.0": 0.1425720602273941,
        "common_gen": 0.1124548614025116,
        "cos_e/v1.11": 0.12303141504526138,
        "glue/mrpc": 0.1261308491230011,
        "kilt_tasks/hotpotqa": 0.11496291309595108
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14728,
        "ag_news": 15648,
        "amazon_polarity": 15104,
        "cnn_dailymail/3.0.0": 15544,
        "common_gen": 15288,
        "cos_e/v1.11": 15125,
        "glue/mrpc": 14936,
        "kilt_tasks/hotpotqa": 15208
      },
      "step": 950
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -71.32050323486328,
        "ag_news": 75.90404510498047,
        "amazon_polarity": 76.26177215576172,
        "cnn_dailymail/3.0.0": 121.23430633544922,
        "common_gen": -58.23031234741211,
        "cos_e/v1.11": 10.917496681213379,
        "glue/mrpc": 28.21626091003418,
        "kilt_tasks/hotpotqa": -42.450714111328125
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0046,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11107101291418076,
        "ag_news": 0.13426856696605682,
        "amazon_polarity": 0.13433052599430084,
        "cnn_dailymail/3.0.0": 0.14235389232635498,
        "common_gen": 0.11295821517705917,
        "cos_e/v1.11": 0.1234789714217186,
        "glue/mrpc": 0.12626247107982635,
        "kilt_tasks/hotpotqa": 0.11527632921934128
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 14920,
        "ag_news": 15856,
        "amazon_polarity": 15296,
        "cnn_dailymail/3.0.0": 15704,
        "common_gen": 15440,
        "cos_e/v1.11": 15261,
        "glue/mrpc": 15072,
        "kilt_tasks/hotpotqa": 15312
      },
      "step": 960
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -76.02584838867188,
        "ag_news": 75.9665298461914,
        "amazon_polarity": 76.24418640136719,
        "cnn_dailymail/3.0.0": 120.28873443603516,
        "common_gen": -58.97481155395508,
        "cos_e/v1.11": 10.66364574432373,
        "glue/mrpc": 27.40798568725586,
        "kilt_tasks/hotpotqa": -40.22873306274414
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1603,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1105591431260109,
        "ag_news": 0.13433781266212463,
        "amazon_polarity": 0.13438567519187927,
        "cnn_dailymail/3.0.0": 0.1422004997730255,
        "common_gen": 0.1129995584487915,
        "cos_e/v1.11": 0.12354554235935211,
        "glue/mrpc": 0.12622636556625366,
        "kilt_tasks/hotpotqa": 0.11574552208185196
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15032,
        "ag_news": 16048,
        "amazon_polarity": 15392,
        "cnn_dailymail/3.0.0": 15888,
        "common_gen": 15616,
        "cos_e/v1.11": 15445,
        "glue/mrpc": 15232,
        "kilt_tasks/hotpotqa": 15488
      },
      "step": 970
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -75.86764526367188,
        "ag_news": 75.93704986572266,
        "amazon_polarity": 76.1864013671875,
        "cnn_dailymail/3.0.0": 120.2077865600586,
        "common_gen": -58.794795989990234,
        "cos_e/v1.11": 8.843785285949707,
        "glue/mrpc": 26.22443199157715,
        "kilt_tasks/hotpotqa": -39.76560592651367
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0851,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11069536954164505,
        "ag_news": 0.1343385875225067,
        "amazon_polarity": 0.13438133895397186,
        "cnn_dailymail/3.0.0": 0.1421508938074112,
        "common_gen": 0.11312945932149887,
        "cos_e/v1.11": 0.12331681698560715,
        "glue/mrpc": 0.1260811984539032,
        "kilt_tasks/hotpotqa": 0.11590633541345596
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15192,
        "ag_news": 16200,
        "amazon_polarity": 15584,
        "cnn_dailymail/3.0.0": 16112,
        "common_gen": 15728,
        "cos_e/v1.11": 15637,
        "glue/mrpc": 15344,
        "kilt_tasks/hotpotqa": 15624
      },
      "step": 980
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -76.7711181640625,
        "ag_news": 75.91927337646484,
        "amazon_polarity": 76.15396881103516,
        "cnn_dailymail/3.0.0": 118.75421905517578,
        "common_gen": -59.16999816894531,
        "cos_e/v1.11": 5.734272480010986,
        "glue/mrpc": 25.381561279296875,
        "kilt_tasks/hotpotqa": -38.06484603881836
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0527,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11072895675897598,
        "ag_news": 0.134399875998497,
        "amazon_polarity": 0.13443994522094727,
        "cnn_dailymail/3.0.0": 0.1419162154197693,
        "common_gen": 0.11322725564241409,
        "cos_e/v1.11": 0.12294279038906097,
        "glue/mrpc": 0.1260468065738678,
        "kilt_tasks/hotpotqa": 0.11629821360111237
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15384,
        "ag_news": 16384,
        "amazon_polarity": 15704,
        "cnn_dailymail/3.0.0": 16272,
        "common_gen": 15856,
        "cos_e/v1.11": 15829,
        "glue/mrpc": 15520,
        "kilt_tasks/hotpotqa": 15752
      },
      "step": 990
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -78.04779815673828,
        "ag_news": 76.07412719726562,
        "amazon_polarity": 76.15839385986328,
        "cnn_dailymail/3.0.0": 119.00970458984375,
        "common_gen": -59.52448272705078,
        "cos_e/v1.11": 5.033375263214111,
        "glue/mrpc": 24.46425437927246,
        "kilt_tasks/hotpotqa": -37.76189422607422
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0932,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11065980792045593,
        "ag_news": 0.13442935049533844,
        "amazon_polarity": 0.13444367051124573,
        "cnn_dailymail/3.0.0": 0.14192698895931244,
        "common_gen": 0.1132756918668747,
        "cos_e/v1.11": 0.12289135903120041,
        "glue/mrpc": 0.12594403326511383,
        "kilt_tasks/hotpotqa": 0.11642907559871674
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15496,
        "ag_news": 16544,
        "amazon_polarity": 15872,
        "cnn_dailymail/3.0.0": 16448,
        "common_gen": 15992,
        "cos_e/v1.11": 16021,
        "glue/mrpc": 15704,
        "kilt_tasks/hotpotqa": 15904
      },
      "step": 1000
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.2,
      "eval_samples_per_second": 80.004,
      "eval_steps_per_second": 5.0,
      "step": 1000
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -77.32852172851562,
        "ag_news": 76.04849243164062,
        "amazon_polarity": 76.06715393066406,
        "cnn_dailymail/3.0.0": 119.13214111328125,
        "common_gen": -58.972023010253906,
        "cos_e/v1.11": 6.571960926055908,
        "glue/mrpc": 23.496049880981445,
        "kilt_tasks/hotpotqa": -40.27793502807617
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0979,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1108393520116806,
        "ag_news": 0.13439297676086426,
        "amazon_polarity": 0.13439613580703735,
        "cnn_dailymail/3.0.0": 0.14187704026699066,
        "common_gen": 0.11342275142669678,
        "cos_e/v1.11": 0.12315419316291809,
        "glue/mrpc": 0.12580128014087677,
        "kilt_tasks/hotpotqa": 0.11611625552177429
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15672,
        "ag_news": 16656,
        "amazon_polarity": 16024,
        "cnn_dailymail/3.0.0": 16584,
        "common_gen": 16152,
        "cos_e/v1.11": 16277,
        "glue/mrpc": 15872,
        "kilt_tasks/hotpotqa": 16024
      },
      "step": 1010
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -82.36771392822266,
        "ag_news": 75.9601058959961,
        "amazon_polarity": 76.02173614501953,
        "cnn_dailymail/3.0.0": 118.15270233154297,
        "common_gen": -57.31625747680664,
        "cos_e/v1.11": 8.963215827941895,
        "glue/mrpc": 24.108488082885742,
        "kilt_tasks/hotpotqa": -38.664573669433594
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9977,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11020571738481522,
        "ag_news": 0.1343272477388382,
        "amazon_polarity": 0.1343376189470291,
        "cnn_dailymail/3.0.0": 0.14161206781864166,
        "common_gen": 0.11370852589607239,
        "cos_e/v1.11": 0.12352880835533142,
        "glue/mrpc": 0.1258905827999115,
        "kilt_tasks/hotpotqa": 0.11638942360877991
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15832,
        "ag_news": 16832,
        "amazon_polarity": 16224,
        "cnn_dailymail/3.0.0": 16680,
        "common_gen": 16304,
        "cos_e/v1.11": 16429,
        "glue/mrpc": 16008,
        "kilt_tasks/hotpotqa": 16232
      },
      "step": 1020
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -81.38627624511719,
        "ag_news": 75.93917083740234,
        "amazon_polarity": 75.89635467529297,
        "cnn_dailymail/3.0.0": 119.16651153564453,
        "common_gen": -57.59135055541992,
        "cos_e/v1.11": 7.825940132141113,
        "glue/mrpc": 22.990455627441406,
        "kilt_tasks/hotpotqa": -41.66044616699219
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0882,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11046787351369858,
        "ag_news": 0.13435101509094238,
        "amazon_polarity": 0.13434384763240814,
        "cnn_dailymail/3.0.0": 0.14178362488746643,
        "common_gen": 0.11378402262926102,
        "cos_e/v1.11": 0.12342902272939682,
        "glue/mrpc": 0.1257803738117218,
        "kilt_tasks/hotpotqa": 0.1160603016614914
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 15992,
        "ag_news": 17024,
        "amazon_polarity": 16400,
        "cnn_dailymail/3.0.0": 16872,
        "common_gen": 16456,
        "cos_e/v1.11": 16557,
        "glue/mrpc": 16128,
        "kilt_tasks/hotpotqa": 16392
      },
      "step": 1030
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -81.75669860839844,
        "ag_news": 75.77131652832031,
        "amazon_polarity": 75.78593444824219,
        "cnn_dailymail/3.0.0": 125.29056549072266,
        "common_gen": -64.0097427368164,
        "cos_e/v1.11": 8.095353126525879,
        "glue/mrpc": 19.955493927001953,
        "kilt_tasks/hotpotqa": -39.95311737060547
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0757,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11049559712409973,
        "ag_news": 0.13429272174835205,
        "amazon_polarity": 0.13429515063762665,
        "cnn_dailymail/3.0.0": 0.1427953541278839,
        "common_gen": 0.11294817179441452,
        "cos_e/v1.11": 0.12349238246679306,
        "glue/mrpc": 0.12531965970993042,
        "kilt_tasks/hotpotqa": 0.11636088043451309
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16144,
        "ag_news": 17224,
        "amazon_polarity": 16576,
        "cnn_dailymail/3.0.0": 17048,
        "common_gen": 16616,
        "cos_e/v1.11": 16693,
        "glue/mrpc": 16256,
        "kilt_tasks/hotpotqa": 16544
      },
      "step": 1040
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -80.65505981445312,
        "ag_news": 75.5934066772461,
        "amazon_polarity": 75.68815612792969,
        "cnn_dailymail/3.0.0": 125.22828674316406,
        "common_gen": -62.65570068359375,
        "cos_e/v1.11": 9.135658264160156,
        "glue/mrpc": 18.86626434326172,
        "kilt_tasks/hotpotqa": -40.152198791503906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9982,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11068510264158249,
        "ag_news": 0.13418729603290558,
        "amazon_polarity": 0.1342029869556427,
        "cnn_dailymail/3.0.0": 0.14266204833984375,
        "common_gen": 0.11316535621881485,
        "cos_e/v1.11": 0.12362997978925705,
        "glue/mrpc": 0.12512171268463135,
        "kilt_tasks/hotpotqa": 0.11634549498558044
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16280,
        "ag_news": 17432,
        "amazon_polarity": 16768,
        "cnn_dailymail/3.0.0": 17168,
        "common_gen": 16768,
        "cos_e/v1.11": 16845,
        "glue/mrpc": 16416,
        "kilt_tasks/hotpotqa": 16704
      },
      "step": 1050
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -81.99787139892578,
        "ag_news": 75.6261215209961,
        "amazon_polarity": 75.46463012695312,
        "cnn_dailymail/3.0.0": 125.75064849853516,
        "common_gen": -60.69258117675781,
        "cos_e/v1.11": 6.321410655975342,
        "glue/mrpc": 17.75467872619629,
        "kilt_tasks/hotpotqa": -40.360897064208984
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9046,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11062052845954895,
        "ag_news": 0.13421420753002167,
        "amazon_polarity": 0.13418760895729065,
        "cnn_dailymail/3.0.0": 0.14273548126220703,
        "common_gen": 0.11354672908782959,
        "cos_e/v1.11": 0.12327101826667786,
        "glue/mrpc": 0.12501221895217896,
        "kilt_tasks/hotpotqa": 0.11641216278076172
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16496,
        "ag_news": 17632,
        "amazon_polarity": 16968,
        "cnn_dailymail/3.0.0": 17280,
        "common_gen": 16856,
        "cos_e/v1.11": 16989,
        "glue/mrpc": 16568,
        "kilt_tasks/hotpotqa": 16872
      },
      "step": 1060
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -81.56179809570312,
        "ag_news": 75.60527801513672,
        "amazon_polarity": 75.3743667602539,
        "cnn_dailymail/3.0.0": 126.5568618774414,
        "common_gen": -60.64333724975586,
        "cos_e/v1.11": 9.036230087280273,
        "glue/mrpc": 14.328676223754883,
        "kilt_tasks/hotpotqa": -41.84951400756836
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1937,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11075904220342636,
        "ag_news": 0.13418692350387573,
        "amazon_polarity": 0.13414905965328217,
        "cnn_dailymail/3.0.0": 0.1428099125623703,
        "common_gen": 0.1136215329170227,
        "cos_e/v1.11": 0.12370719760656357,
        "glue/mrpc": 0.12450926005840302,
        "kilt_tasks/hotpotqa": 0.11625702679157257
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16672,
        "ag_news": 17784,
        "amazon_polarity": 17040,
        "cnn_dailymail/3.0.0": 17408,
        "common_gen": 17056,
        "cos_e/v1.11": 17173,
        "glue/mrpc": 16776,
        "kilt_tasks/hotpotqa": 17032
      },
      "step": 1070
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -81.3714828491211,
        "ag_news": 75.49740600585938,
        "amazon_polarity": 75.40674591064453,
        "cnn_dailymail/3.0.0": 125.08317565917969,
        "common_gen": -59.099586486816406,
        "cos_e/v1.11": 9.85532283782959,
        "glue/mrpc": 10.418707847595215,
        "kilt_tasks/hotpotqa": -41.53529357910156
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1024,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11089816689491272,
        "ag_news": 0.13418841361999512,
        "amazon_polarity": 0.13417360186576843,
        "cnn_dailymail/3.0.0": 0.14253340661525726,
        "common_gen": 0.11393804848194122,
        "cos_e/v1.11": 0.12389439344406128,
        "glue/mrpc": 0.12397925555706024,
        "kilt_tasks/hotpotqa": 0.11639471352100372
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16800,
        "ag_news": 17960,
        "amazon_polarity": 17224,
        "cnn_dailymail/3.0.0": 17560,
        "common_gen": 17232,
        "cos_e/v1.11": 17333,
        "glue/mrpc": 16952,
        "kilt_tasks/hotpotqa": 17160
      },
      "step": 1080
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -84.63384246826172,
        "ag_news": 75.47716522216797,
        "amazon_polarity": 75.42155456542969,
        "cnn_dailymail/3.0.0": 126.59273529052734,
        "common_gen": -60.32706832885742,
        "cos_e/v1.11": 9.512616157531738,
        "glue/mrpc": 10.126025199890137,
        "kilt_tasks/hotpotqa": -40.00178146362305
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0696,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11054866015911102,
        "ag_news": 0.13417406380176544,
        "amazon_polarity": 0.13416501879692078,
        "cnn_dailymail/3.0.0": 0.14274318516254425,
        "common_gen": 0.11384455859661102,
        "cos_e/v1.11": 0.12387792021036148,
        "glue/mrpc": 0.12396988272666931,
        "kilt_tasks/hotpotqa": 0.11667674779891968
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 16976,
        "ag_news": 18080,
        "amazon_polarity": 17424,
        "cnn_dailymail/3.0.0": 17776,
        "common_gen": 17352,
        "cos_e/v1.11": 17469,
        "glue/mrpc": 17104,
        "kilt_tasks/hotpotqa": 17320
      },
      "step": 1090
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -84.37730407714844,
        "ag_news": 75.40264129638672,
        "amazon_polarity": 75.24392700195312,
        "cnn_dailymail/3.0.0": 128.6739959716797,
        "common_gen": -55.03937911987305,
        "cos_e/v1.11": 10.218964576721191,
        "glue/mrpc": 8.586039543151855,
        "kilt_tasks/hotpotqa": -38.393253326416016
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0317,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11051557213068008,
        "ag_news": 0.13396291434764862,
        "amazon_polarity": 0.1339372992515564,
        "cnn_dailymail/3.0.0": 0.14284943044185638,
        "common_gen": 0.1144864484667778,
        "cos_e/v1.11": 0.12384416908025742,
        "glue/mrpc": 0.12360086292028427,
        "kilt_tasks/hotpotqa": 0.11680331826210022
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17096,
        "ag_news": 18304,
        "amazon_polarity": 17592,
        "cnn_dailymail/3.0.0": 17936,
        "common_gen": 17432,
        "cos_e/v1.11": 17653,
        "glue/mrpc": 17288,
        "kilt_tasks/hotpotqa": 17480
      },
      "step": 1100
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1876,
      "eval_samples_per_second": 85.276,
      "eval_steps_per_second": 5.33,
      "step": 1100
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -83.2998046875,
        "ag_news": 75.4925308227539,
        "amazon_polarity": 74.5095443725586,
        "cnn_dailymail/3.0.0": 130.1686248779297,
        "common_gen": -60.495609283447266,
        "cos_e/v1.11": 11.984387397766113,
        "glue/mrpc": 9.389695167541504,
        "kilt_tasks/hotpotqa": -42.52421951293945
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2153,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11079245060682297,
        "ag_news": 0.1340244859457016,
        "amazon_polarity": 0.13386648893356323,
        "cnn_dailymail/3.0.0": 0.14311514794826508,
        "common_gen": 0.11386048793792725,
        "cos_e/v1.11": 0.12419391423463821,
        "glue/mrpc": 0.1238081231713295,
        "kilt_tasks/hotpotqa": 0.11633873730897903
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17320,
        "ag_news": 18384,
        "amazon_polarity": 17720,
        "cnn_dailymail/3.0.0": 18080,
        "common_gen": 17600,
        "cos_e/v1.11": 17829,
        "glue/mrpc": 17456,
        "kilt_tasks/hotpotqa": 17672
      },
      "step": 1110
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -88.06398010253906,
        "ag_news": 75.41595458984375,
        "amazon_polarity": 74.52340698242188,
        "cnn_dailymail/3.0.0": 129.21707153320312,
        "common_gen": -61.732704162597656,
        "cos_e/v1.11": 11.472480773925781,
        "glue/mrpc": 6.510011672973633,
        "kilt_tasks/hotpotqa": -41.85646057128906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.055,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11037733405828476,
        "ag_news": 0.1341577023267746,
        "amazon_polarity": 0.13401474058628082,
        "cnn_dailymail/3.0.0": 0.14306600391864777,
        "common_gen": 0.1138981431722641,
        "cos_e/v1.11": 0.12429468333721161,
        "glue/mrpc": 0.12356057018041611,
        "kilt_tasks/hotpotqa": 0.11663084477186203
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17536,
        "ag_news": 18512,
        "amazon_polarity": 17848,
        "cnn_dailymail/3.0.0": 18232,
        "common_gen": 17696,
        "cos_e/v1.11": 17981,
        "glue/mrpc": 17736,
        "kilt_tasks/hotpotqa": 17800
      },
      "step": 1120
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -86.14598846435547,
        "ag_news": 75.0647201538086,
        "amazon_polarity": 74.39705657958984,
        "cnn_dailymail/3.0.0": 131.04696655273438,
        "common_gen": -63.952392578125,
        "cos_e/v1.11": 10.52375316619873,
        "glue/mrpc": 9.9973783493042,
        "kilt_tasks/hotpotqa": -40.869354248046875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.062,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11061415076255798,
        "ag_news": 0.13396859169006348,
        "amazon_polarity": 0.13386225700378418,
        "cnn_dailymail/3.0.0": 0.14319494366645813,
        "common_gen": 0.11356747895479202,
        "cos_e/v1.11": 0.12407317012548447,
        "glue/mrpc": 0.1239955723285675,
        "kilt_tasks/hotpotqa": 0.11672377586364746
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17624,
        "ag_news": 18744,
        "amazon_polarity": 18016,
        "cnn_dailymail/3.0.0": 18376,
        "common_gen": 17848,
        "cos_e/v1.11": 18221,
        "glue/mrpc": 17872,
        "kilt_tasks/hotpotqa": 17920
      },
      "step": 1130
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -91.57465362548828,
        "ag_news": 75.01176452636719,
        "amazon_polarity": 74.24040222167969,
        "cnn_dailymail/3.0.0": 131.01504516601562,
        "common_gen": -62.545249938964844,
        "cos_e/v1.11": 12.153773307800293,
        "glue/mrpc": 7.9656524658203125,
        "kilt_tasks/hotpotqa": -36.88813781738281
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.986,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10997408628463745,
        "ag_news": 0.13393047451972961,
        "amazon_polarity": 0.1338081806898117,
        "cnn_dailymail/3.0.0": 0.14311611652374268,
        "common_gen": 0.11381324380636215,
        "cos_e/v1.11": 0.12432672828435898,
        "glue/mrpc": 0.12371212989091873,
        "kilt_tasks/hotpotqa": 0.11731905490159988
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17848,
        "ag_news": 18920,
        "amazon_polarity": 18224,
        "cnn_dailymail/3.0.0": 18504,
        "common_gen": 17968,
        "cos_e/v1.11": 18365,
        "glue/mrpc": 18040,
        "kilt_tasks/hotpotqa": 18032
      },
      "step": 1140
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -95.86296081542969,
        "ag_news": 74.96332550048828,
        "amazon_polarity": 74.18840026855469,
        "cnn_dailymail/3.0.0": 131.95326232910156,
        "common_gen": -62.539615631103516,
        "cos_e/v1.11": 13.757783889770508,
        "glue/mrpc": 8.913601875305176,
        "kilt_tasks/hotpotqa": -41.1674919128418
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1624,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10955137014389038,
        "ag_news": 0.13396896421909332,
        "amazon_polarity": 0.13384662568569183,
        "cnn_dailymail/3.0.0": 0.14328287541866302,
        "common_gen": 0.11393322795629501,
        "cos_e/v1.11": 0.1246449202299118,
        "glue/mrpc": 0.12393554300069809,
        "kilt_tasks/hotpotqa": 0.11683639138936996
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 17984,
        "ag_news": 19056,
        "amazon_polarity": 18384,
        "cnn_dailymail/3.0.0": 18656,
        "common_gen": 18136,
        "cos_e/v1.11": 18533,
        "glue/mrpc": 18192,
        "kilt_tasks/hotpotqa": 18240
      },
      "step": 1150
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -95.31127166748047,
        "ag_news": 74.91456604003906,
        "amazon_polarity": 74.34390258789062,
        "cnn_dailymail/3.0.0": 135.07769775390625,
        "common_gen": -62.50636672973633,
        "cos_e/v1.11": 13.655926704406738,
        "glue/mrpc": 5.839386940002441,
        "kilt_tasks/hotpotqa": -41.88749694824219
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.2038,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10967941582202911,
        "ag_news": 0.1339157670736313,
        "amazon_polarity": 0.1338260918855667,
        "cnn_dailymail/3.0.0": 0.14371933043003082,
        "common_gen": 0.11397802084684372,
        "cos_e/v1.11": 0.12462620437145233,
        "glue/mrpc": 0.12348861992359161,
        "kilt_tasks/hotpotqa": 0.11676657199859619
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18160,
        "ag_news": 19160,
        "amazon_polarity": 18528,
        "cnn_dailymail/3.0.0": 18816,
        "common_gen": 18264,
        "cos_e/v1.11": 18765,
        "glue/mrpc": 18340,
        "kilt_tasks/hotpotqa": 18424
      },
      "step": 1160
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -98.70162200927734,
        "ag_news": 74.82373809814453,
        "amazon_polarity": 74.21112060546875,
        "cnn_dailymail/3.0.0": 132.0855255126953,
        "common_gen": -56.809207916259766,
        "cos_e/v1.11": 12.644007682800293,
        "glue/mrpc": 3.1218509674072266,
        "kilt_tasks/hotpotqa": -43.15045166015625
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1096,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10940934717655182,
        "ag_news": 0.13398781418800354,
        "amazon_polarity": 0.13389191031455994,
        "cnn_dailymail/3.0.0": 0.1432664692401886,
        "common_gen": 0.11489088833332062,
        "cos_e/v1.11": 0.12459715455770493,
        "glue/mrpc": 0.12321893125772476,
        "kilt_tasks/hotpotqa": 0.11673746258020401
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18320,
        "ag_news": 19320,
        "amazon_polarity": 18664,
        "cnn_dailymail/3.0.0": 18984,
        "common_gen": 18424,
        "cos_e/v1.11": 18933,
        "glue/mrpc": 18532,
        "kilt_tasks/hotpotqa": 18560
      },
      "step": 1170
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -101.30380249023438,
        "ag_news": 74.62879180908203,
        "amazon_polarity": 74.02840423583984,
        "cnn_dailymail/3.0.0": 132.75257873535156,
        "common_gen": -56.403926849365234,
        "cos_e/v1.11": 12.896218299865723,
        "glue/mrpc": 1.8108066320419312,
        "kilt_tasks/hotpotqa": -46.2711296081543
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1197,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10922898352146149,
        "ag_news": 0.13402728736400604,
        "amazon_polarity": 0.1339336484670639,
        "cnn_dailymail/3.0.0": 0.14341214299201965,
        "common_gen": 0.1150793731212616,
        "cos_e/v1.11": 0.12473687529563904,
        "glue/mrpc": 0.12313877046108246,
        "kilt_tasks/hotpotqa": 0.11644287407398224
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18448,
        "ag_news": 19472,
        "amazon_polarity": 18840,
        "cnn_dailymail/3.0.0": 19176,
        "common_gen": 18560,
        "cos_e/v1.11": 19093,
        "glue/mrpc": 18676,
        "kilt_tasks/hotpotqa": 18752
      },
      "step": 1180
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -95.81733703613281,
        "ag_news": 74.74694061279297,
        "amazon_polarity": 73.85979461669922,
        "cnn_dailymail/3.0.0": 134.31149291992188,
        "common_gen": -58.03425598144531,
        "cos_e/v1.11": 11.452065467834473,
        "glue/mrpc": 0.5307592153549194,
        "kilt_tasks/hotpotqa": -46.47703552246094
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1492,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1099538654088974,
        "ag_news": 0.13396689295768738,
        "amazon_polarity": 0.13382919132709503,
        "cnn_dailymail/3.0.0": 0.14354655146598816,
        "common_gen": 0.11486807465553284,
        "cos_e/v1.11": 0.12449261546134949,
        "glue/mrpc": 0.12292763590812683,
        "kilt_tasks/hotpotqa": 0.11641513556241989
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18632,
        "ag_news": 19592,
        "amazon_polarity": 18952,
        "cnn_dailymail/3.0.0": 19304,
        "common_gen": 18760,
        "cos_e/v1.11": 19293,
        "glue/mrpc": 18852,
        "kilt_tasks/hotpotqa": 18912
      },
      "step": 1190
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -93.3865966796875,
        "ag_news": 74.73319244384766,
        "amazon_polarity": 73.40084075927734,
        "cnn_dailymail/3.0.0": 135.68661499023438,
        "common_gen": -57.94063949584961,
        "cos_e/v1.11": 9.940650939941406,
        "glue/mrpc": 1.8808722496032715,
        "kilt_tasks/hotpotqa": -45.82252883911133
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0277,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11026311665773392,
        "ag_news": 0.1338561773300171,
        "amazon_polarity": 0.13365046679973602,
        "cnn_dailymail/3.0.0": 0.14361700415611267,
        "common_gen": 0.11486060917377472,
        "cos_e/v1.11": 0.12421280890703201,
        "glue/mrpc": 0.1230633407831192,
        "kilt_tasks/hotpotqa": 0.11647640913724899
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18760,
        "ag_news": 19760,
        "amazon_polarity": 19120,
        "cnn_dailymail/3.0.0": 19456,
        "common_gen": 18960,
        "cos_e/v1.11": 19437,
        "glue/mrpc": 19012,
        "kilt_tasks/hotpotqa": 19072
      },
      "step": 1200
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.1942,
      "eval_samples_per_second": 82.389,
      "eval_steps_per_second": 5.149,
      "step": 1200
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -96.42034149169922,
        "ag_news": 74.7077865600586,
        "amazon_polarity": 73.25366973876953,
        "cnn_dailymail/3.0.0": 138.7248077392578,
        "common_gen": -63.13685989379883,
        "cos_e/v1.11": 8.343977928161621,
        "glue/mrpc": 2.753218173980713,
        "kilt_tasks/hotpotqa": -45.560142517089844
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.1009,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11001065373420715,
        "ag_news": 0.13390500843524933,
        "amazon_polarity": 0.13368135690689087,
        "cnn_dailymail/3.0.0": 0.14413489401340485,
        "common_gen": 0.11429422348737717,
        "cos_e/v1.11": 0.1240721121430397,
        "glue/mrpc": 0.12327779084444046,
        "kilt_tasks/hotpotqa": 0.11662393063306808
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 18912,
        "ag_news": 19920,
        "amazon_polarity": 19264,
        "cnn_dailymail/3.0.0": 19616,
        "common_gen": 19120,
        "cos_e/v1.11": 19610,
        "glue/mrpc": 19180,
        "kilt_tasks/hotpotqa": 19232
      },
      "step": 1210
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -94.45103454589844,
        "ag_news": 74.69561767578125,
        "amazon_polarity": 73.1415023803711,
        "cnn_dailymail/3.0.0": 138.17333984375,
        "common_gen": -66.83892059326172,
        "cos_e/v1.11": 13.763702392578125,
        "glue/mrpc": 3.328887939453125,
        "kilt_tasks/hotpotqa": -44.44953918457031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0221,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11024527996778488,
        "ag_news": 0.13377976417541504,
        "amazon_polarity": 0.13354192674160004,
        "cnn_dailymail/3.0.0": 0.14386782050132751,
        "common_gen": 0.11378015577793121,
        "cos_e/v1.11": 0.1247677132487297,
        "glue/mrpc": 0.12328697741031647,
        "kilt_tasks/hotpotqa": 0.11673034727573395
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19048,
        "ag_news": 20104,
        "amazon_polarity": 19384,
        "cnn_dailymail/3.0.0": 19744,
        "common_gen": 19280,
        "cos_e/v1.11": 19778,
        "glue/mrpc": 19388,
        "kilt_tasks/hotpotqa": 19408
      },
      "step": 1220
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -92.224853515625,
        "ag_news": 74.69058990478516,
        "amazon_polarity": 73.03689575195312,
        "cnn_dailymail/3.0.0": 138.4003143310547,
        "common_gen": -64.05712890625,
        "cos_e/v1.11": 16.670978546142578,
        "glue/mrpc": 7.574254989624023,
        "kilt_tasks/hotpotqa": -47.27536392211914
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9976,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1104394868016243,
        "ag_news": 0.13357076048851013,
        "amazon_polarity": 0.13331910967826843,
        "cnn_dailymail/3.0.0": 0.14363868534564972,
        "common_gen": 0.11403824388980865,
        "cos_e/v1.11": 0.1250222623348236,
        "glue/mrpc": 0.12373296916484833,
        "kilt_tasks/hotpotqa": 0.11623840779066086
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19224,
        "ag_news": 20312,
        "amazon_polarity": 19520,
        "cnn_dailymail/3.0.0": 19896,
        "common_gen": 19360,
        "cos_e/v1.11": 19978,
        "glue/mrpc": 19580,
        "kilt_tasks/hotpotqa": 19544
      },
      "step": 1230
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -92.73426818847656,
        "ag_news": 74.62039947509766,
        "amazon_polarity": 72.78659057617188,
        "cnn_dailymail/3.0.0": 135.9553680419922,
        "common_gen": -66.20336151123047,
        "cos_e/v1.11": 14.447282791137695,
        "glue/mrpc": 4.981137752532959,
        "kilt_tasks/hotpotqa": -44.80862808227539
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0344,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11055808514356613,
        "ag_news": 0.13367915153503418,
        "amazon_polarity": 0.1334010362625122,
        "cnn_dailymail/3.0.0": 0.143326073884964,
        "common_gen": 0.11393441259860992,
        "cos_e/v1.11": 0.124851293861866,
        "glue/mrpc": 0.12351711094379425,
        "kilt_tasks/hotpotqa": 0.11673282831907272
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19392,
        "ag_news": 20464,
        "amazon_polarity": 19648,
        "cnn_dailymail/3.0.0": 20056,
        "common_gen": 19536,
        "cos_e/v1.11": 20098,
        "glue/mrpc": 19788,
        "kilt_tasks/hotpotqa": 19712
      },
      "step": 1240
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -91.64510345458984,
        "ag_news": 74.88097381591797,
        "amazon_polarity": 72.73799896240234,
        "cnn_dailymail/3.0.0": 137.9342041015625,
        "common_gen": -62.02119827270508,
        "cos_e/v1.11": 9.067766189575195,
        "glue/mrpc": 0.006500929594039917,
        "kilt_tasks/hotpotqa": -42.92078399658203
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0517,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11076866835355759,
        "ag_news": 0.133707657456398,
        "amazon_polarity": 0.13338392972946167,
        "cnn_dailymail/3.0.0": 0.1435958743095398,
        "common_gen": 0.1145372986793518,
        "cos_e/v1.11": 0.12411792576313019,
        "glue/mrpc": 0.1228531077504158,
        "kilt_tasks/hotpotqa": 0.11703559756278992
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19584,
        "ag_news": 20672,
        "amazon_polarity": 19744,
        "cnn_dailymail/3.0.0": 20248,
        "common_gen": 19600,
        "cos_e/v1.11": 20226,
        "glue/mrpc": 19996,
        "kilt_tasks/hotpotqa": 19904
      },
      "step": 1250
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -92.42279052734375,
        "ag_news": 74.88068389892578,
        "amazon_polarity": 72.72054290771484,
        "cnn_dailymail/3.0.0": 140.56851196289062,
        "common_gen": -64.20027160644531,
        "cos_e/v1.11": 8.202411651611328,
        "glue/mrpc": -1.890409231185913,
        "kilt_tasks/hotpotqa": -40.2191162109375
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0058,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1107238382101059,
        "ag_news": 0.13367119431495667,
        "amazon_polarity": 0.13334624469280243,
        "cnn_dailymail/3.0.0": 0.14394314587116241,
        "common_gen": 0.11429548263549805,
        "cos_e/v1.11": 0.12399972230195999,
        "glue/mrpc": 0.12259860336780548,
        "kilt_tasks/hotpotqa": 0.1174217015504837
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19720,
        "ag_news": 20872,
        "amazon_polarity": 19904,
        "cnn_dailymail/3.0.0": 20424,
        "common_gen": 19728,
        "cos_e/v1.11": 20378,
        "glue/mrpc": 20164,
        "kilt_tasks/hotpotqa": 20064
      },
      "step": 1260
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -96.2682113647461,
        "ag_news": 74.85023498535156,
        "amazon_polarity": 72.45157623291016,
        "cnn_dailymail/3.0.0": 142.35543823242188,
        "common_gen": -65.1302719116211,
        "cos_e/v1.11": 3.8232123851776123,
        "glue/mrpc": -0.4490761458873749,
        "kilt_tasks/hotpotqa": -41.34795379638672
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8959,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11040191352367401,
        "ag_news": 0.13375502824783325,
        "amazon_polarity": 0.13339544832706451,
        "cnn_dailymail/3.0.0": 0.1442858874797821,
        "common_gen": 0.11432182788848877,
        "cos_e/v1.11": 0.12351005524396896,
        "glue/mrpc": 0.12291967868804932,
        "kilt_tasks/hotpotqa": 0.11741019785404205
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 19920,
        "ag_news": 21024,
        "amazon_polarity": 20088,
        "cnn_dailymail/3.0.0": 20544,
        "common_gen": 19888,
        "cos_e/v1.11": 20530,
        "glue/mrpc": 20348,
        "kilt_tasks/hotpotqa": 20192
      },
      "step": 1270
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -98.0376205444336,
        "ag_news": 74.84281158447266,
        "amazon_polarity": 72.33354187011719,
        "cnn_dailymail/3.0.0": 143.05760192871094,
        "common_gen": -65.89360809326172,
        "cos_e/v1.11": 4.685276508331299,
        "glue/mrpc": 1.0385842323303223,
        "kilt_tasks/hotpotqa": -39.85514450073242
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9328,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11020592600107193,
        "ag_news": 0.13368068635463715,
        "amazon_polarity": 0.13330620527267456,
        "cnn_dailymail/3.0.0": 0.14427760243415833,
        "common_gen": 0.11423156410455704,
        "cos_e/v1.11": 0.12359965592622757,
        "glue/mrpc": 0.12309714406728745,
        "kilt_tasks/hotpotqa": 0.11760123819112778
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20064,
        "ag_news": 21144,
        "amazon_polarity": 20272,
        "cnn_dailymail/3.0.0": 20664,
        "common_gen": 20048,
        "cos_e/v1.11": 20642,
        "glue/mrpc": 20564,
        "kilt_tasks/hotpotqa": 20416
      },
      "step": 1280
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -96.33993530273438,
        "ag_news": 74.73905181884766,
        "amazon_polarity": 71.99439239501953,
        "cnn_dailymail/3.0.0": 145.76837158203125,
        "common_gen": -65.1834487915039,
        "cos_e/v1.11": 5.065388202667236,
        "glue/mrpc": 3.5413711071014404,
        "kilt_tasks/hotpotqa": -39.02822494506836
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9696,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1103399395942688,
        "ag_news": 0.13347585499286652,
        "amazon_polarity": 0.1330685168504715,
        "cnn_dailymail/3.0.0": 0.14446640014648438,
        "common_gen": 0.114229217171669,
        "cos_e/v1.11": 0.12351420521736145,
        "glue/mrpc": 0.12330488860607147,
        "kilt_tasks/hotpotqa": 0.1176009252667427
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20240,
        "ag_news": 21288,
        "amazon_polarity": 20504,
        "cnn_dailymail/3.0.0": 20864,
        "common_gen": 20216,
        "cos_e/v1.11": 20762,
        "glue/mrpc": 20716,
        "kilt_tasks/hotpotqa": 20504
      },
      "step": 1290
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -100.0730209350586,
        "ag_news": 74.69734954833984,
        "amazon_polarity": 72.23565673828125,
        "cnn_dailymail/3.0.0": 146.7675323486328,
        "common_gen": -64.20159149169922,
        "cos_e/v1.11": 5.0313615798950195,
        "glue/mrpc": 3.7930288314819336,
        "kilt_tasks/hotpotqa": -38.46646499633789
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9113,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10994287580251694,
        "ag_news": 0.1334431767463684,
        "amazon_polarity": 0.13307927548885345,
        "cnn_dailymail/3.0.0": 0.14455418288707733,
        "common_gen": 0.11439891159534454,
        "cos_e/v1.11": 0.12352166324853897,
        "glue/mrpc": 0.12335220724344254,
        "kilt_tasks/hotpotqa": 0.11770777404308319
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20448,
        "ag_news": 21456,
        "amazon_polarity": 20696,
        "cnn_dailymail/3.0.0": 21024,
        "common_gen": 20352,
        "cos_e/v1.11": 20866,
        "glue/mrpc": 20876,
        "kilt_tasks/hotpotqa": 20656
      },
      "step": 1300
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1938,
      "eval_samples_per_second": 82.578,
      "eval_steps_per_second": 5.161,
      "step": 1300
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -98.8146743774414,
        "ag_news": 74.49485778808594,
        "amazon_polarity": 72.37577819824219,
        "cnn_dailymail/3.0.0": 146.0662384033203,
        "common_gen": -63.96622085571289,
        "cos_e/v1.11": 2.238126039505005,
        "glue/mrpc": 8.335226058959961,
        "kilt_tasks/hotpotqa": -39.70722961425781
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9128,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11013532429933548,
        "ag_news": 0.13336338102817535,
        "amazon_polarity": 0.13305144011974335,
        "cnn_dailymail/3.0.0": 0.14434413611888885,
        "common_gen": 0.11445268243551254,
        "cos_e/v1.11": 0.12313125282526016,
        "glue/mrpc": 0.12396317720413208,
        "kilt_tasks/hotpotqa": 0.11755866557359695
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20592,
        "ag_news": 21608,
        "amazon_polarity": 20840,
        "cnn_dailymail/3.0.0": 21136,
        "common_gen": 20504,
        "cos_e/v1.11": 21098,
        "glue/mrpc": 21092,
        "kilt_tasks/hotpotqa": 20784
      },
      "step": 1310
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -102.79254150390625,
        "ag_news": 74.48441314697266,
        "amazon_polarity": 72.49284362792969,
        "cnn_dailymail/3.0.0": 145.51922607421875,
        "common_gen": -63.22025680541992,
        "cos_e/v1.11": -1.12876296043396,
        "glue/mrpc": 5.972641468048096,
        "kilt_tasks/hotpotqa": -38.816123962402344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9823,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10983147472143173,
        "ag_news": 0.13348069787025452,
        "amazon_polarity": 0.13318833708763123,
        "cnn_dailymail/3.0.0": 0.14434272050857544,
        "common_gen": 0.11471453309059143,
        "cos_e/v1.11": 0.12282215803861618,
        "glue/mrpc": 0.12378555536270142,
        "kilt_tasks/hotpotqa": 0.11783461272716522
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20776,
        "ag_news": 21744,
        "amazon_polarity": 21008,
        "cnn_dailymail/3.0.0": 21256,
        "common_gen": 20688,
        "cos_e/v1.11": 21282,
        "glue/mrpc": 21244,
        "kilt_tasks/hotpotqa": 20936
      },
      "step": 1320
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -102.91346740722656,
        "ag_news": 74.44792938232422,
        "amazon_polarity": 72.49732208251953,
        "cnn_dailymail/3.0.0": 145.34156799316406,
        "common_gen": -65.66974639892578,
        "cos_e/v1.11": 0.27285894751548767,
        "glue/mrpc": 0.3160054087638855,
        "kilt_tasks/hotpotqa": -37.784523010253906
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8631,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10995909571647644,
        "ag_news": 0.13355101644992828,
        "amazon_polarity": 0.13326558470726013,
        "cnn_dailymail/3.0.0": 0.14435416460037231,
        "common_gen": 0.11453671008348465,
        "cos_e/v1.11": 0.12311895191669464,
        "glue/mrpc": 0.12312476336956024,
        "kilt_tasks/hotpotqa": 0.11808966100215912
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 20896,
        "ag_news": 21904,
        "amazon_polarity": 21232,
        "cnn_dailymail/3.0.0": 21376,
        "common_gen": 20816,
        "cos_e/v1.11": 21482,
        "glue/mrpc": 21428,
        "kilt_tasks/hotpotqa": 21080
      },
      "step": 1330
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -107.45075988769531,
        "ag_news": 74.34164428710938,
        "amazon_polarity": 72.30089569091797,
        "cnn_dailymail/3.0.0": 149.87989807128906,
        "common_gen": -69.9671630859375,
        "cos_e/v1.11": 0.5586613416671753,
        "glue/mrpc": 4.26263427734375,
        "kilt_tasks/hotpotqa": -41.25851058959961
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0002,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10950058698654175,
        "ag_news": 0.1335422545671463,
        "amazon_polarity": 0.13324476778507233,
        "cnn_dailymail/3.0.0": 0.1450377255678177,
        "common_gen": 0.11407152563333511,
        "cos_e/v1.11": 0.12320075929164886,
        "glue/mrpc": 0.12370012700557709,
        "kilt_tasks/hotpotqa": 0.11770232766866684
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21048,
        "ag_news": 22024,
        "amazon_polarity": 21400,
        "cnn_dailymail/3.0.0": 21576,
        "common_gen": 20952,
        "cos_e/v1.11": 21658,
        "glue/mrpc": 21612,
        "kilt_tasks/hotpotqa": 21224
      },
      "step": 1340
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -107.70093536376953,
        "ag_news": 74.29100036621094,
        "amazon_polarity": 72.3435287475586,
        "cnn_dailymail/3.0.0": 150.97254943847656,
        "common_gen": -72.55010223388672,
        "cos_e/v1.11": 0.8521667122840881,
        "glue/mrpc": 4.973325729370117,
        "kilt_tasks/hotpotqa": -40.44484329223633
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0124,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10951901972293854,
        "ag_news": 0.13349612057209015,
        "amazon_polarity": 0.1332133710384369,
        "cnn_dailymail/3.0.0": 0.14512410759925842,
        "common_gen": 0.11378461122512817,
        "cos_e/v1.11": 0.12324093282222748,
        "glue/mrpc": 0.1237947940826416,
        "kilt_tasks/hotpotqa": 0.11782711744308472
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21240,
        "ag_news": 22192,
        "amazon_polarity": 21512,
        "cnn_dailymail/3.0.0": 21768,
        "common_gen": 21088,
        "cos_e/v1.11": 21762,
        "glue/mrpc": 21820,
        "kilt_tasks/hotpotqa": 21392
      },
      "step": 1350
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -106.45759582519531,
        "ag_news": 74.16565704345703,
        "amazon_polarity": 73.28257751464844,
        "cnn_dailymail/3.0.0": 150.68650817871094,
        "common_gen": -72.85574340820312,
        "cos_e/v1.11": -4.073563575744629,
        "glue/mrpc": 5.428836345672607,
        "kilt_tasks/hotpotqa": -42.784629821777344
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.901,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10979906469583511,
        "ag_news": 0.13354277610778809,
        "amazon_polarity": 0.13341490924358368,
        "cnn_dailymail/3.0.0": 0.14510516822338104,
        "common_gen": 0.11386854201555252,
        "cos_e/v1.11": 0.12267995625734329,
        "glue/mrpc": 0.12395022809505463,
        "kilt_tasks/hotpotqa": 0.11763942241668701
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21376,
        "ag_news": 22400,
        "amazon_polarity": 21656,
        "cnn_dailymail/3.0.0": 21888,
        "common_gen": 21288,
        "cos_e/v1.11": 21938,
        "glue/mrpc": 21972,
        "kilt_tasks/hotpotqa": 21536
      },
      "step": 1360
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -101.4485855102539,
        "ag_news": 74.26959991455078,
        "amazon_polarity": 73.16879272460938,
        "cnn_dailymail/3.0.0": 150.0706329345703,
        "common_gen": -61.67658233642578,
        "cos_e/v1.11": -6.7011895179748535,
        "glue/mrpc": 5.813878059387207,
        "kilt_tasks/hotpotqa": -43.754390716552734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9064,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11028661578893661,
        "ag_news": 0.13333271443843842,
        "amazon_polarity": 0.13317416608333588,
        "cnn_dailymail/3.0.0": 0.14472034573554993,
        "common_gen": 0.11512342840433121,
        "cos_e/v1.11": 0.12216387689113617,
        "glue/mrpc": 0.12382643669843674,
        "kilt_tasks/hotpotqa": 0.11737246811389923
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21584,
        "ag_news": 22536,
        "amazon_polarity": 21848,
        "cnn_dailymail/3.0.0": 22064,
        "common_gen": 21440,
        "cos_e/v1.11": 22050,
        "glue/mrpc": 22112,
        "kilt_tasks/hotpotqa": 21696
      },
      "step": 1370
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -106.90071868896484,
        "ag_news": 74.29939270019531,
        "amazon_polarity": 73.1534652709961,
        "cnn_dailymail/3.0.0": 149.88951110839844,
        "common_gen": -63.3423957824707,
        "cos_e/v1.11": -7.278866291046143,
        "glue/mrpc": 4.814348220825195,
        "kilt_tasks/hotpotqa": -42.32210159301758
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9329,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10979220271110535,
        "ag_news": 0.13342855870723724,
        "amazon_polarity": 0.13326400518417358,
        "cnn_dailymail/3.0.0": 0.1447487324476242,
        "common_gen": 0.11505698412656784,
        "cos_e/v1.11": 0.12221027165651321,
        "glue/mrpc": 0.12381120026111603,
        "kilt_tasks/hotpotqa": 0.1176881268620491
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21760,
        "ag_news": 22704,
        "amazon_polarity": 21976,
        "cnn_dailymail/3.0.0": 22208,
        "common_gen": 21584,
        "cos_e/v1.11": 22202,
        "glue/mrpc": 22352,
        "kilt_tasks/hotpotqa": 21824
      },
      "step": 1380
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -104.58829498291016,
        "ag_news": 74.18282318115234,
        "amazon_polarity": 73.67205047607422,
        "cnn_dailymail/3.0.0": 148.2333984375,
        "common_gen": -61.90431213378906,
        "cos_e/v1.11": -3.258829116821289,
        "glue/mrpc": 3.9710187911987305,
        "kilt_tasks/hotpotqa": -41.146724700927734
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9464,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.11002743989229202,
        "ag_news": 0.13327382504940033,
        "amazon_polarity": 0.13320079445838928,
        "cnn_dailymail/3.0.0": 0.14429986476898193,
        "common_gen": 0.11517633497714996,
        "cos_e/v1.11": 0.12264982610940933,
        "glue/mrpc": 0.1236044317483902,
        "kilt_tasks/hotpotqa": 0.11776753515005112
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 21904,
        "ag_news": 22864,
        "amazon_polarity": 22144,
        "cnn_dailymail/3.0.0": 22360,
        "common_gen": 21768,
        "cos_e/v1.11": 22346,
        "glue/mrpc": 22480,
        "kilt_tasks/hotpotqa": 22024
      },
      "step": 1390
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -107.47023010253906,
        "ag_news": 74.0063705444336,
        "amazon_polarity": 73.52166748046875,
        "cnn_dailymail/3.0.0": 152.0676727294922,
        "common_gen": -65.8586196899414,
        "cos_e/v1.11": -7.239247798919678,
        "glue/mrpc": 4.6249260902404785,
        "kilt_tasks/hotpotqa": -41.57587814331055
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9141,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10982449352741241,
        "ag_news": 0.13332213461399078,
        "amazon_polarity": 0.1332530379295349,
        "cnn_dailymail/3.0.0": 0.14493200182914734,
        "common_gen": 0.11481358110904694,
        "cos_e/v1.11": 0.12223260849714279,
        "glue/mrpc": 0.12379206717014313,
        "kilt_tasks/hotpotqa": 0.11783011257648468
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22032,
        "ag_news": 23120,
        "amazon_polarity": 22280,
        "cnn_dailymail/3.0.0": 22488,
        "common_gen": 21960,
        "cos_e/v1.11": 22490,
        "glue/mrpc": 22568,
        "kilt_tasks/hotpotqa": 22232
      },
      "step": 1400
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.8125,
      "eval_runtime": 0.1947,
      "eval_samples_per_second": 82.191,
      "eval_steps_per_second": 5.137,
      "step": 1400
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -105.33673095703125,
        "ag_news": 73.99774169921875,
        "amazon_polarity": 73.65597534179688,
        "cnn_dailymail/3.0.0": 154.02281188964844,
        "common_gen": -60.32770538330078,
        "cos_e/v1.11": -5.375305652618408,
        "glue/mrpc": 7.974164009094238,
        "kilt_tasks/hotpotqa": -40.099422454833984
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9504,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10989315062761307,
        "ag_news": 0.13301044702529907,
        "amazon_polarity": 0.13296201825141907,
        "cnn_dailymail/3.0.0": 0.14485332369804382,
        "common_gen": 0.11528344452381134,
        "cos_e/v1.11": 0.12222786247730255,
        "glue/mrpc": 0.1239776685833931,
        "kilt_tasks/hotpotqa": 0.11779217422008514
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22136,
        "ag_news": 23272,
        "amazon_polarity": 22480,
        "cnn_dailymail/3.0.0": 22688,
        "common_gen": 22104,
        "cos_e/v1.11": 22666,
        "glue/mrpc": 22736,
        "kilt_tasks/hotpotqa": 22368
      },
      "step": 1410
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -108.1449966430664,
        "ag_news": 73.98040771484375,
        "amazon_polarity": 73.78483581542969,
        "cnn_dailymail/3.0.0": 152.58399963378906,
        "common_gen": -61.85088348388672,
        "cos_e/v1.11": -4.279898166656494,
        "glue/mrpc": 8.501006126403809,
        "kilt_tasks/hotpotqa": -41.80361557006836
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9891,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10969612747430801,
        "ag_news": 0.13307654857635498,
        "amazon_polarity": 0.1330489069223404,
        "cnn_dailymail/3.0.0": 0.14466336369514465,
        "common_gen": 0.1152142733335495,
        "cos_e/v1.11": 0.12246926873922348,
        "glue/mrpc": 0.12414144724607468,
        "kilt_tasks/hotpotqa": 0.11769002676010132
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22296,
        "ag_news": 23432,
        "amazon_polarity": 22608,
        "cnn_dailymail/3.0.0": 22824,
        "common_gen": 22288,
        "cos_e/v1.11": 22818,
        "glue/mrpc": 22912,
        "kilt_tasks/hotpotqa": 22552
      },
      "step": 1420
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -109.096923828125,
        "ag_news": 73.9466781616211,
        "amazon_polarity": 73.7950439453125,
        "cnn_dailymail/3.0.0": 148.6342315673828,
        "common_gen": -58.86915969848633,
        "cos_e/v1.11": -7.3781256675720215,
        "glue/mrpc": 7.606978416442871,
        "kilt_tasks/hotpotqa": -44.051246643066406
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9552,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10976312309503555,
        "ag_news": 0.1331978291273117,
        "amazon_polarity": 0.13317646086215973,
        "cnn_dailymail/3.0.0": 0.14415431022644043,
        "common_gen": 0.1157451644539833,
        "cos_e/v1.11": 0.12221955507993698,
        "glue/mrpc": 0.12417153269052505,
        "kilt_tasks/hotpotqa": 0.11757204681634903
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22488,
        "ag_news": 23600,
        "amazon_polarity": 22768,
        "cnn_dailymail/3.0.0": 23000,
        "common_gen": 22432,
        "cos_e/v1.11": 22962,
        "glue/mrpc": 23056,
        "kilt_tasks/hotpotqa": 22704
      },
      "step": 1430
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -112.28522491455078,
        "ag_news": 73.98077392578125,
        "amazon_polarity": 73.65970611572266,
        "cnn_dailymail/3.0.0": 149.59335327148438,
        "common_gen": -60.364505767822266,
        "cos_e/v1.11": -11.071295738220215,
        "glue/mrpc": 8.971446990966797,
        "kilt_tasks/hotpotqa": -45.859832763671875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8486,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1095484271645546,
        "ag_news": 0.13330015540122986,
        "amazon_polarity": 0.1332550346851349,
        "cnn_dailymail/3.0.0": 0.14436650276184082,
        "common_gen": 0.11570361256599426,
        "cos_e/v1.11": 0.12187015265226364,
        "glue/mrpc": 0.12447136640548706,
        "kilt_tasks/hotpotqa": 0.11748471111059189
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22688,
        "ag_news": 23760,
        "amazon_polarity": 23000,
        "cnn_dailymail/3.0.0": 23136,
        "common_gen": 22528,
        "cos_e/v1.11": 23098,
        "glue/mrpc": 23240,
        "kilt_tasks/hotpotqa": 22840
      },
      "step": 1440
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -109.96232604980469,
        "ag_news": 73.79768371582031,
        "amazon_polarity": 73.26207733154297,
        "cnn_dailymail/3.0.0": 152.72857666015625,
        "common_gen": -57.42945861816406,
        "cos_e/v1.11": -9.810615539550781,
        "glue/mrpc": 7.158402442932129,
        "kilt_tasks/hotpotqa": -43.68388748168945
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9327,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10973376780748367,
        "ag_news": 0.13308526575565338,
        "amazon_polarity": 0.1330103874206543,
        "cnn_dailymail/3.0.0": 0.14459781348705292,
        "common_gen": 0.11595223098993301,
        "cos_e/v1.11": 0.12189590185880661,
        "glue/mrpc": 0.12408745288848877,
        "kilt_tasks/hotpotqa": 0.11763724684715271
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22832,
        "ag_news": 23888,
        "amazon_polarity": 23208,
        "cnn_dailymail/3.0.0": 23312,
        "common_gen": 22712,
        "cos_e/v1.11": 23210,
        "glue/mrpc": 23424,
        "kilt_tasks/hotpotqa": 22984
      },
      "step": 1450
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -110.49183654785156,
        "ag_news": 73.78695678710938,
        "amazon_polarity": 73.25581359863281,
        "cnn_dailymail/3.0.0": 153.35537719726562,
        "common_gen": -58.46150207519531,
        "cos_e/v1.11": -17.397066116333008,
        "glue/mrpc": 11.788532257080078,
        "kilt_tasks/hotpotqa": -43.095741271972656
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9486,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10976487398147583,
        "ag_news": 0.13310784101486206,
        "amazon_polarity": 0.13303382694721222,
        "cnn_dailymail/3.0.0": 0.14467807114124298,
        "common_gen": 0.11590240150690079,
        "cos_e/v1.11": 0.12099010497331619,
        "glue/mrpc": 0.12474250793457031,
        "kilt_tasks/hotpotqa": 0.11778038740158081
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 22968,
        "ag_news": 24048,
        "amazon_polarity": 23384,
        "cnn_dailymail/3.0.0": 23456,
        "common_gen": 22888,
        "cos_e/v1.11": 23386,
        "glue/mrpc": 23608,
        "kilt_tasks/hotpotqa": 23112
      },
      "step": 1460
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -115.60367584228516,
        "ag_news": 73.5937728881836,
        "amazon_polarity": 73.12255859375,
        "cnn_dailymail/3.0.0": 151.99403381347656,
        "common_gen": -55.67298126220703,
        "cos_e/v1.11": -19.469104766845703,
        "glue/mrpc": 9.45839786529541,
        "kilt_tasks/hotpotqa": -43.40164566040039
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9473,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10935106128454208,
        "ag_news": 0.13320069015026093,
        "amazon_polarity": 0.13313518464565277,
        "cnn_dailymail/3.0.0": 0.1445617377758026,
        "common_gen": 0.11639867722988129,
        "cos_e/v1.11": 0.12087644636631012,
        "glue/mrpc": 0.12457887828350067,
        "kilt_tasks/hotpotqa": 0.11789734661579132
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23152,
        "ag_news": 24160,
        "amazon_polarity": 23576,
        "cnn_dailymail/3.0.0": 23608,
        "common_gen": 23048,
        "cos_e/v1.11": 23554,
        "glue/mrpc": 23776,
        "kilt_tasks/hotpotqa": 23256
      },
      "step": 1470
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -117.95693969726562,
        "ag_news": 73.56446838378906,
        "amazon_polarity": 72.7033462524414,
        "cnn_dailymail/3.0.0": 151.62237548828125,
        "common_gen": -55.18269348144531,
        "cos_e/v1.11": -18.963844299316406,
        "glue/mrpc": 7.848719120025635,
        "kilt_tasks/hotpotqa": -42.61125946044922
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0058,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10917522758245468,
        "ag_news": 0.1332196146249771,
        "amazon_polarity": 0.13310033082962036,
        "cnn_dailymail/3.0.0": 0.14449095726013184,
        "common_gen": 0.11653079092502594,
        "cos_e/v1.11": 0.12100023776292801,
        "glue/mrpc": 0.12441999465227127,
        "kilt_tasks/hotpotqa": 0.11806292831897736
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23264,
        "ag_news": 24360,
        "amazon_polarity": 23688,
        "cnn_dailymail/3.0.0": 23816,
        "common_gen": 23160,
        "cos_e/v1.11": 23738,
        "glue/mrpc": 23952,
        "kilt_tasks/hotpotqa": 23432
      },
      "step": 1480
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -117.48402404785156,
        "ag_news": 73.4255142211914,
        "amazon_polarity": 72.54237365722656,
        "cnn_dailymail/3.0.0": 153.83489990234375,
        "common_gen": -56.46293258666992,
        "cos_e/v1.11": -17.65557861328125,
        "glue/mrpc": 7.857483863830566,
        "kilt_tasks/hotpotqa": -44.08427429199219
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9796,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1092602089047432,
        "ag_news": 0.1331503987312317,
        "amazon_polarity": 0.1330285519361496,
        "cnn_dailymail/3.0.0": 0.14472928643226624,
        "common_gen": 0.11638472229242325,
        "cos_e/v1.11": 0.12115775793790817,
        "glue/mrpc": 0.12440280616283417,
        "kilt_tasks/hotpotqa": 0.11788623780012131
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23368,
        "ag_news": 24536,
        "amazon_polarity": 23856,
        "cnn_dailymail/3.0.0": 23984,
        "common_gen": 23312,
        "cos_e/v1.11": 23882,
        "glue/mrpc": 24152,
        "kilt_tasks/hotpotqa": 23600
      },
      "step": 1490
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -119.05340576171875,
        "ag_news": 73.43951416015625,
        "amazon_polarity": 72.4866714477539,
        "cnn_dailymail/3.0.0": 153.9510498046875,
        "common_gen": -55.18336868286133,
        "cos_e/v1.11": -18.07221031188965,
        "glue/mrpc": 7.291660308837891,
        "kilt_tasks/hotpotqa": -44.861053466796875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0703,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10915857553482056,
        "ag_news": 0.13315676152706146,
        "amazon_polarity": 0.13302573561668396,
        "cnn_dailymail/3.0.0": 0.1447114497423172,
        "common_gen": 0.11659438163042068,
        "cos_e/v1.11": 0.12114758789539337,
        "glue/mrpc": 0.12436230480670929,
        "kilt_tasks/hotpotqa": 0.11784321814775467
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23504,
        "ag_news": 24664,
        "amazon_polarity": 23968,
        "cnn_dailymail/3.0.0": 24152,
        "common_gen": 23504,
        "cos_e/v1.11": 24066,
        "glue/mrpc": 24352,
        "kilt_tasks/hotpotqa": 23760
      },
      "step": 1500
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.191,
      "eval_samples_per_second": 83.75,
      "eval_steps_per_second": 5.234,
      "step": 1500
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -118.93938446044922,
        "ag_news": 73.55717468261719,
        "amazon_polarity": 72.41523742675781,
        "cnn_dailymail/3.0.0": 156.80111694335938,
        "common_gen": -51.58510208129883,
        "cos_e/v1.11": -18.354543685913086,
        "glue/mrpc": 5.511114597320557,
        "kilt_tasks/hotpotqa": -43.891536712646484
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8748,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10914158821105957,
        "ag_news": 0.1330493539571762,
        "amazon_polarity": 0.13289298117160797,
        "cnn_dailymail/3.0.0": 0.14496257901191711,
        "common_gen": 0.11696944385766983,
        "cos_e/v1.11": 0.1210377961397171,
        "glue/mrpc": 0.1240474209189415,
        "kilt_tasks/hotpotqa": 0.11789891123771667
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23632,
        "ag_news": 24904,
        "amazon_polarity": 24120,
        "cnn_dailymail/3.0.0": 24256,
        "common_gen": 23648,
        "cos_e/v1.11": 24274,
        "glue/mrpc": 24520,
        "kilt_tasks/hotpotqa": 23896
      },
      "step": 1510
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -119.46315002441406,
        "ag_news": 73.60393524169922,
        "amazon_polarity": 72.47765350341797,
        "cnn_dailymail/3.0.0": 158.02862548828125,
        "common_gen": -52.19317626953125,
        "cos_e/v1.11": -20.842182159423828,
        "glue/mrpc": 4.738797187805176,
        "kilt_tasks/hotpotqa": -45.386932373046875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8561,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10918952524662018,
        "ag_news": 0.1330995410680771,
        "amazon_polarity": 0.13294574618339539,
        "cnn_dailymail/3.0.0": 0.1451524943113327,
        "common_gen": 0.11698424071073532,
        "cos_e/v1.11": 0.12080646306276321,
        "glue/mrpc": 0.12401838600635529,
        "kilt_tasks/hotpotqa": 0.11780352890491486
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23768,
        "ag_news": 25136,
        "amazon_polarity": 24280,
        "cnn_dailymail/3.0.0": 24408,
        "common_gen": 23776,
        "cos_e/v1.11": 24474,
        "glue/mrpc": 24672,
        "kilt_tasks/hotpotqa": 24016
      },
      "step": 1520
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -118.70294952392578,
        "ag_news": 73.60285186767578,
        "amazon_polarity": 72.60405731201172,
        "cnn_dailymail/3.0.0": 155.46109008789062,
        "common_gen": -52.45520782470703,
        "cos_e/v1.11": -21.216527938842773,
        "glue/mrpc": 6.572470664978027,
        "kilt_tasks/hotpotqa": -44.85887908935547
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 1.0415,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10933021456003189,
        "ag_news": 0.13308185338974,
        "amazon_polarity": 0.1329459249973297,
        "cnn_dailymail/3.0.0": 0.14471150934696198,
        "common_gen": 0.11698655039072037,
        "cos_e/v1.11": 0.12078235298395157,
        "glue/mrpc": 0.12426330149173737,
        "kilt_tasks/hotpotqa": 0.1178983524441719
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 23952,
        "ag_news": 25288,
        "amazon_polarity": 24416,
        "cnn_dailymail/3.0.0": 24520,
        "common_gen": 23984,
        "cos_e/v1.11": 24634,
        "glue/mrpc": 24832,
        "kilt_tasks/hotpotqa": 24184
      },
      "step": 1530
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -119.320068359375,
        "ag_news": 73.47307586669922,
        "amazon_polarity": 73.09866333007812,
        "cnn_dailymail/3.0.0": 154.2714385986328,
        "common_gen": -51.331214904785156,
        "cos_e/v1.11": -17.507566452026367,
        "glue/mrpc": 0.7656080722808838,
        "kilt_tasks/hotpotqa": -44.06804656982422
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9221,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10933639109134674,
        "ag_news": 0.13307099044322968,
        "amazon_polarity": 0.13302019238471985,
        "cnn_dailymail/3.0.0": 0.14450415968894958,
        "common_gen": 0.11717525124549866,
        "cos_e/v1.11": 0.12128383666276932,
        "glue/mrpc": 0.12356363236904144,
        "kilt_tasks/hotpotqa": 0.11804551631212234
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24096,
        "ag_news": 25440,
        "amazon_polarity": 24632,
        "cnn_dailymail/3.0.0": 24696,
        "common_gen": 24048,
        "cos_e/v1.11": 24882,
        "glue/mrpc": 24976,
        "kilt_tasks/hotpotqa": 24320
      },
      "step": 1540
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -120.25567626953125,
        "ag_news": 73.38687896728516,
        "amazon_polarity": 73.08284759521484,
        "cnn_dailymail/3.0.0": 156.62228393554688,
        "common_gen": -51.41558837890625,
        "cos_e/v1.11": -17.21017074584961,
        "glue/mrpc": 3.101933479309082,
        "kilt_tasks/hotpotqa": -43.073673248291016
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9577,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10920792073011398,
        "ag_news": 0.13294531404972076,
        "amazon_polarity": 0.13290424644947052,
        "cnn_dailymail/3.0.0": 0.14468759298324585,
        "common_gen": 0.11711269617080688,
        "cos_e/v1.11": 0.12125267088413239,
        "glue/mrpc": 0.12378063052892685,
        "kilt_tasks/hotpotqa": 0.11810900270938873
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24248,
        "ag_news": 25648,
        "amazon_polarity": 24768,
        "cnn_dailymail/3.0.0": 24816,
        "common_gen": 24240,
        "cos_e/v1.11": 25066,
        "glue/mrpc": 25088,
        "kilt_tasks/hotpotqa": 24496
      },
      "step": 1550
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -122.13585662841797,
        "ag_news": 73.2567367553711,
        "amazon_polarity": 72.99371337890625,
        "cnn_dailymail/3.0.0": 157.34764099121094,
        "common_gen": -49.789955139160156,
        "cos_e/v1.11": -19.218690872192383,
        "glue/mrpc": 0.7042688727378845,
        "kilt_tasks/hotpotqa": -42.23710250854492
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.9561,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10909038782119751,
        "ag_news": 0.13295425474643707,
        "amazon_polarity": 0.1329188346862793,
        "cnn_dailymail/3.0.0": 0.14478379487991333,
        "common_gen": 0.11737631261348724,
        "cos_e/v1.11": 0.12106592953205109,
        "glue/mrpc": 0.12353315204381943,
        "kilt_tasks/hotpotqa": 0.1182771846652031
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24416,
        "ag_news": 25816,
        "amazon_polarity": 24912,
        "cnn_dailymail/3.0.0": 24944,
        "common_gen": 24368,
        "cos_e/v1.11": 25234,
        "glue/mrpc": 25240,
        "kilt_tasks/hotpotqa": 24720
      },
      "step": 1560
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -124.6695556640625,
        "ag_news": 72.96432495117188,
        "amazon_polarity": 72.90851593017578,
        "cnn_dailymail/3.0.0": 159.88430786132812,
        "common_gen": -45.69987106323242,
        "cos_e/v1.11": -13.592708587646484,
        "glue/mrpc": -0.4919247627258301,
        "kilt_tasks/hotpotqa": -42.987274169921875
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8431,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10875384509563446,
        "ag_news": 0.13276056945323944,
        "amazon_polarity": 0.13275307416915894,
        "cnn_dailymail/3.0.0": 0.14494751393795013,
        "common_gen": 0.11777139455080032,
        "cos_e/v1.11": 0.12165006995201111,
        "glue/mrpc": 0.1232694759964943,
        "kilt_tasks/hotpotqa": 0.11809420585632324
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24584,
        "ag_news": 25976,
        "amazon_polarity": 25120,
        "cnn_dailymail/3.0.0": 25032,
        "common_gen": 24544,
        "cos_e/v1.11": 25394,
        "glue/mrpc": 25400,
        "kilt_tasks/hotpotqa": 24880
      },
      "step": 1570
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -127.9207763671875,
        "ag_news": 72.90423583984375,
        "amazon_polarity": 72.72978210449219,
        "cnn_dailymail/3.0.0": 159.13243103027344,
        "common_gen": -46.64482879638672,
        "cos_e/v1.11": -13.812267303466797,
        "glue/mrpc": 0.700755774974823,
        "kilt_tasks/hotpotqa": -40.81063461303711
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.834,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10847245156764984,
        "ag_news": 0.1327591836452484,
        "amazon_polarity": 0.13273587822914124,
        "cnn_dailymail/3.0.0": 0.1448049396276474,
        "common_gen": 0.11770976334810257,
        "cos_e/v1.11": 0.12166275829076767,
        "glue/mrpc": 0.12345250695943832,
        "kilt_tasks/hotpotqa": 0.11840260028839111
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24752,
        "ag_news": 26120,
        "amazon_polarity": 25344,
        "cnn_dailymail/3.0.0": 25112,
        "common_gen": 24696,
        "cos_e/v1.11": 25538,
        "glue/mrpc": 25568,
        "kilt_tasks/hotpotqa": 25080
      },
      "step": 1580
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -126.62378692626953,
        "ag_news": 72.98595428466797,
        "amazon_polarity": 72.63375854492188,
        "cnn_dailymail/3.0.0": 159.57835388183594,
        "common_gen": -47.61421203613281,
        "cos_e/v1.11": -13.942014694213867,
        "glue/mrpc": 0.19475862383842468,
        "kilt_tasks/hotpotqa": -40.09260559082031
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.8225,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.10865237563848495,
        "ag_news": 0.13273373246192932,
        "amazon_polarity": 0.1326868236064911,
        "cnn_dailymail/3.0.0": 0.14479073882102966,
        "common_gen": 0.11760745942592621,
        "cos_e/v1.11": 0.12164684385061264,
        "glue/mrpc": 0.12338414043188095,
        "kilt_tasks/hotpotqa": 0.11849787086248398
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 24904,
        "ag_news": 26336,
        "amazon_polarity": 25552,
        "cnn_dailymail/3.0.0": 25232,
        "common_gen": 24776,
        "cos_e/v1.11": 25706,
        "glue/mrpc": 25708,
        "kilt_tasks/hotpotqa": 25272
      },
      "step": 1590
    },
    {
      "cumulative_estimated_reward": {
        "adversarial_qa/dbidaf": -124.95310974121094,
        "ag_news": 72.7568359375,
        "amazon_polarity": 72.51679229736328,
        "cnn_dailymail/3.0.0": 159.06895446777344,
        "common_gen": -47.45707321166992,
        "cos_e/v1.11": -12.022945404052734,
        "glue/mrpc": -3.3409032821655273,
        "kilt_tasks/hotpotqa": -39.17412185668945
      },
      "epoch": 0.0,
      "learning_rate": 0.0001,
      "loss": 0.861,
      "probabilities": {
        "adversarial_qa/dbidaf": 0.1088838130235672,
        "ag_news": 0.1326816827058792,
        "amazon_polarity": 0.13264982402324677,
        "cnn_dailymail/3.0.0": 0.14465416967868805,
        "common_gen": 0.11765100806951523,
        "cos_e/v1.11": 0.12189369648694992,
        "glue/mrpc": 0.12295656651258469,
        "kilt_tasks/hotpotqa": 0.11862922459840775
      },
      "samples_seen_per_dataset": {
        "adversarial_qa/dbidaf": 25064,
        "ag_news": 26544,
        "amazon_polarity": 25720,
        "cnn_dailymail/3.0.0": 25360,
        "common_gen": 24896,
        "cos_e/v1.11": 25898,
        "glue/mrpc": 25876,
        "kilt_tasks/hotpotqa": 25408
      },
      "step": 1600
    },
    {
      "epoch": 0.0,
      "eval_accuracy": 0.875,
      "eval_runtime": 0.1906,
      "eval_samples_per_second": 83.961,
      "eval_steps_per_second": 5.248,
      "step": 1600
    },
    {
      "epoch": 0.0,
      "step": 1600,
      "total_flos": 6.166590906210877e+17,
      "train_loss": 1.2018935143947602,
      "train_runtime": 18982.1728,
      "train_samples_per_second": 67.432,
      "train_steps_per_second": 0.527
    }
  ],
  "max_steps": 10000,
  "num_train_epochs": 18,
  "total_flos": 6.166590906210877e+17,
  "trial_name": null,
  "trial_params": null
}
